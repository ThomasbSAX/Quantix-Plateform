{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Complexité des problèmes de heuristiques</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Complexité des problèmes de heuristiques</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’étude de la complexité des problèmes de heuristiques trouve son
origine dans le besoin croissant de résoudre des problèmes NP-difficiles
en temps raisonnable. Les heuristiques, ces méthodes approximatives qui
fournissent des solutions satisfaisantes sans garantie d’optimalité,
sont devenues indispensables dans de nombreux domaines, allant de
l’optimisation industrielle à la bioinformatique.</p>
<p>L’émergence des heuristiques est motivée par l’incapacité des
algorithmes exacts à traiter des instances de grande taille en un temps
polynomial. Les heuristiques offrent un compromis entre la qualité de la
solution et le temps de calcul, ce qui les rend indispensables dans des
contextes où l’optimalité absolue n’est pas nécessaire, mais où la
rapidité est cruciale.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la complexité des problèmes de heuristiques, il est
essentiel de définir certains concepts clés.</p>
<div class="definition">
<p>Un problème d’optimisation est un triplet <span
class="math inline">\((\mathcal{S}, \mathcal{F}, \text{opt})\)</span>,
où <span class="math inline">\(\mathcal{S}\)</span> est un ensemble de
solutions candidates, <span class="math inline">\(\mathcal{F} :
\mathcal{S} \rightarrow \mathbb{R}\)</span> est une fonction objectif,
et <span class="math inline">\(\text{opt} \in \{ \min, \max \}\)</span>
indique si l’on cherche à minimiser ou maximiser <span
class="math inline">\(\mathcal{F}\)</span>.</p>
<p>Formellement, pour tout <span class="math inline">\(s \in
\mathcal{S}\)</span>, on cherche à trouver <span
class="math inline">\(s^* \in \mathcal{S}\)</span> tel que : <span
class="math display">\[\text{opt}_{s \in \mathcal{S}} \mathcal{F}(s) =
\mathcal{F}(s^*)\]</span></p>
</div>
<div class="definition">
<p>Une heuristique pour un problème d’optimisation <span
class="math inline">\((\mathcal{S}, \mathcal{F}, \text{opt})\)</span>
est une fonction <span class="math inline">\(\mathcal{H} : \mathcal{S}
\rightarrow \mathcal{S}\)</span> qui associe à chaque solution candidate
une autre solution, généralement en utilisant des informations locales
ou historiques.</p>
<p>Formellement, pour tout <span class="math inline">\(s \in
\mathcal{S}\)</span>, <span
class="math inline">\(\mathcal{H}(s)\)</span> est une solution candidate
qui peut être meilleure que <span class="math inline">\(s\)</span> selon
la fonction objectif <span class="math inline">\(\mathcal{F}\)</span> :
<span class="math display">\[\exists s \in \mathcal{S},
\mathcal{F}(\mathcal{H}(s)) \leq \mathcal{F}(s) \quad \text{si} \quad
\text{opt} = \min\]</span> <span class="math display">\[\exists s \in
\mathcal{S}, \mathcal{F}(\mathcal{H}(s)) \geq \mathcal{F}(s) \quad
\text{si} \quad \text{opt} = \max\]</span></p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Plusieurs théorèmes fondamentaux encadrent l’étude de la complexité
des heuristiques. Parmi eux, le théorème de Cook-Levin et les résultats
sur la complexité moyenne des algorithmes sont particulièrement
pertinents.</p>
<div class="theorem">
<p>Le problème de satisfaction booléenne (SAT) est NP-complet. Cela
signifie que tout problème dans la classe NP peut être réduit en temps
polynomial à une instance de SAT.</p>
<p>Formellement, pour tout problème <span class="math inline">\(L \in
\text{NP}\)</span>, il existe une réduction polynomiale <span
class="math inline">\(R\)</span> telle que : <span
class="math display">\[x \in L \iff R(x) \text{ est
satisfiable}\]</span></p>
</div>
<div class="theorem">
<p>Soit <span class="math inline">\(\mathcal{H}\)</span> une heuristique
pour un problème d’optimisation <span
class="math inline">\((\mathcal{S}, \mathcal{F}, \text{opt})\)</span>.
La complexité moyenne de <span
class="math inline">\(\mathcal{H}\)</span> est définie comme l’espérance
du temps d’exécution de <span class="math inline">\(\mathcal{H}\)</span>
sur une distribution donnée des instances du problème.</p>
<p>Formellement, pour une distribution <span
class="math inline">\(\mathcal{D}\)</span> sur les instances <span
class="math inline">\(\mathcal{I}\)</span>, la complexité moyenne <span
class="math inline">\(E[\mathcal{H}]\)</span> est donnée par : <span
class="math display">\[E[\mathcal{H}] = \sum_{i \in \mathcal{I}} p(i)
\cdot T(\mathcal{H}(i))\]</span> où <span
class="math inline">\(p(i)\)</span> est la probabilité de l’instance
<span class="math inline">\(i\)</span> selon <span
class="math inline">\(\mathcal{D}\)</span>, et <span
class="math inline">\(T(\mathcal{H}(i))\)</span> est le temps
d’exécution de <span class="math inline">\(\mathcal{H}\)</span> sur
<span class="math inline">\(i\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour illustrer la complexité des heuristiques, considérons un exemple
simple : le problème du voyageur de commerce (TSP).</p>
<div class="proof">
<p><em>Preuve de la NP-difficulté du TSP.</em> Le problème du voyageur
de commerce consiste à trouver le plus court chemin qui visite un
ensemble de villes exactement une fois et retourne à la ville de
départ.</p>
<p>Pour montrer que le TSP est NP-difficile, nous devons démontrer qu’il
existe une réduction polynomiale d’un problème NP-complet connu, comme
le problème du cycle hamiltonien (HAM-CYCLE), au TSP.</p>
<p>Soit <span class="math inline">\(G = (V, E)\)</span> un graphe non
orienté. Nous pouvons construire une instance du TSP en associant à
chaque arête <span class="math inline">\((u, v) \in E\)</span> un poids
<span class="math inline">\(w(u, v) = 1\)</span>, et à toute autre paire
de sommets <span class="math inline">\((u, v) \notin E\)</span> un poids
<span class="math inline">\(w(u, v) = 2\)</span>.</p>
<p>Si <span class="math inline">\(G\)</span> contient un cycle
hamiltonien, alors il existe une solution au TSP de coût <span
class="math inline">\(|V|\)</span> (en utilisant uniquement les arêtes
du cycle). Inversement, si le TSP admet une solution de coût <span
class="math inline">\(|V|\)</span>, alors <span
class="math inline">\(G\)</span> contient un cycle hamiltonien.</p>
<p>Ainsi, le TSP est NP-difficile. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Plusieurs propriétés importantes découlent des définitions et
théorèmes précédents.</p>
<div class="corollaire">
<p>Soit <span class="math inline">\(\mathcal{H}\)</span> une heuristique
pour un problème d’optimisation <span
class="math inline">\((\mathcal{S}, \mathcal{F}, \text{opt})\)</span>.
Si <span class="math inline">\(\mathcal{H}\)</span> est appliquée
itérativement à partir d’une solution initiale <span
class="math inline">\(s_0 \in \mathcal{S}\)</span>, alors la suite de
solutions <span class="math inline">\(\{ s_n \}_{n \geq 0}\)</span>
générée par <span class="math inline">\(\mathcal{H}\)</span> converge
vers un optimum local.</p>
<p>Formellement, pour tout <span class="math inline">\(\epsilon &gt;
0\)</span>, il existe un entier <span class="math inline">\(N\)</span>
tel que : <span class="math display">\[\forall n \geq N,
|\mathcal{F}(s_n) - \mathcal{F}(s^*)| &lt; \epsilon\]</span> où <span
class="math inline">\(s^*\)</span> est un optimum local.</p>
</div>
<div class="proof">
<p><em>Preuve du corollaire.</em> Par définition d’une heuristique,
<span class="math inline">\(\mathcal{H}(s_n)\)</span> est une solution
candidate qui améliore ou maintient la valeur de la fonction objectif
par rapport à <span class="math inline">\(s_n\)</span>.</p>
<p>Ainsi, pour tout <span class="math inline">\(n \geq 0\)</span>, <span
class="math inline">\(\mathcal{F}(s_{n+1}) \leq
\mathcal{F}(s_n)\)</span> si <span class="math inline">\(\text{opt} =
\min\)</span>, ou <span class="math inline">\(\mathcal{F}(s_{n+1}) \geq
\mathcal{F}(s_n)\)</span> si <span class="math inline">\(\text{opt} =
\max\)</span>.</p>
<p>La suite <span class="math inline">\(\{ \mathcal{F}(s_n) \}_{n \geq
0}\)</span> est donc monotone et bornée, ce qui implique sa convergence
vers un optimum local. ◻</p>
</div>
<div class="corollaire">
<p>Soit <span class="math inline">\(\mathcal{H}\)</span> une heuristique
pour un problème d’optimisation <span
class="math inline">\((\mathcal{S}, \mathcal{F}, \text{opt})\)</span>.
Si <span class="math inline">\(\mathcal{H}\)</span> est appliquée à une
solution initiale <span class="math inline">\(s_0 \in
\mathcal{S}\)</span>, alors la solution obtenue <span
class="math inline">\(\mathcal{H}(s_0)\)</span> est stable sous de
petites perturbations de <span class="math inline">\(s_0\)</span>.</p>
<p>Formellement, pour tout <span class="math inline">\(\epsilon &gt;
0\)</span>, il existe un <span class="math inline">\(\delta &gt;
0\)</span> tel que : <span class="math display">\[\forall s \in
\mathcal{S}, \|s - s_0\| &lt; \delta \implies \|\mathcal{H}(s) -
\mathcal{H}(s_0)\| &lt; \epsilon\]</span></p>
</div>
<div class="proof">
<p><em>Preuve du corollaire.</em> La stabilité des heuristiques découle
de la continuité de la fonction objectif <span
class="math inline">\(\mathcal{F}\)</span> et de la nature locale des
heuristiques.</p>
<p>Si <span class="math inline">\(s\)</span> est proche de <span
class="math inline">\(s_0\)</span>, alors <span
class="math inline">\(\mathcal{F}(s)\)</span> est proche de <span
class="math inline">\(\mathcal{F}(s_0)\)</span>. Par conséquent, <span
class="math inline">\(\mathcal{H}(s)\)</span> sera proche de <span
class="math inline">\(\mathcal{H}(s_0)\)</span>, car les heuristiques
utilisent des informations locales pour améliorer la solution. ◻</p>
</div>
</body>
</html>
{% include "footer.html" %}

