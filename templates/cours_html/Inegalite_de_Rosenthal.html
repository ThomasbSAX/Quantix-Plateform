{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’inégalité de Rosenthal : Un joyau des inégalités probabilistes</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’inégalité de Rosenthal : Un joyau des inégalités
probabilistes</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de Rosenthal, établie par Donald Rosenthal en 1970, est
une pierre angulaire des inégalités probabilistes. Elle généralise et
unifie plusieurs résultats classiques, notamment ceux de Khintchine et
de Hoeffding. L’origine de cette inégalité réside dans l’étude des
sommes de variables aléatoires indépendantes, un domaine central en
théorie des probabilités. Rosenthal a su identifier une condition
suffisante pour borner la queue de distribution d’une somme aléatoire,
ce qui a des implications profondes en statistique, en théorie des
processus stochastiques et même en apprentissage automatique.</p>
<p>Cette inégalité émerge naturellement lorsque l’on cherche à
comprendre le comportement des sommes de variables aléatoires qui ne
sont pas nécessairement indépendantes. Elle est indispensable dans
l’analyse des algorithmes stochastiques, où les dépendances entre les
variables sont souvent inévitables. De plus, elle offre des outils
puissants pour l’étude de la concentration des mesures, un domaine en
plein essor.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour aborder l’inégalité de Rosenthal, il est essentiel de comprendre
les concepts de base. Supposons que nous ayons une suite de variables
aléatoires <span class="math inline">\((X_n)_{n \geq 1}\)</span>
centrées, c’est-à-dire que <span class="math inline">\(\mathbb{E}[X_n] =
0\)</span> pour tout <span class="math inline">\(n\)</span>. Nous
cherchons à borner la probabilité que leur somme <span
class="math inline">\(S_N = \sum_{n=1}^N X_n\)</span> soit grande en
valeur absolue.</p>
<p>Nous commençons par définir la variance des variables <span
class="math inline">\(X_n\)</span>. La variance d’une variable aléatoire
<span class="math inline">\(X\)</span> est donnée par : <span
class="math display">\[\text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2]
= \mathbb{E}[X^2]\]</span> puisque <span
class="math inline">\(X\)</span> est centrée. La variance mesure
l’étendue des valeurs que peut prendre la variable aléatoire autour de
sa moyenne.</p>
<p>Ensuite, nous introduisons le concept de moment d’ordre <span
class="math inline">\(p\)</span> d’une variable aléatoire. Pour un
entier <span class="math inline">\(p \geq 1\)</span>, le moment d’ordre
<span class="math inline">\(p\)</span> de <span
class="math inline">\(X\)</span> est défini par : <span
class="math display">\[\mathbb{E}[|X|^p]\]</span> Les moments
fournissent une mesure de la dispersion des valeurs prises par <span
class="math inline">\(X\)</span>.</p>
<p>Enfin, nous avons besoin du concept d’inégalité de type Khintchine.
Une inégalité de ce type permet de borner la probabilité que <span
class="math inline">\(S_N\)</span> dépasse un certain seuil en fonction
des variances et des moments des variables <span
class="math inline">\(X_n\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>L’inégalité de Rosenthal est un résultat profond qui combine des
idées issues de plusieurs domaines. Pour l’énoncer, nous avons besoin de
quelques hypothèses.</p>
<p>Supposons que <span class="math inline">\((X_n)_{n \geq 1}\)</span>
soit une suite de variables aléatoires centrées et bornées, c’est-à-dire
qu’il existe une constante <span class="math inline">\(M\)</span> telle
que <span class="math inline">\(|X_n| \leq M\)</span> presque sûrement
pour tout <span class="math inline">\(n\)</span>. Nous notons <span
class="math inline">\(\sigma_n^2 = \text{Var}(X_n)\)</span>.</p>
<p>L’inégalité de Rosenthal s’énonce comme suit :</p>
<div class="theorem">
<p>Pour tout <span class="math inline">\(p \geq 2\)</span>, il existe
une constante universelle <span class="math inline">\(C_p\)</span> telle
que pour tout <span class="math inline">\(N \geq 1\)</span>, <span
class="math display">\[\mathbb{E}\left[\left|\sum_{n=1}^N
X_n\right|^p\right] \leq C_p \left( \sum_{n=1}^N \sigma_n^p +
\left(\sum_{n=1}^N \mathbb{E}[|X_n|^2]\right)^{p/2}
\right).\]</span></p>
</div>
<p>Pour comprendre cette inégalité, commençons par le cas <span
class="math inline">\(p = 2\)</span>. Dans ce cas, l’inégalité se réduit
à : <span class="math display">\[\mathbb{E}\left[\left|\sum_{n=1}^N
X_n\right|^2\right] \leq C_2 \left( \sum_{n=1}^N \sigma_n^2 +
\left(\sum_{n=1}^N \mathbb{E}[|X_n|^2]\right) \right).\]</span> Cette
inégalité est une généralisation de l’inégalité de Khintchine, qui ne
tient pas compte des dépendances entre les variables.</p>
<p>Pour <span class="math inline">\(p &gt; 2\)</span>, l’inégalité
devient plus complexe. Le terme <span class="math inline">\(\sum_{n=1}^N
\sigma_n^p\)</span> capture les contributions des moments d’ordre <span
class="math inline">\(p\)</span> des variables individuelles, tandis que
le terme <span class="math inline">\(\left(\sum_{n=1}^N
\mathbb{E}[|X_n|^2]\right)^{p/2}\)</span> capture les contributions des
variances.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>La preuve de l’inégalité de Rosenthal est un exercice délicat qui
combine des techniques d’analyse et de théorie des probabilités. Nous
allons esquisser les étapes principales.</p>
<div class="proof">
<p><em>Proof.</em> Nous commençons par le cas <span
class="math inline">\(p = 2\)</span>. Par l’inégalité de Cauchy-Schwarz,
nous avons : <span
class="math display">\[\mathbb{E}\left[\left|\sum_{n=1}^N
X_n\right|^2\right] = \sum_{i,j=1}^N \mathbb{E}[X_i X_j].\]</span> En
utilisant l’hypothèse de centrage, nous pouvons écrire <span
class="math inline">\(\mathbb{E}[X_i X_j] = \text{Cov}(X_i,
X_j)\)</span>, où <span class="math inline">\(\text{Cov}\)</span>
désigne la covariance. Par l’inégalité de Cauchy-Schwarz, nous avons :
<span class="math display">\[|\text{Cov}(X_i, X_j)| \leq
\sqrt{\text{Var}(X_i) \text{Var}(X_j)}.\]</span> En utilisant cette
inégalité, nous obtenons : <span
class="math display">\[\mathbb{E}\left[\left|\sum_{n=1}^N
X_n\right|^2\right] \leq C_2 \left( \sum_{n=1}^N \sigma_n^2 +
\left(\sum_{n=1}^N \mathbb{E}[|X_n|^2]\right) \right),\]</span> où <span
class="math inline">\(C_2\)</span> est une constante universelle.</p>
<p>Pour <span class="math inline">\(p &gt; 2\)</span>, la preuve est
plus complexe et repose sur des techniques de décomposition et
d’interpolation. Nous utilisons le théorème de Hölder pour séparer les
termes et appliquer l’inégalité de Rosenthal pour <span
class="math inline">\(p = 2\)</span>. Les détails techniques sont omis
ici, mais la clé est de montrer que les moments d’ordre <span
class="math inline">\(p\)</span> peuvent être contrôlés par une
combinaison des variances et des moments d’ordre <span
class="math inline">\(p\)</span> des variables individuelles. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Rosenthal a plusieurs conséquences importantes. Nous
en listons quelques-unes :</p>
<ol>
<li><p><strong>Inégalité de type Khintchine</strong> : Pour des
variables aléatoires indépendantes, l’inégalité de Rosenthal se réduit à
l’inégalité de Khintchine.</p></li>
<li><p><strong>Inégalité de type Hoeffding</strong> : Pour des variables
aléatoires bornées et indépendantes, l’inégalité de Rosenthal implique
une inégalité de type Hoeffding.</p></li>
<li><p><strong>Concentration des mesures</strong> : L’inégalité de
Rosenthal peut être utilisée pour établir des résultats de concentration
des mesures, qui sont essentiels en statistique et en apprentissage
automatique.</p></li>
</ol>
<p>Nous allons développer chacun de ces points.</p>
<h2 class="unnumbered"
id="propriété-i-inégalité-de-type-khintchine">Propriété (i) : Inégalité
de type Khintchine</h2>
<p>Si les variables <span class="math inline">\(X_n\)</span> sont
indépendantes, alors l’inégalité de Rosenthal se réduit à : <span
class="math display">\[\mathbb{E}\left[\left|\sum_{n=1}^N
X_n\right|^p\right] \leq C_p \left( \sum_{n=1}^N \sigma_n^p +
\left(\sum_{n=1}^N \mathbb{E}[|X_n|^2]\right)^{p/2} \right).\]</span>
Ceci est une généralisation de l’inégalité de Khintchine, qui ne tient
pas compte des dépendances entre les variables.</p>
<h2 class="unnumbered"
id="propriété-ii-inégalité-de-type-hoeffding">Propriété (ii) : Inégalité
de type Hoeffding</h2>
<p>Si les variables <span class="math inline">\(X_n\)</span> sont
indépendantes et bornées, alors l’inégalité de Rosenthal implique une
inégalité de type Hoeffding. Plus précisément, pour tout <span
class="math inline">\(t &gt; 0\)</span>, nous avons : <span
class="math display">\[\mathbb{P}\left(\left|\sum_{n=1}^N X_n\right|
\geq t\right) \leq 2 \exp\left(-\frac{t^2}{2 \sum_{n=1}^N
\sigma_n^2}\right).\]</span> Cette inégalité est cruciale pour l’analyse
des algorithmes stochastiques.</p>
<h2 class="unnumbered"
id="propriété-iii-concentration-des-mesures">Propriété (iii) :
Concentration des mesures</h2>
<p>L’inégalité de Rosenthal peut être utilisée pour établir des
résultats de concentration des mesures. Par exemple, elle permet de
montrer que la somme <span class="math inline">\(S_N\)</span> se
concentre autour de sa moyenne avec une probabilité exponentielle. Ceci
est essentiel en statistique pour l’analyse des estimateurs.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’inégalité de Rosenthal est un résultat fondamental en théorie des
probabilités. Elle généralise et unifie plusieurs résultats classiques,
et elle a des applications dans de nombreux domaines, notamment en
statistique et en apprentissage automatique. La preuve de cette
inégalité est un exercice délicat qui combine des techniques d’analyse
et de théorie des probabilités. Les propriétés et corollaires de cette
inégalité offrent des outils puissants pour l’étude des sommes de
variables aléatoires et pour l’analyse des algorithmes
stochastiques.</p>
</body>
</html>
{% include "footer.html" %}

