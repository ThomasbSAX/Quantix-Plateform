{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>RMSLE (Root Mean Squared Logarithmic Error)</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">RMSLE (Root Mean Squared Logarithmic Error)</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’erreur quadratique moyenne logarithmique, ou RMSLE (Root Mean
Squared Logarithmic Error), est une mesure d’erreur couramment utilisée
dans les problèmes de régression, notamment lorsque les données
présentent des variations d’échelle importantes. Cette métrique est
particulièrement utile dans les contextes où les valeurs prédites et
réelles peuvent varier sur plusieurs ordres de grandeur, comme dans les
prévisions économiques ou les modèles de croissance.</p>
<p>Le RMSLE émerge comme une alternative à l’erreur quadratique moyenne
(MSE) traditionnelle, car il est moins sensible aux grandes valeurs
aberrantes. En prenant le logarithme des valeurs avant de calculer
l’erreur, le RMSLE atténue l’impact des grandes différences entre les
valeurs prédites et réelles, ce qui le rend plus robuste dans les
scénarios où les données sont fortement dispersées.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre le RMSLE, commençons par considérer deux ensembles de
valeurs : les valeurs réelles <span class="math inline">\(y_i\)</span>
et les valeurs prédites <span class="math inline">\(\hat{y}_i\)</span>.
L’idée est de mesurer l’erreur entre ces deux ensembles de manière
logarithmique.</p>
<p>Supposons que nous voulions une mesure d’erreur qui ne soit pas trop
influencée par les grandes différences entre <span
class="math inline">\(y_i\)</span> et <span
class="math inline">\(\hat{y}_i\)</span>. Une approche naturelle
consiste à prendre le logarithme des valeurs avant de calculer l’erreur.
Cela nous amène à définir l’erreur logarithmique comme suit :</p>
<p><span class="math display">\[\text{Logarithmic Error} = \log(y_i) -
\log(\hat{y}_i)\]</span></p>
<p>Ensuite, nous voulons une mesure qui soit la moyenne des erreurs
logarithmiques au carré. Cela nous donne :</p>
<p><span class="math display">\[\text{Mean Squared Logarithmic Error} =
\frac{1}{n} \sum_{i=1}^{n} (\log(y_i) - \log(\hat{y}_i))^2\]</span></p>
<p>Enfin, pour obtenir une mesure qui soit dans la même unité que les
valeurs originales, nous prenons la racine carrée de cette moyenne.
Ainsi, nous arrivons à la définition formelle du RMSLE :</p>
<div class="definition">
<p>Soit <span class="math inline">\(y = (y_1, y_2, \ldots, y_n)\)</span>
un ensemble de valeurs réelles et <span class="math inline">\(\hat{y} =
(\hat{y}_1, \hat{y}_2, \ldots, \hat{y}_n)\)</span> un ensemble de
valeurs prédites. Le RMSLE est défini par :</p>
<p><span class="math display">\[\text{RMSLE}(y, \hat{y}) =
\sqrt{\frac{1}{n} \sum_{i=1}^{n} (\log(y_i + 1) - \log(\hat{y}_i +
1))^2}\]</span></p>
<p>où <span class="math inline">\(n\)</span> est le nombre de valeurs,
et <span class="math inline">\(\log\)</span> désigne le logarithme
naturel.</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le RMSLE possède plusieurs propriétés intéressantes qui le rendent
utile dans divers contextes. En voici quelques-unes :</p>
<div class="theorem">
<p>Le RMSLE est toujours non négatif, c’est-à-dire que pour tout
ensemble de valeurs réelles <span class="math inline">\(y\)</span> et
prédites <span class="math inline">\(\hat{y}\)</span>, on a :</p>
<p><span class="math display">\[\text{RMSLE}(y, \hat{y}) \geq
0\]</span></p>
<p>De plus, le RMSLE est égal à zéro si et seulement si <span
class="math inline">\(y_i = \hat{y}_i\)</span> pour tout <span
class="math inline">\(i\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La non-négativité découle du fait que le carré de
toute différence réelle est non négatif. De plus, si <span
class="math inline">\(\text{RMSLE}(y, \hat{y}) = 0\)</span>, alors
chaque terme de la somme doit être nul, ce qui implique que <span
class="math inline">\(y_i = \hat{y}_i\)</span> pour tout <span
class="math inline">\(i\)</span>. Réciproquement, si <span
class="math inline">\(y_i = \hat{y}_i\)</span> pour tout <span
class="math inline">\(i\)</span>, alors chaque terme de la somme est
nul, et donc le RMSLE est égal à zéro. ◻</p>
</div>
<div class="corollary">
<p>Le RMSLE est invariant par translation logarithmique, c’est-à-dire
que pour tout réel <span class="math inline">\(a &gt; 0\)</span>, on a
:</p>
<p><span class="math display">\[\text{RMSLE}(y, \hat{y}) =
\text{RMSLE}(a y, a \hat{y})\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Cela découle du fait que le logarithme d’une
constante multiplicative est une constante additive. Plus précisément,
on a :</p>
<p><span class="math display">\[\log(a y_i + 1) = \log(a) + \log(y_i +
1)\]</span></p>
<p>et</p>
<p><span class="math display">\[\log(a \hat{y}_i + 1) = \log(a) +
\log(\hat{y}_i + 1)\]</span></p>
<p>Ainsi, la différence <span class="math inline">\(\log(a y_i + 1) -
\log(a \hat{y}_i + 1)\)</span> est égale à <span
class="math inline">\(\log(y_i + 1) - \log(\hat{y}_i + 1)\)</span>, et
le RMSLE reste inchangé. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le RMSLE est une mesure d’erreur puissante et robuste,
particulièrement adaptée aux problèmes de régression où les données
présentent des variations d’échelle importantes. Sa capacité à atténuer
l’impact des grandes valeurs aberrantes en fait un outil précieux dans
de nombreux domaines d’application.</p>
</body>
</html>
{% include "footer.html" %}

