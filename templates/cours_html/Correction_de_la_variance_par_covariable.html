{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Correction de la variance par covariable</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Correction de la variance par covariable</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>En statistique, la correction de la variance par covariable est une
technique essentielle pour améliorer la précision des estimations. Cette
méthode permet de réduire la variance d’un estimateur en introduisant
une ou plusieurs covariables dans le modèle. L’origine de cette
technique remonte aux travaux pionniers sur la régression linéaire et
l’analyse de covariance. Elle est indispensable dans les études où les
données présentent des variations indésirables dues à des facteurs non
contrôlés.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant de formaliser la correction de la variance par covariable, il
est important de comprendre ce que nous cherchons à accomplir. Supposons
que nous ayons un estimateur <span
class="math inline">\(\hat{\theta}\)</span> de la vraie valeur <span
class="math inline">\(\theta\)</span>, mais que cet estimateur soit
sujet à une variance élevée. Nous cherchons un moyen de réduire cette
variance en utilisant des informations supplémentaires, appelées
covariables.</p>
<div class="definition">
<p>Soit <span class="math inline">\(Y\)</span> une variable aléatoire
d’intérêt et <span class="math inline">\(X\)</span> une covariable. Nous
cherchons à estimer <span class="math inline">\(\mathbb{E}[Y | X =
x]\)</span>. La correction de la variance par covariable consiste à
modéliser cette espérance conditionnelle en fonction de <span
class="math inline">\(X\)</span>.</p>
</div>
<p>Formellement, nous pouvons écrire : <span
class="math display">\[\mathbb{E}[Y | X = x] = \beta_0 + \beta_1
x\]</span> où <span class="math inline">\(\beta_0\)</span> et <span
class="math inline">\(\beta_1\)</span> sont des coefficients à
estimer.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental dans ce contexte est le théorème de
Gauss-Markov, qui garantit que l’estimateur des moindres carrés est le
meilleur estimateur linéaire non biaisé (BLUE) sous certaines
conditions.</p>
<div class="theorem">
<p>Soit le modèle linéaire général : <span class="math display">\[Y =
X\beta + \epsilon\]</span> où <span class="math inline">\(X\)</span> est
une matrice de covariables, <span class="math inline">\(\beta\)</span>
est un vecteur de coefficients, et <span
class="math inline">\(\epsilon\)</span> est un vecteur d’erreurs avec
<span class="math inline">\(\mathbb{E}[\epsilon] = 0\)</span> et <span
class="math inline">\(\text{Var}(\epsilon) = \sigma^2 I\)</span>. Alors,
l’estimateur des moindres carrés <span class="math inline">\(\hat{\beta}
= (X^T X)^{-1} X^T Y\)</span> est le meilleur estimateur linéaire non
biaisé.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Gauss-Markov, nous devons montrer que
l’estimateur des moindres carrés est non biaisé et qu’il a la plus
petite variance parmi tous les estimateurs linéaires non biaisés.</p>
<div class="proof">
<p><em>Proof.</em> 1. **Non-biais** : Nous avons <span
class="math display">\[\mathbb{E}[\hat{\beta}] = \mathbb{E}[(X^T X)^{-1}
X^T Y] = (X^T X)^{-1} X^T \mathbb{E}[Y] = (X^T X)^{-1} X^T X \beta =
\beta\]</span> Ainsi, <span class="math inline">\(\hat{\beta}\)</span>
est non biaisé.</p>
<p>2. **Variance minimale** : Considérons un autre estimateur linéaire
non biaisé <span class="math inline">\(\tilde{\beta} = A Y\)</span>, où
<span class="math inline">\(A\)</span> est une matrice telle que <span
class="math inline">\(A X = I\)</span>. La variance de <span
class="math inline">\(\tilde{\beta}\)</span> est donnée par <span
class="math display">\[\text{Var}(\tilde{\beta}) = A \text{Var}(Y) A^T =
\sigma^2 A A^T\]</span> Nous devons montrer que <span
class="math inline">\(\text{Var}(\hat{\beta}) \leq
\text{Var}(\tilde{\beta})\)</span> pour tout <span
class="math inline">\(A\)</span> tel que <span class="math inline">\(A X
= I\)</span>. En utilisant le fait que <span class="math inline">\((X^T
X)^{-1} X^T\)</span> est la pseudo-inverse de <span
class="math inline">\(X\)</span>, nous pouvons montrer que <span
class="math inline">\(\hat{\beta}\)</span> minimise cette
variance. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
correction de la variance par covariable.</p>
<ul>
<li><p>**Réduction de la variance** : En introduisant des covariables
pertinentes, nous pouvons réduire la variance de l’estimateur de <span
class="math inline">\(\theta\)</span>.</p></li>
<li><p>**Efficacité** : L’estimateur corrigé est souvent plus efficace
que l’estimateur non corrigé, c’est-à-dire qu’il a une variance plus
faible.</p></li>
<li><p>**Robustesse** : La correction de la variance par covariable peut
rendre les estimations plus robustes aux variations indésirables dans
les données.</p></li>
</ul>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La correction de la variance par covariable est une technique
puissante pour améliorer la précision des estimations statistiques. En
utilisant des covariables appropriées, nous pouvons réduire la variance
de nos estimateurs et obtenir des résultats plus fiables. Cette méthode
est particulièrement utile dans les études où les données présentent des
variations indésirables dues à des facteurs non contrôlés.</p>
</body>
</html>
{% include "footer.html" %}

