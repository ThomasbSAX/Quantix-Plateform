{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Mean Absolute Error (MAE) : Une Mesure Fondamentale en Apprentissage Automatique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Mean Absolute Error (MAE) : Une Mesure Fondamentale en
Apprentissage Automatique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’erreur absolue moyenne, ou Mean Absolute Error (MAE), est une
métrique d’évaluation essentielle dans le domaine de l’apprentissage
automatique et de la statistique. Son origine remonte aux premières
tentatives de quantification des écarts entre les valeurs prédites par
un modèle et les valeurs réelles observées. Le MAE émerge comme une
alternative robuste à d’autres mesures telles que l’erreur quadratique
moyenne (MSE), offrant une interprétation plus intuitive et une
sensibilité réduite aux valeurs aberrantes.</p>
<p>Le MAE est indispensable dans les cadres où la robustesse et
l’interprétabilité sont primordiales. Par exemple, en prévision
économique ou en analyse de séries temporelles, le MAE permet de mesurer
les écarts de manière linéaire, sans surpondérer les erreurs
importantes. Cette propriété en fait un outil privilégié pour
l’évaluation des modèles de régression et de classification, notamment
dans les contextes où les données sont bruitées ou présentent des
outliers.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir le MAE, commençons par comprendre ce que nous cherchons
à mesurer. Imaginons un modèle de prédiction qui, pour chaque
observation <span class="math inline">\(i\)</span>, produit une valeur
<span class="math inline">\(\hat{y}_i\)</span> alors que la vraie valeur
est <span class="math inline">\(y_i\)</span>. Nous voulons quantifier
l’écart moyen entre ces prédictions et les valeurs réelles, de manière à
ce que cet écart soit indépendant de la direction (positif ou négatif)
et proportionnel à sa magnitude.</p>
<p>Formellement, le Mean Absolute Error (MAE) est défini comme suit
:</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathcal{D} = \{ (x_i, y_i)
\}_{i=1}^n\)</span> un ensemble de <span
class="math inline">\(n\)</span> observations, où <span
class="math inline">\(y_i\)</span> est la valeur réelle et <span
class="math inline">\(\hat{y}_i\)</span> la valeur prédite par un modèle
pour l’observation <span class="math inline">\(x_i\)</span>. Le MAE est
donné par :</p>
<p><span class="math display">\[\text{MAE} = \frac{1}{n} \sum_{i=1}^n
|y_i - \hat{y}_i|\]</span></p>
<p>Autrement dit, pour tout <span class="math inline">\(i \in \{1, 2,
\dots, n\}\)</span>, le MAE est la moyenne des valeurs absolues des
différences entre les valeurs réelles <span
class="math inline">\(y_i\)</span> et les valeurs prédites <span
class="math inline">\(\hat{y}_i\)</span>.</p>
</div>
<p>Une autre formulation, équivalente mais parfois plus pratique pour
des raisons computationnelles, est :</p>
<p><span class="math display">\[\text{MAE} = \mathbb{E}_{(x,y) \sim
\mathcal{D}}[|y - \hat{y}(x)|]\]</span></p>
<p>où <span class="math inline">\(\mathbb{E}\)</span> désigne
l’espérance mathématique sur la distribution des données <span
class="math inline">\(\mathcal{D}\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Le MAE possède plusieurs propriétés intéressantes qui le rendent
attractif pour l’évaluation des modèles. Considérons d’abord la
propriété de linéarité.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(\hat{y}_1\)</span> et <span
class="math inline">\(\hat{y}_2\)</span> deux prédictions pour une même
observation <span class="math inline">\(y\)</span>. Alors, le MAE
vérifie la propriété de linéarité suivante :</p>
<p><span class="math display">\[\text{MAE}(\hat{y}_1 + \hat{y}_2) =
\text{MAE}(\hat{y}_1) + \text{MAE}(\hat{y}_2)\]</span></p>
<p><em>Démonstration :</em> Considérons un ensemble de <span
class="math inline">\(n\)</span> observations. Nous avons :</p>
<p><span class="math display">\[\text{MAE}(\hat{y}_1 + \hat{y}_2) =
\frac{1}{n} \sum_{i=1}^n |y_i - (\hat{y}_1 + \hat{y}_2)_i|\]</span></p>
<p>En utilisant la propriété de linéarité de la valeur absolue, nous
obtenons :</p>
<p><span class="math display">\[= \frac{1}{n} \sum_{i=1}^n |(y_i -
\hat{y}_1) - \hat{y}_2|\]</span></p>
<p>Cependant, cette démonstration est incomplète et nécessite des
hypothèses supplémentaires pour être valide. En réalité, la propriété de
linéarité du MAE n’est pas généralement vraie pour des prédictions
arbitraires. Une formulation plus précise serait :</p>
<p><span class="math display">\[\text{MAE}(a\hat{y}_1 + b) = |a|
\text{MAE}(\hat{y}_1) + |b|\]</span></p>
<p>où <span class="math inline">\(a\)</span> et <span
class="math inline">\(b\)</span> sont des constantes.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour illustrer les propriétés du MAE, considérons la preuve de la
propriété d’invariance par translation.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(b\)</span> une
constante réelle. Nous voulons montrer que :</p>
<p><span class="math display">\[\text{MAE}(\hat{y} + b) =
\text{MAE}(\hat{y}) + |b|\]</span></p>
<p>Commençons par écrire le MAE de <span class="math inline">\(\hat{y} +
b\)</span> :</p>
<p><span class="math display">\[\text{MAE}(\hat{y} + b) = \frac{1}{n}
\sum_{i=1}^n |y_i - (\hat{y}_i + b)|\]</span></p>
<p>En utilisant la propriété de linéarité de la valeur absolue, nous
avons :</p>
<p><span class="math display">\[= \frac{1}{n} \sum_{i=1}^n |(y_i -
\hat{y}_i) - b|\]</span></p>
<p>En appliquant l’inégalité triangulaire, nous obtenons :</p>
<p><span class="math display">\[= \frac{1}{n} \sum_{i=1}^n |y_i -
\hat{y}_i| + |b|\]</span></p>
<p>Ce qui est exactement :</p>
<p><span class="math display">\[= \text{MAE}(\hat{y}) + |b|\]</span></p>
<p>Ainsi, nous avons démontré que le MAE est invariant par
translation. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le MAE possède plusieurs propriétés intéressantes qui en font un
outil puissant pour l’évaluation des modèles. En voici quelques-unes
:</p>
<ol>
<li><p><strong>Invariance par Translation :</strong> Comme démontré
précédemment, le MAE est invariant par translation. Cela signifie que
l’ajout d’une constante à toutes les prédictions ne change pas le
MAE.</p></li>
<li><p><strong>Sensibilité aux Outliers :</strong> Le MAE est moins
sensible aux valeurs aberrantes que le MSE, car il ne pénalisera pas
excessivement les grandes erreurs. Cela en fait une mesure plus robuste
dans les contextes où les données sont bruitées.</p></li>
<li><p><strong>Interprétabilité :</strong> Le MAE est directement
interprétable comme la moyenne des erreurs absolues. Cela facilite son
utilisation et son interprétation dans des contextes pratiques.</p></li>
</ol>
<p>Pour illustrer la propriété de sensibilité aux outliers, considérons
un exemple simple.</p>
<div class="example">
<p>Supposons que nous ayons trois observations avec les valeurs réelles
<span class="math inline">\(y = [1, 2, 3]\)</span> et les prédictions
<span class="math inline">\(\hat{y} = [1, 2, 10]\)</span>. Le MAE est
:</p>
<p><span class="math display">\[\text{MAE} = \frac{1}{3} (|1-1| + |2-2|
+ |3-10|) = \frac{7}{3} \approx 2.33\]</span></p>
<p>Si nous ajoutons une observation aberrante, par exemple <span
class="math inline">\(y = [1, 2, 3, 100]\)</span> et <span
class="math inline">\(\hat{y} = [1, 2, 3, 10]\)</span>, le MAE devient
:</p>
<p><span class="math display">\[\text{MAE} = \frac{1}{4} (|1-1| + |2-2|
+ |3-3| + |100-10|) = \frac{90}{4} = 22.5\]</span></p>
<p>Bien que l’outlier ait un impact significatif, le MAE reste plus
robuste que le MSE, qui serait beaucoup plus affecté par cette valeur
aberrante.</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le Mean Absolute Error (MAE) est une métrique fondamentale en
apprentissage automatique et en statistique, offrant une mesure robuste
et interprétable des erreurs de prédiction. Ses propriétés d’invariance
par translation, de sensibilité réduite aux outliers et son
interprétation directe en font un outil privilégié pour l’évaluation des
modèles. Bien que moins sensible aux grandes erreurs que le MSE, le MAE
reste un choix populaire pour de nombreuses applications pratiques.</p>
</body>
</html>
{% include "footer.html" %}

