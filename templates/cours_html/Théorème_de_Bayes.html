{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Le Théorème de Bayes : Un Pilier de l’Inférence Statistique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Le Théorème de Bayes : Un Pilier de l’Inférence
Statistique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Le théorème de Bayes, du nom du mathématicien britannique Thomas
Bayes (1701-1761), est une pierre angulaire de la théorie des
probabilités et de l’inférence statistique. Il émerge dans un contexte
où l’on cherche à mettre à jour nos croyances en fonction de nouvelles
informations. Ce théorème est indispensable dans des domaines aussi
variés que la médecine, l’ingénierie, les sciences sociales et
l’intelligence artificielle.</p>
<p>L’origine du théorème de Bayes remonte au XVIIIe siècle, mais son
importance n’a été pleinement reconnue qu’au XIXe siècle avec le
développement de la statistique bayésienne. Ce théorème permet de passer
d’une probabilité a priori à une probabilité a posteriori, en intégrant
des données observées. Il est donc au cœur de l’apprentissage
automatique et de la prise de décision sous incertitude.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant d’énoncer le théorème de Bayes, il est essentiel de définir
quelques concepts fondamentaux.</p>
<div class="definition">
<p><strong>Définition 1</strong>. <em>Soit <span
class="math inline">\((\Omega, \mathcal{F}, P)\)</span> un espace
probabilisé. Une variable aléatoire <span
class="math inline">\(X\)</span> est une fonction mesurable de <span
class="math inline">\(\Omega\)</span> dans un espace mesurable <span
class="math inline">\((E, \mathcal{E})\)</span>.</em></p>
</div>
<div class="definition">
<p><strong>Définition 2</strong>. <em>Soit <span
class="math inline">\(X\)</span> une variable aléatoire prenant ses
valeurs dans un ensemble fini ou dénombrable <span
class="math inline">\(E\)</span>. La loi de probabilité de <span
class="math inline">\(X\)</span> est la fonction <span
class="math inline">\(P_X: \mathcal{E} \rightarrow [0,1]\)</span>
définie par : <span class="math display">\[P_X(A) = P(X \in A), \quad
\forall A \in \mathcal{E}.\]</span></em></p>
</div>
<div class="definition">
<p><strong>Définition 3</strong>. <em>Soient <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> deux variables aléatoires. La loi
jointe de <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> est la fonction <span
class="math inline">\(P_{X,Y}: \mathcal{E} \times \mathcal{F}
\rightarrow [0,1]\)</span> définie par : <span
class="math display">\[P_{X,Y}(A,B) = P(X \in A, Y \in B), \quad \forall
A \in \mathcal{E}, \forall B \in \mathcal{F}.\]</span></em></p>
</div>
<h1 id="théorème-de-bayes">Théorème de Bayes</h1>
<p>Le théorème de Bayes relie les probabilités conditionnelles de deux
événements <span class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span>. Il permet de calculer la probabilité
conditionnelle inverse, c’est-à-dire la probabilité que <span
class="math inline">\(A\)</span> se réalise sachant que <span
class="math inline">\(B\)</span> s’est réalisé, en fonction de la
probabilité que <span class="math inline">\(B\)</span> se réalise
sachant que <span class="math inline">\(A\)</span> s’est réalisé.</p>
<div class="theorem">
<p><strong>Théorème 4</strong> (Théorème de Bayes). <em>Soient <span
class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span> deux événements tels que <span
class="math inline">\(P(B) &gt; 0\)</span>. Alors, <span
class="math display">\[P(A|B) =
\frac{P(B|A)P(A)}{P(B)}.\]</span></em></p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Bayes, nous partons de la définition des
probabilités conditionnelles.</p>
<div class="proof">
<p><em>Proof.</em> Par définition de la probabilité conditionnelle, nous
avons : <span class="math display">\[P(A|B) = \frac{P(A \cap
B)}{P(B)}.\]</span></p>
<p>De même, <span class="math display">\[P(B|A) = \frac{P(A \cap
B)}{P(A)}.\]</span></p>
<p>En réarrangeant cette dernière équation, nous obtenons : <span
class="math display">\[P(A \cap B) = P(B|A)P(A).\]</span></p>
<p>En substituant cette expression dans la première équation, nous
obtenons : <span class="math display">\[P(A|B) =
\frac{P(B|A)P(A)}{P(B)}.\]</span></p>
<p>Ceci achève la preuve du théorème de Bayes. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Le théorème de Bayes a de nombreuses applications et implications.
Nous en présentons quelques-unes ci-dessous.</p>
<div class="corollary">
<p><strong>Corollaire 5</strong>. <em>Soient <span
class="math inline">\(A_1, A_2, \ldots, A_n\)</span> des événements
mutuellement exclusifs et exhaustifs tels que <span
class="math inline">\(P(A_i) &gt; 0\)</span> pour tout <span
class="math inline">\(i\)</span>. Alors, pour tout événement <span
class="math inline">\(B\)</span> tel que <span
class="math inline">\(P(B) &gt; 0\)</span>, nous avons : <span
class="math display">\[P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum_{j=1}^n
P(B|A_j)P(A_j)}.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Par le théorème de Bayes, nous avons : <span
class="math display">\[P(A_i|B) =
\frac{P(B|A_i)P(A_i)}{P(B)}.\]</span></p>
<p>En utilisant le théorème de la probabilité totale, nous avons : <span
class="math display">\[P(B) = \sum_{j=1}^n P(B|A_j)P(A_j).\]</span></p>
<p>En substituant cette expression dans la première équation, nous
obtenons : <span class="math display">\[P(A_i|B) =
\frac{P(B|A_i)P(A_i)}{\sum_{j=1}^n P(B|A_j)P(A_j)}.\]</span></p>
<p>Ceci achève la preuve du corollaire. ◻</p>
</div>
<div class="remark">
<p><strong>Remarque 6</strong>. <em>Le théorème de Bayes est
particulièrement utile dans les cas où nous avons des informations a
priori sur les événements <span class="math inline">\(A_i\)</span> et où
nous voulons mettre à jour ces informations en fonction de nouvelles
observations <span class="math inline">\(B\)</span>.</em></p>
</div>
<h1 id="exemple">Exemple</h1>
<p>Considérons un exemple classique en médecine. Supposons que nous
testions une maladie rare qui touche 1% de la population. Le test de
dépistage a une sensibilité de 99% (probabilité de détecter la maladie
si elle est présente) et une spécificité de 95% (probabilité de ne pas
détecter la maladie si elle est absente).</p>
<p>Soit <span class="math inline">\(D\)</span> l’événement "la personne
est malade" et <span class="math inline">\(T\)</span> l’événement "le
test est positif". Nous voulons calculer la probabilité que la personne
soit malade sachant que le test est positif, c’est-à-dire <span
class="math inline">\(P(D|T)\)</span>.</p>
<p>Nous avons les informations suivantes : - <span
class="math inline">\(P(D) = 0.01\)</span>, - <span
class="math inline">\(P(T|D) = 0.99\)</span>, - <span
class="math inline">\(P(T|\neg D) = 0.05\)</span>.</p>
<p>En utilisant le théorème de Bayes, nous avons : <span
class="math display">\[P(D|T) = \frac{P(T|D)P(D)}{P(T)}.\]</span></p>
<p>En utilisant le théorème de la probabilité totale, nous avons : <span
class="math display">\[P(T) = P(T|D)P(D) + P(T|\neg D)P(\neg
D).\]</span></p>
<p>En substituant les valeurs connues, nous obtenons : <span
class="math display">\[P(T) = 0.99 \times 0.01 + 0.05 \times 0.99 =
0.0099 + 0.0495 = 0.0594.\]</span></p>
<p>En substituant cette valeur dans l’expression pour <span
class="math inline">\(P(D|T)\)</span>, nous obtenons : <span
class="math display">\[P(D|T) = \frac{0.99 \times 0.01}{0.0594} \approx
0.1667.\]</span></p>
<p>Ainsi, même si le test est positif, la probabilité que la personne
soit réellement malade n’est que d’environ 16.67%. Cela montre
l’importance de prendre en compte la prévalence de la maladie et les
caractéristiques du test.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Le théorème de Bayes est un outil puissant pour l’inférence
statistique. Il permet de mettre à jour nos croyances en fonction de
nouvelles informations et est largement utilisé dans des domaines aussi
variés que la médecine, l’ingénierie et les sciences sociales.
Comprendre et appliquer ce théorème est essentiel pour toute personne
travaillant dans le domaine de la statistique ou de l’apprentissage
automatique.</p>
</body>
</html>
{% include "footer.html" %}

