{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Valeurs Singulières : Théorie et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Valeurs Singulières : Théorie et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les valeurs singulières constituent un outil fondamental en analyse
numérique et en algèbre linéaire. Elles émergent naturellement dans
l’étude des matrices et des opérateurs linéaires, offrant une
généralisation puissante du concept de valeurs propres. Historiquement,
les valeurs singulières ont été introduites pour résoudre des problèmes
de moindres carrés et d’inversion de matrices mal conditionnées. Leur
importance réside dans leur capacité à capturer l’information
essentielle d’une matrice, tout en fournissant des outils robustes pour
l’analyse des données et la compression d’images.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir les valeurs singulières, commençons par considérer une
matrice <span class="math inline">\(A\)</span> de taille <span
class="math inline">\(m \times n\)</span>. Nous cherchons à comprendre
comment cette matrice transforme les vecteurs de l’espace source vers
l’espace cible. Intuitivement, nous voulons identifier les directions
dans lesquelles la transformation est la plus forte ou la plus
faible.</p>
<div class="definition">
<p>Soit <span class="math inline">\(A\)</span> une matrice réelle de
taille <span class="math inline">\(m \times n\)</span>. Les valeurs
singulières de <span class="math inline">\(A\)</span> sont les nombres
réels non négatifs <span class="math inline">\(\sigma_1, \sigma_2,
\ldots, \sigma_r\)</span> (où <span class="math inline">\(r = \min(m,
n)\)</span>) tels que : <span class="math display">\[\sigma_i =
\sqrt{\lambda_i(A^T A)}\]</span> où <span
class="math inline">\(\lambda_i(A^T A)\)</span> sont les valeurs propres
de la matrice <span class="math inline">\(A^T A\)</span>, ordonnées de
manière décroissante.</p>
</div>
<p>Une autre formulation équivalente est la suivante : <span
class="math display">\[\sigma_i = \inf_{S \subset \mathbb{R}^n, \dim(S)
= i} \sup_{\substack{x \in S \\ \|x\|_2 = 1}} \|Ax\|_2\]</span> où <span
class="math inline">\(\inf\)</span> et <span
class="math inline">\(\sup\)</span> sont pris sur les sous-espaces de
dimension appropriée.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème central concernant les valeurs singulières est le suivant
:</p>
<div class="theorem">
<p>Toute matrice <span class="math inline">\(A\)</span> de taille <span
class="math inline">\(m \times n\)</span> peut être décomposée en :
<span class="math display">\[A = U \Sigma V^T\]</span> où :</p>
<ul>
<li><p><span class="math inline">\(U\)</span> est une matrice
orthogonale de taille <span class="math inline">\(m \times
m\)</span>,</p></li>
<li><p><span class="math inline">\(V\)</span> est une matrice
orthogonale de taille <span class="math inline">\(n \times
n\)</span>,</p></li>
<li><p><span class="math inline">\(\Sigma\)</span> est une matrice
diagonale de taille <span class="math inline">\(m \times n\)</span> dont
les éléments diagonaux sont les valeurs singulières de <span
class="math inline">\(A\)</span>, ordonnées de manière
décroissante.</p></li>
</ul>
</div>
<p>La preuve de ce théorème repose sur plusieurs étapes clés. Tout
d’abord, nous considérons la matrice <span class="math inline">\(A^T
A\)</span>, qui est symétrique et positive. Ensuite, nous diagonalisons
cette matrice pour obtenir ses valeurs propres et vecteurs propres. Les
valeurs singulières de <span class="math inline">\(A\)</span> sont alors
les racines carrées des valeurs propres de <span
class="math inline">\(A^T A\)</span>. Enfin, nous construisons les
matrices <span class="math inline">\(U\)</span> et <span
class="math inline">\(V\)</span> à partir des vecteurs propres de <span
class="math inline">\(A^T A\)</span> et <span
class="math inline">\(AA^T\)</span>, respectivement.</p>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer le théorème de la décomposition en valeurs
singulières, nous procédons comme suit :</p>
<div class="proof">
<p><em>Proof.</em> Considérons la matrice <span
class="math inline">\(A\)</span> de taille <span class="math inline">\(m
\times n\)</span>. La matrice <span class="math inline">\(A^T A\)</span>
est symétrique et positive, donc diagonalisable. Soit <span
class="math inline">\(V\)</span> la matrice dont les colonnes sont les
vecteurs propres de <span class="math inline">\(A^T A\)</span>, et soit
<span class="math inline">\(\Lambda\)</span> la matrice diagonale des
valeurs propres de <span class="math inline">\(A^T A\)</span>. Nous
avons alors : <span class="math display">\[A^T A V = V \Lambda\]</span>
En multipliant à gauche par <span class="math inline">\(A\)</span>, nous
obtenons : <span class="math display">\[A A^T (A V) = A V
\Lambda\]</span> Cela montre que les colonnes de <span
class="math inline">\(A V\)</span> sont des vecteurs propres de <span
class="math inline">\(A A^T\)</span>. En normalisant ces vecteurs, nous
obtenons les colonnes de la matrice <span
class="math inline">\(U\)</span>. La matrice <span
class="math inline">\(\Sigma\)</span> est alors construite en prenant
les racines carrées des valeurs propres de <span
class="math inline">\(A^T A\)</span> sur la diagonale.</p>
<p>Ainsi, nous avons : <span class="math display">\[A = U \Sigma
V^T\]</span> ce qui achève la preuve. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Les valeurs singulières possèdent plusieurs propriétés importantes,
que nous énumérons ci-dessous :</p>
<ol>
<li><p>Les valeurs singulières d’une matrice sont toujours non
négatives.</p></li>
<li><p>Le rang d’une matrice est égal au nombre de valeurs singulières
non nulles.</p></li>
<li><p>La norme spectrale d’une matrice est égale à sa plus grande
valeur singulière.</p></li>
<li><p>Les valeurs singulières sont invariantes par transformation
orthogonale, c’est-à-dire que si <span class="math inline">\(Q\)</span>
est une matrice orthogonale, alors les valeurs singulières de <span
class="math inline">\(A\)</span> et <span
class="math inline">\(QA\)</span> sont identiques.</p></li>
</ol>
<p>Chacune de ces propriétés peut être démontrée en utilisant les
définitions et théorèmes précédents. Par exemple, pour la propriété
(iii), nous avons : <span class="math display">\[\|A\|_2 = \max_{\|x\|_2
= 1} \|Ax\|_2 = \sigma_1\]</span> où <span
class="math inline">\(\sigma_1\)</span> est la plus grande valeur
singulière de <span class="math inline">\(A\)</span>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Les valeurs singulières offrent un cadre puissant pour l’analyse des
matrices et des opérateurs linéaires. Leur utilisation est omniprésente
en analyse numérique, en traitement du signal et en apprentissage
automatique. La décomposition en valeurs singulières (SVD) est un outil
indispensable pour la compression de données, la réduction de dimension
et l’étude des structures sous-jacentes dans les ensembles de données
complexes.</p>
</body>
</html>
{% include "footer.html" %}

