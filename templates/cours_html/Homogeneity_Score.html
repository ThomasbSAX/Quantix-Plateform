{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Homogeneity Score: A Measure of Cluster Quality</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Homogeneity Score: A Measure of Cluster Quality</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>Dans le domaine de l’analyse des données, la détection de clusters
est une tâche fondamentale pour comprendre la structure sous-jacente des
ensembles de données. L’évaluation de la qualité des clusters obtenus
est cruciale pour valider les résultats et améliorer les algorithmes.
Parmi les mesures de qualité des clusters, le <em>Homogeneity Score</em>
se distingue par sa capacité à évaluer la pureté des clusters par
rapport aux étiquettes de classe véritables.</p>
<p>Le concept d’homogénéité émerge naturellement dans le contexte des
données étiquetées, où l’objectif est de regrouper les instances
similaires tout en séparant celles qui sont différentes. L’homogénéité
est indispensable pour s’assurer que les clusters reflètent fidèlement
la structure des données sous-jacentes, en particulier lorsque les
étiquettes de classe sont disponibles.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir le <em>Homogeneity Score</em>, nous devons d’abord
comprendre ce que nous cherchons à mesurer. Supposons que nous avons un
ensemble de données avec des étiquettes de classe véritables et que nous
avons appliqué un algorithme de clustering pour regrouper ces données.
Nous voulons quantifier dans quelle mesure les clusters sont composés
d’instances appartenant à la même classe.</p>
<p>Formellement, soit <span class="math inline">\(C\)</span> l’ensemble
des clusters obtenus par un algorithme de clustering et <span
class="math inline">\(Y\)</span> l’ensemble des étiquettes de classe
véritables. Nous définissons le <em>Homogeneity Score</em> comme suit
:</p>
<div class="definition">
<p>Le <em>Homogeneity Score</em> est une mesure de la pureté des
clusters par rapport aux étiquettes de classe véritables. Il est défini
comme : <span class="math display">\[H = 1 -
\frac{H(C|Y)}{H(Y)}\]</span> où <span
class="math inline">\(H(C|Y)\)</span> est l’entropie conditionnelle des
clusters donnés les étiquettes de classe et <span
class="math inline">\(H(Y)\)</span> est l’entropie des étiquettes de
classe.</p>
</div>
<p>Pour mieux comprendre cette définition, considérons les
quantificateurs suivants :</p>
<p><span class="math display">\[H = 1 - \frac{\sum_{c \in C} P(c) \cdot
H(Y|c)}{\sum_{y \in Y} -P(y) \log P(y)}\]</span></p>
<p>où <span class="math inline">\(P(c)\)</span> est la probabilité d’un
cluster <span class="math inline">\(c\)</span>, <span
class="math inline">\(H(Y|c)\)</span> est l’entropie des étiquettes de
classe données le cluster <span class="math inline">\(c\)</span>, et
<span class="math inline">\(P(y)\)</span> est la probabilité d’une
étiquette de classe <span class="math inline">\(y\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Pour mieux comprendre les propriétés du <em>Homogeneity Score</em>,
nous pouvons énoncer quelques théorèmes importants.</p>
<div class="theorem">
<p>Le <em>Homogeneity Score</em> est borné entre 0 et 1 : <span
class="math display">\[0 \leq H \leq 1\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve de ce théorème découle des propriétés de
l’entropie. L’entropie <span class="math inline">\(H(Y)\)</span> est
toujours positive, et l’entropie conditionnelle <span
class="math inline">\(H(C|Y)\)</span> est également positive. Par
conséquent, le rapport <span
class="math inline">\(\frac{H(C|Y)}{H(Y)}\)</span> est compris entre 0
et 1, ce qui implique que <span class="math inline">\(H\)</span> est
également compris entre 0 et 1. ◻</p>
</div>
<div class="theorem">
<p>Un <em>Homogeneity Score</em> de 1 indique que tous les clusters sont
composés d’instances appartenant à la même classe, tandis qu’un score de
0 indique que les clusters sont aussi mélangés que possible par rapport
aux étiquettes de classe.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Si <span class="math inline">\(H = 1\)</span>, cela
signifie que <span class="math inline">\(H(C|Y) = 0\)</span>, ce qui
implique que chaque cluster est composé d’instances appartenant à une
seule classe. Inversement, si <span class="math inline">\(H =
0\)</span>, cela signifie que <span class="math inline">\(H(C|Y) =
H(Y)\)</span>, ce qui implique que les clusters sont aussi mélangés que
possible par rapport aux étiquettes de classe. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour illustrer les propriétés du <em>Homogeneity Score</em>, nous
pouvons considérer un exemple simple.</p>
<div class="example">
<p>Supposons que nous avons un ensemble de données avec deux classes
<span class="math inline">\(Y = \{y_1, y_2\}\)</span> et trois clusters
<span class="math inline">\(C = \{c_1, c_2, c_3\}\)</span>. Les
probabilités des clusters et des étiquettes de classe sont les suivantes
: <span class="math display">\[P(c_1) = 0.5, \quad P(c_2) = 0.3, \quad
P(c_3) = 0.2\]</span> <span class="math display">\[P(y_1) = 0.6, \quad
P(y_2) = 0.4\]</span> Les entropies conditionnelles sont : <span
class="math display">\[H(Y|c_1) = 0, \quad H(Y|c_2) = 0.5, \quad
H(Y|c_3) = 1\]</span> Calculons le <em>Homogeneity Score</em> : <span
class="math display">\[H = 1 - \frac{0.5 \cdot 0 + 0.3 \cdot 0.5 + 0.2
\cdot 1}{-0.6 \log(0.6) - 0.4 \log(0.4)} = 1 - \frac{0.35}{0.613}
\approx 0.426\]</span></p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous pouvons énoncer plusieurs propriétés et corollaires du
<em>Homogeneity Score</em> :</p>
<ol>
<li><p>Le <em>Homogeneity Score</em> est invariant sous les permutations
des clusters et des étiquettes de classe.</p></li>
<li><p>Le <em>Homogeneity Score</em> est une mesure externe de la
qualité des clusters, car elle nécessite les étiquettes de classe
véritables.</p></li>
<li><p>Le <em>Homogeneity Score</em> peut être utilisé pour comparer
différents algorithmes de clustering sur le même ensemble de
données.</p></li>
</ol>
<div class="proof">
<p><em>Proof.</em> Pour prouver la propriété (i), nous devons montrer
que le <em>Homogeneity Score</em> ne change pas si nous permutons les
clusters ou les étiquettes de classe. Cela découle du fait que
l’entropie est une mesure symétrique.</p>
<p>Pour la propriété (ii), nous devons montrer que le <em>Homogeneity
Score</em> nécessite les étiquettes de classe véritables pour être
calculé. Cela est évident car l’entropie conditionnelle <span
class="math inline">\(H(C|Y)\)</span> dépend des étiquettes de classe
véritables.</p>
<p>Pour la propriété (iii), nous devons montrer que le <em>Homogeneity
Score</em> peut être utilisé pour comparer différents algorithmes de
clustering. Cela est possible car le score est normalisé entre 0 et 1,
ce qui permet une comparaison directe. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le <em>Homogeneity Score</em> est une mesure puissante et flexible
pour évaluer la qualité des clusters par rapport aux étiquettes de
classe véritables. Ses propriétés mathématiques et son interprétation
intuitive en font un outil précieux pour les chercheurs et les
praticiens dans le domaine de l’analyse des données. En comprenant et en
utilisant le <em>Homogeneity Score</em>, nous pouvons améliorer la
qualité de nos clusters et mieux comprendre la structure sous-jacente
des ensembles de données.</p>
</body>
</html>
{% include "footer.html" %}

