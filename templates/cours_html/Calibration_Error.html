{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Calibration Error: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Calibration Error: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La notion d’erreur de calibration, ou <em>calibration error</em>,
émerge dans le contexte des modèles statistiques et des systèmes de
prédiction. Historiquement, cette notion a été développée pour évaluer
la fiabilité des prévisions probabilistes. L’erreur de calibration
mesure l’écart entre les probabilités prédites et les fréquences
observées, ce qui est crucial pour garantir la robustesse des modèles
dans des applications pratiques telles que la météorologie, la finance,
et l’apprentissage automatique.</p>
<p>L’importance de cette notion réside dans sa capacité à fournir une
mesure objective de la qualité des prédictions probabilistes. Un modèle
bien calibré est celui dont les prévisions sont cohérentes avec les
événements observés. Par exemple, si un modèle prédit une probabilité de
70% pour un événement, cet événement devrait se produire environ 70% du
temps. L’erreur de calibration permet donc d’identifier et de corriger
les biais dans les modèles, améliorant ainsi leur fiabilité.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’erreur de calibration, commençons par définir ce
que nous cherchons à mesurer. Supposons que nous avons un modèle de
prédiction qui, pour chaque observation, fournit une probabilité <span
class="math inline">\(p\)</span> que l’événement se produise. Nous
voulons évaluer si ces probabilités sont cohérentes avec les fréquences
observées.</p>
<p>Formellement, soit <span class="math inline">\(\mathcal{D} = \{ (x_i,
y_i) \}_{i=1}^n\)</span> un ensemble de données, où <span
class="math inline">\(x_i\)</span> représente les caractéristiques de
l’observation et <span class="math inline">\(y_i \in \{0, 1\}\)</span>
indique si l’événement s’est produit. Soit <span
class="math inline">\(f: \mathcal{X} \rightarrow [0, 1]\)</span> une
fonction de score qui prédit la probabilité <span
class="math inline">\(p_i = f(x_i)\)</span> que <span
class="math inline">\(y_i = 1\)</span>.</p>
<p>L’erreur de calibration peut être définie comme la différence entre
la probabilité prédite et la fréquence observée. Pour un intervalle de
probabilités <span class="math inline">\([a, b]\)</span>, nous
définissons la fréquence observée comme :</p>
<p><span class="math display">\[\hat{q}([a, b]) = \frac{\sum_{i=1}^n
\mathbb{I}(p_i \in [a, b]) y_i}{\sum_{i=1}^n \mathbb{I}(p_i \in [a,
b])}\]</span></p>
<p>où <span class="math inline">\(\mathbb{I}\)</span> est la fonction
indicatrice. L’erreur de calibration pour cet intervalle est alors :</p>
<p><span class="math display">\[\text{Calibration Error}([a, b]) = |b -
a| \cdot \left| \frac{1}{n([a, b])} \sum_{i=1}^n \mathbb{I}(p_i \in [a,
b]) (y_i - p_i) \right|\]</span></p>
<p>où <span class="math inline">\(n([a, b]) = \sum_{i=1}^n
\mathbb{I}(p_i \in [a, b])\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental dans l’étude de l’erreur de calibration est
le théorème de Brier, qui fournit une mesure de la qualité des
prédictions probabilistes. Ce théorème est basé sur le score de Brier,
qui mesure la différence entre les probabilités prédites et les
événements observés.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(p_i\)</span> la probabilité prédite
que l’événement <span class="math inline">\(y_i = 1\)</span> se
produise, et soit <span class="math inline">\(y_i\)</span> l’événement
observé. Le score de Brier est défini comme :</p>
<p><span class="math display">\[\text{Brier Score} = \frac{1}{n}
\sum_{i=1}^n (y_i - p_i)^2\]</span></p>
<p>Le score de Brier est minimal lorsque les probabilités prédites sont
parfaitement calibrées, c’est-à-dire lorsque <span
class="math inline">\(p_i = \mathbb{E}[y_i | x_i]\)</span>.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Brier, nous devons montrer que le score
de Brier est minimal lorsque les probabilités prédites sont égales aux
probabilités réelles. Considérons la fonction de coût :</p>
<p><span class="math display">\[L(p, y) = (y - p)^2\]</span></p>
<p>Nous voulons minimiser cette fonction par rapport à <span
class="math inline">\(p\)</span>. En prenant la dérivée de <span
class="math inline">\(L\)</span> par rapport à <span
class="math inline">\(p\)</span>, nous obtenons :</p>
<p><span class="math display">\[\frac{\partial L}{\partial p} = -2(y -
p)\]</span></p>
<p>En égalisant la dérivée à zéro, nous trouvons :</p>
<p><span class="math display">\[-2(y - p) = 0 \implies p =
y\]</span></p>
<p>Cependant, comme <span class="math inline">\(y\)</span> est une
variable binaire, nous devons considérer l’espérance conditionnelle. En
prenant l’espérance de <span class="math inline">\(L\)</span> par
rapport à la distribution conditionnelle de <span
class="math inline">\(y\)</span> donné <span
class="math inline">\(x\)</span>, nous avons :</p>
<p><span class="math display">\[\mathbb{E}[L(p, y) | x] = \mathbb{E}[(y
- p)^2 | x]\]</span></p>
<p>En développant cette expression, nous obtenons :</p>
<p><span class="math display">\[\mathbb{E}[(y - p)^2 | x] =
\mathbb{E}[y^2 | x] - 2p\mathbb{E}[y | x] + p^2\]</span></p>
<p>Pour minimiser cette expression, nous prenons la dérivée par rapport
à <span class="math inline">\(p\)</span> :</p>
<p><span class="math display">\[\frac{\partial \mathbb{E}[L(p, y) |
x]}{\partial p} = -2\mathbb{E}[y | x] + 2p\]</span></p>
<p>En égalisant la dérivée à zéro, nous trouvons :</p>
<p><span class="math display">\[-2\mathbb{E}[y | x] + 2p = 0 \implies p
= \mathbb{E}[y | x]\]</span></p>
<p>Cela montre que le score de Brier est minimal lorsque les
probabilités prédites sont égales aux probabilités réelles.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de l’erreur
de calibration.</p>
<ol>
<li><p>L’erreur de calibration est toujours non négative. Cela découle
du fait que c’est une mesure de la différence entre les probabilités
prédites et les fréquences observées.</p></li>
<li><p>L’erreur de calibration est nulle si et seulement si le modèle
est parfaitement calibré. Cela signifie que les probabilités prédites
sont exactement égales aux fréquences observées pour tous les
intervalles de probabilités.</p></li>
<li><p>L’erreur de calibration est invariante par transformation
monotone des probabilités prédites. Cela signifie que si nous appliquons
une fonction strictement croissante aux probabilités prédites, l’erreur
de calibration reste inchangée.</p></li>
</ol>
<p>Pour prouver la propriété (iii), supposons que nous avons une
transformation monotone <span class="math inline">\(g: [0, 1]
\rightarrow [0, 1]\)</span> telle que <span
class="math inline">\(g\)</span> est strictement croissante. Nous
voulons montrer que l’erreur de calibration reste inchangée lorsque nous
remplaçons <span class="math inline">\(p_i\)</span> par <span
class="math inline">\(g(p_i)\)</span>.</p>
<p>Considérons l’erreur de calibration pour un intervalle <span
class="math inline">\([a, b]\)</span> :</p>
<p><span class="math display">\[\text{Calibration Error}([a, b]) = |b -
a| \cdot \left| \frac{1}{n([a, b])} \sum_{i=1}^n \mathbb{I}(p_i \in [a,
b]) (y_i - p_i) \right|\]</span></p>
<p>En remplaçant <span class="math inline">\(p_i\)</span> par <span
class="math inline">\(g(p_i)\)</span>, nous obtenons :</p>
<p><span class="math display">\[\text{Calibration Error}([g(a), g(b)]) =
|g(b) - g(a)| \cdot \left| \frac{1}{n([a, b])} \sum_{i=1}^n
\mathbb{I}(p_i \in [a, b]) (y_i - g(p_i)) \right|\]</span></p>
<p>Comme <span class="math inline">\(g\)</span> est strictement
croissante, nous avons <span class="math inline">\(g(b) - g(a) = b -
a\)</span>. De plus, comme <span class="math inline">\(g\)</span> est
une transformation monotone, l’ordre des probabilités prédites reste
inchangé. Par conséquent, l’erreur de calibration reste inchangée.</p>
</body>
</html>
{% include "footer.html" %}

