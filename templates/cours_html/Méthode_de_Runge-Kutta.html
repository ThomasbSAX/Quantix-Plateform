{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Méthode de Runge-Kutta : Une Approche Numérique pour les Équations Différentielles Ordinaires</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Méthode de Runge-Kutta : Une Approche Numérique pour
les Équations Différentielles Ordinaires</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les équations différentielles ordinaires (EDO) sont omniprésentes en
sciences et en ingénierie, modélisant des phénomènes allant de la
dynamique des populations à la mécanique quantique. Cependant, résoudre
analytiquement ces équations est souvent impossible. C’est ici que les
méthodes numériques entrent en jeu, et parmi elles, la méthode de
Runge-Kutta se distingue par sa précision et sa robustesse.</p>
<p>La méthode de Runge-Kutta, développée indépendamment par les
mathématiciens allemands Carl Runge et Wilhelm Kutta à la fin du XIXe
siècle, est une famille de méthodes itératives pour résoudre
numériquement les EDO. Son importance réside dans sa capacité à fournir
des solutions approchées avec une erreur contrôlée, tout en étant
relativement simple à implémenter.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant de plonger dans les détails, il est essentiel de comprendre ce
que nous cherchons à accomplir. Supposons que nous ayons une EDO de la
forme : <span class="math display">\[y&#39; = f(t, y)\]</span> avec des
conditions initiales <span class="math inline">\(y(t_0) = y_0\)</span>.
Notre objectif est de trouver une approximation de <span
class="math inline">\(y(t)\)</span> à un instant futur <span
class="math inline">\(t_n = t_0 + n \Delta t\)</span>, où <span
class="math inline">\(\Delta t\)</span> est le pas de
discrétisation.</p>
<p>Pour ce faire, nous introduisons la notion d’une méthode à un pas.
Une telle méthode utilise uniquement les informations disponibles à
l’instant courant pour calculer la solution à l’instant suivant. La
méthode de Runge-Kutta est une généralisation de cette idée, utilisant
plusieurs évaluations intermédiaires pour améliorer la précision.</p>
<div class="definition">
<p>Une méthode de Runge-Kutta d’ordre <span
class="math inline">\(p\)</span> est définie par un ensemble de
coefficients <span class="math inline">\(a_{ij}\)</span>, <span
class="math inline">\(b_i\)</span>, et <span
class="math inline">\(c_i\)</span> tels que pour chaque pas de temps, la
solution approchée <span class="math inline">\(y_{n+1}\)</span> est
donnée par : <span class="math display">\[y_{n+1} = y_n + \Delta t
\sum_{i=1}^s b_i k_i\]</span> où les <span
class="math inline">\(k_i\)</span> sont calculés comme suit : <span
class="math display">\[\begin{aligned}
k_1 &amp;= f(t_n, y_n) \\
k_2 &amp;= f(t_n + c_2 \Delta t, y_n + a_{21} \Delta t k_1) \\
&amp;\vdots \\
k_s &amp;= f(t_n + c_s \Delta t, y_n + a_{s1} \Delta t k_1 + \dots +
a_{s,s-1} \Delta t k_{s-1})
\end{aligned}\]</span> et où la matrice <span class="math inline">\(A =
(a_{ij})\)</span> est à diagonale nulle, et le vecteur <span
class="math inline">\(c\)</span> est défini par <span
class="math inline">\(c_i = \sum_{j=1}^i a_{ij}\)</span>.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux concernant les méthodes de Runge-Kutta
est celui de l’ordre. Il garantit que l’erreur d’approximation diminue
avec le pas de discrétisation selon une certaine puissance.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(y(t)\)</span> la solution exacte de
l’EDO <span class="math inline">\(y&#39; = f(t, y)\)</span>, et <span
class="math inline">\(y_n\)</span> la solution approchée obtenue par une
méthode de Runge-Kutta d’ordre <span class="math inline">\(p\)</span>.
Alors, il existe une constante <span class="math inline">\(C &gt;
0\)</span> telle que pour tout <span class="math inline">\(n\)</span>,
on a : <span class="math display">\[|y(t_n) - y_n| \leq C (\Delta
t)^p\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous devons d’abord comprendre comment
l’erreur s’accumule à chaque pas de temps. Considérons l’erreur locale
<span class="math inline">\(\epsilon_n = y(t_{n+1}) - y(t_n) - \Delta t
\sum_{i=1}^s b_i k_i\)</span>. Par le théorème du développement limité,
nous pouvons écrire : <span class="math display">\[y(t_{n+1}) = y(t_n) +
\Delta t y&#39;(t_n) + \frac{(\Delta t)^2}{2}
y&#39;&#39;(\xi_n)\]</span> pour un certain <span
class="math inline">\(\xi_n \in [t_n, t_{n+1}]\)</span>. En utilisant
les propriétés de la méthode de Runge-Kutta, nous pouvons montrer que :
<span class="math display">\[\epsilon_n = \frac{(\Delta t)^p}{p!}
y^{(p)}(\eta_n) + O((\Delta t)^{p+1})\]</span> pour un certain <span
class="math inline">\(\eta_n \in [t_n, t_{n+1}]\)</span>. L’erreur
globale est alors obtenue en sommant les erreurs locales sur tous les
pas de temps, ce qui donne le résultat souhaité.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Les méthodes de Runge-Kutta possèdent plusieurs propriétés
intéressantes, que nous énumérons ci-dessous :</p>
<ol>
<li><p>**Consistance** : Une méthode de Runge-Kutta est consistante si
et seulement si <span class="math inline">\(\sum_{i=1}^s b_i =
1\)</span>. Cela garantit que l’erreur locale tend vers zéro lorsque
<span class="math inline">\(\Delta t\)</span> tend vers zéro.</p></li>
<li><p>**Stabilité** : La stabilité d’une méthode de Runge-Kutta dépend
des valeurs propres du problème et des coefficients <span
class="math inline">\(b_i\)</span> et <span
class="math inline">\(c_i\)</span>. Une méthode est dite stable si elle
peut résoudre des problèmes raides sans produire d’oscillations
numériques.</p></li>
<li><p>**Précision** : L’ordre <span class="math inline">\(p\)</span>
d’une méthode de Runge-Kutta détermine sa précision. Plus <span
class="math inline">\(p\)</span> est élevé, plus la méthode est précise,
mais cela peut nécessiter davantage de calculs intermédiaires.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La méthode de Runge-Kutta est un outil puissant pour la résolution
numérique des EDO. Sa flexibilité et sa précision en font un choix
privilégié dans de nombreuses applications scientifiques et
industrielles. Cependant, le choix d’une méthode particulière dépend des
caractéristiques spécifiques du problème à résoudre, notamment sa
raideur et la précision requise.</p>
</body>
</html>
{% include "footer.html" %}

