{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance Totale Multivariée : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance Totale Multivariée : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La variance totale multivariée est une notion fondamentale en
statistique et en analyse des données. Elle généralise le concept
classique de variance à un cadre multidimensionnel, permettant ainsi
d’étudier la dispersion et les corrélations entre plusieurs variables
simultanément. Cette généralisation est indispensable dans de nombreux
domaines, notamment en économétrie, en biostatistique et en ingénierie
des systèmes complexes.</p>
<p>L’origine de cette notion remonte aux travaux pionniers de Karl
Pearson et Ronald Fisher au début du XXe siècle. Cependant, c’est avec
l’avènement des ordinateurs et des méthodes numériques modernes que la
variance totale multivariée a trouvé ses applications les plus
fructueuses. Elle permet de répondre à des questions cruciales telles
que la détection de structures cachées dans les données, l’analyse des
risques financiers ou encore l’optimisation des processus
industriels.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la variance totale multivariée, commençons par
rappeler le concept de variance pour une seule variable. La variance
d’une variable aléatoire <span class="math inline">\(X\)</span> est une
mesure de sa dispersion autour de son espérance mathématique. Elle est
définie comme :</p>
<p><span class="math display">\[\text{Var}(X) = \mathbb{E}\left[(X -
\mathbb{E}[X])^2\right]\]</span></p>
<p>Maintenant, considérons un vecteur aléatoire <span
class="math inline">\(\mathbf{X} = (X_1, X_2, \ldots, X_p)^T\)</span> de
dimension <span class="math inline">\(p\)</span>. La variance totale
multivariée est une généralisation de la variance qui capture à la fois
la dispersion des variables individuelles et leurs interrelations.</p>
<div class="definition">
<p>La variance totale multivariée du vecteur aléatoire <span
class="math inline">\(\mathbf{X}\)</span> est définie comme la trace de
sa matrice de covariance <span class="math inline">\(\Sigma\)</span>,
notée <span
class="math inline">\(\text{Var}_{\text{tot}}(\mathbf{X})\)</span>.
Formellement,</p>
<p><span class="math display">\[\text{Var}_{\text{tot}}(\mathbf{X}) =
\text{tr}(\Sigma) = \sum_{i=1}^p \sigma_{ii}\]</span></p>
<p>où <span class="math inline">\(\sigma_{ii} = \text{Var}(X_i)\)</span>
est la variance de la <span class="math inline">\(i\)</span>-ème
variable et <span class="math inline">\(\sigma_{ij} = \text{Cov}(X_i,
X_j)\)</span> est la covariance entre les <span
class="math inline">\(i\)</span>-ème et <span
class="math inline">\(j\)</span>-ème variables.</p>
</div>
<p>Une autre manière de formuler la variance totale multivariée est
d’utiliser l’espérance du carré de la norme euclidienne du vecteur <span
class="math inline">\(\mathbf{X}\)</span> :</p>
<p><span class="math display">\[\text{Var}_{\text{tot}}(\mathbf{X}) =
\mathbb{E}\left[ \|\mathbf{X} - \mathbb{E}[\mathbf{X}]\|^2
\right]\]</span></p>
<p>Cette formulation met en évidence le fait que la variance totale
multivariée mesure la dispersion moyenne du vecteur <span
class="math inline">\(\mathbf{X}\)</span> autour de son espérance.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental en analyse des données multivariées est le
théorème de la décomposition spectrale de la matrice de covariance. Ce
théorème permet de diagonaliser la matrice de covariance, ce qui
simplifie grandement l’analyse des données.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\Sigma\)</span> une matrice de
covariance symétrique définie positive. Il existe une matrice
orthonormale <span class="math inline">\(U\)</span> et une matrice
diagonale <span class="math inline">\(D\)</span> telles que :</p>
<p><span class="math display">\[\Sigma = U D U^T\]</span></p>
<p>où les éléments diagonaux de <span class="math inline">\(D\)</span>
sont les valeurs propres de <span class="math inline">\(\Sigma\)</span>,
notées <span class="math inline">\(\lambda_1, \lambda_2, \ldots,
\lambda_p\)</span>, et les colonnes de <span
class="math inline">\(U\)</span> sont les vecteurs propres
correspondants.</p>
</div>
<p>La décomposition spectrale permet de réécrire la variance totale
multivariée en termes des valeurs propres de la matrice de covariance
:</p>
<p><span class="math display">\[\text{Var}_{\text{tot}}(\mathbf{X}) =
\sum_{i=1}^p \lambda_i\]</span></p>
<p>Cette formulation est particulièrement utile pour l’analyse en
composantes principales (ACP), une méthode de réduction de dimension qui
utilise les valeurs propres pour identifier les directions principales
de variation des données.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de la décomposition spectrale, nous
utilisons plusieurs résultats fondamentaux de l’algèbre linéaire. Tout
d’abord, rappelons que toute matrice symétrique réelle admet une
décomposition en valeurs singulières. Ensuite, comme <span
class="math inline">\(\Sigma\)</span> est définie positive, ses valeurs
propres sont strictement positives.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\Sigma\)</span> une
matrice de covariance symétrique définie positive. Par le théorème
spectral, il existe une base orthonormale de <span
class="math inline">\(\mathbb{R}^p\)</span> constituée de vecteurs
propres de <span class="math inline">\(\Sigma\)</span>. Notons <span
class="math inline">\(U\)</span> la matrice dont les colonnes sont ces
vecteurs propres et <span class="math inline">\(D\)</span> la matrice
diagonale des valeurs propres correspondantes. Alors, par définition de
la décomposition spectrale,</p>
<p><span class="math display">\[\Sigma = U D U^T\]</span></p>
<p>Cette égalité montre que <span class="math inline">\(\Sigma\)</span>
est diagonalisable et que ses valeurs propres sont réelles et positives.
La trace de <span class="math inline">\(\Sigma\)</span> est alors égale
à la somme de ses valeurs propres :</p>
<p><span class="math display">\[\text{tr}(\Sigma) = \sum_{i=1}^p
\lambda_i\]</span></p>
<p>Ce qui achève la preuve. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La variance totale multivariée possède plusieurs propriétés
importantes qui en font un outil puissant pour l’analyse des
données.</p>
<div class="proposition">
<p>La variance totale multivariée est invariante par translation. Plus
précisément, pour tout vecteur <span class="math inline">\(\mathbf{a}
\in \mathbb{R}^p\)</span>,</p>
<p><span class="math display">\[\text{Var}_{\text{tot}}(\mathbf{X} +
\mathbf{a}) = \text{Var}_{\text{tot}}(\mathbf{X})\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\mathbf{Y} =
\mathbf{X} + \mathbf{a}\)</span>. Alors,</p>
<p><span class="math display">\[\mathbb{E}[\mathbf{Y}] =
\mathbb{E}[\mathbf{X}] + \mathbf{a}\]</span></p>
<p>et</p>
<p><span class="math display">\[\text{Cov}(\mathbf{Y}) =
\text{Cov}(\mathbf{X})\]</span></p>
<p>Par conséquent,</p>
<p><span class="math display">\[\text{Var}_{\text{tot}}(\mathbf{Y}) =
\text{tr}(\text{Cov}(\mathbf{Y})) = \text{tr}(\text{Cov}(\mathbf{X})) =
\text{Var}_{\text{tot}}(\mathbf{X})\]</span></p>
<p>Ce qui prouve l’invariance par translation. ◻</p>
</div>
<div class="proposition">
<p>La variance totale multivariée est additive. Plus précisément, pour
deux vecteurs aléatoires indépendants <span
class="math inline">\(\mathbf{X}\)</span> et <span
class="math inline">\(\mathbf{Y}\)</span>,</p>
<p><span class="math display">\[\text{Var}_{\text{tot}}(\mathbf{X} +
\mathbf{Y}) = \text{Var}_{\text{tot}}(\mathbf{X}) +
\text{Var}_{\text{tot}}(\mathbf{Y})\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\mathbf{Z} =
\mathbf{X} + \mathbf{Y}\)</span>. Comme <span
class="math inline">\(\mathbf{X}\)</span> et <span
class="math inline">\(\mathbf{Y}\)</span> sont indépendants,</p>
<p><span class="math display">\[\text{Cov}(\mathbf{Z}) =
\text{Cov}(\mathbf{X}) + \text{Cov}(\mathbf{Y})\]</span></p>
<p>Par conséquent,</p>
<p><span class="math display">\[\text{Var}_{\text{tot}}(\mathbf{Z}) =
\text{tr}(\text{Cov}(\mathbf{Z})) = \text{tr}(\text{Cov}(\mathbf{X})) +
\text{tr}(\text{Cov}(\mathbf{Y})) = \text{Var}_{\text{tot}}(\mathbf{X})
+ \text{Var}_{\text{tot}}(\mathbf{Y})\]</span></p>
<p>Ce qui prouve l’additivité de la variance totale multivariée. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La variance totale multivariée est un concept central en statistique
multidimensionnelle. Elle permet de capturer la dispersion et les
corrélations entre plusieurs variables simultanément, offrant ainsi des
outils puissants pour l’analyse des données complexes. Les théorèmes et
propriétés présentés dans cet article montrent comment cette notion peut
être utilisée pour simplifier et interpréter les structures
sous-jacentes dans les données.</p>
<p>Les applications de la variance totale multivariée sont vastes et
continuent de croître avec l’avènement des big data et des méthodes
d’apprentissage automatique. Que ce soit en économétrie, en
biostatistique ou en ingénierie, la compréhension approfondie de cette
notion est essentielle pour tirer pleinement parti des données
disponibles et prendre des décisions éclairées.</p>
</body>
</html>
{% include "footer.html" %}

