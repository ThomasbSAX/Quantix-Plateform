{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Corrélation semi-partielle : Une analyse approfondie</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Corrélation semi-partielle : Une analyse
approfondie</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La corrélation semi-partielle émerge comme une notion fondamentale en
statistique multivariée, permettant de capturer les relations linéaires
entre variables tout en contrôlant l’influence d’autres variables. Son
origine remonte aux travaux pionniers de Karl Pearson et Charles
Spearman, mais c’est avec l’avènement des modèles linéaires généralisés
que cette notion a trouvé son plein essor. La corrélation semi-partielle
est indispensable dans l’analyse des données complexes où les variables
sont interdépendantes, offrant une méthode rigoureuse pour isoler
l’effet d’une variable tout en tenant compte des autres. Elle trouve des
applications dans divers domaines, de la psychométrie à l’économie, en
passant par les sciences sociales.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la corrélation semi-partielle, considérons d’abord
une situation où nous avons trois variables <span
class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>
et <span class="math inline">\(Z\)</span>. Nous cherchons à mesurer la
relation linéaire entre <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> tout en contrôlant l’effet de <span
class="math inline">\(Z\)</span>. Intuitivement, nous voulons
"partiellement" éliminer l’influence de <span
class="math inline">\(Z\)</span> sur la relation entre <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>.</p>
<p>Formellement, la corrélation semi-partielle entre <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> contrôlant <span
class="math inline">\(Z\)</span> est définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(X, Y, Z\)</span> trois variables
aléatoires centrées et réduites. La corrélation semi-partielle entre
<span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> contrôlant <span
class="math inline">\(Z\)</span> est donnée par : <span
class="math display">\[r_{XY.Z} = \frac{\text{Cov}(X - \hat{X}, Y -
\hat{Y})}{\sqrt{\text{Var}(X - \hat{X})} \sqrt{\text{Var}(Y -
\hat{Y})}}\]</span> où <span class="math inline">\(\hat{X}\)</span> et
<span class="math inline">\(\hat{Y}\)</span> sont les prédictions
linéaires de <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> à partir de <span
class="math inline">\(Z\)</span>, c’est-à-dire : <span
class="math display">\[\hat{X} = E[X|Z] = \rho_{XZ} Z, \quad \hat{Y} =
E[Y|Z] = \rho_{YZ} Z\]</span></p>
</div>
<p>Une autre formulation équivalente est : <span
class="math display">\[r_{XY.Z} = \frac{r_{XY} - r_{XZ} r_{YZ}}{\sqrt{(1
- r_{XZ}^2)(1 - r_{YZ}^2)}}\]</span> où <span
class="math inline">\(r_{XY}\)</span>, <span
class="math inline">\(r_{XZ}\)</span> et <span
class="math inline">\(r_{YZ}\)</span> sont les coefficients de
corrélation de Pearson entre les variables correspondantes.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Considérons maintenant un théorème fondamental concernant la
corrélation semi-partielle.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X, Y, Z\)</span> trois variables
aléatoires centrées et réduites. La corrélation semi-partielle <span
class="math inline">\(r_{XY.Z}\)</span> satisfait les propriétés
suivantes :</p>
<ol>
<li><p><span class="math inline">\(-1 \leq r_{XY.Z} \leq
1\)</span></p></li>
<li><p>Si <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont indépendantes conditionnellement à
<span class="math inline">\(Z\)</span>, alors <span
class="math inline">\(r_{XY.Z} = 0\)</span></p></li>
<li><p>La corrélation semi-partielle est invariante sous transformations
linéaires des variables.</p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer le premier point, nous utilisons
l’inégalité de Cauchy-Schwarz : <span
class="math display">\[|\text{Cov}(X - \hat{X}, Y - \hat{Y})| \leq
\sqrt{\text{Var}(X - \hat{X})} \sqrt{\text{Var}(Y - \hat{Y})}\]</span>
ce qui implique directement que <span class="math inline">\(|r_{XY.Z}|
\leq 1\)</span>.</p>
<p>Pour le deuxième point, si <span class="math inline">\(X\)</span> et
<span class="math inline">\(Y\)</span> sont indépendantes
conditionnellement à <span class="math inline">\(Z\)</span>, alors :
<span class="math display">\[\text{Cov}(X - \hat{X}, Y - \hat{Y}) =
0\]</span> et donc <span class="math inline">\(r_{XY.Z} =
0\)</span>.</p>
<p>Enfin, pour le troisième point, soit <span class="math inline">\(a,
b, c\)</span> des constantes non nulles. Alors : <span
class="math display">\[r_{aX + c, bY + c.Z} = r_{XY.Z}\]</span> car les
transformations linéaires ne changent pas la structure de dépendance
conditionnelle. ◻</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour illustrer les preuves détaillées, considérons le calcul de la
corrélation semi-partielle.</p>
<div class="proof">
<p><em>Proof.</em> Nous voulons montrer que : <span
class="math display">\[r_{XY.Z} = \frac{r_{XY} - r_{XZ} r_{YZ}}{\sqrt{(1
- r_{XZ}^2)(1 - r_{YZ}^2)}}\]</span></p>
<p>Commençons par exprimer les covariances et variances en termes des
coefficients de corrélation : <span class="math display">\[\text{Cov}(X
- \hat{X}, Y - \hat{Y}) = \text{Cov}(X, Y) - \text{Cov}(X, \hat{Y}) -
\text{Cov}(\hat{X}, Y) + \text{Cov}(\hat{X}, \hat{Y})\]</span> <span
class="math display">\[= r_{XY} - r_{XZ} r_{YZ} - r_{XZ} r_{YZ} +
r_{XZ}^2 r_{YZ}^2\]</span> <span class="math display">\[= r_{XY} - 2
r_{XZ} r_{YZ} + r_{XZ}^2 r_{YZ}^2\]</span></p>
<p>De même, pour les variances : <span
class="math display">\[\text{Var}(X - \hat{X}) = 1 - r_{XZ}^2\]</span>
<span class="math display">\[\text{Var}(Y - \hat{Y}) = 1 -
r_{YZ}^2\]</span></p>
<p>En substituant ces expressions dans la définition de <span
class="math inline">\(r_{XY.Z}\)</span>, nous obtenons : <span
class="math display">\[r_{XY.Z} = \frac{r_{XY} - 2 r_{XZ} r_{YZ} +
r_{XZ}^2 r_{YZ}^2}{\sqrt{(1 - r_{XZ}^2)(1 - r_{YZ}^2)}}\]</span></p>
<p>Cependant, en simplifiant davantage, nous remarquons que : <span
class="math display">\[r_{XY} - r_{XZ} r_{YZ} = \text{Cov}(X - \hat{X},
Y - \hat{Y})\]</span> et donc : <span class="math display">\[r_{XY.Z} =
\frac{r_{XY} - r_{XZ} r_{YZ}}{\sqrt{(1 - r_{XZ}^2)(1 -
r_{YZ}^2)}}\]</span> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
corrélation semi-partielle.</p>
<div class="proposition">
<p>La corrélation semi-partielle satisfait les propriétés suivantes
:</p>
<ol>
<li><p>Symétrie : <span class="math inline">\(r_{XY.Z} =
r_{YX.Z}\)</span></p></li>
<li><p>Invariance sous permutation des variables contrôlées : <span
class="math inline">\(r_{XY.Z} = r_{X.YZ}\)</span></p></li>
<li><p>Si <span class="math inline">\(Z\)</span> est une variable
constante, alors <span class="math inline">\(r_{XY.Z} =
r_{XY}\)</span></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em> Pour la propriété (i), nous avons : <span
class="math display">\[r_{XY.Z} = \frac{\text{Cov}(X - \hat{X}, Y -
\hat{Y})}{\sqrt{\text{Var}(X - \hat{X})} \sqrt{\text{Var}(Y - \hat{Y})}}
= r_{YX.Z}\]</span></p>
<p>Pour la propriété (ii), nous utilisons le fait que les prédictions
linéaires sont symétriques en <span class="math inline">\(Y\)</span> et
<span class="math inline">\(Z\)</span>.</p>
<p>Pour la propriété (iii), si <span class="math inline">\(Z\)</span>
est constante, alors <span class="math inline">\(\hat{X} = \hat{Y} =
0\)</span>, et donc : <span class="math display">\[r_{XY.Z} =
r_{XY}\]</span> ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La corrélation semi-partielle est un outil puissant pour l’analyse
des données multivariées, permettant de capturer les relations linéaires
entre variables tout en contrôlant l’influence d’autres variables. Ses
propriétés et théorèmes fondamentaux offrent une base solide pour des
applications dans divers domaines, de la psychométrie à l’économie. Les
preuves détaillées et les corollaires présentés dans cet article
illustrent la richesse et la complexité de cette notion, ouvrant la voie
à des recherches futures dans ce domaine fascinant.</p>
</body>
</html>
{% include "footer.html" %}

