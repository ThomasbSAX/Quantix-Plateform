{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Chamfer Loss : Une Perte pour l’Appariement de Nuages de Points</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Chamfer Loss : Une Perte pour l’Appariement de Nuages
de Points</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’apprentissage de représentations géométriques à partir de nuages de
points est une tâche centrale en vision par ordinateur et en
apprentissage automatique. Les nuages de points, ensembles non
structurés de vecteurs 3D, sont omniprésents dans les applications de
réalité augmentée, de reconnaissance d’objets et de cartographie 3D.
Cependant, la nature non structurée des nuages de points rend leur
traitement complexe.</p>
<p>La perte de Chamfer (Chamfer Loss) émerge comme une solution élégante
pour l’appariement de nuages de points. Elle mesure la distance entre
deux ensembles de points en utilisant une approche basée sur les plus
proches voisins, offrant ainsi une métrique robuste et differentiable.
Cette perte est indispensable dans les architectures d’apprentissage
profond pour traiter des nuages de points, permettant une optimisation
efficace et une généralisation améliorée.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la perte de Chamfer, nous cherchons à mesurer la
distance entre deux ensembles de points <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span>. Intuitivement, cette distance devrait
capturer la proximité entre chaque point de <span
class="math inline">\(P\)</span> et le plus proche voisin dans <span
class="math inline">\(Q\)</span>, et vice versa.</p>
<p>Formellement, la perte de Chamfer est définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(P = \{ p_1, \ldots, p_n
\}\)</span> et <span class="math inline">\(Q = \{ q_1, \ldots, q_m
\}\)</span> deux ensembles de points dans <span
class="math inline">\(\mathbb{R}^d\)</span>. La perte de Chamfer est
donnée par : <span class="math display">\[L_{\text{Chamfer}}(P, Q) =
\frac{1}{n} \sum_{p \in P} \min_{q \in Q} \| p - q \|_2^2 + \frac{1}{m}
\sum_{q \in Q} \min_{p \in P} \| p - q \|_2^2\]</span></p>
</div>
<p>Cette définition peut être réécrite en utilisant des quantificateurs
: <span class="math display">\[L_{\text{Chamfer}}(P, Q) = \frac{1}{n}
\sum_{i=1}^n \min_{j=1, \ldots, m} \| p_i - q_j \|_2^2 + \frac{1}{m}
\sum_{j=1}^m \min_{i=1, \ldots, n} \| p_i - q_j \|_2^2\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la perte de Chamfer est le suivant
:</p>
<div class="theorem">
<p>La perte de Chamfer est differentiable presque partout. Plus
précisément, pour des ensembles de points <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> en position générale (i.e., aucun point
n’est équidistant de plusieurs points de l’autre ensemble), la perte de
Chamfer est differentiable.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, nous utilisons le
fait que la fonction <span class="math inline">\(\min_{q \in Q} \| p - q
\|_2^2\)</span> est differentiable en tout point <span
class="math inline">\(p\)</span> où le plus proche voisin de <span
class="math inline">\(p\)</span> dans <span
class="math inline">\(Q\)</span> est unique. Cela découle du fait que la
fonction distance au carré est differentiable et que le minimum d’une
famille de fonctions differentiables est differentiable en tout point où
l’argument du minimum est unique.</p>
<p>Ainsi, chaque terme de la somme dans la définition de <span
class="math inline">\(L_{\text{Chamfer}}(P, Q)\)</span> est
differentiable en position générale. Par conséquent, la somme totale est
également differentiable. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Considérons la preuve détaillée de la differentiabilité de la perte
de Chamfer. Nous commençons par analyser chaque terme
individuellement.</p>
<p>Soit <span class="math inline">\(p \in P\)</span> et définissons :
<span class="math display">\[f(p, Q) = \min_{q \in Q} \| p - q
\|_2^2\]</span></p>
<p>Pour un point <span class="math inline">\(p\)</span> donné, supposons
que le plus proche voisin de <span class="math inline">\(p\)</span> dans
<span class="math inline">\(Q\)</span> est unique et noté <span
class="math inline">\(q^*\)</span>. Alors, nous avons : <span
class="math display">\[f(p, Q) = \| p - q^* \|_2^2\]</span></p>
<p>Le gradient de <span class="math inline">\(f\)</span> par rapport à
<span class="math inline">\(p\)</span> est donné par : <span
class="math display">\[\nabla_p f(p, Q) = 2 (p - q^*)\]</span></p>
<p>De même, pour <span class="math inline">\(q \in Q\)</span>,
définissons : <span class="math display">\[g(q, P) = \min_{p \in P} \| p
- q \|_2^2\]</span></p>
<p>Supposons que le plus proche voisin de <span
class="math inline">\(q\)</span> dans <span
class="math inline">\(P\)</span> est unique et noté <span
class="math inline">\(p^*\)</span>. Alors, nous avons : <span
class="math display">\[g(q, P) = \| p^* - q \|_2^2\]</span></p>
<p>Le gradient de <span class="math inline">\(g\)</span> par rapport à
<span class="math inline">\(q\)</span> est donné par : <span
class="math display">\[\nabla_q g(q, P) = 2 (q - p^*)\]</span></p>
<p>Ainsi, le gradient de la perte de Chamfer est donné par : <span
class="math display">\[\nabla_{P, Q} L_{\text{Chamfer}}(P, Q) = \left(
\frac{2}{n} (p_i - q_i^*), \frac{2}{m} (q_j - p_j^*) \right)\]</span> où
<span class="math inline">\(q_i^*\)</span> est le plus proche voisin de
<span class="math inline">\(p_i\)</span> dans <span
class="math inline">\(Q\)</span>, et <span
class="math inline">\(p_j^*\)</span> est le plus proche voisin de <span
class="math inline">\(q_j\)</span> dans <span
class="math inline">\(P\)</span>.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons ci-dessous quelques propriétés importantes de la perte
de Chamfer :</p>
<ol>
<li><p><strong>Symétrie</strong> : La perte de Chamfer est symétrique,
c’est-à-dire que <span class="math inline">\(L_{\text{Chamfer}}(P, Q) =
L_{\text{Chamfer}}(Q, P)\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Cela découle directement de la définition. En effet,
nous avons : <span class="math display">\[L_{\text{Chamfer}}(P, Q) =
\frac{1}{n} \sum_{p \in P} \min_{q \in Q} \| p - q \|_2^2 + \frac{1}{m}
\sum_{q \in Q} \min_{p \in P} \| p - q \|_2^2\]</span> et <span
class="math display">\[L_{\text{Chamfer}}(Q, P) = \frac{1}{m} \sum_{q
\in Q} \min_{p \in P} \| q - p \|_2^2 + \frac{1}{n} \sum_{p \in P}
\min_{q \in Q} \| q - p \|_2^2\]</span> Comme <span
class="math inline">\(\| p - q \|_2^2 = \| q - p \|_2^2\)</span>, les
deux expressions sont égales. ◻</p>
</div></li>
<li><p><strong>Normalisation</strong> : La perte de Chamfer est
normalisée par le nombre de points dans chaque ensemble, ce qui la rend
indépendante de la taille des ensembles.</p>
<div class="proof">
<p><em>Proof.</em> La normalisation par <span
class="math inline">\(\frac{1}{n}\)</span> et <span
class="math inline">\(\frac{1}{m}\)</span> garantit que la perte est une
moyenne des distances, indépendamment de la taille des ensembles <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span>. ◻</p>
</div></li>
<li><p><strong>Robustesse</strong> : La perte de Chamfer est robuste aux
bruit et aux variations mineures dans les nuages de points.</p>
<div class="proof">
<p><em>Proof.</em> La minimisation des distances aux plus proches
voisins rend la perte insensible aux petites perturbations, car les
points bruités sont appariés à leurs voisins les plus proches. ◻</p>
</div></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La perte de Chamfer est un outil puissant pour l’appariement de
nuages de points, offrant une métrique differentiable et robuste. Son
utilisation dans les architectures d’apprentissage profond a permis des
avancées significatives dans le traitement des données géométriques. Les
propriétés et théorèmes présentés dans cet article soulignent son
importance et sa polyvalence dans divers domaines de la vision par
ordinateur et de l’apprentissage automatique.</p>
</body>
</html>
{% include "footer.html" %}

