{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Réduction de dimension non-linéaire : Méthodes et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Réduction de dimension non-linéaire : Méthodes et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La réduction de dimension est une problématique centrale en
apprentissage automatique et en analyse de données. L’objectif est de
projeter des données de haute dimension dans un espace de plus faible
dimension tout en préservant les structures sous-jacentes. Les méthodes
linéaires, telles que l’Analyse en Composantes Principales (ACP), sont
largement utilisées pour leur simplicité et leur efficacité. Cependant,
elles supposent que les données peuvent être linéairement séparées, ce
qui n’est pas toujours le cas.</p>
<p>La réduction de dimension non-linéaire émerge comme une solution pour
capturer des structures complexes et des relations non linéaires dans
les données. Cette approche est indispensable dans de nombreux domaines,
tels que la vision par ordinateur, la bioinformatique et les sciences
sociales, où les données présentent souvent des dépendances non
linéaires.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la réduction de dimension non-linéaire, il est
essentiel de définir quelques concepts clés.</p>
<h2 class="unnumbered" id="manifold">Manifold</h2>
<p>Considérons un ensemble de données <span class="math inline">\(X =
\{x_1, x_2, \ldots, x_n\}\)</span> dans <span
class="math inline">\(\mathbb{R}^d\)</span>. Nous cherchons à
représenter ces données sur une variété (manifold) de dimension <span
class="math inline">\(m\)</span>, où <span class="math inline">\(m &lt;
d\)</span>. Une variété est un espace topologique localement homéomorphe
à <span class="math inline">\(\mathbb{R}^m\)</span>.</p>
<div class="definition">
<p>Soit <span class="math inline">\(M\)</span> un ensemble. On dit que
<span class="math inline">\(M\)</span> est une variété de dimension
<span class="math inline">\(m\)</span> si pour tout point <span
class="math inline">\(p \in M\)</span>, il existe un voisinage <span
class="math inline">\(U\)</span> de <span
class="math inline">\(p\)</span> et une application <span
class="math inline">\(\phi: U \rightarrow V \subset
\mathbb{R}^m\)</span> qui est un homéomorphisme.</p>
</div>
<h2 class="unnumbered" id="projection-non-linéaire">Projection
Non-Linéaire</h2>
<p>La projection non-linéaire consiste à trouver une application <span
class="math inline">\(f: \mathbb{R}^d \rightarrow \mathbb{R}^m\)</span>
telle que les relations non linéaires entre les données soient
préservées.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X \subset \mathbb{R}^d\)</span> un
ensemble de données. Une projection non-linéaire est une application
<span class="math inline">\(f: X \rightarrow Y \subset
\mathbb{R}^m\)</span> telle que pour tout <span
class="math inline">\(x_i, x_j \in X\)</span>, la distance <span
class="math inline">\(\|f(x_i) - f(x_j)\|\)</span> est préservée au
mieux.</p>
</div>
<h1 class="unnumbered"
id="méthodes-de-réduction-de-dimension-non-linéaire">Méthodes de
Réduction de Dimension Non-Linéaire</h1>
<p>Plusieurs méthodes ont été développées pour effectuer une réduction
de dimension non-linéaire. Nous en présentons quelques-unes ici.</p>
<h2 class="unnumbered" id="isomap">Isomap</h2>
<p>L’Isomap (Isometric Mapping) est une méthode qui utilise les
distances géodésiques pour capturer la structure non linéaire des
données.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X = \{x_1, x_2, \ldots,
x_n\}\)</span> un ensemble de données. L’Isomap consiste à :</p>
<ol>
<li><p>Construire un graphe des <span
class="math inline">\(k\)</span>-plus proches voisins.</p></li>
<li><p>Calculer les distances géodésiques entre chaque paire de points
en utilisant l’algorithme de Dijkstra.</p></li>
<li><p>Appliquer une ACP sur la matrice des distances géodésiques pour
obtenir les coordonnées de basse dimension.</p></li>
</ol>
</div>
<h2 class="unnumbered" id="locally-linear-embedding-lle">Locally Linear
Embedding (LLE)</h2>
<p>Le LLE est une autre méthode populaire pour la réduction de dimension
non-linéaire. Il suppose que les données peuvent être représentées comme
des combinaisons linéaires de leurs voisins.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X = \{x_1, x_2, \ldots,
x_n\}\)</span> un ensemble de données. Le LLE consiste à :</p>
<ol>
<li><p>Pour chaque point <span class="math inline">\(x_i\)</span>,
trouver les coefficients <span class="math inline">\(w_{ij}\)</span>
tels que <span class="math inline">\(x_i = \sum_j w_{ij} x_j\)</span>,
où <span class="math inline">\(x_j\)</span> sont les <span
class="math inline">\(k\)</span>-plus proches voisins de <span
class="math inline">\(x_i\)</span>.</p></li>
<li><p>Minimiser la somme des carrés des distances entre les points
projetés et leurs reconstructions linéaires.</p></li>
<li><p>Appliquer une ACP sur la matrice des coefficients pour obtenir
les coordonnées de basse dimension.</p></li>
</ol>
</div>
<h1 class="unnumbered" id="théorèmes-et-preuves">Théorèmes et
Preuves</h1>
<p>Nous présentons ici quelques théorèmes importants liés à la réduction
de dimension non-linéaire.</p>
<h2 class="unnumbered" id="théorème-de-lisomap">Théorème de
l’Isomap</h2>
<p>Le théorème suivant montre que l’Isomap peut récupérer la structure
géométrique des données si elles sont échantillonnées à partir d’une
variété.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(M\)</span> une variété de dimension
<span class="math inline">\(m\)</span> plongée dans <span
class="math inline">\(\mathbb{R}^d\)</span>. Si les données sont
échantillonnées uniformément sur <span class="math inline">\(M\)</span>,
alors l’Isomap peut récupérer la structure géométrique de <span
class="math inline">\(M\)</span> avec une erreur qui tend vers zéro
lorsque le nombre de points tend vers l’infini.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve repose sur le fait que les distances
géodésiques entre les points convergent vers les vraies distances
géodésiques sur la variété lorsque le nombre de points tend vers
l’infini. Ensuite, l’ACP appliquée sur la matrice des distances
géodésiques permet de récupérer les coordonnées de basse
dimension. ◻</p>
</div>
<h2 class="unnumbered" id="théorème-du-lle">Théorème du LLE</h2>
<p>Le théorème suivant montre que le LLE peut récupérer la structure
locale des données.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X = \{x_1, x_2, \ldots,
x_n\}\)</span> un ensemble de données échantillonnées à partir d’une
variété <span class="math inline">\(M\)</span>. Si les données sont
suffisamment denses, alors le LLE peut récupérer la structure locale de
<span class="math inline">\(M\)</span> avec une erreur qui tend vers
zéro lorsque le nombre de points tend vers l’infini.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve repose sur le fait que les coefficients
<span class="math inline">\(w_{ij}\)</span> convergent vers les vraies
relations linéaires locales entre les points lorsque le nombre de points
tend vers l’infini. Ensuite, la minimisation de la somme des carrés des
distances permet de récupérer les coordonnées de basse dimension. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous présentons ici quelques propriétés et corollaires importants
liés à la réduction de dimension non-linéaire.</p>
<h2 class="unnumbered" id="propriétés-de-lisomap">Propriétés de
l’Isomap</h2>
<ol>
<li><p>L’Isomap préserve les distances géodésiques entre les
points.</p></li>
<li><p>L’Isomap peut récupérer la structure globale des données si elles
sont échantillonnées uniformément sur une variété.</p></li>
</ol>
<h2 class="unnumbered" id="propriétés-du-lle">Propriétés du LLE</h2>
<ol>
<li><p>Le LLE préserve les relations linéaires locales entre les
points.</p></li>
<li><p>Le LLE peut récupérer la structure locale des données si elles
sont suffisamment denses.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La réduction de dimension non-linéaire est une approche puissante
pour capturer des structures complexes et des relations non linéaires
dans les données. Les méthodes telles que l’Isomap et le LLE ont
démontré leur efficacité dans de nombreux domaines. Cependant, des défis
demeurent, notamment en termes de scalabilité et d’interprétabilité. Les
recherches futures devraient se concentrer sur le développement de
méthodes plus robustes et efficaces pour la réduction de dimension
non-linéaire.</p>
</body>
</html>
{% include "footer.html" %}

