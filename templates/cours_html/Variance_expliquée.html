{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance Expliquée : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance Expliquée : Fondements et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La variance, concept central en statistique et en probabilité, émerge
comme une mesure fondamentale de la dispersion des données autour d’une
moyenne. Son origine remonte aux travaux pionniers de Carl Friedrich
Gauss au début du XIXe siècle, dans le cadre de la théorie des erreurs.
La variance répond à un besoin crucial : quantifier l’écart entre les
observations et leur valeur centrale, permettant ainsi de comprendre la
variabilité inhérente aux phénomènes étudiés.</p>
<p>Dans un cadre plus moderne, la variance est indispensable en analyse
de données, en apprentissage automatique, et même en finance pour
évaluer les risques. Elle permet de comparer la stabilité de différentes
distributions et de prendre des décisions éclairées basées sur la
dispersion des données.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la variance, considérons un ensemble de données ou
une distribution de probabilité. Nous cherchons à mesurer à quel point
les valeurs individuelles s’écartent de la moyenne. Intuitivement, plus
les points sont éloignés de la moyenne, plus la variance sera
élevée.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X = \{x_1, x_2, \ldots,
x_n\}\)</span> un ensemble de <span class="math inline">\(n\)</span>
observations. La variance <span class="math inline">\(\sigma^2\)</span>
est définie comme la moyenne des carrés des écarts à la moyenne <span
class="math inline">\(\mu\)</span>.</p>
<p><span class="math display">\[\sigma^2 = \frac{1}{n} \sum_{i=1}^{n}
(x_i - \mu)^2\]</span></p>
<p>où <span class="math inline">\(\mu = \frac{1}{n} \sum_{i=1}^{n}
x_i\)</span> est la moyenne des observations.</p>
</div>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
discrète prenant les valeurs <span class="math inline">\(x_1, x_2,
\ldots, x_n\)</span> avec les probabilités correspondantes <span
class="math inline">\(p_1, p_2, \ldots, p_n\)</span>. La variance de
<span class="math inline">\(X\)</span> est donnée par :</p>
<p><span class="math display">\[\text{Var}(X) = \sum_{i=1}^{n} p_i (x_i
- \mathbb{E}[X])^2\]</span></p>
<p>où <span class="math inline">\(\mathbb{E}[X] = \sum_{i=1}^{n} x_i
p_i\)</span> est l’espérance mathématique de <span
class="math inline">\(X\)</span>.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la variance est celui de la linéarité
de la variance pour les variables aléatoires indépendantes.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> deux variables aléatoires
indépendantes. La variance de la somme <span class="math inline">\(X +
Y\)</span> est égale à la somme des variances :</p>
<p><span class="math display">\[\text{Var}(X + Y) = \text{Var}(X) +
\text{Var}(Y)\]</span></p>
<p>De manière plus générale, pour des variables aléatoires <span
class="math inline">\(X_1, X_2, \ldots, X_n\)</span> deux à deux
indépendantes, on a :</p>
<p><span class="math display">\[\text{Var}\left(\sum_{i=1}^{n}
X_i\right) = \sum_{i=1}^{n} \text{Var}(X_i)\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<div class="proof">
<p><em>Proof.</em> Pour démontrer la linéarité de la variance, nous
utilisons les propriétés de l’espérance et de la variance. Considérons
deux variables aléatoires indépendantes <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>.</p>
<p>Premièrement, nous avons :</p>
<p><span class="math display">\[\mathbb{E}[X + Y] = \mathbb{E}[X] +
\mathbb{E}[Y]\]</span></p>
<p>Ensuite, la variance de <span class="math inline">\(X + Y\)</span>
est définie par :</p>
<p><span class="math display">\[\text{Var}(X + Y) = \mathbb{E}\left[((X
+ Y) - \mathbb{E}[X + Y])^2\right]\]</span></p>
<p>En développant le carré, nous obtenons :</p>
<p><span class="math display">\[\text{Var}(X + Y) = \mathbb{E}\left[(X -
\mathbb{E}[X] + Y - \mathbb{E}[Y])^2\right]\]</span></p>
<p>En utilisant l’indépendance de <span class="math inline">\(X\)</span>
et <span class="math inline">\(Y\)</span>, le produit des écarts est nul
en espérance :</p>
<p><span class="math display">\[\mathbb{E}\left[(X - \mathbb{E}[X])(Y -
\mathbb{E}[Y])\right] = 0\]</span></p>
<p>Ainsi, nous avons :</p>
<p><span class="math display">\[\text{Var}(X + Y) = \mathbb{E}\left[(X -
\mathbb{E}[X])^2\right] + \mathbb{E}\left[(Y -
\mathbb{E}[Y])^2\right]\]</span></p>
<p>Ce qui prouve que :</p>
<p><span class="math display">\[\text{Var}(X + Y) = \text{Var}(X) +
\text{Var}(Y)\]</span></p>
<p>Pour généraliser à <span class="math inline">\(n\)</span> variables
aléatoires indépendantes, le raisonnement est identique en appliquant la
propriété de manière itérative. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<ol>
<li><p>La variance est toujours non négative, c’est-à-dire <span
class="math inline">\(\text{Var}(X) \geq 0\)</span> pour toute variable
aléatoire <span class="math inline">\(X\)</span>.</p></li>
<li><p>La variance d’une constante est nulle, c’est-à-dire si <span
class="math inline">\(X = c\)</span> où <span
class="math inline">\(c\)</span> est une constante, alors <span
class="math inline">\(\text{Var}(X) = 0\)</span>.</p></li>
<li><p>La variance est invariante par translation, c’est-à-dire si <span
class="math inline">\(Y = X + c\)</span> où <span
class="math inline">\(c\)</span> est une constante, alors <span
class="math inline">\(\text{Var}(Y) = \text{Var}(X)\)</span>.</p></li>
<li><p>La variance est homogène de degré 2, c’est-à-dire si <span
class="math inline">\(Y = aX\)</span> où <span
class="math inline">\(a\)</span> est une constante, alors <span
class="math inline">\(\text{Var}(Y) = a^2
\text{Var}(X)\)</span>.</p></li>
</ol>
<div class="proof">
<p><em>Proof.</em> Pour démontrer la propriété (iii), considérons <span
class="math inline">\(Y = X + c\)</span>. La variance de <span
class="math inline">\(Y\)</span> est donnée par :</p>
<p><span class="math display">\[\text{Var}(Y) = \mathbb{E}\left[(Y -
\mathbb{E}[Y])^2\right]\]</span></p>
<p>En substituant <span class="math inline">\(Y = X + c\)</span>, nous
avons :</p>
<p><span class="math display">\[\mathbb{E}[Y] = \mathbb{E}[X] +
c\]</span></p>
<p>Ainsi,</p>
<p><span class="math display">\[\text{Var}(Y) = \mathbb{E}\left[(X + c -
(\mathbb{E}[X] + c))^2\right] = \mathbb{E}\left[(X -
\mathbb{E}[X])^2\right] = \text{Var}(X)\]</span></p>
<p>Ce qui prouve que la variance est invariante par translation. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La variance est un outil puissant pour comprendre la dispersion des
données et évaluer la variabilité des phénomènes étudiés. Ses propriétés
et théorèmes associés en font un concept fondamental en statistique et
en probabilité, avec des applications pratiques dans de nombreux
domaines. Une compréhension approfondie de la variance est essentielle
pour toute analyse statistique rigoureuse.</p>
</body>
</html>
{% include "footer.html" %}

