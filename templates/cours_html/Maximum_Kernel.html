{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Maximum Kernel : Théorie et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Maximum Kernel : Théorie et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’analyse des données est un domaine en pleine expansion, notamment
avec l’essor de l’apprentissage automatique. Parmi les outils les plus
puissants, on trouve les méthodes basées sur les noyaux (kernels), qui
permettent de transformer des données non linéairement séparables en un
espace où elles deviennent linéairement séparables. Le maximum kernel,
une généralisation des noyaux classiques, émerge comme un outil
indispensable pour traiter des problèmes complexes où les données
présentent des structures hiérarchiques ou des dépendances non
linéaires.</p>
<p>L’idée sous-jacente au maximum kernel est de capturer les relations
maximales entre les données, en exploitant des fonctions de noyau qui
peuvent être vues comme des mesures de similarité. Ce concept trouve ses
racines dans la théorie des fonctions reproduisantes (RKHS) et a été
popularisé par les travaux de Bernard Schölkopf et ses collaborateurs
dans le cadre des machines à vecteurs de support (SVM).</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre le maximum kernel, commençons par rappeler quelques
notions fondamentales.</p>
<h2 class="unnumbered" id="noyau-et-espace-de-hilbert">Noyau et Espace
de Hilbert</h2>
<p>Un noyau est une fonction qui mesure la similarité entre deux
vecteurs. Formellement, un noyau est une fonction <span
class="math inline">\(k: \mathcal{X} \times \mathcal{X} \to
\mathbb{R}\)</span> qui est symétrique et positive définie. Cela
signifie que pour tout ensemble de points <span
class="math inline">\(\{x_1, \dots, x_n\}\)</span> dans <span
class="math inline">\(\mathcal{X}\)</span>, la matrice de Gram <span
class="math inline">\(K\)</span> définie par <span
class="math inline">\(K_{ij} = k(x_i, x_j)\)</span> est positive
semi-définie.</p>
<p>Un espace de Hilbert à noyau reproduisant (RKHS) est un espace de
fonctions <span class="math inline">\(\mathcal{H}\)</span> associé à un
noyau <span class="math inline">\(k\)</span>, tel que pour tout point
<span class="math inline">\(x \in \mathcal{X}\)</span>, la fonction
<span class="math inline">\(k(x, \cdot)\)</span> appartient à <span
class="math inline">\(\mathcal{H}\)</span>.</p>
<h2 class="unnumbered" id="maximum-kernel">Maximum Kernel</h2>
<p>Le maximum kernel est une généralisation des noyaux classiques, où
l’on cherche à capturer les relations maximales entre les données.
Formellement, soit <span class="math inline">\(\mathcal{X}\)</span> un
ensemble de points et <span class="math inline">\(k: \mathcal{X} \times
\mathcal{X} \to \mathbb{R}\)</span> un noyau. Le maximum kernel <span
class="math inline">\(k_{\text{max}}\)</span> est défini comme suit
:</p>
<p><span class="math display">\[k_{\text{max}}(x, y) = \max_{i=1, \dots,
n} k(x_i, x) \cdot k(x_i, y)\]</span></p>
<p>où <span class="math inline">\(\{x_1, \dots, x_n\}\)</span> est un
ensemble de points dans <span
class="math inline">\(\mathcal{X}\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<h2 class="unnumbered"
id="théorème-de-représentation-du-maximum-kernel">Théorème de
Représentation du Maximum Kernel</h2>
<p>Le maximum kernel peut être représenté comme un produit de noyaux.
Plus précisément, nous avons le théorème suivant :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(k\)</span> un noyau et <span
class="math inline">\(\{x_1, \dots, x_n\}\)</span> un ensemble de points
dans <span class="math inline">\(\mathcal{X}\)</span>. Alors le maximum
kernel <span class="math inline">\(k_{\text{max}}\)</span> peut être
écrit comme :</p>
<p><span class="math display">\[k_{\text{max}}(x, y) = \sum_{i=1}^n
k(x_i, x) \cdot k(x_i, y)\]</span></p>
<p>où les coefficients <span class="math inline">\(\alpha_i = k(x_i,
x)\)</span> sont déterminés par le point <span
class="math inline">\(x\)</span>.</p>
</div>
<h2 class="unnumbered" id="preuve-du-théorème-de-représentation">Preuve
du Théorème de Représentation</h2>
<p>Pour prouver ce théorème, nous utilisons le fait que le maximum
kernel est une combinaison convexe des noyaux <span
class="math inline">\(k(x_i, \cdot)\)</span>. En effet, pour tout point
<span class="math inline">\(x\)</span>, nous pouvons écrire :</p>
<p><span class="math display">\[k_{\text{max}}(x, y) = \max_{i=1, \dots,
n} k(x_i, x) \cdot k(x_i, y) = \sum_{i=1}^n \alpha_i(x) \cdot k(x_i,
y)\]</span></p>
<p>où <span class="math inline">\(\alpha_i(x) = \mathbb{I}_{i =
\arg\max_{j=1, \dots, n} k(x_j, x)}\)</span> est une fonction
indicatrice. En utilisant les propriétés des noyaux et la positivité de
<span class="math inline">\(k\)</span>, nous pouvons montrer que cette
représentation est valide.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<h2 class="unnumbered" id="propriété-de-symétrie">Propriété de
Symétrie</h2>
<p>Le maximum kernel est symétrique, c’est-à-dire que pour tout <span
class="math inline">\(x, y \in \mathcal{X}\)</span>, nous avons :</p>
<p><span class="math display">\[k_{\text{max}}(x, y) = k_{\text{max}}(y,
x)\]</span></p>
<h2 class="unnumbered" id="propriété-de-positive-définité">Propriété de
Positive Définité</h2>
<p>Le maximum kernel est positive semi-définie. Cela signifie que pour
tout ensemble de points <span class="math inline">\(\{x_1, \dots,
x_n\}\)</span> dans <span class="math inline">\(\mathcal{X}\)</span>, la
matrice de Gram <span class="math inline">\(K_{\text{max}}\)</span>
définie par <span class="math inline">\(K_{\text{max}, ij} =
k_{\text{max}}(x_i, x_j)\)</span> est positive semi-définie.</p>
<h2 class="unnumbered" id="corollaire-de-représentation">Corollaire de
Représentation</h2>
<p>Un corollaire du théorème de représentation est que le maximum kernel
peut être vu comme une combinaison linéaire des noyaux <span
class="math inline">\(k(x_i, \cdot)\)</span>. Cela permet de l’utiliser
dans les algorithmes d’apprentissage automatique qui nécessitent des
noyaux positifs définis.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le maximum kernel est un outil puissant pour capturer les relations
maximales entre les données. Ses propriétés de symétrie et de positive
définité en font un candidat idéal pour une utilisation dans les
méthodes d’apprentissage automatique, notamment les machines à vecteurs
de support. Les travaux futurs pourraient explorer des extensions du
maximum kernel pour traiter des données de plus haute dimension et des
structures plus complexes.</p>
</body>
</html>
{% include "footer.html" %}

