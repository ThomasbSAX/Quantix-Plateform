{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Matrice de Confusion : Un Outil Fondamental en Apprentissage Automatique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Matrice de Confusion : Un Outil Fondamental en
Apprentissage Automatique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’apprentissage automatique, en tant que discipline scientifique,
repose sur la capacité à évaluer et à interpréter les performances des
modèles prédictifs. Dans ce contexte, la matrice de confusion émerge
comme un outil indispensable pour quantifier et visualiser les erreurs
commises par un classificateur. Son origine remonte aux travaux
pionniers en statistique et en intelligence artificielle, où la
nécessité de comprendre les failles des modèles s’est imposée comme une
priorité.</p>
<p>La matrice de confusion trouve son utilité dans divers domaines,
allant de la médecine à la finance, en passant par la reconnaissance
d’images. Elle permet non seulement d’évaluer la précision des modèles,
mais aussi de mettre en lumière les types spécifiques d’erreurs
commises. Cela est crucial pour améliorer les algorithmes et adapter
leurs performances aux besoins spécifiques des applications.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la matrice de confusion, considérons un
classificateur binaire qui prédit l’appartenance d’une observation à une
de deux classes, par exemple "positif" ou "négatif". Nous cherchons à
quantifier les erreurs de classification en comparant les prédictions du
modèle aux étiquettes réelles.</p>
<div class="definition">
<p>Soit <span class="math inline">\(C\)</span> une matrice de confusion
associée à un classificateur binaire. Pour un ensemble de données <span
class="math inline">\(D\)</span> contenant <span
class="math inline">\(N\)</span> observations, <span
class="math inline">\(C\)</span> est une matrice <span
class="math inline">\(2 \times 2\)</span> définie comme suit :</p>
<p><span class="math display">\[C = \begin{pmatrix}
TP &amp; FP \\
FN &amp; TN
\end{pmatrix}\]</span></p>
<p>où :</p>
<ul>
<li><p><span class="math inline">\(TP\)</span> (True Positives) est le
nombre de vrais positifs, c’est-à-dire le nombre d’observations
correctement prédites comme positives.</p></li>
<li><p><span class="math inline">\(FP\)</span> (False Positives) est le
nombre de faux positifs, c’est-à-dire le nombre d’observations
incorrectement prédites comme positives.</p></li>
<li><p><span class="math inline">\(FN\)</span> (False Negatives) est le
nombre de faux négatifs, c’est-à-dire le nombre d’observations
incorrectement prédites comme négatives.</p></li>
<li><p><span class="math inline">\(TN\)</span> (True Negatives) est le
nombre de vrais négatifs, c’est-à-dire le nombre d’observations
correctement prédites comme négatives.</p></li>
</ul>
<p>Formellement, pour toute observation <span class="math inline">\(x_i
\in D\)</span>, avec <span class="math inline">\(y_i\)</span> son
étiquette réelle et <span class="math inline">\(\hat{y}_i\)</span> sa
prédiction, nous avons :</p>
<p><span class="math display">\[TP = \sum_{i=1}^{N} \mathbb{1}(y_i = 1
\land \hat{y}_i = 1)\]</span> <span class="math display">\[FP =
\sum_{i=1}^{N} \mathbb{1}(y_i = 0 \land \hat{y}_i = 1)\]</span> <span
class="math display">\[FN = \sum_{i=1}^{N} \mathbb{1}(y_i = 1 \land
\hat{y}_i = 0)\]</span> <span class="math display">\[TN = \sum_{i=1}^{N}
\mathbb{1}(y_i = 0 \land \hat{y}_i = 0)\]</span></p>
<p>où <span class="math inline">\(\mathbb{1}\)</span> est la fonction
indicatrice.</p>
</div>
<h1 class="unnumbered" id="théorèmes-et-propriétés">Théorèmes et
Propriétés</h1>
<p>La matrice de confusion permet de calculer plusieurs métriques
importantes pour évaluer les performances d’un classificateur. Voici
quelques-unes des principales métriques dérivées de la matrice de
confusion.</p>
<div class="theorem">
<p>La précision (<span class="math inline">\(P\)</span>) d’un
classificateur est définie comme le rapport entre le nombre de vrais
positifs et la somme des vrais positifs et des faux positifs.
Formellement :</p>
<p><span class="math display">\[P = \frac{TP}{TP + FP}\]</span></p>
<p>Cette métrique mesure la capacité du classificateur à ne prédire
comme positif que les observations qui le sont réellement.</p>
</div>
<div class="theorem">
<p>Le rappel (<span class="math inline">\(R\)</span>) d’un
classificateur est défini comme le rapport entre le nombre de vrais
positifs et la somme des vrais positifs et des faux négatifs.
Formellement :</p>
<p><span class="math display">\[R = \frac{TP}{TP + FN}\]</span></p>
<p>Cette métrique mesure la capacité du classificateur à identifier
toutes les observations positives.</p>
</div>
<div class="theorem">
<p>Le F-score (<span class="math inline">\(F\)</span>) est une métrique
qui combine la précision et le rappel. Il est défini comme la moyenne
harmonique de la précision et du rappel. Formellement :</p>
<p><span class="math display">\[F = 2 \cdot \frac{P \cdot R}{P +
R}\]</span></p>
<p>Le F-score est particulièrement utile lorsque l’on souhaite
équilibrer la précision et le rappel.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour démontrer les propriétés des métriques dérivées de la matrice de
confusion, nous allons utiliser les définitions précédentes.</p>
<div class="proof">
<p><em>Preuve du Théorème de la Précision.</em> Soit <span
class="math inline">\(C\)</span> une matrice de confusion associée à un
classificateur binaire. La précision est définie comme le rapport entre
le nombre de vrais positifs et la somme des vrais positifs et des faux
positifs. Par définition, nous avons :</p>
<p><span class="math display">\[P = \frac{TP}{TP + FP}\]</span></p>
<p>Cette formule est directement dérivée de la matrice de confusion et
mesure la proportion des prédictions positives qui sont correctes. ◻</p>
</div>
<div class="proof">
<p><em>Preuve du Théorème du Rappel.</em> De manière similaire, le
rappel est défini comme le rapport entre le nombre de vrais positifs et
la somme des vrais positifs et des faux négatifs. Par définition, nous
avons :</p>
<p><span class="math display">\[R = \frac{TP}{TP + FN}\]</span></p>
<p>Cette formule mesure la proportion des observations positives qui
sont correctement identifiées par le classificateur. ◻</p>
</div>
<div class="proof">
<p><em>Preuve du Théorème du F-score.</em> Le F-score est la moyenne
harmonique de la précision et du rappel. Par définition, nous avons
:</p>
<p><span class="math display">\[F = 2 \cdot \frac{P \cdot R}{P +
R}\]</span></p>
<p>Cette formule permet de combiner la précision et le rappel en une
seule métrique, ce qui est utile pour évaluer globalement les
performances du classificateur. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La matrice de confusion et les métriques dérivées possèdent plusieurs
propriétés intéressantes qui peuvent être utilisées pour améliorer les
performances des classificateurs.</p>
<div class="corollaire">
<p>Soit <span class="math inline">\(C\)</span> une matrice de confusion
associée à un classificateur binaire. Les propriétés suivantes sont
vérifiées :</p>
<ul>
<li><p><span class="math inline">\(TP + FP + FN + TN = N\)</span>, où
<span class="math inline">\(N\)</span> est le nombre total
d’observations.</p></li>
<li><p>La précision et le rappel sont compris entre 0 et 1, c’est-à-dire
<span class="math inline">\(P \in [0, 1]\)</span> et <span
class="math inline">\(R \in [0, 1]\)</span>.</p></li>
<li><p>Le F-score est également compris entre 0 et 1, c’est-à-dire <span
class="math inline">\(F \in [0, 1]\)</span>.</p></li>
</ul>
</div>
<div class="proof">
<p><em>Preuve des Propriétés de la Matrice de Confusion.</em> La
première propriété découle directement de la définition de la matrice de
confusion, car chaque observation est comptée exactement une fois dans
l’une des quatre catégories.</p>
<p>Pour la deuxième propriété, nous savons que <span
class="math inline">\(TP\)</span>, <span
class="math inline">\(FP\)</span>, <span
class="math inline">\(FN\)</span> et <span
class="math inline">\(TN\)</span> sont tous des nombres entiers positifs
ou nuls. Par conséquent, la précision et le rappel sont des rapports de
nombres entiers positifs ou nuls, ce qui implique qu’ils sont compris
entre 0 et 1.</p>
<p>La troisième propriété découle de la définition du F-score comme
moyenne harmonique de la précision et du rappel. Comme la précision et
le rappel sont compris entre 0 et 1, leur moyenne harmonique l’est
également. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La matrice de confusion est un outil fondamental en apprentissage
automatique pour évaluer les performances des classificateurs. Elle
permet de quantifier et de visualiser les erreurs commises par un
modèle, ce qui est essentiel pour améliorer ses performances. Les
métriques dérivées de la matrice de confusion, telles que la précision,
le rappel et le F-score, fournissent des informations précieuses pour
comprendre les forces et les faiblesses d’un classificateur.</p>
<p>En conclusion, la matrice de confusion est un outil indispensable
pour tout chercheur ou praticien en apprentissage automatique. Son
utilisation permet de développer des modèles plus robustes et plus
précis, adaptés aux besoins spécifiques des applications.</p>
</body>
</html>
{% include "footer.html" %}

