{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Loi bêta-binomiale a posteriori : Une approche bayésienne pour l’estimation de probabilités</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Loi bêta-binomiale a posteriori : Une approche
bayésienne pour l’estimation de probabilités</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La loi bêta-binomiale a posteriori émerge comme un outil fondamental
dans l’analyse bayésienne des données binomiales. Son importance réside
dans sa capacité à modéliser l’incertitude associée à l’estimation de
probabilités à partir d’observations discrètes. Historiquement, cette
loi a été développée pour répondre au besoin de combiner des
informations a priori avec des données observées, permettant ainsi une
estimation plus robuste et flexible des paramètres inconnus.</p>
<p>Dans un cadre bayésien, l’estimation de probabilités repose sur la
mise à jour des croyances a priori en fonction des données observées. La
loi bêta-binomiale a posteriori joue un rôle clé dans ce processus, en
fournissant une distribution de probabilité qui capture l’incertitude
résiduelle après l’observation des données. Cette approche est
particulièrement utile dans les domaines où les données sont limitées ou
sujettes à des variations importantes.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la loi bêta-binomiale a posteriori, commençons par
définir les concepts de base. Supposons que nous observions un nombre
<span class="math inline">\(n\)</span> d’essais indépendants, chacun
ayant une probabilité de succès <span class="math inline">\(p\)</span>.
Nous voulons estimer cette probabilité <span
class="math inline">\(p\)</span> en utilisant une approche
bayésienne.</p>
<p>Avant de voir les données, nous avons une distribution a priori pour
<span class="math inline">\(p\)</span>, souvent modélisée par une loi
bêta de paramètres <span class="math inline">\(\alpha\)</span> et <span
class="math inline">\(\beta\)</span>. La densité de probabilité a priori
est donnée par :</p>
<p><span class="math display">\[f_{\text{a priori}}(p) = \frac{p^{\alpha
- 1} (1 - p)^{\beta - 1}}{B(\alpha, \beta)}\]</span></p>
<p>où <span class="math inline">\(B(\alpha, \beta)\)</span> est la
fonction bêta.</p>
<p>Après avoir observé <span class="math inline">\(x\)</span> succès en
<span class="math inline">\(n\)</span> essais, nous voulons mettre à
jour notre croyance a priori pour obtenir une distribution a posteriori.
La loi bêta-binomiale a posteriori est alors définie comme la
distribution de <span class="math inline">\(p\)</span>
conditionnellement aux données observées.</p>
<div class="definition">
<p>La loi bêta-binomiale a posteriori est la distribution de probabilité
de <span class="math inline">\(p\)</span> donnée par :</p>
<p><span class="math display">\[f_{\text{a posteriori}}(p | x, n) =
\frac{p^{x + \alpha - 1} (1 - p)^{n - x + \beta - 1}}{B(x + \alpha, n -
x + \beta)}\]</span></p>
<p>où <span class="math inline">\(B(\cdot, \cdot)\)</span> est la
fonction bêta.</p>
</div>
<p>Cette distribution peut également être exprimée en termes de
quantificateurs :</p>
<p><span class="math display">\[\forall p \in [0, 1], \quad f_{\text{a
posteriori}}(p | x, n) = \frac{p^{x + \alpha - 1} (1 - p)^{n - x + \beta
- 1}}{B(x + \alpha, n - x + \beta)}\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la loi bêta-binomiale a posteriori est
le théorème de conjugaison, qui stipule que la distribution a posteriori
appartient à la même famille de distributions que la distribution a
priori.</p>
<div class="theorem">
<p>Si la distribution a priori de <span class="math inline">\(p\)</span>
est une loi bêta de paramètres <span
class="math inline">\(\alpha\)</span> et <span
class="math inline">\(\beta\)</span>, alors la distribution a posteriori
de <span class="math inline">\(p\)</span> après avoir observé <span
class="math inline">\(x\)</span> succès en <span
class="math inline">\(n\)</span> essais est également une loi bêta de
paramètres <span class="math inline">\(\alpha + x\)</span> et <span
class="math inline">\(\beta + n - x\)</span>.</p>
</div>
<p>La démonstration de ce théorème repose sur l’application du théorème
de Bayes et la propriété de conjugaison de la distribution bêta.</p>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer le théorème de conjugaison, commençons par rappeler le
théorème de Bayes :</p>
<p><span class="math display">\[f_{\text{a posteriori}}(p | x, n) =
\frac{f(x | p, n) f_{\text{a priori}}(p)}{f(x | n)}\]</span></p>
<p>où <span class="math inline">\(f(x | p, n)\)</span> est la
distribution de vraisemblance des données, et <span
class="math inline">\(f_{\text{a priori}}(p)\)</span> est la
distribution a priori de <span class="math inline">\(p\)</span>.</p>
<p>La vraisemblance des données, sous l’hypothèse que les essais sont
indépendants et identiquement distribués selon une loi binomiale, est
donnée par :</p>
<p><span class="math display">\[f(x | p, n) = \binom{n}{x} p^x (1 -
p)^{n - x}\]</span></p>
<p>En substituant les expressions de la vraisemblance et de la
distribution a priori dans le théorème de Bayes, nous obtenons :</p>
<p><span class="math display">\[f_{\text{a posteriori}}(p | x, n) =
\frac{\binom{n}{x} p^x (1 - p)^{n - x} \cdot \frac{p^{\alpha - 1} (1 -
p)^{\beta - 1}}{B(\alpha, \beta)}}{\int_0^1 \binom{n}{x} p^x (1 - p)^{n
- x} \cdot \frac{p^{\alpha - 1} (1 - p)^{\beta - 1}}{B(\alpha, \beta)}
dp}\]</span></p>
<p>En simplifiant l’expression, nous trouvons que la distribution a
posteriori est proportionnelle à <span class="math inline">\(p^{x +
\alpha - 1} (1 - p)^{n - x + \beta - 1}\)</span>, ce qui montre qu’elle
suit une loi bêta de paramètres <span class="math inline">\(\alpha +
x\)</span> et <span class="math inline">\(\beta + n - x\)</span>.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La loi bêta-binomiale a posteriori possède plusieurs propriétés
intéressantes, que nous allons maintenant explorer.</p>
<ol>
<li><p><strong>Propriété de conjugaison</strong> : Comme nous l’avons
vu, la distribution a posteriori appartient à la même famille de
distributions que la distribution a priori. Cette propriété simplifie
considérablement les calculs et permet une mise à jour facile des
croyances en fonction des nouvelles données.</p></li>
<li><p><strong>Moyenne et variance</strong> : La moyenne et la variance
de la distribution bêta a posteriori sont données par :</p>
<p><span class="math display">\[\mathbb{E}[p | x, n] = \frac{\alpha +
x}{\alpha + \beta + n}\]</span></p>
<p><span class="math display">\[\text{Var}(p | x, n) = \frac{(\alpha +
x)(\beta + n - x)}{(\alpha + \beta + n)^2 (\alpha + \beta + n +
1)}\]</span></p>
<p>Ces expressions montrent comment les paramètres a priori et les
données observées influencent l’estimation de la probabilité <span
class="math inline">\(p\)</span>.</p></li>
<li><p><strong>Intervalle de crédibilité</strong> : Un intervalle de
crédibilité pour <span class="math inline">\(p\)</span> peut être obtenu
en utilisant les quantiles de la distribution bêta a posteriori. Par
exemple, un intervalle de crédibilité à 95% peut être calculé en
trouvant les valeurs <span class="math inline">\(p_L\)</span> et <span
class="math inline">\(p_U\)</span> telles que :</p>
<p><span class="math display">\[P(p &lt; p_L | x, n) = 0.025 \quad
\text{et} \quad P(p &gt; p_U | x, n) = 0.025\]</span></p>
<p>Ces valeurs peuvent être obtenues en utilisant des tables de la
distribution bêta ou des méthodes numériques.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La loi bêta-binomiale a posteriori est un outil puissant pour
l’estimation bayésienne de probabilités. Son utilisation permet de
combiner des informations a priori avec des données observées,
fournissant ainsi une estimation plus robuste et flexible des paramètres
inconnus. Les propriétés de conjugaison et les expressions analytiques
pour la moyenne, la variance et les intervalles de crédibilité en font
un choix privilégié dans de nombreuses applications pratiques.</p>
<p>En conclusion, la loi bêta-binomiale a posteriori illustre
parfaitement l’approche bayésienne en statistique, où les croyances a
priori sont mises à jour en fonction des données observées pour fournir
une estimation plus précise et incertaine des paramètres inconnus.</p>
</body>
</html>
{% include "footer.html" %}

