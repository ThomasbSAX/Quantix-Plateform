{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Convergence de la norme</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Convergence de la norme</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La notion de convergence est fondamentale en analyse mathématique.
Elle permet de formaliser l’idée intuitive d’approximation et de limite.
Parmi les différentes notions de convergence, la convergence en norme se
distingue par son lien étroit avec la structure topologique des espaces
vectoriels normés. Cette notion émerge naturellement dans le cadre de
l’analyse fonctionnelle, où elle permet d’étudier les propriétés des
suites et des séries dans des espaces de fonctions. La convergence en
norme est indispensable pour comprendre le comportement asymptotique des
solutions d’équations différentielles, des approximations numériques, et
des méthodes itératives.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la notion de convergence en norme, commençons par
rappeler ce qu’est une norme sur un espace vectoriel. Une norme permet
de mesurer la "taille" des vecteurs dans cet espace.</p>
<div class="definition">
<p>Soit <span class="math inline">\(E\)</span> un <span
class="math inline">\(\mathbb{K}\)</span>-espace vectoriel (<span
class="math inline">\(\mathbb{K} = \mathbb{R}\)</span> ou <span
class="math inline">\(\mathbb{C}\)</span>). Une norme sur <span
class="math inline">\(E\)</span> est une application <span
class="math inline">\(\| \cdot \| : E \to \mathbb{R}_+\)</span> telle
que pour tout <span class="math inline">\(x, y \in E\)</span> et tout
<span class="math inline">\(\lambda \in \mathbb{K}\)</span>, les
propriétés suivantes sont satisfaites :</p>
<ol>
<li><p><span class="math inline">\(\|x\| = 0\)</span> si et seulement si
<span class="math inline">\(x = 0\)</span>,</p></li>
<li><p><span class="math inline">\(\|\lambda x\| = |\lambda|
\|x\|\)</span>,</p></li>
<li><p><span class="math inline">\(\|x + y\| \leq \|x\| +
\|y\|\)</span>.</p></li>
</ol>
</div>
<p>Maintenant, nous pouvons définir la convergence en norme.</p>
<div class="definition">
<p>Soit <span class="math inline">\((E, \| \cdot \|)\)</span> un espace
vectoriel normé et soit <span class="math inline">\((x_n)_{n \in
\mathbb{N}}\)</span> une suite d’éléments de <span
class="math inline">\(E\)</span>. On dit que la suite <span
class="math inline">\((x_n)\)</span> converge en norme vers un élément
<span class="math inline">\(x \in E\)</span> si : <span
class="math display">\[\forall \epsilon &gt; 0, \exists N \in
\mathbb{N}, \forall n \geq N, \|x_n - x\| &lt; \epsilon.\]</span> En
d’autres termes, la suite <span class="math inline">\((x_n)\)</span>
converge en norme vers <span class="math inline">\(x\)</span> si la
suite des normes des différences <span class="math inline">\(\|x_n -
x\|\)</span> tend vers zéro lorsque <span
class="math inline">\(n\)</span> tend vers l’infini.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental concernant la convergence en norme est le
suivant :</p>
<div class="theorem">
<p>Soit <span class="math inline">\((E, \| \cdot \|)\)</span> un espace
vectoriel normé. Une série <span
class="math inline">\(\sum_{n=0}^{\infty} x_n\)</span> converge en norme
si et seulement si la suite partielle <span class="math inline">\(S_N =
\sum_{n=0}^{N} x_n\)</span> est de Cauchy pour la norme <span
class="math inline">\(\| \cdot \|\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Supposons que la série <span
class="math inline">\(\sum_{n=0}^{\infty} x_n\)</span> converge en norme
vers un élément <span class="math inline">\(S \in E\)</span>. Alors,
pour tout <span class="math inline">\(\epsilon &gt; 0\)</span>, il
existe un entier <span class="math inline">\(N_0\)</span> tel que pour
tout <span class="math inline">\(N, M \geq N_0\)</span>, on a : <span
class="math display">\[\|S_N - S_M\| = \left\| \sum_{n=N}^{M} x_n
\right\| &lt; \epsilon.\]</span> Cela montre que la suite <span
class="math inline">\((S_N)\)</span> est de Cauchy.</p>
<p>Réciproquement, supposons que la suite <span
class="math inline">\((S_N)\)</span> est de Cauchy. Puisque <span
class="math inline">\(E\)</span> est complet, la suite <span
class="math inline">\((S_N)\)</span> converge vers un élément <span
class="math inline">\(S \in E\)</span>. Par conséquent, la série <span
class="math inline">\(\sum_{n=0}^{\infty} x_n\)</span> converge en norme
vers <span class="math inline">\(S\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
convergence en norme.</p>
<ol>
<li><p>La convergence en norme est compatible avec les opérations
linéaires. Plus précisément, si <span
class="math inline">\((x_n)\)</span> et <span
class="math inline">\((y_n)\)</span> convergent en norme vers <span
class="math inline">\(x\)</span> et <span
class="math inline">\(y\)</span> respectivement, alors la suite <span
class="math inline">\((x_n + y_n)\)</span> converge en norme vers <span
class="math inline">\(x + y\)</span>, et pour tout scalaire <span
class="math inline">\(\lambda \in \mathbb{K}\)</span>, la suite <span
class="math inline">\((\lambda x_n)\)</span> converge en norme vers
<span class="math inline">\(\lambda x\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\epsilon &gt;
0\)</span>. Puisque <span class="math inline">\((x_n)\)</span> et <span
class="math inline">\((y_n)\)</span> convergent en norme vers <span
class="math inline">\(x\)</span> et <span
class="math inline">\(y\)</span> respectivement, il existe des entiers
<span class="math inline">\(N_1\)</span> et <span
class="math inline">\(N_2\)</span> tels que pour tout <span
class="math inline">\(n \geq N_1\)</span>, on a <span
class="math inline">\(\|x_n - x\| &lt; \epsilon/2\)</span>, et pour tout
<span class="math inline">\(n \geq N_2\)</span>, on a <span
class="math inline">\(\|y_n - y\| &lt; \epsilon/2\)</span>. En prenant
<span class="math inline">\(N = \max(N_1, N_2)\)</span>, on obtient pour
tout <span class="math inline">\(n \geq N\)</span> : <span
class="math display">\[\|(x_n + y_n) - (x + y)\| \leq \|x_n - x\| +
\|y_n - y\| &lt; \epsilon.\]</span> Cela montre que <span
class="math inline">\((x_n + y_n)\)</span> converge en norme vers <span
class="math inline">\(x + y\)</span>.</p>
<p>De même, pour tout scalaire <span class="math inline">\(\lambda \in
\mathbb{K}\)</span>, on a : <span class="math display">\[\|\lambda x_n -
\lambda x\| = |\lambda| \|x_n - x\| &lt; |\lambda| \epsilon.\]</span> En
choisissant <span class="math inline">\(\epsilon&#39; = \epsilon /
|\lambda|\)</span>, on obtient que <span class="math inline">\((\lambda
x_n)\)</span> converge en norme vers <span class="math inline">\(\lambda
x\)</span>. ◻</p>
</div></li>
<li><p>La convergence en norme implique la convergence faible. Plus
précisément, si <span class="math inline">\((x_n)\)</span> converge en
norme vers <span class="math inline">\(x\)</span>, alors pour toute
forme linéaire continue <span class="math inline">\(f\)</span> sur <span
class="math inline">\(E\)</span>, la suite <span
class="math inline">\((f(x_n))\)</span> converge vers <span
class="math inline">\(f(x)\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(f\)</span> une forme
linéaire continue sur <span class="math inline">\(E\)</span>. Puisque
<span class="math inline">\((x_n)\)</span> converge en norme vers <span
class="math inline">\(x\)</span>, il existe un entier <span
class="math inline">\(N\)</span> tel que pour tout <span
class="math inline">\(n \geq N\)</span>, on a <span
class="math inline">\(\|x_n - x\| &lt; \epsilon\)</span>. Par continuité
de <span class="math inline">\(f\)</span>, il existe une constante <span
class="math inline">\(C &gt; 0\)</span> telle que pour tout <span
class="math inline">\(y \in E\)</span>, on a <span
class="math inline">\(|f(y)| \leq C \|y\|\)</span>. Par conséquent, pour
tout <span class="math inline">\(n \geq N\)</span>, on a : <span
class="math display">\[|f(x_n) - f(x)| = |f(x_n - x)| \leq C \|x_n - x\|
&lt; C \epsilon.\]</span> Cela montre que <span
class="math inline">\((f(x_n))\)</span> converge vers <span
class="math inline">\(f(x)\)</span>. ◻</p>
</div></li>
<li><p>La convergence en norme est compatible avec les produits
scalaires. Plus précisément, si <span
class="math inline">\((x_n)\)</span> et <span
class="math inline">\((y_n)\)</span> convergent en norme vers <span
class="math inline">\(x\)</span> et <span
class="math inline">\(y\)</span> respectivement, alors la suite <span
class="math inline">\((\langle x_n, y_n \rangle)\)</span> converge vers
<span class="math inline">\(\langle x, y \rangle\)</span>, où <span
class="math inline">\(\langle \cdot, \cdot \rangle\)</span> désigne le
produit scalaire.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\epsilon &gt;
0\)</span>. Puisque <span class="math inline">\((x_n)\)</span> et <span
class="math inline">\((y_n)\)</span> convergent en norme vers <span
class="math inline">\(x\)</span> et <span
class="math inline">\(y\)</span> respectivement, il existe des entiers
<span class="math inline">\(N_1\)</span> et <span
class="math inline">\(N_2\)</span> tels que pour tout <span
class="math inline">\(n \geq N_1\)</span>, on a <span
class="math inline">\(\|x_n - x\| &lt; \epsilon/2\)</span>, et pour tout
<span class="math inline">\(n \geq N_2\)</span>, on a <span
class="math inline">\(\|y_n - y\| &lt; \epsilon/2\)</span>. En prenant
<span class="math inline">\(N = \max(N_1, N_2)\)</span>, on obtient pour
tout <span class="math inline">\(n \geq N\)</span> : <span
class="math display">\[|\langle x_n, y_n \rangle - \langle x, y \rangle|
= |\langle x_n - x, y_n \rangle + \langle x, y_n - y \rangle| \leq \|x_n
- x\| \|y_n\| + \|x\| \|y_n - y\|.\]</span> En utilisant l’inégalité de
Cauchy-Schwarz, on a <span class="math inline">\(\|y_n\| \leq C\)</span>
pour tout <span class="math inline">\(n\)</span>, où <span
class="math inline">\(C\)</span> est une constante indépendante de <span
class="math inline">\(n\)</span>. Par conséquent, pour tout <span
class="math inline">\(n \geq N\)</span>, on a : <span
class="math display">\[|\langle x_n, y_n \rangle - \langle x, y \rangle|
\leq C \|x_n - x\| + \|x\| \|y_n - y\| &lt; (C + \|x\|)
\epsilon.\]</span> Cela montre que <span class="math inline">\((\langle
x_n, y_n \rangle)\)</span> converge vers <span
class="math inline">\(\langle x, y \rangle\)</span>. ◻</p>
</div></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La convergence en norme est une notion centrale en analyse
fonctionnelle et en théorie des espaces vectoriels normés. Elle permet
de généraliser les concepts classiques de convergence des suites et des
séries à des espaces plus abstraits. Les propriétés et théorèmes
associés à la convergence en norme sont essentiels pour comprendre le
comportement asymptotique des solutions d’équations différentielles, des
approximations numériques, et des méthodes itératives. En outre, la
convergence en norme est compatible avec les opérations linéaires et les
produits scalaires, ce qui en fait un outil puissant pour l’étude des
espaces de fonctions.</p>
</body>
</html>
{% include "footer.html" %}

