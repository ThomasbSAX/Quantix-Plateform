{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>F-score (F1-score) : Une mesure harmonique de la performance des classifieurs</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">F-score (F1-score) : Une mesure harmonique de la
performance des classifieurs</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>En apprentissage supervisé, l’évaluation des classifieurs est une
tâche cruciale pour mesurer leur performance. Parmi les nombreuses
métriques disponibles, le F-score (ou F1-score) occupe une place
particulière en raison de sa capacité à combiner précision et rappel de
manière équilibrée. Introduit initialement dans le contexte de la
recherche d’information, ce score est désormais largement utilisé en
classification binaire et multiclasse.</p>
<p>L’émergence du F-score répond à un besoin fondamental : évaluer la
qualité d’un classifieur non pas seulement par sa capacité à identifier
correctement les instances positives (rappel), mais aussi par sa
capacité à minimiser les fausses alarmes (précision). En effet, dans de
nombreuses applications, un classifieur qui identifie correctement
toutes les instances positives mais avec un taux élevé de fausses
alarmes peut être tout aussi problématique qu’un classifieur qui manque
la plupart des instances positives.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire le F-score, commençons par définir les concepts
fondamentaux de précision et de rappel.</p>
<h2 class="unnumbered" id="précision">Précision</h2>
<p>Considérons un classifieur binaire qui prédit si une instance
appartient à la classe positive ou négative. La précision mesure la
proportion d’instances prédites comme positives qui sont effectivement
positives.</p>
<p>Formellement, soit <span class="math inline">\(TP\)</span> le nombre
de vrais positifs (true positives), <span
class="math inline">\(FP\)</span> le nombre de faux positifs (false
positives). La précision est définie comme :</p>
<p><span class="math display">\[\text{Précision} = \frac{TP}{TP +
FP}\]</span></p>
<h2 class="unnumbered" id="rappel">Rappel</h2>
<p>Le rappel, quant à lui, mesure la proportion d’instances positives
qui sont correctement identifiées par le classifieur.</p>
<p>Formellement, soit <span class="math inline">\(FN\)</span> le nombre
de faux négatifs (false negatives). Le rappel est défini comme :</p>
<p><span class="math display">\[\text{Rappel} = \frac{TP}{TP +
FN}\]</span></p>
<h2 class="unnumbered" id="f-score">F-score</h2>
<p>Le F-score est une mesure harmonique de la précision et du rappel. Il
est défini comme la moyenne harmonique de ces deux métriques, ce qui
signifie qu’il penche en faveur des classifieurs qui ont à la fois une
haute précision et un haut rappel.</p>
<p>Formellement, le F-score est défini comme :</p>
<p><span class="math display">\[F\text{-score} = 2 \cdot
\frac{\text{Précision} \cdot \text{Rappel}}{\text{Précision} +
\text{Rappel}}\]</span></p>
<p>Cette définition peut être réécrite en utilisant les notations
précédentes :</p>
<p><span class="math display">\[F\text{-score} = 2 \cdot \frac{\left(
\frac{TP}{TP + FP} \right) \cdot \left( \frac{TP}{TP + FN}
\right)}{\left( \frac{TP}{TP + FP} \right) + \left( \frac{TP}{TP + FN}
\right)}\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<h2 class="unnumbered" id="théorème-de-la-moyenne-harmonique">Théorème
de la moyenne harmonique</h2>
<p>Le F-score est une application directe du concept de moyenne
harmonique. La moyenne harmonique de deux nombres <span
class="math inline">\(a\)</span> et <span
class="math inline">\(b\)</span> est définie comme :</p>
<p><span class="math display">\[H(a, b) = \frac{2ab}{a + b}\]</span></p>
<p>Il est bien connu que la moyenne harmonique est toujours inférieure
ou égale à la moyenne arithmétique, c’est-à-dire :</p>
<p><span class="math display">\[H(a, b) \leq \frac{a +
b}{2}\]</span></p>
<p>Cette propriété est cruciale pour comprendre pourquoi le F-score
penche en faveur des classifieurs qui ont à la fois une haute précision
et un haut rappel.</p>
<h2 class="unnumbered" id="théorème-de-loptimalité-du-f-score">Théorème
de l’optimalité du F-score</h2>
<p>Un classifieur est optimal au sens du F-score s’il maximise à la fois
la précision et le rappel. Formellement, soit <span
class="math inline">\(C\)</span> un classifieur et <span
class="math inline">\(F(C)\)</span> son F-score. Alors :</p>
<p><span class="math display">\[C^* = \arg\max_C F(C)\]</span></p>
<p>où <span class="math inline">\(C^*\)</span> est le classifieur
optimal.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<h2 class="unnumbered"
id="preuve-du-théorème-de-la-moyenne-harmonique">Preuve du théorème de
la moyenne harmonique</h2>
<p>Pour prouver que <span class="math inline">\(H(a, b) \leq \frac{a +
b}{2}\)</span>, commençons par écrire l’inégalité :</p>
<p><span class="math display">\[\frac{2ab}{a + b} \leq \frac{a +
b}{2}\]</span></p>
<p>En multipliant les deux côtés par <span class="math inline">\(2(a +
b)\)</span>, nous obtenons :</p>
<p><span class="math display">\[4ab \leq (a + b)^2\]</span></p>
<p>En développant le carré, nous avons :</p>
<p><span class="math display">\[4ab \leq a^2 + 2ab + b^2\]</span></p>
<p>En simplifiant, nous obtenons :</p>
<p><span class="math display">\[0 \leq a^2 - 2ab + b^2\]</span></p>
<p>Ce qui est équivalent à :</p>
<p><span class="math display">\[0 \leq (a - b)^2\]</span></p>
<p>Cette inégalité est toujours vraie, ce qui prouve le théorème.</p>
<h2 class="unnumbered"
id="preuve-du-théorème-de-loptimalité-du-f-score">Preuve du théorème de
l’optimalité du F-score</h2>
<p>Pour prouver que <span class="math inline">\(C^*\)</span> maximise le
F-score, nous devons montrer que pour tout classifieur <span
class="math inline">\(C\)</span>, <span class="math inline">\(F(C^*)
\geq F(C)\)</span>.</p>
<p>Considérons deux classifieurs <span
class="math inline">\(C_1\)</span> et <span
class="math inline">\(C_2\)</span> avec des précisions et rappels
respectifs <span class="math inline">\((\text{Pr}_1,
\text{Ra}_1)\)</span> et <span class="math inline">\((\text{Pr}_2,
\text{Ra}_2)\)</span>. Supposons que <span
class="math inline">\(C_1\)</span> ait une précision et un rappel
supérieurs à ceux de <span class="math inline">\(C_2\)</span>,
c’est-à-dire :</p>
<p><span class="math display">\[\text{Pr}_1 \geq \text{Pr}_2 \quad
\text{et} \quad \text{Ra}_1 \geq \text{Ra}_2\]</span></p>
<p>Alors, en utilisant la propriété de la moyenne harmonique, nous avons
:</p>
<p><span class="math display">\[F(C_1) = H(\text{Pr}_1, \text{Ra}_1)
\geq H(\text{Pr}_2, \text{Ra}_2) = F(C_2)\]</span></p>
<p>Cela montre que <span class="math inline">\(C_1\)</span> a un F-score
supérieur à celui de <span class="math inline">\(C_2\)</span>, ce qui
prouve le théorème.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
corollaires</h1>
<h2 class="unnumbered" id="propriété-1-symétrie-du-f-score">Propriété 1
: Symétrie du F-score</h2>
<p>Le F-score est symétrique en précision et rappel. Cela signifie que
:</p>
<p><span class="math display">\[F(\text{Pr}, \text{Ra}) = F(\text{Ra},
\text{Pr})\]</span></p>
<h2 class="unnumbered" id="preuve-de-la-propriété-1">Preuve de la
propriété 1</h2>
<p>Pour prouver cette symétrie, nous utilisons la définition du F-score
:</p>
<p><span class="math display">\[F(\text{Pr}, \text{Ra}) = 2 \cdot
\frac{\text{Pr} \cdot \text{Ra}}{\text{Pr} + \text{Ra}}\]</span></p>
<p>En échangeant la précision et le rappel, nous obtenons :</p>
<p><span class="math display">\[F(\text{Ra}, \text{Pr}) = 2 \cdot
\frac{\text{Ra} \cdot \text{Pr}}{\text{Ra} + \text{Pr}} = 2 \cdot
\frac{\text{Pr} \cdot \text{Ra}}{\text{Pr} + \text{Ra}} = F(\text{Pr},
\text{Ra})\]</span></p>
<h2 class="unnumbered" id="propriété-2-bornes-du-f-score">Propriété 2 :
Bornes du F-score</h2>
<p>Le F-score est borné entre 0 et 1. Formellement, pour tout
classifieur <span class="math inline">\(C\)</span>, nous avons :</p>
<p><span class="math display">\[0 \leq F(C) \leq 1\]</span></p>
<h2 class="unnumbered" id="preuve-de-la-propriété-2">Preuve de la
propriété 2</h2>
<p>Pour prouver cette borne, nous utilisons le fait que la précision et
le rappel sont tous deux compris entre 0 et 1. En utilisant la propriété
de la moyenne harmonique, nous savons que :</p>
<p><span class="math display">\[H(a, b) \leq \frac{a + b}{2} \leq
1\]</span></p>
<p>Puisque <span class="math inline">\(a, b \in [0, 1]\)</span>, il
s’ensuit que :</p>
<p><span class="math display">\[F(C) = H(\text{Pr}, \text{Ra}) \leq
1\]</span></p>
<p>De plus, si <span class="math inline">\(\text{Pr} = 0\)</span> ou
<span class="math inline">\(\text{Ra} = 0\)</span>, alors <span
class="math inline">\(F(C) = 0\)</span>. Donc, <span
class="math inline">\(F(C) \in [0, 1]\)</span>.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le F-score est une métrique puissante et flexible pour évaluer la
performance des classifieurs. Sa capacité à combiner précision et rappel
de manière équilibrée en fait un outil indispensable dans de nombreuses
applications. En comprenant les propriétés fondamentales du F-score et
ses implications, nous pouvons mieux évaluer et améliorer nos modèles de
classification.</p>
</body>
</html>
{% include "footer.html" %}

