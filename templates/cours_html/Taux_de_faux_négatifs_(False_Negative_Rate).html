{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Taux de faux négatifs (False Negative Rate)</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Taux de faux négatifs (False Negative Rate)</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Le taux de faux négatifs, ou <em>False Negative Rate</em> (FNR), est
une mesure fondamentale en statistique et en apprentissage automatique,
particulièrement dans le cadre de l’évaluation des modèles de
classification. Il émerge naturellement lorsque l’on cherche à
quantifier la performance d’un modèle binaire en termes de son
incapacité à détecter certaines classes. Historiquement, cette notion
est intimement liée au développement des tests diagnostiques en médecine
et à l’analyse des erreurs dans les systèmes de décision
automatisés.</p>
<p>Le FNR est indispensable pour comprendre les limites d’un modèle,
surtout dans des contextes où les coûts associés aux erreurs de type II
(faux négatifs) sont élevés. Par exemple, dans le dépistage de maladies,
un faux négatif peut avoir des conséquences graves pour la santé du
patient. Ainsi, le FNR permet de mesurer la fiabilité d’un modèle dans
des situations critiques.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir le taux de faux négatifs, commençons par comprendre ce
que nous cherchons à capturer. Imaginons un modèle de classification
binaire qui prédit si une instance appartient à la classe positive ou
négative. Un faux négatif se produit lorsque le modèle prédit à tort
qu’une instance appartient à la classe négative alors qu’elle est en
réalité positive. Le FNR mesure la proportion de faux négatifs parmi
toutes les instances réellement positives.</p>
<p>Formellement, soit <span class="math inline">\(TP\)</span> le nombre
de vrais positifs, <span class="math inline">\(FP\)</span> le nombre de
faux positifs, <span class="math inline">\(TN\)</span> le nombre de
vrais négatifs, et <span class="math inline">\(FN\)</span> le nombre de
faux négatifs. Le taux de faux négatifs est défini comme suit :</p>
<div class="definition">
<p>Le taux de faux négatifs <span class="math inline">\(FNR\)</span> est
donné par : <span class="math display">\[FNR = \frac{FN}{FN +
TP}\]</span> Autrement dit, pour tout ensemble de données <span
class="math inline">\(D\)</span> et un modèle de classification <span
class="math inline">\(M\)</span>, nous avons : <span
class="math display">\[FNR(M, D) = \frac{\sum_{i=1}^{|D|} \mathbb{I}(y_i
= 1 \text{ et } M(x_i) = 0)}{\sum_{i=1}^{|D|} \mathbb{I}(y_i =
1)}\]</span> où <span class="math inline">\(y_i\)</span> est la vraie
classe de l’instance <span class="math inline">\(x_i\)</span>, et <span
class="math inline">\(M(x_i)\)</span> est la prédiction du modèle pour
cette instance.</p>
</div>
<h1 id="théorèmes-et-propriétés">Théorèmes et Propriétés</h1>
<p>Le taux de faux négatifs est lié à plusieurs concepts fondamentaux en
théorie de la décision et en apprentissage automatique. Par exemple, il
est complémentaire au taux de vrais positifs (True Positive Rate, TPR),
qui mesure la capacité du modèle à détecter correctement les instances
positives.</p>
<div class="theorem">
<p>Le taux de faux négatifs <span class="math inline">\(FNR\)</span> et
le taux de vrais positifs <span class="math inline">\(TPR\)</span> sont
liés par la relation suivante : <span class="math display">\[FNR = 1 -
TPR\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Par définition, le taux de vrais positifs est donné
par : <span class="math display">\[TPR = \frac{TP}{FN + TP}\]</span> En
réarrangeant cette équation, nous obtenons : <span
class="math display">\[FNR = 1 - TPR = 1 - \frac{TP}{FN + TP} =
\frac{FN}{FN + TP}\]</span> Ce qui prouve la relation entre <span
class="math inline">\(FNR\)</span> et <span
class="math inline">\(TPR\)</span>. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Le taux de faux négatifs possède plusieurs propriétés intéressantes
qui en font un outil puissant pour l’évaluation des modèles de
classification.</p>
<div class="corollaire">
<p>Le taux de faux négatifs <span class="math inline">\(FNR\)</span> et
le taux de vrais positifs <span class="math inline">\(TPR\)</span> sont
complémentaires, c’est-à-dire que : <span class="math display">\[FNR +
TPR = 1\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Cette propriété découle directement de la relation
entre <span class="math inline">\(FNR\)</span> et <span
class="math inline">\(TPR\)</span> établie dans le théorème précédent.
En effet, si <span class="math inline">\(FNR = 1 - TPR\)</span>, alors :
<span class="math display">\[FNR + TPR = (1 - TPR) + TPR =
1\]</span> ◻</p>
</div>
<div class="corollaire">
<p>Le taux de faux négatifs <span class="math inline">\(FNR\)</span>
dépend du seuil de décision utilisé par le modèle. Plus le seuil est
élevé, plus <span class="math inline">\(FNR\)</span> tend à augmenter,
et inversement.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Un seuil de décision élevé signifie que le modèle est
plus strict dans la classification des instances comme positives. Par
conséquent, il y aura moins de vrais positifs et plus de faux négatifs,
ce qui augmentera <span class="math inline">\(FNR\)</span>. Inversement,
un seuil plus bas rendra le modèle moins strict, réduisant ainsi <span
class="math inline">\(FNR\)</span>. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Le taux de faux négatifs est une mesure cruciale pour évaluer la
performance des modèles de classification, en particulier dans les
contextes où les faux négatifs ont des conséquences graves. En
comprenant et en utilisant cette mesure, nous pouvons mieux appréhender
les limites de nos modèles et prendre des décisions éclairées pour
améliorer leur fiabilité.</p>
</body>
</html>
{% include "footer.html" %}

