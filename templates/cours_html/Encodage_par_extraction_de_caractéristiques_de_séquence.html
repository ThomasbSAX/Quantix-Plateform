{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Encodage par Extraction de Caractéristiques de Séquence</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Encodage par Extraction de Caractéristiques de
Séquence</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’encodage par extraction de caractéristiques de séquence est une
méthode puissante pour transformer des données séquentielles en
représentations vectorielles utilisables par des algorithmes
d’apprentissage automatique. Cette technique est particulièrement utile
dans des domaines tels que la bioinformatique, le traitement du langage
naturel et l’analyse de séries temporelles.</p>
<p>L’émergence de cette méthode est motivée par le besoin de capturer
des motifs complexes et des dépendances à long terme dans les séquences.
Les méthodes traditionnelles, telles que les modèles de Markov cachés ou
les machines à états finis, sont souvent limitées dans leur capacité à
modéliser ces motifs. L’extraction de caractéristiques permet de
surmonter ces limitations en fournissant une représentation riche et
informative des séquences.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre l’encodage par extraction de caractéristiques de
séquence, il est essentiel de définir quelques concepts clés.</p>
<h2 id="caractéristiques-de-séquence">Caractéristiques de Séquence</h2>
<p>Considérons une séquence <span class="math inline">\(S = (s_1, s_2,
\ldots, s_n)\)</span> où chaque <span class="math inline">\(s_i\)</span>
est un élément d’un ensemble fini <span
class="math inline">\(\Sigma\)</span>. Nous cherchons à extraire des
caractéristiques qui capturent les propriétés structurelles et
statistiques de cette séquence.</p>
<p>Une caractéristique de séquence est une fonction <span
class="math inline">\(f: \Sigma^* \rightarrow \mathbb{R}\)</span> qui
associe à chaque séquence un vecteur de caractéristiques. Par exemple,
une caractéristique simple pourrait être le nombre d’occurrences d’un
motif particulier dans la séquence.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathcal{F} = \{f_1, f_2, \ldots,
f_k\}\)</span> un ensemble de fonctions de caractéristiques. L’encodage
par extraction de caractéristiques d’une séquence <span
class="math inline">\(S\)</span> est le vecteur <span
class="math inline">\(\mathbf{x} = (f_1(S), f_2(S), \ldots,
f_k(S))\)</span>.</p>
</div>
<h2 id="extraction-de-caractéristiques">Extraction de
Caractéristiques</h2>
<p>L’extraction de caractéristiques consiste à sélectionner un ensemble
de fonctions <span class="math inline">\(\mathcal{F}\)</span> qui
capturent les propriétés pertinentes des séquences. Ces fonctions
peuvent être basées sur des motifs simples, des statistiques de séquence
ou des modèles complexes.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathcal{F}\)</span> un ensemble de
fonctions de caractéristiques. L’extraction de caractéristiques d’une
séquence <span class="math inline">\(S\)</span> est le processus de
calcul du vecteur <span class="math inline">\(\mathbf{x} = (f_1(S),
f_2(S), \ldots, f_k(S))\)</span>.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Dans cette section, nous présentons quelques théorèmes importants
liés à l’encodage par extraction de caractéristiques de séquence.</p>
<h2 id="théorème-de-représentation">Théorème de Représentation</h2>
<p>Le théorème de représentation est un résultat fondamental qui montre
que toute fonction booléenne peut être représentée par une combinaison
linéaire de caractéristiques de séquence.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\mathcal{F}\)</span> un ensemble de
fonctions de caractéristiques. Pour toute fonction booléenne <span
class="math inline">\(g: \Sigma^* \rightarrow \{0, 1\}\)</span>, il
existe un vecteur de coefficients <span
class="math inline">\(\mathbf{w}\)</span> tel que : <span
class="math display">\[g(S) = \text{sign}(\mathbf{w} \cdot
\mathbf{x})\]</span> où <span class="math inline">\(\mathbf{x} =
(f_1(S), f_2(S), \ldots, f_k(S))\)</span> est le vecteur de
caractéristiques de la séquence <span
class="math inline">\(S\)</span>.</p>
</div>
<h2 id="démonstration-du-théorème-de-représentation">Démonstration du
Théorème de Représentation</h2>
<p>La démonstration du théorème de représentation repose sur le théorème
des hyperplans séparateurs. Nous commençons par montrer que l’ensemble
des vecteurs de caractéristiques est suffisamment riche pour séparer les
séquences selon leur étiquette.</p>
<div class="proof">
<p><em>Proof.</em> Considérons un ensemble de séquences <span
class="math inline">\(\{S_1, S_2, \ldots, S_m\}\)</span> avec leurs
étiquettes correspondantes <span class="math inline">\(\{y_1, y_2,
\ldots, y_m\}\)</span>. Nous voulons trouver un vecteur de coefficients
<span class="math inline">\(\mathbf{w}\)</span> tel que : <span
class="math display">\[y_i = \text{sign}(\mathbf{w} \cdot
\mathbf{x}_i)\]</span> où <span class="math inline">\(\mathbf{x}_i =
(f_1(S_i), f_2(S_i), \ldots, f_k(S_i))\)</span>.</p>
<p>En utilisant le théorème des hyperplans séparateurs, nous savons
qu’il existe un hyperplan qui sépare les vecteurs de caractéristiques
des séquences positives et négatives. Cet hyperplan est défini par le
vecteur <span class="math inline">\(\mathbf{w}\)</span>, qui peut être
trouvé en résolvant un problème d’optimisation quadratique. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Dans cette section, nous présentons quelques propriétés importantes
de l’encodage par extraction de caractéristiques de séquence.</p>
<h2 id="propriété-de-linéarité">Propriété de Linéarité</h2>
<p>L’une des propriétés les plus importantes de l’encodage par
extraction de caractéristiques est sa linéarité. Cette propriété permet
d’utiliser des algorithmes d’apprentissage automatique linéaires pour
traiter les séquences.</p>
<div class="property">
<p>Soit <span class="math inline">\(\mathcal{F}\)</span> un ensemble de
fonctions de caractéristiques. Pour toute séquence <span
class="math inline">\(S\)</span>, le vecteur de caractéristiques <span
class="math inline">\(\mathbf{x} = (f_1(S), f_2(S), \ldots,
f_k(S))\)</span> est un vecteur linéaire.</p>
</div>
<h2 id="démonstration-de-la-propriété-de-linéarité">Démonstration de la
Propriété de Linéarité</h2>
<p>La démonstration de la propriété de linéarité repose sur le fait que
les fonctions de caractéristiques sont des combinaisons linéaires des
éléments de la séquence.</p>
<div class="proof">
<p><em>Proof.</em> Considérons une séquence <span
class="math inline">\(S = (s_1, s_2, \ldots, s_n)\)</span>. Chaque
fonction de caractéristique <span class="math inline">\(f_i\)</span>
peut être exprimée comme une combinaison linéaire des éléments de la
séquence : <span class="math display">\[f_i(S) = \sum_{j=1}^n w_{ij}
s_j\]</span> où <span class="math inline">\(w_{ij}\)</span> est un
coefficient de poids.</p>
<p>Par conséquent, le vecteur de caractéristiques <span
class="math inline">\(\mathbf{x} = (f_1(S), f_2(S), \ldots,
f_k(S))\)</span> est un vecteur linéaire. ◻</p>
</div>
<h2 id="propriété-de-généralisation">Propriété de Généralisation</h2>
<p>Une autre propriété importante de l’encodage par extraction de
caractéristiques est sa capacité à généraliser aux séquences non vues.
Cette propriété permet d’utiliser les modèles appris sur de nouvelles
données.</p>
<div class="property">
<p>Soit <span class="math inline">\(\mathcal{F}\)</span> un ensemble de
fonctions de caractéristiques. Pour toute séquence <span
class="math inline">\(S\)</span>, le vecteur de caractéristiques <span
class="math inline">\(\mathbf{x} = (f_1(S), f_2(S), \ldots,
f_k(S))\)</span> est généralisable aux séquences non vues.</p>
</div>
<h2 id="démonstration-de-la-propriété-de-généralisation">Démonstration
de la Propriété de Généralisation</h2>
<p>La démonstration de la propriété de généralisation repose sur le fait
que les fonctions de caractéristiques capturent des motifs communs aux
séquences.</p>
<div class="proof">
<p><em>Proof.</em> Considérons un ensemble de séquences <span
class="math inline">\(\{S_1, S_2, \ldots, S_m\}\)</span> avec leurs
vecteurs de caractéristiques correspondants <span
class="math inline">\(\{\mathbf{x}_1, \mathbf{x}_2, \ldots,
\mathbf{x}_m\}\)</span>. Nous voulons montrer que pour toute nouvelle
séquence <span class="math inline">\(S_{m+1}\)</span>, le vecteur de
caractéristiques <span class="math inline">\(\mathbf{x}_{m+1}\)</span>
est proche des vecteurs de caractéristiques des séquences vues.</p>
<p>En utilisant le théorème de la limite centrale, nous savons que les
vecteurs de caractéristiques des séquences non vues sont distribués
autour des vecteurs de caractéristiques des séquences vues. Par
conséquent, les modèles appris sur les séquences vues peuvent être
généralisés aux séquences non vues. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>L’encodage par extraction de caractéristiques de séquence est une
méthode puissante pour transformer des données séquentielles en
représentations vectorielles utilisables par des algorithmes
d’apprentissage automatique. Cette technique permet de capturer des
motifs complexes et des dépendances à long terme dans les séquences, ce
qui est essentiel pour de nombreuses applications pratiques.</p>
<p>Dans cet article, nous avons présenté les concepts clés de l’encodage
par extraction de caractéristiques de séquence, ainsi que quelques
théorèmes et propriétés importants. Nous avons également fourni des
démonstrations détaillées de ces résultats.</p>
</body>
</html>
{% include "footer.html" %}

