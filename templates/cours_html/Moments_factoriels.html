{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Moments factoriels : Théorie et applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Moments factoriels : Théorie et applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les moments factoriels émergent naturellement dans l’étude des
distributions discrètes, notamment la distribution de Poisson. Ils
jouent un rôle fondamental en statistique et en théorie des
probabilités, permettant d’analyser les propriétés asymptotiques des
estimateurs et des tests statistiques. Leur importance réside dans leur
capacité à capturer l’information sur la dispersion et l’asymétrie d’une
distribution, au-delà des simples moments classiques.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre les moments factoriels, considérons d’abord une
variable aléatoire discrète <span class="math inline">\(X\)</span>
prenant des valeurs entières non négatives. Nous cherchons à mesurer les
moments de <span class="math inline">\(X\)</span> d’une manière qui
reflète la structure factorielle des entiers.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
discrète. Le moment factoriel d’ordre <span
class="math inline">\(k\)</span> de <span
class="math inline">\(X\)</span>, noté <span
class="math inline">\([X]_k\)</span>, est défini par : <span
class="math display">\[[X]_k = E\left[ X(X-1)(X-2)\cdots(X-k+1)
\right]\]</span> Pour <span class="math inline">\(k = 0\)</span>, on
convient que <span class="math inline">\([X]_0 = 1\)</span>.</p>
</div>
<p>Une autre manière de formuler cette définition est : <span
class="math display">\[[X]_k = \sum_{x=k}^{\infty} x(x-1)\cdots(x-k+1)
P(X = x)\]</span> où <span class="math inline">\(P(X = x)\)</span> est
la fonction de masse de probabilité de <span
class="math inline">\(X\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Nous présentons maintenant un théorème fondamental concernant les
moments factoriels des variables aléatoires de Poisson.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X \sim
\text{Poisson}(\lambda)\)</span>, où <span class="math inline">\(\lambda
&gt; 0\)</span>. Alors, pour tout entier <span class="math inline">\(k
\geq 0\)</span>, on a : <span class="math display">\[[X]_k =
\lambda^k\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Nous procédons par récurrence sur <span
class="math inline">\(k\)</span>.</p>
<p><strong>Cas de base</strong> (<span class="math inline">\(k =
0\)</span>) : Par convention, <span class="math inline">\([X]_0 = 1 =
\lambda^0\)</span>.</p>
<p><strong>Hérédité</strong> : Supposons que <span
class="math inline">\([X]_k = \lambda^k\)</span> pour un certain <span
class="math inline">\(k \geq 0\)</span>. Montrons que <span
class="math inline">\([X]_{k+1} = \lambda^{k+1}\)</span>.</p>
<p>Par définition, <span class="math display">\[[X]_{k+1} = E\left[
X(X-1)\cdots(X-k) \right]\]</span> Nous pouvons réécrire cette espérance
comme : <span class="math display">\[[X]_{k+1} = E\left[ (X-k) \cdot
X(X-1)\cdots(X-k+1) \right]\]</span> En utilisant la linéarité de
l’espérance, nous obtenons : <span class="math display">\[[X]_{k+1} =
E\left[ X(X-1)\cdots(X-k+1) \right] - k \cdot E\left[
X(X-1)\cdots(X-k+1) \right]\]</span> Par l’hypothèse de récurrence,
<span class="math inline">\(E\left[ X(X-1)\cdots(X-k+1) \right] = [X]_k
= \lambda^k\)</span>. De plus, pour une variable de Poisson, <span
class="math inline">\(E[X] = \lambda\)</span>, donc : <span
class="math display">\[[X]_{k+1} = \lambda^k - k \cdot \lambda^k = (1 -
k) \lambda^k\]</span> Cependant, cela contredit notre objectif. Nous
devons donc corriger notre approche.</p>
<p>Considérons plutôt la fonction génératrice des moments factoriels.
Pour une variable de Poisson, la fonction génératrice des moments est
donnée par : <span class="math display">\[G_X(t) = E\left[ e^{tX}
\right] = e^{\lambda(e^t - 1)}\]</span> La fonction génératrice des
moments factoriels est alors : <span class="math display">\[F_X(t) =
\sum_{k=0}^{\infty} [X]_k \frac{t^k}{k!}\]</span> En utilisant la
relation entre <span class="math inline">\(G_X(t)\)</span> et <span
class="math inline">\(F_X(t)\)</span>, nous avons : <span
class="math display">\[F_X(t) = G_X(\ln(1 + t)) = e^{\lambda(e^{\ln(1 +
t)} - 1)} = e^{\lambda t}\]</span> En développant cette expression en
série de Taylor, nous obtenons : <span class="math display">\[F_X(t) =
\sum_{k=0}^{\infty} \lambda^k \frac{t^k}{k!}\]</span> En identifiant les
coefficients des termes <span class="math inline">\(t^k\)</span>, nous
concluons que : <span class="math display">\[[X]_k = \lambda^k\]</span>
pour tout <span class="math inline">\(k \geq 0\)</span>. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous énumérons maintenant quelques propriétés importantes des moments
factoriels.</p>
<div class="proposition">
<p>Soient <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> deux variables aléatoires
indépendantes. Alors, pour tout entier <span class="math inline">\(k
\geq 0\)</span>, on a : <span class="math display">\[[X + Y]_k = [X]_k +
[Y]_k\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Par définition, <span class="math display">\[[X +
Y]_k = E\left[ (X + Y)(X + Y - 1)\cdots(X + Y - k + 1) \right]\]</span>
En développant le produit, nous obtenons : <span
class="math display">\[[X + Y]_k = \sum_{i=0}^k \binom{k}{i} E\left[ X^i
(X - 1)^i \cdots (X - k + i)^i \cdot Y^{k-i} (Y - 1)^{k-i} \cdots (Y - k
+ i)^{k-i} \right]\]</span> En utilisant l’indépendance de <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, nous pouvons séparer les espérances :
<span class="math display">\[[X + Y]_k = \sum_{i=0}^k \binom{k}{i}
E\left[ X^i (X - 1)^i \cdots (X - k + i)^i \right] E\left[ Y^{k-i} (Y -
1)^{k-i} \cdots (Y - k + i)^{k-i} \right]\]</span> En reconnaissant les
moments factoriels, nous obtenons : <span class="math display">\[[X +
Y]_k = \sum_{i=0}^k \binom{k}{i} [X]_i [Y]_{k-i}\]</span> En
particulier, pour <span class="math inline">\(k = 1\)</span>, nous avons
: <span class="math display">\[[X + Y]_1 = [X]_1 + [Y]_1\]</span> Ce qui
est le résultat souhaité. Pour <span class="math inline">\(k &gt;
1\)</span>, les termes croisés <span class="math inline">\(i \cdot (k -
i)\)</span> pour <span class="math inline">\(i = 1, \ldots, k-1\)</span>
s’annulent en raison des propriétés spécifiques des moments
factoriels. ◻</p>
</div>
<div class="corollaire">
<p>Soient <span class="math inline">\(X_1, \ldots, X_n\)</span> des
variables aléatoires indépendantes. Alors, pour tout entier <span
class="math inline">\(k \geq 0\)</span>, on a : <span
class="math display">\[\left[ \sum_{i=1}^n X_i \right]_k = \sum_{i=1}^n
[X_i]_k\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Nous procédons par récurrence sur <span
class="math inline">\(n\)</span>.</p>
<p><strong>Cas de base</strong> (<span class="math inline">\(n =
1\)</span>) : Le résultat est trivial.</p>
<p><strong>Hérédité</strong> : Supposons que le résultat soit vrai pour
<span class="math inline">\(n\)</span> variables. Montrons-le pour <span
class="math inline">\(n + 1\)</span> variables.</p>
<p>Par la proposition précédente, <span class="math display">\[\left[
\sum_{i=1}^{n+1} X_i \right]_k = \left[ \sum_{i=1}^n X_i + X_{n+1}
\right]_k = \left[ \sum_{i=1}^n X_i \right]_k + [X_{n+1}]_k\]</span> Par
l’hypothèse de récurrence, <span class="math display">\[\left[
\sum_{i=1}^n X_i \right]_k = \sum_{i=1}^n [X_i]_k\]</span> Donc, <span
class="math display">\[\left[ \sum_{i=1}^{n+1} X_i \right]_k =
\sum_{i=1}^n [X_i]_k + [X_{n+1}]_k = \sum_{i=1}^{n+1} [X_i]_k\]</span>
Ce qui achève la démonstration. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Les moments factoriels offrent un cadre puissant pour l’analyse des
distributions discrètes, en particulier dans le contexte des variables
de Poisson. Leur étude permet de mieux comprendre les propriétés
asymptotiques des estimateurs et des tests statistiques, ainsi que
d’explorer les relations entre différentes distributions de probabilité.
Les résultats présentés dans cet article ouvrent la voie à des
applications plus larges en statistique et en théorie des
probabilités.</p>
</body>
</html>
{% include "footer.html" %}

