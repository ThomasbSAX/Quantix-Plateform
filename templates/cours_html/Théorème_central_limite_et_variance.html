{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Théorème central limite et variance</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Théorème central limite et variance</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<p>Voici un article scientifique en LaTeX sur le théorème central limite
et la variance :</p>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>Le théorème central limite (TCL) est sans doute l’un des résultats
les plus fondamentaux et puissants de la théorie des probabilités. Il
émerge naturellement dans l’étude des lois des grands nombres et joue un
rôle central en statistique mathématique. Historiquement, ses premières
formulations remontent aux travaux de Laplace au début du XIXème siècle,
bien que sa version moderne soit due à Lyapunov en 1901.</p>
<p>Ce théorème est indispensable dans de nombreux domaines des sciences
appliquées où l’on manipule des variables aléatoires. Il permet
notamment d’approcher la distribution de sommes de variables aléatoires
par une loi normale, même lorsque les variables originales ne sont pas
elles-mêmes normalement distribuées. La variance, quant à elle, mesure
la dispersion d’une variable aléatoire autour de sa moyenne et joue un
rôle crucial dans le TCL.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Commençons par rappeler quelques notions fondamentales. On cherche à
comprendre comment se comporte la somme de variables aléatoires
indépendantes et identiquement distribuées (i.i.d.) lorsque le nombre de
termes tend vers l’infini.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X_1, X_2, \ldots\)</span> une suite
de variables aléatoires définies sur un même espace probabilisé <span
class="math inline">\((\Omega, \mathcal{F}, P)\)</span>. On dit que ces
variables sont indépendantes et identiquement distribuées (i.i.d.)
si:</p>
<ol>
<li><p><span class="math inline">\(\forall n \in \mathbb{N}^*, \forall
i_1, \ldots, i_n \in \{1, 2, \ldots\}\)</span>, les variables <span
class="math inline">\(X_{i_1}, \ldots, X_{i_n}\)</span> sont
indépendantes.</p></li>
<li><p><span class="math inline">\(\forall n \in \mathbb{N}^*, \forall
i_1, \ldots, i_n \in \{1, 2, \ldots\}\)</span>, les lois de <span
class="math inline">\(X_{i_1}, \ldots, X_{i_n}\)</span> sont
identiques.</p></li>
</ol>
</div>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire de
moyenne <span class="math inline">\(\mathbb{E}[X] = \mu\)</span>. La
variance de <span class="math inline">\(X\)</span> est définie par:
<span class="math display">\[\mathrm{Var}(X) = \mathbb{E}\left[(X -
\mu)^2\right] = \mathbb{E}[X^2] - (\mathbb{E}[X])^2\]</span></p>
</div>
<h1 class="unnumbered" id="théorème-central-limite-de-lyapunov">Théorème
central limite de Lyapunov</h1>
<p>Nous allons maintenant énoncer le théorème central limite dans sa
version due à Lyapunov. Pour cela, nous avons besoin de quelques
notations supplémentaires.</p>
<p>Soit <span class="math inline">\((X_n)_{n \geq 1}\)</span> une suite
de variables aléatoires i.i.d. de moyenne <span
class="math inline">\(\mu\)</span> et de variance <span
class="math inline">\(\sigma^2\)</span>. On définit la somme normalisée:
<span class="math display">\[S_n = \frac{1}{\sqrt{n}} \sum_{k=1}^n (X_k
- \mu)\]</span> et la variance normalisée: <span
class="math display">\[B_n^2 = \sum_{k=1}^n \mathbb{E}\left[(X_k -
\mu)^2 \mathbf{1}_{\{|X_k - \mu| &gt; n \epsilon_n\}}\right]\]</span> où
<span class="math inline">\((\epsilon_n)_{n \geq 1}\)</span> est une
suite de nombres réels strictement positifs telle que <span
class="math inline">\(\epsilon_n \to 0\)</span> et <span
class="math inline">\(n \epsilon_n^2 \to \infty\)</span>.</p>
<div class="theorem">
<p>Si <span class="math inline">\(\lim_{n \to \infty}
\frac{B_n^2}{\sigma^2 n} = 0\)</span>, alors pour toute fonction bornée
et continue <span class="math inline">\(f: \mathbb{R} \to
\mathbb{R}\)</span>: <span class="math display">\[\lim_{n \to \infty}
\mathbb{E}\left[f\left(\frac{S_n}{\sigma}\right)\right] =
\int_{\mathbb{R}} f(x) \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx\]</span></p>
</div>
<h1 class="unnumbered"
id="preuve-du-théorème-central-limite-de-lyapunov">Preuve du théorème
central limite de Lyapunov</h1>
<p>La preuve repose sur le lemme de Slutsky et la convergence en loi des
sommes de variables aléatoires. Nous allons développer cette preuve
étape par étape.</p>
<div class="proof">
<p><em>Proof.</em> Par hypothèse, <span class="math inline">\(\lim_{n
\to \infty} \frac{B_n^2}{\sigma^2 n} = 0\)</span>. Cela implique que
pour tout <span class="math inline">\(\epsilon &gt; 0\)</span>: <span
class="math display">\[\lim_{n \to \infty} P\left(\left|\frac{1}{n}
\sum_{k=1}^n (X_k - \mu)^2 \mathbf{1}_{\{|X_k - \mu| &gt; n
\epsilon_n\}}\right| &gt; \epsilon\right) = 0\]</span> En effet, par
l’inégalité de Markov: <span
class="math display">\[P\left(\left|\frac{1}{n} \sum_{k=1}^n (X_k -
\mu)^2 \mathbf{1}_{\{|X_k - \mu| &gt; n \epsilon_n\}}\right| &gt;
\epsilon\right) \leq \frac{1}{n^2 \epsilon^2} \sum_{k=1}^n
\mathbb{E}\left[(X_k - \mu)^2 \mathbf{1}_{\{|X_k - \mu| &gt; n
\epsilon_n\}}\right] = \frac{B_n^2}{n^2 \epsilon^2}\]</span></p>
<p>Considérons maintenant la somme normalisée <span
class="math inline">\(S_n\)</span>. On peut écrire: <span
class="math display">\[\frac{S_n}{\sigma} = \frac{1}{\sqrt{n}}
\sum_{k=1}^n \frac{X_k - \mu}{\sigma} = \frac{1}{\sqrt{n}} \sum_{k=1}^n
Y_k\]</span> où <span class="math inline">\(Y_k = \frac{X_k -
\mu}{\sigma}\)</span>.</p>
<p>Par le lemme de Slutsky, il suffit de montrer que pour toute fonction
bornée et continue <span class="math inline">\(f: \mathbb{R} \to
\mathbb{R}\)</span>: <span class="math display">\[\lim_{n \to \infty}
\mathbb{E}\left[f\left(\frac{S_n}{\sigma}\right)\right] =
\int_{\mathbb{R}} f(x) \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx\]</span></p>
<p>Pour cela, nous utilisons la convergence en loi des sommes de
variables aléatoires. En effet, par le théorème des accroissements finis
et l’hypothèse de Lyapunov, on a: <span
class="math display">\[\mathbb{E}\left[f\left(\frac{S_n}{\sigma}\right)\right]
- \int_{\mathbb{R}} f(x) \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx =
o(1)\]</span> où <span class="math inline">\(o(1)\)</span> désigne une
quantité qui tend vers 0 lorsque <span class="math inline">\(n \to
\infty\)</span>.</p>
<p>Enfin, en utilisant la continuité de <span
class="math inline">\(f\)</span> et le théorème de convergence dominée,
on obtient: <span class="math display">\[\lim_{n \to \infty}
\mathbb{E}\left[f\left(\frac{S_n}{\sigma}\right)\right] =
\int_{\mathbb{R}} f(x) \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx\]</span> ce qui
achève la preuve. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
corollaires</h1>
<p>Nous allons maintenant énoncer quelques propriétés importantes du
théorème central limite.</p>
<div class="corollary">
<p>Sous les hypothèses du théorème central limite de Lyapunov, la
fonction caractéristique de <span class="math inline">\(S_n\)</span>
converge vers celle d’une loi normale centrée réduite: <span
class="math display">\[\lim_{n \to \infty} \mathbb{E}\left[e^{it
S_n}\right] = e^{-t^2/2}\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Cela découle directement de l’énoncé du théorème en
prenant <span class="math inline">\(f(x) = e^{itx}\)</span> et en
utilisant la continuité de cette fonction. ◻</p>
</div>
<div class="corollary">
<p>Sous les hypothèses du théorème central limite de Lyapunov, si <span
class="math inline">\(X_1\)</span> admet une densité <span
class="math inline">\(f\)</span>, alors la somme normalisée <span
class="math inline">\(S_n\)</span> converge en loi vers une variable
aléatoire de densité <span
class="math inline">\(\frac{e^{-x^2/2}}{\sqrt{2\pi}}\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Cela résulte du théorème de Lévy et de la convergence
des fonctions caractéristiques. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le théorème central limite est un résultat fondamental en théorie des
probabilités et en statistique mathématique. Il permet d’approcher la
distribution de sommes de variables aléatoires par une loi normale, même
lorsque les variables originales ne sont pas elles-mêmes normalement
distribuées. La variance joue un rôle crucial dans ce théorème, car elle
mesure la dispersion des variables aléatoires autour de leur
moyenne.</p>
<p>Les applications du TCL sont nombreuses et variées, allant des
sciences physiques aux sciences sociales en passant par l’ingénierie. Il
est donc essentiel de bien comprendre ce théorème et ses implications
pour pouvoir l’appliquer correctement dans différents contextes.</p>
</body>
</html>
{% include "footer.html" %}

