{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Divergence de Jensen-Tsallis</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Divergence de Jensen-Tsallis</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La divergence de Jensen-Tsallis émerge dans le cadre des
généralisations des entropies classiques, notamment l’entropie de
Shannon et l’entropie de Tsallis. Introduite pour la première fois par
Constantino Tsallis dans les années 1980, cette divergence trouve ses
racines dans la physique statistique et la théorie de l’information.
Elle est particulièrement utile pour modéliser des systèmes complexes où
les interactions non-linéaires jouent un rôle crucial.</p>
<p>La divergence de Jensen-Tsallis est indispensable dans l’étude des
systèmes hors d’équilibre, des réseaux complexes et des processus
stochastiques non-markoviens. Elle permet de quantifier les écarts entre
distributions de probabilité de manière plus flexible que les
divergences classiques, offrant ainsi des outils puissants pour
l’analyse et la modélisation de phénomènes complexes.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la divergence de Jensen-Tsallis, commençons par
comprendre ce que nous cherchons à mesurer. Supposons que nous ayons
deux distributions de probabilité <span class="math inline">\(P\)</span>
et <span class="math inline">\(Q\)</span> sur un ensemble fini ou
infini. Nous voulons quantifier la différence entre ces deux
distributions en tenant compte de leurs interactions non-linéaires.</p>
<p>La divergence de Jensen-Tsallis est définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilité sur
un ensemble <span class="math inline">\(X\)</span>, et soit <span
class="math inline">\(q\)</span> un paramètre réel tel que <span
class="math inline">\(q &gt; 0\)</span>. La divergence de Jensen-Tsallis
est donnée par : <span class="math display">\[D_q(P \| Q) =
\frac{1}{q-1} \left( 1 - \sum_{x \in X} P(x)^q Q(x)^{1-q}
\right)\]</span></p>
</div>
<p>Cette définition peut également être formulée de manière équivalente
en utilisant des intégrales pour des distributions continues :</p>
<p><span class="math display">\[D_q(P \| Q) = \frac{1}{q-1} \left( 1 -
\int_{X} P(x)^q Q(x)^{1-q} \, dx \right)\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la divergence de Jensen-Tsallis est le
théorème de non-négativité, qui montre que la divergence est toujours
positive ou nulle.</p>
<div class="theoreme">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilité sur
un ensemble <span class="math inline">\(X\)</span>, et soit <span
class="math inline">\(q &gt; 0\)</span>. Alors : <span
class="math display">\[D_q(P \| Q) \geq 0\]</span> avec égalité si et
seulement si <span class="math inline">\(P = Q\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de non-négativité, nous utilisons
l’inégalité de Jensen pour les fonctions convexes. Considérons la
fonction <span class="math inline">\(f(x) = x^q\)</span>, qui est
convexe pour <span class="math inline">\(q &gt; 1\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Par l’inégalité de Jensen, nous avons : <span
class="math display">\[\sum_{x \in X} P(x) f\left( \frac{Q(x)}{P(x)}
\right) \geq f\left( \sum_{x \in X} P(x) \frac{Q(x)}{P(x)}
\right)\]</span> En substituant <span class="math inline">\(f(x) =
x^q\)</span>, nous obtenons : <span class="math display">\[\sum_{x \in
X} P(x) \left( \frac{Q(x)}{P(x)} \right)^q \geq \left( \sum_{x \in X}
Q(x) \right)^q\]</span> Puisque <span class="math inline">\(\sum_{x \in
X} Q(x) = 1\)</span>, cela se simplifie en : <span
class="math display">\[\sum_{x \in X} P(x)^{1-q} Q(x)^q \geq 1\]</span>
En réarrangeant, nous obtenons : <span class="math display">\[\sum_{x
\in X} P(x)^q Q(x)^{1-q} \leq 1\]</span> En multipliant par <span
class="math inline">\(\frac{1}{q-1}\)</span> et en soustrayant 1, nous
avons : <span class="math display">\[D_q(P \| Q) \geq 0\]</span>
L’égalité a lieu si et seulement si <span class="math inline">\(P =
Q\)</span>. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La divergence de Jensen-Tsallis possède plusieurs propriétés
intéressantes :</p>
<ol>
<li><p><strong>Continuité</strong> : La divergence de Jensen-Tsallis est
continue en fonction du paramètre <span
class="math inline">\(q\)</span>.</p></li>
<li><p><strong>Invariance par transformation</strong> : La divergence
est invariante sous les transformations affines des distributions de
probabilité.</p></li>
<li><p><strong>Convexité</strong> : La divergence est convexe en
fonction de <span class="math inline">\(P\)</span> pour un <span
class="math inline">\(q\)</span> fixe.</p></li>
</ol>
<p>Pour prouver la continuité, nous utilisons le fait que la fonction
<span class="math inline">\(f(x) = x^q\)</span> est continue en <span
class="math inline">\(q\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(q_n\)</span> une
suite convergeant vers <span class="math inline">\(q\)</span>. Alors,
pour chaque <span class="math inline">\(x \in X\)</span>, nous avons :
<span class="math display">\[\lim_{n \to \infty} P(x)^{q_n} Q(x)^{1-q_n}
= P(x)^q Q(x)^{1-q}\]</span> Par le théorème de convergence dominée,
nous pouvons intervertir la limite et la somme : <span
class="math display">\[\lim_{n \to \infty} \sum_{x \in X} P(x)^{q_n}
Q(x)^{1-q_n} = \sum_{x \in X} P(x)^q Q(x)^{1-q}\]</span> Ainsi, la
divergence de Jensen-Tsallis est continue en <span
class="math inline">\(q\)</span>. ◻</p>
</div>
</body>
</html>
{% include "footer.html" %}

