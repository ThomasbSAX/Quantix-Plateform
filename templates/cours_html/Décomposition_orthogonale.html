{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Décomposition Orthogonale: Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Décomposition Orthogonale: Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La décomposition orthogonale est un concept fondamental en algèbre
linéaire, avec des applications vastes et profondes dans de nombreux
domaines scientifiques. Historiquement, cette notion émerge avec les
travaux de David Hilbert et Erhard Schmidt sur les espaces de fonctions
au début du XXème siècle. La décomposition orthogonale permet de
représenter un vecteur ou une fonction comme une somme de vecteurs ou
fonctions mutuellement orthogonaux, facilitant ainsi l’analyse et la
compréhension des structures sous-jacentes.</p>
<p>Cette approche est indispensable dans le traitement du signal,
l’apprentissage automatique, et la résolution numérique des équations
différentielles. Elle offre une méthode puissante pour simplifier les
problèmes complexes en décomposant des espaces vectoriels en
sous-espaces orthogonaux, permettant ainsi une analyse plus fine et une
résolution plus efficace.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la décomposition orthogonale, commençons par définir
ce que nous cherchons à obtenir. Supposons que nous ayons un espace
vectoriel <span class="math inline">\(V\)</span> muni d’un produit
scalaire <span class="math inline">\(\langle \cdot, \cdot
\rangle\)</span>. Nous souhaitons exprimer un vecteur <span
class="math inline">\(v \in V\)</span> comme une somme de vecteurs
orthogonaux. Cela signifie que chaque composante du vecteur <span
class="math inline">\(v\)</span> est indépendante des autres, ce qui
simplifie grandement l’analyse.</p>
<p>Formellement, nous définissons la décomposition orthogonale comme
suit:</p>
<div class="definition">
<p>Soit <span class="math inline">\(V\)</span> un espace vectoriel de
dimension finie muni d’un produit scalaire <span
class="math inline">\(\langle \cdot, \cdot \rangle\)</span>. Une
décomposition orthogonale de <span class="math inline">\(V\)</span> est
une famille de sous-espaces vectoriels <span
class="math inline">\((W_i)_{i \in I}\)</span> telle que:</p>
<ul>
<li><p><span class="math inline">\(V = \bigoplus_{i \in I} W_i\)</span>
(somme directe),</p></li>
<li><p><span class="math inline">\(\langle w_i, w_j \rangle = 0\)</span>
pour tout <span class="math inline">\(i \neq j\)</span> et pour tout
<span class="math inline">\(w_i \in W_i, w_j \in W_j\)</span>.</p></li>
</ul>
</div>
<p>Une autre manière de formuler cette définition est la suivante:</p>
<div class="definition">
<p>Soit <span class="math inline">\(V\)</span> un espace vectoriel de
dimension finie muni d’un produit scalaire <span
class="math inline">\(\langle \cdot, \cdot \rangle\)</span>. Une
décomposition orthogonale de <span class="math inline">\(V\)</span> est
une famille de vecteurs <span class="math inline">\((e_i)_{i \in
I}\)</span> telle que:</p>
<ul>
<li><p><span class="math inline">\(\langle e_i, e_j \rangle = 0\)</span>
pour tout <span class="math inline">\(i \neq j\)</span>,</p></li>
<li><p>Tout vecteur <span class="math inline">\(v \in V\)</span> peut
s’écrire comme une combinaison linéaire finie des <span
class="math inline">\(e_i\)</span>.</p></li>
</ul>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la décomposition orthogonale est le
théorème de projection orthogonale, qui nous permet de projeter un
vecteur sur un sous-espace orthogonal.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(V\)</span> un espace vectoriel muni
d’un produit scalaire <span class="math inline">\(\langle \cdot, \cdot
\rangle\)</span>, et soit <span class="math inline">\(W\)</span> un
sous-espace vectoriel de <span class="math inline">\(V\)</span>. Pour
tout vecteur <span class="math inline">\(v \in V\)</span>, il existe un
unique vecteur <span class="math inline">\(w \in W\)</span> tel que:
<span class="math display">\[v - w\]</span> est orthogonal à <span
class="math inline">\(W\)</span>. Le vecteur <span
class="math inline">\(w\)</span> est appelé la projection orthogonale de
<span class="math inline">\(v\)</span> sur <span
class="math inline">\(W\)</span>.</p>
</div>
<p>Une autre formulation de ce théorème est la suivante:</p>
<div class="theorem">
<p>Soit <span class="math inline">\(V\)</span> un espace vectoriel muni
d’un produit scalaire <span class="math inline">\(\langle \cdot, \cdot
\rangle\)</span>, et soit <span class="math inline">\(W\)</span> un
sous-espace vectoriel de <span class="math inline">\(V\)</span>. Pour
tout vecteur <span class="math inline">\(v \in V\)</span>, il existe un
unique vecteur <span class="math inline">\(w \in W\)</span> tel que:
<span class="math display">\[\langle v - w, u \rangle = 0\]</span> pour
tout <span class="math inline">\(u \in W\)</span>. Le vecteur <span
class="math inline">\(w\)</span> est appelé la projection orthogonale de
<span class="math inline">\(v\)</span> sur <span
class="math inline">\(W\)</span>.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de projection orthogonale, nous allons
utiliser le théorème des espaces vectoriels supplémentaires et les
propriétés du produit scalaire.</p>
<div class="proof">
<p><em>Preuve du Théorème de Projection Orthogonale.</em> Soit <span
class="math inline">\(V\)</span> un espace vectoriel muni d’un produit
scalaire <span class="math inline">\(\langle \cdot, \cdot
\rangle\)</span>, et soit <span class="math inline">\(W\)</span> un
sous-espace vectoriel de <span class="math inline">\(V\)</span>. Nous
voulons montrer qu’il existe un unique vecteur <span
class="math inline">\(w \in W\)</span> tel que: <span
class="math display">\[v - w\]</span> est orthogonal à <span
class="math inline">\(W\)</span>.</p>
<p>Considérons l’ensemble des vecteurs de la forme: <span
class="math display">\[v - w\]</span> pour <span class="math inline">\(w
\in W\)</span>. Cet ensemble est un sous-espace vectoriel de <span
class="math inline">\(V\)</span> supplémentaire à <span
class="math inline">\(W\)</span>, car: <span class="math display">\[V =
(v - W) \oplus W\]</span></p>
<p>Maintenant, pour tout <span class="math inline">\(u \in W\)</span>,
nous avons: <span class="math display">\[\langle v - w, u \rangle =
0\]</span></p>
<p>En développant cette expression, nous obtenons: <span
class="math display">\[\langle v, u \rangle = \langle w, u
\rangle\]</span></p>
<p>Puisque <span class="math inline">\(W\)</span> est un sous-espace
vectoriel de <span class="math inline">\(V\)</span>, il existe une base
orthonormée <span class="math inline">\((e_i)_{i \in I}\)</span> de
<span class="math inline">\(W\)</span>. Nous pouvons donc écrire <span
class="math inline">\(w\)</span> comme une combinaison linéaire des
<span class="math inline">\(e_i\)</span>: <span class="math display">\[w
= \sum_{i \in I} \langle w, e_i \rangle e_i\]</span></p>
<p>En substituant cette expression dans l’équation précédente, nous
obtenons: <span class="math display">\[\langle v, u \rangle = \sum_{i
\in I} \langle w, e_i \rangle \langle e_i, u \rangle\]</span></p>
<p>Puisque <span class="math inline">\((e_i)_{i \in I}\)</span> est une
base orthonormée de <span class="math inline">\(W\)</span>, nous avons:
<span class="math display">\[\langle e_i, u \rangle = 0\]</span> pour
tout <span class="math inline">\(i \in I\)</span> sauf un seul. Par
conséquent, nous avons: <span class="math display">\[\langle v, u
\rangle = \langle w, e_i \rangle\]</span></p>
<p>En résolvant cette équation pour <span class="math inline">\(\langle
w, e_i \rangle\)</span>, nous obtenons: <span
class="math display">\[\langle w, e_i \rangle = \frac{\langle v, u
\rangle}{\|e_i\|^2}\]</span></p>
<p>Puisque <span class="math inline">\((e_i)_{i \in I}\)</span> est une
base orthonormée de <span class="math inline">\(W\)</span>, nous avons
<span class="math inline">\(\|e_i\| = 1\)</span> pour tout <span
class="math inline">\(i \in I\)</span>. Par conséquent, nous avons:
<span class="math display">\[\langle w, e_i \rangle = \langle v, u
\rangle\]</span></p>
<p>En substituant cette expression dans l’expression de <span
class="math inline">\(w\)</span>, nous obtenons: <span
class="math display">\[w = \sum_{i \in I} \langle v, u \rangle
e_i\]</span></p>
<p>Puisque <span class="math inline">\((e_i)_{i \in I}\)</span> est une
base orthonormée de <span class="math inline">\(W\)</span>, nous avons:
<span class="math display">\[w = P_W v\]</span> où <span
class="math inline">\(P_W\)</span> est la projection orthogonale sur
<span class="math inline">\(W\)</span>.</p>
<p>Pour montrer l’unicité de <span class="math inline">\(w\)</span>,
supposons qu’il existe un autre vecteur <span
class="math inline">\(w&#39; \in W\)</span> tel que: <span
class="math display">\[v - w&#39;\]</span> est orthogonal à <span
class="math inline">\(W\)</span>. En utilisant le même raisonnement que
ci-dessus, nous pouvons montrer que: <span class="math display">\[w&#39;
= P_W v\]</span></p>
<p>Par conséquent, <span class="math inline">\(w\)</span> est
unique. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous allons maintenant lister quelques propriétés importantes de la
décomposition orthogonale.</p>
<div class="proposition">
<p>Soit <span class="math inline">\(V\)</span> un espace vectoriel muni
d’un produit scalaire <span class="math inline">\(\langle \cdot, \cdot
\rangle\)</span>, et soit <span class="math inline">\((W_i)_{i \in
I}\)</span> une décomposition orthogonale de <span
class="math inline">\(V\)</span>. Alors:</p>
<ul>
<li><p>Pour tout <span class="math inline">\(v \in V\)</span>, nous
avons: <span class="math display">\[\|v\|^2 = \sum_{i \in I} \|P_{W_i}
v\|^2\]</span> où <span class="math inline">\(P_{W_i}\)</span> est la
projection orthogonale sur <span
class="math inline">\(W_i\)</span>.</p></li>
<li><p>Pour tout <span class="math inline">\(v, w \in V\)</span>, nous
avons: <span class="math display">\[\langle v, w \rangle = \sum_{i \in
I} \langle P_{W_i} v, P_{W_i} w \rangle\]</span></p></li>
<li><p>Pour tout <span class="math inline">\(v \in V\)</span>, nous
avons: <span class="math display">\[P_{W_i} v = 0\]</span> pour tout
<span class="math inline">\(i \in I\)</span> sauf un seul.</p></li>
</ul>
</div>
<div class="proof">
<p><em>Preuve de la Proposition.</em> Nous allons prouver chaque
propriété une par une.</p>
<p><strong>Preuve de (i):</strong></p>
<p>Pour tout <span class="math inline">\(v \in V\)</span>, nous avons:
<span class="math display">\[v = \sum_{i \in I} P_{W_i} v\]</span></p>
<p>En prenant le produit scalaire de chaque côté avec <span
class="math inline">\(v\)</span>, nous obtenons: <span
class="math display">\[\|v\|^2 = \sum_{i \in I} \langle P_{W_i} v, v
\rangle\]</span></p>
<p>En utilisant le fait que <span class="math inline">\(P_{W_i} v \in
W_i\)</span> et que <span class="math inline">\((W_i)_{i \in I}\)</span>
est une décomposition orthogonale de <span
class="math inline">\(V\)</span>, nous avons: <span
class="math display">\[\langle P_{W_i} v, v \rangle = \|P_{W_i}
v\|^2\]</span></p>
<p>Par conséquent, nous avons: <span class="math display">\[\|v\|^2 =
\sum_{i \in I} \|P_{W_i} v\|^2\]</span></p>
<p><strong>Preuve de (ii):</strong></p>
<p>Pour tout <span class="math inline">\(v, w \in V\)</span>, nous
avons: <span class="math display">\[\langle v, w \rangle = \sum_{i \in
I} \langle P_{W_i} v, w \rangle\]</span></p>
<p>En utilisant le fait que <span class="math inline">\(P_{W_i} v \in
W_i\)</span> et que <span class="math inline">\((W_i)_{i \in I}\)</span>
est une décomposition orthogonale de <span
class="math inline">\(V\)</span>, nous avons: <span
class="math display">\[\langle P_{W_i} v, w \rangle = \langle P_{W_i} v,
P_{W_i} w \rangle\]</span></p>
<p>Par conséquent, nous avons: <span class="math display">\[\langle v, w
\rangle = \sum_{i \in I} \langle P_{W_i} v, P_{W_i} w
\rangle\]</span></p>
<p><strong>Preuve de (iii):</strong></p>
<p>Pour tout <span class="math inline">\(v \in V\)</span>, nous avons:
<span class="math display">\[P_{W_i} v = 0\]</span> pour tout <span
class="math inline">\(i \in I\)</span> sauf un seul, car <span
class="math inline">\((W_i)_{i \in I}\)</span> est une décomposition
orthogonale de <span class="math inline">\(V\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La décomposition orthogonale est un outil puissant et polyvalent en
algèbre linéaire, avec des applications dans de nombreux domaines
scientifiques. Elle permet de simplifier l’analyse des espaces
vectoriels en les décomposant en sous-espaces orthogonaux, facilitant
ainsi la résolution de problèmes complexes. Les théorèmes et propriétés
présentés dans cet article fournissent une base solide pour comprendre
et utiliser la décomposition orthogonale dans diverses applications.</p>
</body>
</html>
{% include "footer.html" %}

