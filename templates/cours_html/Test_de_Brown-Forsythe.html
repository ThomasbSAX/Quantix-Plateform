{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Test de Brown-Forsythe : Une généralisation robuste du test de Levene</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Test de Brown-Forsythe : Une généralisation robuste du
test de Levene</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>Le test de Brown-Forsythe émerge dans le paysage des tests
statistiques comme une réponse robuste aux limitations du test de
Levene. Conçu pour évaluer l’homogénéité des variances dans un contexte
d’analyse de variance (ANOVA), ce test s’avère particulièrement utile
lorsque les données présentent des distributions non normales ou des
écarts à la normalité. Son importance réside dans sa capacité à fournir
des résultats fiables même en présence de violations des hypothèses
classiques, ce qui en fait un outil indispensable pour les chercheurs
travaillant avec des données réelles souvent complexes et
imparfaites.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre le test de Brown-Forsythe, il est essentiel de saisir
les concepts fondamentaux qui le sous-tendent. Supposons que nous ayons
<span class="math inline">\(k\)</span> groupes de données, avec <span
class="math inline">\(n_i\)</span> observations dans le groupe <span
class="math inline">\(i\)</span>, pour <span class="math inline">\(i =
1, 2, \ldots, k\)</span>. Nous cherchons à tester l’hypothèse nulle
selon laquelle les variances des <span class="math inline">\(k\)</span>
groupes sont égales.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X_{ij}\)</span> l’observation <span
class="math inline">\(j\)</span> dans le groupe <span
class="math inline">\(i\)</span>, où <span class="math inline">\(i = 1,
2, \ldots, k\)</span> et <span class="math inline">\(j = 1, 2, \ldots,
n_i\)</span>. La statistique de test de Brown-Forsythe est définie comme
suit :</p>
<p><span class="math display">\[F = \frac{\sum_{i=1}^{k} n_i (\bar{X}_i
- \text{med}(X))^2 / (k-1)}{\sum_{i=1}^{k} \sum_{j=1}^{n_i} (X_{ij} -
\bar{X}_i)^2 / (N-k)}\]</span></p>
<p>où <span class="math inline">\(\bar{X}_i\)</span> est la moyenne du
groupe <span class="math inline">\(i\)</span>, <span
class="math inline">\(\text{med}(X)\)</span> est la médiane de toutes
les observations, et <span class="math inline">\(N = \sum_{i=1}^{k}
n_i\)</span> est le nombre total d’observations.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Le test de Brown-Forsythe repose sur plusieurs théorèmes et
propriétés statistiques. L’un des plus importants est le théorème
suivant, qui établit la distribution de la statistique de test sous
l’hypothèse nulle.</p>
<div class="theorem">
<p>Sous l’hypothèse nulle <span class="math inline">\(H_0\)</span> que
les variances des <span class="math inline">\(k\)</span> groupes sont
égales, la statistique de test <span class="math inline">\(F\)</span>
suit une distribution de Fisher-Snedecor avec <span
class="math inline">\(k-1\)</span> et <span
class="math inline">\(N-k\)</span> degrés de liberté, notée <span
class="math inline">\(F_{k-1, N-k}\)</span>.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous devons démontrer que la statistique de
test <span class="math inline">\(F\)</span> suit bien une distribution
de Fisher-Snedecor sous l’hypothèse nulle. Commençons par rappeler que,
sous <span class="math inline">\(H_0\)</span>, les variances des groupes
sont égales et que les observations sont indépendantes et normalement
distribuées.</p>
<div class="proof">
<p><em>Proof.</em> Sous <span class="math inline">\(H_0\)</span>, nous
avons que les variances des groupes sont égales, c’est-à-dire <span
class="math inline">\(\sigma_1^2 = \sigma_2^2 = \ldots = \sigma_k^2 =
\sigma^2\)</span>. De plus, les observations <span
class="math inline">\(X_{ij}\)</span> sont indépendantes et normalement
distribuées avec une variance commune <span
class="math inline">\(\sigma^2\)</span>.</p>
<p>La statistique de test <span class="math inline">\(F\)</span> peut
être réécrite comme :</p>
<p><span class="math display">\[F = \frac{\text{SSB} / (k-1)}{\text{SSE}
/ (N-k)}\]</span></p>
<p>où <span class="math inline">\(\text{SSB} = \sum_{i=1}^{k} n_i
(\bar{X}_i - \text{med}(X))^2\)</span> est la somme des carrés entre les
groupes et <span class="math inline">\(\text{SSE} = \sum_{i=1}^{k}
\sum_{j=1}^{n_i} (X_{ij} - \bar{X}_i)^2\)</span> est la somme des carrés
dans les groupes.</p>
<p>Sous <span class="math inline">\(H_0\)</span>, <span
class="math inline">\(\text{SSB} / \sigma^2\)</span> suit une
distribution du chi-carré avec <span class="math inline">\(k-1\)</span>
degrés de liberté, et <span class="math inline">\(\text{SSE} /
\sigma^2\)</span> suit une distribution du chi-carré avec <span
class="math inline">\(N-k\)</span> degrés de liberté. De plus, ces deux
statistiques sont indépendantes.</p>
<p>Par conséquent, le rapport <span class="math inline">\(F =
\frac{\text{SSB} / (k-1)}{\text{SSE} / (N-k)}\)</span> suit une
distribution de Fisher-Snedecor avec <span
class="math inline">\(k-1\)</span> et <span
class="math inline">\(N-k\)</span> degrés de liberté. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le test de Brown-Forsythe possède plusieurs propriétés intéressantes
qui en font un outil puissant pour l’analyse des données.</p>
<ol>
<li><p><strong>Robustesse aux violations de la normalité</strong> : Le
test de Brown-Forsythe est robuste aux violations de l’hypothèse de
normalité des données. Cela signifie qu’il peut fournir des résultats
fiables même lorsque les données ne suivent pas une distribution
normale.</p></li>
<li><p><strong>Sensibilité aux différences de variances</strong> : Le
test est sensible aux différences de variances entre les groupes. Plus
les variances des groupes sont différentes, plus la statistique de test
<span class="math inline">\(F\)</span> sera élevée, ce qui augmente la
probabilité de rejeter l’hypothèse nulle.</p></li>
<li><p><strong>Indépendance des tailles d’échantillon</strong> : Le test
de Brown-Forsythe ne nécessite pas que les tailles d’échantillon des
groupes soient égales. Il peut être appliqué même lorsque les groupes
ont des tailles différentes, ce qui est souvent le cas dans les études
réelles.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le test de Brown-Forsythe représente une avancée significative dans
le domaine des tests d’homogénéité des variances. Sa robustesse aux
violations de la normalité et sa sensibilité aux différences de
variances en font un outil précieux pour les chercheurs travaillant avec
des données complexes et imparfaites. En comprenant les concepts
fondamentaux, les théorèmes sous-jacents et les propriétés de ce test,
nous pouvons mieux apprécier son importance et son utilité dans
l’analyse statistique.</p>
</body>
</html>
{% include "footer.html" %}

