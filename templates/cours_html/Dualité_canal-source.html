{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Dualité canal-source : Un pont entre théorie de l’information et optimisation</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Dualité canal-source : Un pont entre théorie de
l’information et optimisation</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La dualité canal-source émerge comme un concept fondamental à
l’intersection de la théorie de l’information et de l’optimisation.
Cette notion, introduite pour la première fois par Shannon dans ses
travaux pionniers sur la théorie de l’information, établit un lien
profond entre les problèmes de compression de données et de transmission
fiable. L’objectif est de comprendre comment les contraintes d’un canal
de communication influencent les stratégies optimales de compression, et
vice versa.</p>
<p>Cette dualité est indispensable dans le cadre des systèmes de
communication modernes, où l’efficacité énergétique et la fiabilité sont
cruciales. Elle permet de formuler des problèmes complexes en termes de
programmes convexes, facilitant ainsi leur résolution et leur
analyse.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la dualité canal-source, il est essentiel de définir
les concepts clés de manière rigoureuse.</p>
<h2 id="canal-de-communication">Canal de communication</h2>
<p>Un canal de communication est un système qui prend en entrée une
séquence de symboles et produit en sortie une autre séquence,
potentiellement corrompue par du bruit. Formellement, un canal sans
mémoire est défini par une fonction de transition <span
class="math inline">\(W(y|x)\)</span>, où <span
class="math inline">\(x\)</span> est l’entrée et <span
class="math inline">\(y\)</span> la sortie.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathcal{X}\)</span> et <span
class="math inline">\(\mathcal{Y}\)</span> des ensembles finis. Un canal
de communication est une application <span class="math inline">\(W:
\mathcal{X} \rightarrow \mathcal{P}(\mathcal{Y})\)</span>, où <span
class="math inline">\(\mathcal{P}(\mathcal{Y})\)</span> désigne
l’ensemble des distributions de probabilité sur <span
class="math inline">\(\mathcal{Y}\)</span>. Pour tout <span
class="math inline">\(x \in \mathcal{X}\)</span>, <span
class="math inline">\(W(\cdot|x)\)</span> est une distribution de
probabilité sur <span class="math inline">\(\mathcal{Y}\)</span>.</p>
</div>
<h2 id="source-dinformation">Source d’information</h2>
<p>Une source d’information est un processus aléatoire qui génère des
séquences de symboles. Une source sans mémoire est définie par une
distribution de probabilité <span class="math inline">\(P(x)\)</span>
sur un ensemble fini <span
class="math inline">\(\mathcal{X}\)</span>.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathcal{X}\)</span> un ensemble
fini. Une source d’information est une distribution de probabilité <span
class="math inline">\(P: \mathcal{X} \rightarrow [0,1]\)</span> telle
que <span class="math inline">\(\sum_{x \in \mathcal{X}} P(x) =
1\)</span>.</p>
</div>
<h2 id="dualité-canal-source">Dualité canal-source</h2>
<p>La dualité canal-source établit une relation entre les capacités d’un
canal et les taux de compression d’une source. Cette relation est
formalisée par le théorème de la dualité canal-source, que nous
aborderons dans la section suivante.</p>
<h1 id="théorèmes">Théorèmes</h1>
<h2 id="théorème-de-la-dualité-canal-source">Théorème de la dualité
canal-source</h2>
<p>Le théorème de la dualité canal-source est un résultat fondamental
qui relie les capacités d’un canal et les taux de compression d’une
source. Ce théorème montre que, sous certaines conditions, le problème
de la transmission fiable à travers un canal peut être formulé comme un
problème de compression de source.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(W\)</span> un canal de communication
et <span class="math inline">\(P\)</span> une source d’information.
Supposons que le canal <span class="math inline">\(W\)</span> est
symétrique et que la source <span class="math inline">\(P\)</span> est
stationnaire et ergodique. Alors, le taux de transmission maximal fiable
à travers le canal <span class="math inline">\(W\)</span> est égal au
taux de compression minimal pour la source <span
class="math inline">\(P\)</span>.</p>
</div>
<h2 id="formulation-mathématique">Formulation mathématique</h2>
<p>Pour formaliser ce théorème, nous introduisons les notions de
capacité d’un canal et de taux de compression.</p>
<div class="definition">
<p>La capacité <span class="math inline">\(C\)</span> d’un canal <span
class="math inline">\(W\)</span> est définie comme : <span
class="math display">\[C = \max_{P(x)} I(X;Y),\]</span> où <span
class="math inline">\(I(X;Y)\)</span> est l’information mutuelle entre
<span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, et la maximisation est effectuée sur
toutes les distributions de probabilité <span
class="math inline">\(P(x)\)</span> sur <span
class="math inline">\(\mathcal{X}\)</span>.</p>
</div>
<div class="definition">
<p>Le taux de compression <span class="math inline">\(R\)</span> d’une
source <span class="math inline">\(P\)</span> est défini comme : <span
class="math display">\[R = H(P),\]</span> où <span
class="math inline">\(H(P)\)</span> est l’entropie de la source <span
class="math inline">\(P\)</span>.</p>
</div>
<p>Le théorème de la dualité canal-source peut alors être formulé comme
suit :</p>
<div class="theorem">
<p>Sous les hypothèses du théorème précédent, nous avons : <span
class="math display">\[C = R.\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<h2 id="preuve-du-théorème-de-la-dualité-canal-source">Preuve du
théorème de la dualité canal-source</h2>
<p>Pour prouver ce théorème, nous devons montrer que le taux de
transmission maximal fiable à travers le canal <span
class="math inline">\(W\)</span> est égal au taux de compression minimal
pour la source <span class="math inline">\(P\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Commençons par rappeler que le taux de transmission
maximal fiable à travers un canal <span class="math inline">\(W\)</span>
est donné par sa capacité <span class="math inline">\(C\)</span>.
D’autre part, le taux de compression minimal pour une source <span
class="math inline">\(P\)</span> est donné par son entropie <span
class="math inline">\(H(P)\)</span>.</p>
<p>Sous les hypothèses du théorème, le canal <span
class="math inline">\(W\)</span> est symétrique et la source <span
class="math inline">\(P\)</span> est stationnaire et ergodique. Cela
signifie que l’information mutuelle <span
class="math inline">\(I(X;Y)\)</span> est maximisée lorsque <span
class="math inline">\(P(x) = W(y|x)\)</span>.</p>
<p>En utilisant la symétrie du canal, nous pouvons montrer que : <span
class="math display">\[I(X;Y) = H(Y) - H(Y|X).\]</span></p>
<p>Puisque <span class="math inline">\(W\)</span> est symétrique, <span
class="math inline">\(H(Y|X) = 0\)</span>, et donc : <span
class="math display">\[I(X;Y) = H(Y).\]</span></p>
<p>D’autre part, comme <span class="math inline">\(P\)</span> est
stationnaire et ergodique, nous avons : <span
class="math display">\[H(P) = H(Y).\]</span></p>
<p>En combinant ces résultats, nous obtenons : <span
class="math display">\[C = \max_{P(x)} I(X;Y) = H(Y) = H(P) =
R.\]</span></p>
<p>Cela achève la preuve du théorème de la dualité canal-source. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriétés-de-la-dualité-canal-source">Propriétés de la dualité
canal-source</h2>
<p>Nous énumérons et développons les propriétés clés de la dualité
canal-source.</p>
<ol>
<li><p>La dualité canal-source est valable pour les canaux symétriques
et les sources stationnaires et ergodiques. Cette propriété est cruciale
pour l’application du théorème dans les systèmes de communication
pratiques.</p></li>
<li><p>La dualité canal-source permet de formuler des problèmes
complexes en termes de programmes convexes. Cela facilite leur
résolution et leur analyse, rendant le théorème particulièrement utile
pour l’optimisation des systèmes de communication.</p></li>
<li><p>La dualité canal-source établit un lien entre la théorie de
l’information et l’optimisation. Ce lien est essentiel pour comprendre
les limitations fondamentales des systèmes de communication et pour
développer des stratégies optimales de compression et de
transmission.</p></li>
</ol>
<h2 id="corollaires">Corollaires</h2>
<p>Nous présentons quelques corollaires importants du théorème de la
dualité canal-source.</p>
<div class="corollary">
<p>Soit <span class="math inline">\(W\)</span> un canal de communication
symétrique et <span class="math inline">\(P\)</span> une source
d’information stationnaire et ergodique. Alors, le taux de transmission
maximal fiable à travers le canal <span class="math inline">\(W\)</span>
est égal au taux de compression minimal pour la source <span
class="math inline">\(P\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Ce corollaire est une conséquence directe du théorème
de la dualité canal-source. En effet, sous les hypothèses du corollaire,
nous avons <span class="math inline">\(C = R\)</span>, ce qui implique
que le taux de transmission maximal fiable est égal au taux de
compression minimal. ◻</p>
</div>
<div class="corollary">
<p>Soit <span class="math inline">\(W\)</span> un canal de communication
symétrique et <span class="math inline">\(P\)</span> une source
d’information stationnaire et ergodique. Alors, le problème de la
transmission fiable à travers le canal <span
class="math inline">\(W\)</span> peut être formulé comme un problème de
compression de source.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Ce corollaire découle également du théorème de la
dualité canal-source. En effet, sous les hypothèses du corollaire, le
problème de la transmission fiable peut être formulé en termes de
compression de source, ce qui facilite sa résolution et son
analyse. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La dualité canal-source est un concept fondamental en théorie de
l’information et en optimisation. Elle établit un lien profond entre les
problèmes de compression de données et de transmission fiable,
permettant de formuler des problèmes complexes en termes de programmes
convexes. Les applications de cette dualité sont nombreuses et variées,
allant des systèmes de communication modernes aux algorithmes
d’optimisation avancés.</p>
<p>En conclusion, la dualité canal-source est un outil puissant pour
comprendre les limitations fondamentales des systèmes de communication
et pour développer des stratégies optimales de compression et de
transmission. Son étude continue de susciter un vif intérêt dans la
communauté scientifique, ouvrant la voie à de nouvelles découvertes et
applications.</p>
</body>
</html>
{% include "footer.html" %}

