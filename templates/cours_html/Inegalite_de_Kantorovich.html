{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’inégalité de Kantorovich: Une exploration mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’inégalité de Kantorovich: Une exploration
mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’inégalité de Kantorovich, nommée en l’honneur du mathématicien
soviétique Leonid Vitaliyevich Kantorovich (1912-1986), est une
inégalité fondamentale en analyse mathématique et en théorie des
probabilités. Cette inégalité émerge dans le cadre de l’étude des
fonctions convexes et des mesures de probabilité. Elle est indispensable
pour comprendre les propriétés des espérances conditionnelles, des
martingales et des inégalités de concentration.</p>
<p>L’origine historique de cette inégalité remonte aux années 1940,
lorsque Kantorovich travaillait sur des problèmes d’optimisation et de
programmation linéaire. L’inégalité a été formulée pour la première fois
dans un contexte de théorie des probabilités, mais elle a depuis trouvé
des applications dans divers domaines, notamment en statistique, en
théorie du contrôle et en apprentissage automatique.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant de formuler l’inégalité de Kantorovich, il est essentiel de
comprendre certains concepts clés. Supposons que nous ayons une fonction
convexe et une mesure de probabilité. Nous cherchons à comprendre
comment l’espérance d’une fonction convexe peut être bornée en termes de
l’espérance de la fonction elle-même et de sa dérivée.</p>
<div class="definition">
<p>Soit <span class="math inline">\(f: \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction. On dit que <span
class="math inline">\(f\)</span> est convexe si pour tout <span
class="math inline">\(x, y \in \mathbb{R}^n\)</span> et pour tout <span
class="math inline">\(\lambda \in [0, 1]\)</span>, on a: <span
class="math display">\[f(\lambda x + (1 - \lambda) y) \leq \lambda f(x)
+ (1 - \lambda) f(y).\]</span></p>
</div>
<div class="definition">
<p>Soit <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> un
espace probabilisé et <span class="math inline">\(\mathcal{G}\)</span>
une sous-tribu de <span class="math inline">\(\mathcal{F}\)</span>.
L’espérance conditionnelle de <span class="math inline">\(X\)</span> par
rapport à <span class="math inline">\(\mathcal{G}\)</span>, notée <span
class="math inline">\(E[X | \mathcal{G}]\)</span>, est une fonction
mesurable par rapport à <span class="math inline">\(\mathcal{G}\)</span>
telle que pour toute fonction mesurable bornée <span
class="math inline">\(h\)</span>, on a: <span
class="math display">\[E[h(X) | \mathcal{G}] = E[h(E[X |
\mathcal{G}])].\]</span></p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>L’inégalité de Kantorovich est un résultat puissant qui relie
l’espérance d’une fonction convexe à l’espérance de la fonction
elle-même et de sa dérivée. Voici une formulation classique de cette
inégalité.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(f: \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction convexe et différentiable. Soit <span
class="math inline">\(X\)</span> une variable aléatoire à valeurs dans
<span class="math inline">\(\mathbb{R}^n\)</span>. Alors, pour toute
sous-tribu <span class="math inline">\(\mathcal{G}\)</span> de <span
class="math inline">\(\mathcal{F}\)</span>, on a: <span
class="math display">\[E[f(X) | \mathcal{G}] \geq f(E[X | \mathcal{G}])
+ E[(X - E[X | \mathcal{G}])^T \nabla f(E[X |
\mathcal{G}])].\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer l’inégalité de Kantorovich, nous utilisons le fait que
<span class="math inline">\(f\)</span> est convexe et différentiable.
Nous commençons par appliquer le théorème de Jensen à la fonction <span
class="math inline">\(f\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(Y = E[X |
\mathcal{G}]\)</span>. Puisque <span class="math inline">\(f\)</span>
est convexe, nous pouvons utiliser le théorème de Jensen pour obtenir:
<span class="math display">\[E[f(X) | \mathcal{G}] \geq f(E[X |
\mathcal{G}]).\]</span></p>
<p>Ensuite, nous utilisons le fait que <span
class="math inline">\(f\)</span> est différentiable pour linéariser
l’expression. Nous avons: <span class="math display">\[f(X) \geq f(Y) +
(X - Y)^T \nabla f(Y).\]</span></p>
<p>En prenant l’espérance conditionnelle des deux côtés, nous obtenons:
<span class="math display">\[E[f(X) | \mathcal{G}] \geq f(Y) + E[(X -
Y)^T \nabla f(Y)].\]</span></p>
<p>En substituant <span class="math inline">\(Y = E[X |
\mathcal{G}]\)</span>, nous obtenons finalement: <span
class="math display">\[E[f(X) | \mathcal{G}] \geq f(E[X | \mathcal{G}])
+ E[(X - E[X | \mathcal{G}])^T \nabla f(E[X |
\mathcal{G}])].\]</span> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’inégalité de Kantorovich a plusieurs propriétés intéressantes et
corollaires. Nous en listons quelques-uns ci-dessous.</p>
<ol>
<li><p>Si <span class="math inline">\(f\)</span> est une fonction
affine, c’est-à-dire <span class="math inline">\(f(x) = a^T x +
b\)</span>, alors l’inégalité de Kantorovich se réduit à une égalité:
<span class="math display">\[E[f(X) | \mathcal{G}] = f(E[X |
\mathcal{G}]).\]</span></p></li>
<li><p>Si <span class="math inline">\(f\)</span> est une fonction
strictement convexe, l’inégalité de Kantorovich est stricte: <span
class="math display">\[E[f(X) | \mathcal{G}] &gt; f(E[X | \mathcal{G}])
+ E[(X - E[X | \mathcal{G}])^T \nabla f(E[X |
\mathcal{G}])].\]</span></p></li>
<li><p>L’inégalité de Kantorovich peut être utilisée pour borner
l’erreur d’approximation dans les méthodes de Monte Carlo. Par exemple,
si <span class="math inline">\(f\)</span> est une fonction convexe et
<span class="math inline">\(X\)</span> est une variable aléatoire,
alors: <span class="math display">\[E[f(X)] \geq f(E[X]) + E[(X -
E[X])^T \nabla f(E[X])].\]</span></p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’inégalité de Kantorovich est un outil puissant en analyse
mathématique et en théorie des probabilités. Elle trouve des
applications dans divers domaines, notamment en statistique, en théorie
du contrôle et en apprentissage automatique. Dans cet article, nous
avons présenté l’inégalité de Kantorovich, ses définitions, ses
théorèmes et ses preuves. Nous avons également discuté de certaines
propriétés et corollaires importants.</p>
</body>
</html>
{% include "footer.html" %}

