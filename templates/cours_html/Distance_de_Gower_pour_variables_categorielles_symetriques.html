{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Gower pour variables catégorielles symétriques</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Gower pour variables catégorielles
symétriques</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Gower émerge comme une réponse élégante à un problème
fondamental en analyse des données : la mesure de similarité entre
entités décrites par des variables mixtes, incluant des variables
catégorielles symétriques. Historiquement, cette notion trouve ses
racines dans les travaux de Gower (1971), qui cherchait à unifier les
approches de dissimilarité pour des données hétérogènes. L’enjeu est
crucial dans des domaines variés, de la biologie à la sociologie, où les
variables catégorielles symétriques (c’est-à-dire sans ordre
intrinsèque) nécessitent une métrique adaptée.</p>
<p>Cette distance est indispensable pour des applications telles que le
clustering ou l’analyse factorielle, où la symétrie des catégories
impose une approche distincte de celle des variables ordinales ou
numériques. Elle résout le paradoxe de la comparaison entre catégories
non ordonnées, en attribuant une valeur binaire à l’égalité ou la
différence, tout en intégrant une pondération pour les variables
manquantes.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la distance de Gower, considérons un ensemble
d’entités <span class="math inline">\(I\)</span> et un ensemble de
variables catégorielles symétriques <span
class="math inline">\(J\)</span>. Nous cherchons une mesure qui capture
la dissimilarité entre deux entités <span class="math inline">\(i, k \in
I\)</span> pour une variable <span class="math inline">\(j \in
J\)</span>. Intuitivement, cette dissimilarité doit être maximale si les
catégories diffèrent et nulle si elles sont identiques.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une matrice de données où
chaque ligne correspond à une entité et chaque colonne à une variable
catégorielle symétrique. Pour deux entités <span
class="math inline">\(i, k \in I\)</span> et une variable <span
class="math inline">\(j \in J\)</span>, la dissimilarité élémentaire est
définie comme :</p>
<p><span class="math display">\[d_{jk} =
\begin{cases}
0 &amp; \text{si } X_{ij} = X_{kj}, \\
1 &amp; \text{sinon.}
\end{cases}\]</span></p>
<p>En notation quantifiée, pour tout <span class="math inline">\(i, k
\in I\)</span> et <span class="math inline">\(j \in J\)</span>, la
dissimilarité s’exprime par :</p>
<p><span class="math display">\[d_{jk} = \mathbb{I}(X_{ij} \neq
X_{kj})\]</span></p>
<p>où <span class="math inline">\(\mathbb{I}\)</span> est l’indicatrice
de la condition <span class="math inline">\(X_{ij} \neq
X_{kj}\)</span>.</p>
</div>
<p>Pour plusieurs variables, la distance de Gower agrège ces
dissimilarités élémentaires en une mesure globale. Considérons un
vecteur de pondérations <span class="math inline">\(w \in [0,
1]^{|J|}\)</span> pour tenir compte de l’importance relative des
variables.</p>
<div class="definition">
<p>Pour deux entités <span class="math inline">\(i, k \in I\)</span>, la
distance de Gower est donnée par :</p>
<p><span class="math display">\[D(i, k) = \frac{\sum_{j \in J} w_j
d_{jk}}{\sum_{j \in J} w_j}\]</span></p>
<p>En notation quantifiée, pour tout <span class="math inline">\(i, k
\in I\)</span>, la distance s’exprime par :</p>
<p><span class="math display">\[D(i, k) = \frac{\sum_{j=1}^{|J|} w_j
\mathbb{I}(X_{ij} \neq X_{kj})}{\sum_{j=1}^{|J|} w_j}\]</span></p>
<p>où <span class="math inline">\(\mathbb{I}\)</span> est l’indicatrice
de la condition <span class="math inline">\(X_{ij} \neq
X_{kj}\)</span>.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème central lié à la distance de Gower est celui de sa
normalisation. Ce théorème assure que la distance reste comprise entre 0
et 1, ce qui est crucial pour l’interprétabilité.</p>
<div class="theorem">
<p>Pour toute paire d’entités <span class="math inline">\(i, k \in
I\)</span>, la distance de Gower <span class="math inline">\(D(i,
k)\)</span> satisfait :</p>
<p><span class="math display">\[0 \leq D(i, k) \leq 1\]</span></p>
<p>De plus, <span class="math inline">\(D(i, k) = 0\)</span> si et
seulement si les entités <span class="math inline">\(i\)</span> et <span
class="math inline">\(k\)</span> sont identiques sur toutes les
variables pondérées, et <span class="math inline">\(D(i, k) = 1\)</span>
si elles diffèrent sur toutes les variables pondérées.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La borne inférieure <span class="math inline">\(D(i,
k) \geq 0\)</span> est immédiate car les dissimilarités élémentaires
<span class="math inline">\(d_{jk}\)</span> sont non négatives et les
pondérations <span class="math inline">\(w_j\)</span> le sont
également.</p>
<p>Pour la borne supérieure, notons que chaque terme <span
class="math inline">\(d_{jk} \leq 1\)</span>. Ainsi,</p>
<p><span class="math display">\[\sum_{j \in J} w_j d_{jk} \leq \sum_{j
\in J} w_j\]</span></p>
<p>En divisant par <span class="math inline">\(\sum_{j \in J}
w_j\)</span>, on obtient <span class="math inline">\(D(i, k) \leq
1\)</span>.</p>
<p>L’égalité <span class="math inline">\(D(i, k) = 0\)</span> implique
que tous les termes <span class="math inline">\(d_{jk} = 0\)</span>,
c’est-à-dire que <span class="math inline">\(X_{ij} = X_{kj}\)</span>
pour tout <span class="math inline">\(j \in J\)</span>. Réciproquement,
si <span class="math inline">\(X_{ij} = X_{kj}\)</span> pour tout <span
class="math inline">\(j \in J\)</span>, alors tous les termes <span
class="math inline">\(d_{jk} = 0\)</span> et donc <span
class="math inline">\(D(i, k) = 0\)</span>.</p>
<p>De même, l’égalité <span class="math inline">\(D(i, k) = 1\)</span>
implique que tous les termes <span class="math inline">\(d_{jk} =
1\)</span>, c’est-à-dire que <span class="math inline">\(X_{ij} \neq
X_{kj}\)</span> pour tout <span class="math inline">\(j \in J\)</span>.
Réciproquement, si <span class="math inline">\(X_{ij} \neq
X_{kj}\)</span> pour tout <span class="math inline">\(j \in J\)</span>,
alors tous les termes <span class="math inline">\(d_{jk} = 1\)</span> et
donc <span class="math inline">\(D(i, k) = 1\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La distance de Gower possède plusieurs propriétés remarquables,
notamment en ce qui concerne la symétrie et le triangle.</p>
<div class="corollaire">
<p>Pour toute paire d’entités <span class="math inline">\(i, k \in
I\)</span>, la distance de Gower est symétrique :</p>
<p><span class="math display">\[D(i, k) = D(k, i)\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La symétrie découle directement de la définition. En
effet,</p>
<p><span class="math display">\[D(i, k) = \frac{\sum_{j \in J} w_j
\mathbb{I}(X_{ij} \neq X_{kj})}{\sum_{j \in J} w_j} = \frac{\sum_{j \in
J} w_j \mathbb{I}(X_{kj} \neq X_{ij})}{\sum_{j \in J} w_j} = D(k,
i)\]</span></p>
<p>car <span class="math inline">\(\mathbb{I}(X_{ij} \neq X_{kj}) =
\mathbb{I}(X_{kj} \neq X_{ij})\)</span>. ◻</p>
</div>
<div class="corollaire">
<p>Pour toute entité <span class="math inline">\(i \in I\)</span>, la
distance de Gower entre <span class="math inline">\(i\)</span> et
lui-même est nulle :</p>
<p><span class="math display">\[D(i, i) = 0\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour <span class="math inline">\(k = i\)</span>, tous
les termes <span class="math inline">\(d_{jk} = 0\)</span> car <span
class="math inline">\(X_{ij} = X_{ij}\)</span>. Ainsi,</p>
<p><span class="math display">\[D(i, i) = \frac{\sum_{j \in J} w_j \cdot
0}{\sum_{j \in J} w_j} = 0\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La distance de Gower pour variables catégorielles symétriques offre
une solution robuste et interprétable à la mesure de dissimilarité dans
des contextes hétérogènes. Son élégance réside dans sa capacité à
unifier les approches tout en respectant la nature des données. Les
propriétés de normalisation, symétrie et identité en font un outil
indispensable pour l’analyse des données mixtes.</p>
</body>
</html>
{% include "footer.html" %}

