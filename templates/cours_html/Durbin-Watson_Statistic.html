{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Statistique de Durbin-Watson : Une Analyse Approfondie</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Statistique de Durbin-Watson : Une Analyse
Approfondie</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La statistique de Durbin-Watson émerge dans le cadre des modèles de
régression linéaire, où l’hypothèse fondamentale d’indépendance des
résidus est souvent cruciale. Introduite par James Durbin et Geoffrey
Watson en 1950, cette statistique permet de tester l’autocorrélation des
résidus d’un modèle de régression, en particulier pour détecter une
autocorrélation de premier ordre.</p>
<p>L’importance de cette statistique réside dans sa capacité à
identifier les violations de l’hypothèse d’indépendance, ce qui peut
conduire à des estimations biaisées et inefficaces des paramètres du
modèle. Dans un contexte où les données temporelles ou spatiales sont
courantes, la détection de l’autocorrélation devient un enjeu majeur
pour la validité des inférences statistiques.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la statistique de Durbin-Watson, commençons par
considérer un modèle de régression linéaire simple :</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_i +
\epsilon_i\]</span></p>
<p>où <span class="math inline">\(y_i\)</span> est la variable
dépendante, <span class="math inline">\(x_i\)</span> est la variable
indépendante, <span class="math inline">\(\beta_0\)</span> et <span
class="math inline">\(\beta_1\)</span> sont les coefficients de
régression, et <span class="math inline">\(\epsilon_i\)</span> est le
résidu.</p>
<p>Nous cherchons à tester si les résidus <span
class="math inline">\(\epsilon_i\)</span> sont autocorrélés. Plus
précisément, nous voulons tester l’hypothèse nulle <span
class="math inline">\(H_0\)</span> selon laquelle les résidus sont
indépendants et identiquement distribués (i.i.d.) contre l’hypothèse
alternative <span class="math inline">\(H_1\)</span> selon laquelle les
résidus sont autocorrélés de premier ordre.</p>
<p>La statistique de Durbin-Watson est définie comme suit :</p>
<p><span class="math display">\[DW = \frac{\sum_{i=2}^n (e_i -
e_{i-1})^2}{\sum_{i=1}^n e_i^2}\]</span></p>
<p>où <span class="math inline">\(e_i\)</span> sont les résidus estimés
du modèle de régression.</p>
<p>Cette statistique peut également être exprimée en termes des
covariances empiriques des résidus :</p>
<p><span class="math display">\[DW = 2(1 - \hat{\rho})\]</span></p>
<p>où <span class="math inline">\(\hat{\rho}\)</span> est l’estimateur
de l’autocorrélation de premier ordre des résidus.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la statistique de Durbin-Watson est le
suivant :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(e_1, e_2, \ldots, e_n\)</span> les
résidus d’un modèle de régression linéaire. La statistique de
Durbin-Watson <span class="math inline">\(DW\)</span> est définie par
:</p>
<p><span class="math display">\[DW = \frac{\sum_{i=2}^n (e_i -
e_{i-1})^2}{\sum_{i=1}^n e_i^2}\]</span></p>
<p>Si les résidus sont i.i.d., alors <span
class="math inline">\(DW\)</span> tend vers 2 lorsque <span
class="math inline">\(n\)</span> tend vers l’infini.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous commençons par exprimer la statistique
de Durbin-Watson en termes des covariances empiriques :</p>
<p><span class="math display">\[DW = \frac{\sum_{i=2}^n (e_i^2 - 2 e_i
e_{i-1} + e_{i-1}^2)}{\sum_{i=1}^n e_i^2}\]</span></p>
<p>En réarrangeant les termes, nous obtenons :</p>
<p><span class="math display">\[DW = 2 - \frac{2 \sum_{i=2}^n e_i
e_{i-1}}{\sum_{i=1}^n e_i^2}\]</span></p>
<p>L’estimateur de l’autocorrélation de premier ordre <span
class="math inline">\(\hat{\rho}\)</span> est donné par :</p>
<p><span class="math display">\[\hat{\rho} = \frac{\sum_{i=2}^n e_i
e_{i-1}}{\sum_{i=1}^n e_i^2}\]</span></p>
<p>En substituant cette expression dans la formule précédente, nous
obtenons :</p>
<p><span class="math display">\[DW = 2(1 - \hat{\rho})\]</span></p>
<p>Si les résidus sont i.i.d., alors <span
class="math inline">\(\hat{\rho}\)</span> tend vers 0 lorsque <span
class="math inline">\(n\)</span> tend vers l’infini. Par conséquent,
<span class="math inline">\(DW\)</span> tend vers 2.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Les propriétés de la statistique de Durbin-Watson sont nombreuses et
importantes. En voici quelques-unes :</p>
<ol>
<li><p>Si les résidus sont i.i.d., alors <span
class="math inline">\(DW\)</span> est proche de 2.</p></li>
<li><p>Si les résidus sont positivement autocorrélés, alors <span
class="math inline">\(DW\)</span> est inférieur à 2.</p></li>
<li><p>Si les résidus sont négativement autocorrélés, alors <span
class="math inline">\(DW\)</span> est supérieur à 2.</p></li>
</ol>
<p>Pour prouver ces propriétés, nous utilisons le fait que <span
class="math inline">\(DW = 2(1 - \hat{\rho})\)</span>. Si les résidus
sont i.i.d., alors <span class="math inline">\(\hat{\rho}\)</span> est
proche de 0, et donc <span class="math inline">\(DW\)</span> est proche
de 2. Si les résidus sont positivement autocorrélés, alors <span
class="math inline">\(\hat{\rho}\)</span> est positif, et donc <span
class="math inline">\(DW\)</span> est inférieur à 2. Enfin, si les
résidus sont négativement autocorrélés, alors <span
class="math inline">\(\hat{\rho}\)</span> est négatif, et donc <span
class="math inline">\(DW\)</span> est supérieur à 2.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La statistique de Durbin-Watson est un outil essentiel pour tester
l’autocorrélation des résidus dans les modèles de régression linéaire.
Son utilisation permet de valider l’hypothèse d’indépendance des
résidus, ce qui est crucial pour la validité des inférences
statistiques. Les propriétés et théorèmes associés à cette statistique
offrent une compréhension approfondie de son comportement et de ses
applications pratiques.</p>
</body>
</html>
{% include "footer.html" %}

