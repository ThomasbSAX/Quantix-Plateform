{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>NUTS: No-U-Turn Sampler Une Révolution dans les Méthodes de Monte Carlo par Chaînes de Markov</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">NUTS: No-U-Turn Sampler<br />
Une Révolution dans les Méthodes de Monte Carlo par Chaînes de
Markov</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’émergence des méthodes de Monte Carlo par Chaînes de Markov (MCMC)
a révolutionné l’inférence statistique en permettant d’échantillonner
des distributions complexes pour lesquelles les méthodes analytiques
sont intractables. Parmi ces méthodes, le No-U-Turn Sampler (NUTS) se
distingue par son efficacité et sa capacité à automatiser le processus
d’échantillonnage.</p>
<p>Le NUTS a été introduit par Matthew D. Hoffman et Andrew Gelman en
2014 comme une amélioration de l’algorithme Hamiltonian Monte Carlo
(HMC). L’idée centrale derrière NUTS est d’éliminer le problème des
tours indésirables (no-u-turn) qui peuvent survenir dans HMC, ce qui
améliore significativement l’efficacité de l’échantillonnage.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant de définir NUTS, il est essentiel de comprendre les concepts
fondamentaux sur lesquels il repose. Considérons une distribution cible
<span class="math inline">\(\pi(\theta)\)</span> que nous souhaitons
échantillonner. L’objectif est de générer des échantillons <span
class="math inline">\(\theta^{(1)}, \theta^{(2)}, \ldots,
\theta^{(n)}\)</span> distribués selon <span
class="math inline">\(\pi(\theta)\)</span>.</p>
<h2 id="algorithme-hamiltonian-monte-carlo-hmc">Algorithme Hamiltonian
Monte Carlo (HMC)</h2>
<p>L’algorithme HMC utilise les principes de la mécanique hamiltonienne
pour proposer des transitions dans l’espace des paramètres. Il introduit
une variable auxiliaire <span class="math inline">\(p\)</span>
représentant le moment, et définit une dynamique hamiltonienne sur
l’espace conjugué <span class="math inline">\((\theta, p)\)</span>.</p>
<div class="definition">
<p>Soit <span class="math inline">\(H(\theta, p) = U(\theta) +
K(p)\)</span> la fonction hamiltonienne, où <span
class="math inline">\(U(\theta) = -\log \pi(\theta)\)</span> est le
potentiel et <span class="math inline">\(K(p) = \frac{1}{2} p^T M^{-1}
p\)</span> est l’énergie cinétique, avec <span
class="math inline">\(M\)</span> une matrice de masse positive
définie.</p>
</div>
<p>La dynamique hamiltonienne est donnée par les équations
différentielles suivantes: <span
class="math display">\[\frac{d\theta}{dt} = \frac{\partial H}{\partial
p}, \quad \frac{dp}{dt} = -\frac{\partial H}{\partial
\theta}\]</span></p>
<h2 id="no-u-turn-sampler-nuts">No-U-Turn Sampler (NUTS)</h2>
<p>Le NUTS est une extension de HMC qui élimine le problème des tours
indésirables en construisant un arbre binaire de propositions. L’idée
est de construire un ensemble de propositions valides qui respectent la
condition no-u-turn, ce qui permet d’améliorer l’efficacité de
l’échantillonnage.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\theta_0\)</span> une position
initiale et <span class="math inline">\(p_0\)</span> un moment initial.
Le NUTS construit un arbre binaire de propositions <span
class="math inline">\((\theta, p)\)</span> en explorant l’espace des
paramètres tout en respectant la condition no-u-turn. L’algorithme
accepte ou rejette une proposition en fonction du rapport de
Metropolis-Hastings.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<h2 id="théorème-de-convergence-de-nuts">Théorème de Convergence de
NUTS</h2>
<p>Le théorème de convergence de NUTS garantit que les échantillons
générés par l’algorithme convergent vers la distribution cible <span
class="math inline">\(\pi(\theta)\)</span>.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\{\theta^{(t)}\}_{t=1}^n\)</span>
une séquence d’échantillons générés par NUTS. Sous des conditions
régulières sur <span class="math inline">\(\pi(\theta)\)</span> et la
dynamique hamiltonienne, la séquence <span
class="math inline">\(\{\theta^{(t)}\}_{t=1}^n\)</span> converge vers
<span class="math inline">\(\pi(\theta)\)</span> en distribution.</p>
</div>
<h2 id="démonstration-du-théorème-de-convergence">Démonstration du
Théorème de Convergence</h2>
<p>La démonstration du théorème de convergence repose sur les propriétés
des chaînes de Markov et la théorie ergodique. Nous utilisons le fait
que NUTS est une extension de HMC, qui est lui-même un cas particulier
des algorithmes Metropolis-Hastings.</p>
<div class="proof">
<p><em>Proof.</em> La preuve suit plusieurs étapes: 1. Montrer que NUTS
est une chaîne de Markov ergodique. 2. Utiliser les propriétés de la
dynamique hamiltonienne pour établir une borne sur le temps de mélange.
3. Appliquer les théorèmes ergodiques pour conclure la convergence.</p>
<p>En détail, nous avons:</p>
<ol>
<li><p>La chaîne de Markov générée par NUTS est ergodique car elle
satisfait les conditions d’irréductibilité et d’apériodicité.</p></li>
<li><p>La dynamique hamiltonienne assure que les propositions sont
explorées de manière efficace, ce qui permet de borner le temps de
mélange.</p></li>
<li><p>Par les théorèmes ergodiques, la séquence d’échantillons converge
vers la distribution cible <span
class="math inline">\(\pi(\theta)\)</span>.</p></li>
</ol>
<p> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriété-de-symétrie">Propriété de Symétrie</h2>
<p>La construction de l’arbre binaire dans NUTS assure une symétrie dans
les propositions, ce qui améliore l’efficacité de l’algorithme.</p>
<div class="property">
<p>Soit <span class="math inline">\((\theta, p)\)</span> une proposition
générée par NUTS. Alors, la proposition symétrique <span
class="math inline">\((-\theta, -p)\)</span> est également valide.</p>
</div>
<h2 id="corollaire-de-lefficacité">Corollaire de l’Efficacité</h2>
<p>Le NUTS est plus efficace que HMC en termes de temps de calcul et de
qualité des échantillons.</p>
<div class="corollary">
<p>Le NUTS réduit le nombre de calculs nécessaires pour atteindre une
précision donnée par rapport à HMC.</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Le No-U-Turn Sampler (NUTS) représente une avancée significative dans
les méthodes de Monte Carlo par Chaînes de Markov. En éliminant le
problème des tours indésirables et en automatisant le processus
d’échantillonnage, NUTS offre une solution robuste et efficace pour
l’inférence statistique. Les théorèmes de convergence et les propriétés
de symétrie garantissent la fiabilité et l’efficacité de l’algorithme,
faisant de NUTS un outil indispensable dans le domaine de la
modélisation statistique.</p>
</body>
</html>
{% include "footer.html" %}

