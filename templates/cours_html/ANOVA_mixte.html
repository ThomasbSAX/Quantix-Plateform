{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Analyse de variance mixte : Théorie et applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Analyse de variance mixte : Théorie et
applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’analyse de variance (ANOVA) mixte est une extension puissante des
modèles d’ANOVA classiques, permettant de prendre en compte à la fois
des effets fixes et aléatoires. Cette approche est particulièrement
utile dans les situations où certains facteurs sont considérés comme
représentatifs d’une population plus large, tandis que d’autres sont
spécifiques à l’étude en cours.</p>
<p>L’ANOVA mixte émerge comme une réponse aux limitations des modèles
purement fixes ou aléatoires. Elle permet de modéliser des structures de
données complexes, telles que les expériences hiérarchiques ou les
études longitudinales, où les observations sont imbriquées ou croisées.
Cette méthode est indispensable pour tirer des conclusions valides et
généralisables dans de nombreux domaines, notamment en psychologie, en
biologie, et en sciences sociales.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’ANOVA mixte, il est essentiel de définir clairement
les concepts d’effets fixes et aléatoires.</p>
<h2 class="unnumbered" id="effets-fixes">Effets fixes</h2>
<p>Considérons un facteur <span class="math inline">\(A\)</span> avec
<span class="math inline">\(a\)</span> niveaux. Si nous sommes
intéressés par les effets spécifiques de chaque niveau de ce facteur,
alors <span class="math inline">\(A\)</span> est un effet fixe.
Formellement, nous avons :</p>
<p><span class="math display">\[\mu_{ij} = \mu + \alpha_i +
\epsilon_{ij}\]</span></p>
<p>où <span class="math inline">\(\mu\)</span> est la moyenne globale,
<span class="math inline">\(\alpha_i\)</span> est l’effet du <span
class="math inline">\(i\)</span>-ème niveau du facteur <span
class="math inline">\(A\)</span>, et <span
class="math inline">\(\epsilon_{ij}\)</span> est l’erreur aléatoire.</p>
<h2 class="unnumbered" id="effets-aléatoires">Effets aléatoires</h2>
<p>Un facteur <span class="math inline">\(B\)</span> avec <span
class="math inline">\(b\)</span> niveaux est considéré comme un effet
aléatoire si les niveaux sont échantillonnés à partir d’une population
plus large. Dans ce cas, nous modélisons les effets aléatoires comme
suit :</p>
<p><span class="math display">\[\mu_{ij} = \mu + \alpha_i + b_j +
\epsilon_{ij}\]</span></p>
<p>où <span class="math inline">\(b_j\)</span> est l’effet aléatoire du
<span class="math inline">\(j\)</span>-ème niveau du facteur <span
class="math inline">\(B\)</span>, supposé être distribué selon une loi
normale avec moyenne zéro et variance <span
class="math inline">\(\sigma^2_b\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>L’ANOVA mixte repose sur plusieurs théorèmes fondamentaux, notamment
celui de la décomposition de la variance et le théorème des moindres
carrés généralisés.</p>
<h2 class="unnumbered" id="décomposition-de-la-variance">Décomposition
de la variance</h2>
<p>Le théorème de la décomposition de la variance stipule que la
variance totale peut être divisée en composantes liées aux effets fixes
et aléatoires. Formellement, nous avons :</p>
<p><span class="math display">\[\sigma^2_{\text{totale}} =
\sigma^2_{\text{effets fixes}} + \sigma^2_{\text{effets aléatoires}} +
\sigma^2_{\text{erreur}}\]</span></p>
<p>où <span class="math inline">\(\sigma^2_{\text{totale}}\)</span> est
la variance totale, <span class="math inline">\(\sigma^2_{\text{effets
fixes}}\)</span> est la variance attribuable aux effets fixes, <span
class="math inline">\(\sigma^2_{\text{effets aléatoires}}\)</span> est
la variance attribuable aux effets aléatoires, et <span
class="math inline">\(\sigma^2_{\text{erreur}}\)</span> est la variance
de l’erreur.</p>
<h2 class="unnumbered"
id="théorème-des-moindres-carrés-généralisés">Théorème des moindres
carrés généralisés</h2>
<p>Le théorème des moindres carrés généralisés étend le principe des
moindres carrés aux modèles mixtes. Il stipule que les estimateurs des
effets fixes sont obtenus en minimisant la somme des carrés des résidus
pondérés par l’inverse de la matrice de variance-covariance des effets
aléatoires.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<h2 class="unnumbered"
id="preuve-du-théorème-de-la-décomposition-de-la-variance">Preuve du
théorème de la décomposition de la variance</h2>
<p>Pour prouver ce théorème, nous commençons par exprimer la variance
totale en termes de moyennes et d’écarts :</p>
<p><span class="math display">\[\sigma^2_{\text{totale}} = \frac{1}{N}
\sum_{i=1}^{a} \sum_{j=1}^{b} (y_{ij} - \bar{y}_{..})^2\]</span></p>
<p>où <span class="math inline">\(N = a \times b\)</span> est le nombre
total d’observations, et <span
class="math inline">\(\bar{y}_{..}\)</span> est la moyenne globale.
Ensuite, nous décomposons cette expression en utilisant les effets fixes
et aléatoires :</p>
<p><span class="math display">\[\sigma^2_{\text{totale}} = \frac{1}{N}
\sum_{i=1}^{a} \sum_{j=1}^{b} (\alpha_i + b_j +
\epsilon_{ij})^2\]</span></p>
<p>En développant cette expression et en utilisant les propriétés des
effets fixes et aléatoires, nous obtenons la décomposition
souhaitée.</p>
<h2 class="unnumbered"
id="preuve-du-théorème-des-moindres-carrés-généralisés">Preuve du
théorème des moindres carrés généralisés</h2>
<p>La preuve de ce théorème repose sur l’utilisation de la matrice de
variance-covariance des effets aléatoires. Nous minimisons la fonction
de somme des carrés pondérés :</p>
<p><span class="math display">\[S = (y - X\beta)^T V^{-1} (y -
X\beta)\]</span></p>
<p>où <span class="math inline">\(y\)</span> est le vecteur des
observations, <span class="math inline">\(X\)</span> est la matrice de
conception, <span class="math inline">\(\beta\)</span> est le vecteur
des paramètres fixes, et <span class="math inline">\(V\)</span> est la
matrice de variance-covariance. En prenant la dérivée de <span
class="math inline">\(S\)</span> par rapport à <span
class="math inline">\(\beta\)</span> et en égalant à zéro, nous obtenons
les estimateurs des moindres carrés généralisés.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
corollaires</h1>
<h2 class="unnumbered" id="propriété-de-linéarité">Propriété de
linéarité</h2>
<p>L’ANOVA mixte possède une propriété de linéarité, ce qui signifie que
les effets fixes et aléatoires peuvent être combinés linéairement pour
prédire les observations.</p>
<h2 class="unnumbered" id="corollaire-de-la-généralisation">Corollaire
de la généralisation</h2>
<p>Un corollaire important de l’ANOVA mixte est la possibilité de
généraliser les résultats à une population plus large, grâce à la
modélisation des effets aléatoires.</p>
<h2 class="unnumbered" id="propriété-de-robustesse">Propriété de
robustesse</h2>
<p>L’ANOVA mixte est robuste aux violations des hypothèses de normalité
et d’homogénéité des variances, dans la mesure où les effets aléatoires
sont correctement spécifiés.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’ANOVA mixte est une méthode puissante et flexible pour l’analyse de
données complexes. Elle combine les avantages des modèles fixes et
aléatoires, permettant une modélisation précise et une généralisation
valide des résultats. Les théorèmes et propriétés présentés dans cet
article fournissent une base solide pour l’application de cette méthode
dans divers domaines de recherche.</p>
</body>
</html>
{% include "footer.html" %}

