{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Gower pour variables continues asymétriques</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Gower pour variables continues
asymétriques</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Gower est une mesure de dissimilarité qui généralise
la notion de distance euclidienne pour des données mixtes, c’est-à-dire
contenant à la fois des variables quantitatives et qualitatives.
Introduite par Gower en 1971, cette distance est particulièrement utile
dans le cadre de l’analyse des données et de la classification. Elle
permet de prendre en compte les spécificités des différentes variables,
notamment leur nature et leur échelle de mesure.</p>
<p>L’émergence de cette notion répond à un besoin crucial en statistique
: traiter des données hétérogènes tout en préservant leur structure
intrinsèque. Les variables continues asymétriques, par exemple, ne
peuvent pas être simplement normalisées ou standardisées sans perdre des
informations importantes sur leur distribution. La distance de Gower
offre une solution élégante à ce problème en pondérant les contributions
des variables selon leur type et leur asymétrie.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la distance de Gower, nous devons d’abord comprendre ce
que nous cherchons à mesurer. Nous voulons une mesure de dissimilarité
entre deux objets décrits par un ensemble de variables, où certaines de
ces variables sont continues et asymétriques. La distance doit être
capable de capturer les différences entre les objets tout en tenant
compte des particularités de chaque variable.</p>
<p>Formellement, soit <span class="math inline">\(X\)</span> un ensemble
de variables <span class="math inline">\(\{X_1, X_2, \ldots,
X_p\}\)</span>, où certaines variables sont continues et asymétriques.
Pour deux objets <span class="math inline">\(i\)</span> et <span
class="math inline">\(j\)</span>, la distance de Gower <span
class="math inline">\(d_{ij}\)</span> est définie comme suit :</p>
<p><span class="math display">\[d_{ij} = \frac{\sum_{k=1}^{p}
\delta_{ijk}}{\sum_{k=1}^{p} \delta_{ijk}}\]</span></p>
<p>où <span class="math inline">\(\delta_{ijk}\)</span> est la
contribution de la variable <span class="math inline">\(k\)</span> à la
distance entre les objets <span class="math inline">\(i\)</span> et
<span class="math inline">\(j\)</span>.</p>
<p>Pour les variables continues asymétriques, la contribution <span
class="math inline">\(\delta_{ijk}\)</span> peut être définie de
plusieurs manières. Une approche courante consiste à utiliser une
transformation qui prend en compte l’asymétrie de la variable. Par
exemple, si <span class="math inline">\(X_k\)</span> est une variable
continue asymétrique, nous pouvons définir :</p>
<p><span class="math display">\[\delta_{ijk} = \frac{|X_{ik} -
X_{jk}|}{\max(X_k) - \min(X_k)}\]</span></p>
<p>où <span class="math inline">\(X_{ik}\)</span> et <span
class="math inline">\(X_{jk}\)</span> sont les valeurs de la variable
<span class="math inline">\(k\)</span> pour les objets <span
class="math inline">\(i\)</span> et <span
class="math inline">\(j\)</span>, respectivement.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème important lié à la distance de Gower est le théorème de
l’optimalité, qui stipule que la distance de Gower minimise une certaine
fonction de perte sous certaines conditions. Ce théorème est crucial
pour comprendre pourquoi la distance de Gower est une mesure efficace de
dissimilarité.</p>
<p>Formellement, soit <span class="math inline">\(\mathcal{L}\)</span>
une fonction de perte définie sur l’ensemble des distances possibles. Le
théorème de l’optimalité peut être énoncé comme suit :</p>
<p><span class="math display">\[\forall i, j \in \{1, 2, \ldots, n\},
\quad d_{ij} = \arg\min_{d} \mathcal{L}(d)\]</span></p>
<p>où <span class="math inline">\(d\)</span> est une distance
quelconque.</p>
<p>La démonstration de ce théorème repose sur plusieurs lemmes et
propriétés, notamment la propriété de triangulation et la propriété de
symétrie. La preuve détaillée est complexe et dépasse le cadre de cet
article, mais elle montre que la distance de Gower est une mesure
optimale dans un sens bien précis.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver les propriétés de la distance de Gower, nous devons
utiliser plusieurs théorèmes et lemmes. Par exemple, pour prouver que la
distance de Gower est une mesure de dissimilarité valide, nous devons
montrer qu’elle satisfait les propriétés suivantes :</p>
<ul>
<li><p>Non-négativité : <span class="math inline">\(d_{ij} \geq
0\)</span> pour tout <span class="math inline">\(i, j\)</span>.</p></li>
<li><p>Identité des indiscernables : <span class="math inline">\(d_{ij}
= 0\)</span> si et seulement si <span class="math inline">\(i =
j\)</span>.</p></li>
<li><p>Symétrie : <span class="math inline">\(d_{ij} = d_{ji}\)</span>
pour tout <span class="math inline">\(i, j\)</span>.</p></li>
<li><p>Inégalité triangulaire : <span class="math inline">\(d_{ik} \leq
d_{ij} + d_{jk}\)</span> pour tout <span class="math inline">\(i, j,
k\)</span>.</p></li>
</ul>
<p>La preuve de la non-négativité est immédiate car les contributions
<span class="math inline">\(\delta_{ijk}\)</span> sont définies comme
des valeurs absolues, qui sont toujours non négatives. La preuve de
l’identité des indiscernables repose sur le fait que si <span
class="math inline">\(i = j\)</span>, alors toutes les contributions
<span class="math inline">\(\delta_{ijk}\)</span> sont nulles, car <span
class="math inline">\(X_{ik} = X_{jk}\)</span>.</p>
<p>La symétrie est également évidente car <span
class="math inline">\(|X_{ik} - X_{jk}| = |X_{jk} - X_{ik}|\)</span>.
Enfin, la preuve de l’inégalité triangulaire est plus complexe et repose
sur des propriétés des normes et des distances.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La distance de Gower possède plusieurs propriétés intéressantes,
notamment :</p>
<ul>
<li><p>La distance de Gower est invariante par translation. Cela
signifie que si nous ajoutons une constante à toutes les valeurs d’une
variable, la distance entre deux objets reste inchangée.</p></li>
<li><p>La distance de Gower est homogène de degré 1. Cela signifie que
si nous multiplions toutes les valeurs d’une variable par une constante
positive, la distance entre deux objets est multipliée par cette même
constante.</p></li>
<li><p>La distance de Gower peut être généralisée à des variables
qualitatives en utilisant une mesure de dissimilarité appropriée pour
ces variables.</p></li>
</ul>
<p>La preuve de l’invariance par translation est simple : si nous
ajoutons une constante <span class="math inline">\(c\)</span> à toutes
les valeurs de la variable <span class="math inline">\(k\)</span>, alors
<span class="math inline">\(|X_{ik} + c - (X_{jk} + c)| = |X_{ik} -
X_{jk}|\)</span>, donc la contribution <span
class="math inline">\(\delta_{ijk}\)</span> reste inchangée.</p>
<p>La preuve de l’homogénéité de degré 1 est également simple : si nous
multiplions toutes les valeurs de la variable <span
class="math inline">\(k\)</span> par une constante positive <span
class="math inline">\(a\)</span>, alors <span
class="math inline">\(|aX_{ik} - aX_{jk}| = a|X_{ik} - X_{jk}|\)</span>,
donc la contribution <span class="math inline">\(\delta_{ijk}\)</span>
est multipliée par <span class="math inline">\(a\)</span>.</p>
<p>Enfin, la généralisation à des variables qualitatives repose sur
l’utilisation de mesures de dissimilarité appropriées, telles que la
distance de Hamming pour les variables catégorielles.</p>
</body>
</html>
{% include "footer.html" %}

