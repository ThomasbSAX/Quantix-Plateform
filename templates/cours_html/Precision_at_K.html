{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Precision at K : Une Mesure de Performance en Apprentissage Automatique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Precision at K : Une Mesure de Performance en
Apprentissage Automatique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’apprentissage automatique, en particulier les systèmes de
recommandation, repose sur des métriques de performance pour évaluer
l’efficacité des modèles prédictifs. Parmi ces métriques, la
<em>Precision at K</em> (Précision à K) est une mesure cruciale pour
quantifier la pertinence des prédictions d’un modèle. Cette notion
émerge dans un contexte où les utilisateurs sont submergés par des
quantités massives d’informations, et où il est essentiel de filtrer et
de prioriser les éléments les plus pertinents.</p>
<p>La Précision à K est indispensable dans des domaines tels que la
recommandation de produits, la recherche d’information, et les systèmes
de filtrage collaboratif. Elle permet de mesurer la proportion de
prédictions correctes parmi les K premières recommandations ou résultats
proposés par le modèle. Cette métrique est particulièrement utile
lorsque l’on souhaite évaluer la capacité d’un modèle à identifier
rapidement les éléments les plus pertinents pour un utilisateur
donné.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la Précision à K, commençons par définir les concepts
fondamentaux. Supposons que nous ayons un ensemble de prédictions
ordonnées par un modèle, et que nous soyons intéressés par les K
premières prédictions. Nous voulons mesurer dans quelle mesure ces K
prédictions sont correctes par rapport à un ensemble de vérité terrain
(ground truth).</p>
<p>Formellement, soit <span class="math inline">\(P\)</span> l’ensemble
des K premières prédictions du modèle, et soit <span
class="math inline">\(R\)</span> l’ensemble des éléments pertinents
selon la vérité terrain. La Précision à K est définie comme le rapport
entre le nombre d’éléments corrects dans les K premières prédictions et
K lui-même.</p>
<div class="definition">
<p>Soit <span class="math inline">\(P = \{p_1, p_2, \ldots,
p_K\}\)</span> l’ensemble des K premières prédictions d’un modèle, et
soit <span class="math inline">\(R\)</span> l’ensemble des éléments
pertinents selon la vérité terrain. La Précision à K est définie par :
<span class="math display">\[\text{Precision@K} = \frac{|\{p \in P \mid
p \in R\}|}{K}\]</span> Autrement dit, pour tout <span
class="math inline">\(k \in \{1, 2, \ldots, K\}\)</span>, nous avons :
<span class="math display">\[\text{Precision@K} = \frac{1}{K}
\sum_{i=1}^{K} \mathbb{I}(p_i \in R)\]</span> où <span
class="math inline">\(\mathbb{I}\)</span> est la fonction indicatrice
qui vaut 1 si <span class="math inline">\(p_i \in R\)</span> et 0
sinon.</p>
</div>
<h1 id="théorèmes-et-propriétés">Théorèmes et Propriétés</h1>
<p>La Précision à K possède plusieurs propriétés intéressantes qui en
font une métrique robuste pour l’évaluation des modèles de
recommandation. Nous allons explorer certaines de ces propriétés et
leurs implications.</p>
<div class="theorem">
<p>La Précision à K est une fonction monotone décroissante de K.
Autrement dit, pour tout <span class="math inline">\(K_1 \leq
K_2\)</span>, nous avons : <span
class="math display">\[\text{Precision@}K_1 \geq
\text{Precision@}K_2\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, considérons deux
valeurs <span class="math inline">\(K_1\)</span> et <span
class="math inline">\(K_2\)</span> telles que <span
class="math inline">\(K_1 \leq K_2\)</span>. Nous voulons montrer que
<span class="math inline">\(\text{Precision@}K_1 \geq
\text{Precision@}K_2\)</span>.</p>
<p>Par définition, nous avons : <span
class="math display">\[\text{Precision@}K_1 = \frac{|\{p \in P_{K_1}
\mid p \in R\}|}{K_1}\]</span> et <span
class="math display">\[\text{Precision@}K_2 = \frac{|\{p \in P_{K_2}
\mid p \in R\}|}{K_2}\]</span> où <span
class="math inline">\(P_{K_1}\)</span> et <span
class="math inline">\(P_{K_2}\)</span> sont les ensembles des K
premières prédictions pour <span class="math inline">\(K_1\)</span> et
<span class="math inline">\(K_2\)</span> respectivement.</p>
<p>Puisque <span class="math inline">\(P_{K_1} \subseteq
P_{K_2}\)</span>, il s’ensuit que : <span class="math display">\[|\{p
\in P_{K_1} \mid p \in R\}| \leq |\{p \in P_{K_2} \mid p \in
R\}|\]</span> En divisant par <span class="math inline">\(K_1\)</span>
et <span class="math inline">\(K_2\)</span> respectivement, nous
obtenons : <span class="math display">\[\frac{|\{p \in P_{K_1} \mid p
\in R\}|}{K_1} \geq \frac{|\{p \in P_{K_2} \mid p \in
R\}|}{K_2}\]</span> ce qui prouve que <span
class="math inline">\(\text{Precision@}K_1 \geq
\text{Precision@}K_2\)</span>. ◻</p>
</div>
<h1 id="preuves-et-démonstrations">Preuves et Démonstrations</h1>
<p>Pour illustrer l’importance de la Précision à K, considérons un
exemple concret. Supposons que nous ayons un système de recommandation
de films, et que nous voulions évaluer la performance du modèle en
utilisant la Précision à 5.</p>
<div class="example">
<p>Soit <span class="math inline">\(P = \{p_1, p_2, p_3, p_4,
p_5\}\)</span> l’ensemble des 5 premières recommandations du modèle, et
soit <span class="math inline">\(R = \{r_1, r_2\}\)</span> l’ensemble
des films pertinents selon la vérité terrain. Supposons que <span
class="math inline">\(p_1 = r_1\)</span> et <span
class="math inline">\(p_3 = r_2\)</span>.</p>
<p>Alors, la Précision à 5 est calculée comme suit : <span
class="math display">\[\text{Precision@5} = \frac{|\{p_1, p_3\} \cap
\{r_1, r_2\}|}{5} = \frac{2}{5} = 0.4\]</span></p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La Précision à K possède plusieurs propriétés intéressantes qui en
font une métrique robuste pour l’évaluation des modèles de
recommandation. Nous allons explorer certaines de ces propriétés et
leurs implications.</p>
<div class="corollaire">
<p>La Précision à K est une métrique normalisée, c’est-à-dire qu’elle
prend des valeurs dans l’intervalle <span class="math inline">\([0,
1]\)</span>. Autrement dit, pour tout <span class="math inline">\(K \geq
1\)</span>, nous avons : <span class="math display">\[0 \leq
\text{Precision@K} \leq 1\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Par définition, la Précision à K est le rapport entre
le nombre d’éléments corrects dans les K premières prédictions et K
lui-même. Puisque le nombre d’éléments corrects est toujours inférieur
ou égal à K, il s’ensuit que : <span class="math display">\[0 \leq
\text{Precision@K} \leq 1\]</span> ◻</p>
</div>
<div class="corollaire">
<p>La Précision à K est une métrique symétrique, c’est-à-dire qu’elle ne
dépend pas de l’ordre des éléments dans les K premières prédictions.
Autrement dit, pour tout <span class="math inline">\(K \geq 1\)</span>,
nous avons : <span class="math display">\[\text{Precision@K} =
\text{Precision@K&#39;}\]</span> où <span
class="math inline">\(K&#39;\)</span> est une permutation des K
premières prédictions.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Puisque la Précision à K est définie comme le rapport
entre le nombre d’éléments corrects dans les K premières prédictions et
K lui-même, elle ne dépend pas de l’ordre des éléments. Par conséquent,
toute permutation des K premières prédictions ne change pas la valeur de
la Précision à K. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La Précision à K est une métrique essentielle pour évaluer la
performance des modèles de recommandation et des systèmes de recherche
d’information. Elle permet de mesurer la proportion de prédictions
correctes parmi les K premières recommandations ou résultats proposés
par le modèle. Ses propriétés de monotonicité, de normalisation et de
symétrie en font une métrique robuste et fiable pour l’évaluation des
modèles prédictifs.</p>
<p>En conclusion, la Précision à K est un outil précieux pour les
chercheurs et les praticiens en apprentissage automatique, leur
permettant de comparer et d’optimiser les performances des modèles dans
divers domaines d’application.</p>
</body>
</html>
{% include "footer.html" %}

