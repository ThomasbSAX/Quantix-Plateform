{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Complexité en temps</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title"><strong>Complexité en temps</strong></h1>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La notion de complexité en temps émerge naturellement dans le cadre
de l’analyse des algorithmes. En effet, avec l’avènement de
l’informatique moderne, il est devenu crucial d’évaluer non seulement la
correction d’un algorithme, mais aussi son efficacité en termes de temps
d’exécution. Cette préoccupation est à la fois historique, conceptuelle
et technique.</p>
<p>Historiquement, les premiers travaux sur la complexité en temps
remontent aux années 1960 avec des pionniers comme Donald Knuth, qui a
posé les bases de l’analyse algorithmique. Conceptuellement, la
complexité en temps permet de quantifier le coût temporel d’un
algorithme en fonction de la taille de ses entrées. Techniquement, elle
est indispensable pour comparer les performances de différents
algorithmes et choisir celui qui convient le mieux à une tâche
donnée.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la complexité en temps, il est essentiel de définir
quelques notions clés. Commençons par le concept de fonction de
coût.</p>
<h2 id="fonction-de-coût">Fonction de Coût</h2>
<p>Nous cherchons à mesurer le temps qu’un algorithme prend pour
exécuter une tâche en fonction de la taille de l’entrée. Imaginons un
algorithme qui trie une liste de nombres. Plus la liste est longue, plus
l’algorithme mettra du temps à la trier.</p>
<p>Formellement, soit <span class="math inline">\(A\)</span> un
algorithme et <span class="math inline">\(n\)</span> la taille de
l’entrée. La fonction de coût <span
class="math inline">\(T_A(n)\)</span> est définie comme le nombre
maximal d’opérations élémentaires que l’algorithme <span
class="math inline">\(A\)</span> effectue pour traiter une entrée de
taille <span class="math inline">\(n\)</span>.</p>
<p><span class="math display">\[T_A(n) = \max \{ t_A(x) \mid x \in
\mathcal{I}, |x| = n \}\]</span></p>
<p>où <span class="math inline">\(t_A(x)\)</span> est le temps
d’exécution de l’algorithme <span class="math inline">\(A\)</span> sur
l’entrée <span class="math inline">\(x\)</span>, et <span
class="math inline">\(\mathcal{I}\)</span> est l’ensemble des entrées
possibles.</p>
<h2 id="complexité-en-temps">Complexité en Temps</h2>
<p>La complexité en temps d’un algorithme est une notion asymptotique
qui capture le comportement de la fonction de coût pour des entrées de
taille très grande. Nous cherchons à décrire comment <span
class="math inline">\(T_A(n)\)</span> se comporte lorsque <span
class="math inline">\(n\)</span> tend vers l’infini.</p>
<p>Formellement, soit <span class="math inline">\(f(n)\)</span> et <span
class="math inline">\(g(n)\)</span> deux fonctions de <span
class="math inline">\(\mathbb{N}\)</span> dans <span
class="math inline">\(\mathbb{R}^+\)</span>. On dit que <span
class="math inline">\(f(n)\)</span> est en <span
class="math inline">\(O(g(n))\)</span> (lire "f de n est big-O de g de
n") si et seulement si :</p>
<p><span class="math display">\[\exists c &gt; 0, \exists n_0 \in
\mathbb{N}, \forall n \geq n_0, f(n) \leq c \cdot g(n)\]</span></p>
<p>En d’autres termes, <span class="math inline">\(f(n)\)</span> est
bornée supérieurement par une constante multipliée par <span
class="math inline">\(g(n)\)</span> pour les grandes valeurs de <span
class="math inline">\(n\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<h2 id="théorème-de-master">Théorème de Master</h2>
<p>Le théorème de Master est un outil fondamental pour analyser la
complexité des algorithmes de type "divide and conquer". Il permet de
déterminer la complexité en temps d’un algorithme récursif qui divise le
problème en sous-problèmes de taille égale.</p>
<p>Soit <span class="math inline">\(T(n)\)</span> la fonction de
récurrence définie par :</p>
<p><span class="math display">\[T(n) = aT\left(\frac{n}{b}\right) +
f(n)\]</span></p>
<p>où <span class="math inline">\(a \geq 1\)</span>, <span
class="math inline">\(b &gt; 1\)</span>, et <span
class="math inline">\(f(n)\)</span> est une fonction asymptotiquement
positive.</p>
<p>Le théorème de Master énonce que :</p>
<p>1. Si <span class="math inline">\(f(n) = O(n^{\log_b a -
\epsilon})\)</span> pour quelque <span class="math inline">\(\epsilon
&gt; 0\)</span>, alors <span class="math inline">\(T(n) =
\Theta(n^{\log_b a})\)</span>. 2. Si <span class="math inline">\(f(n) =
\Theta(n^{\log_b a} \log^k n)\)</span>, alors <span
class="math inline">\(T(n) = \Theta(n^{\log_b a} \log^{k+1} n)\)</span>.
3. Si <span class="math inline">\(f(n) = \Omega(n^{\log_b a +
\epsilon})\)</span> pour quelque <span class="math inline">\(\epsilon
&gt; 0\)</span> et si <span class="math inline">\(af(n/b) \leq
cf(n)\)</span> pour quelque <span class="math inline">\(c &lt;
1\)</span> (condition régulière), alors <span class="math inline">\(T(n)
= \Theta(f(n))\)</span>.</p>
<h2 id="preuves-du-théorème-de-master">Preuves du Théorème de
Master</h2>
<p>Pour prouver le théorème de Master, nous utilisons la méthode de
l’arbre de récurrence. Considérons un arbre où chaque nœud représente
une instance du problème, et les enfants représentent les
sous-problèmes.</p>
<p>1. **Cas 1** : Si <span class="math inline">\(f(n)\)</span> est
suffisamment petit, le coût total est dominé par les feuilles de
l’arbre. Le nombre de feuilles est <span class="math inline">\(n^{\log_b
a}\)</span>, donc le coût total est <span
class="math inline">\(\Theta(n^{\log_b a})\)</span>.</p>
<p>2. **Cas 2** : Si <span class="math inline">\(f(n)\)</span> est
exactement de la forme <span class="math inline">\(n^{\log_b a} \log^k
n\)</span>, le coût total est <span
class="math inline">\(\Theta(n^{\log_b a} \log^{k+1} n)\)</span>.</p>
<p>3. **Cas 3** : Si <span class="math inline">\(f(n)\)</span> est
suffisamment grand et régulier, le coût total est dominé par la racine
de l’arbre, donc <span class="math inline">\(T(n) =
\Theta(f(n))\)</span>.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriété-de-transitivité">Propriété de Transitivité</h2>
<p>La relation <span class="math inline">\(O\)</span> est transitive.
C’est-à-dire que si <span class="math inline">\(f(n) = O(g(n))\)</span>
et <span class="math inline">\(g(n) = O(h(n))\)</span>, alors <span
class="math inline">\(f(n) = O(h(n))\)</span>.</p>
<p>Preuve : Soit <span class="math inline">\(f(n) = O(g(n))\)</span>,
alors il existe <span class="math inline">\(c_1 &gt; 0\)</span> et <span
class="math inline">\(n_1 \in \mathbb{N}\)</span> tels que pour tout
<span class="math inline">\(n \geq n_1\)</span>, <span
class="math inline">\(f(n) \leq c_1 g(n)\)</span>. De même, comme <span
class="math inline">\(g(n) = O(h(n))\)</span>, il existe <span
class="math inline">\(c_2 &gt; 0\)</span> et <span
class="math inline">\(n_2 \in \mathbb{N}\)</span> tels que pour tout
<span class="math inline">\(n \geq n_2\)</span>, <span
class="math inline">\(g(n) \leq c_2 h(n)\)</span>. En prenant <span
class="math inline">\(n_0 = \max(n_1, n_2)\)</span> et <span
class="math inline">\(c = c_1 c_2\)</span>, nous avons pour tout <span
class="math inline">\(n \geq n_0\)</span> :</p>
<p><span class="math display">\[f(n) \leq c_1 g(n) \leq c_1 c_2 h(n) = c
h(n)\]</span></p>
<p>Donc <span class="math inline">\(f(n) = O(h(n))\)</span>.</p>
<h2 id="corollaire-de-la-propriété-de-transitivité">Corollaire de la
Propriété de Transitivité</h2>
<p>La relation <span class="math inline">\(\Theta\)</span> est également
transitive. C’est-à-dire que si <span class="math inline">\(f(n) =
\Theta(g(n))\)</span> et <span class="math inline">\(g(n) =
\Theta(h(n))\)</span>, alors <span class="math inline">\(f(n) =
\Theta(h(n))\)</span>.</p>
<p>Preuve : Comme <span class="math inline">\(f(n) =
\Theta(g(n))\)</span>, il existe <span class="math inline">\(c_1, c_2
&gt; 0\)</span> et <span class="math inline">\(n_1 \in
\mathbb{N}\)</span> tels que pour tout <span class="math inline">\(n
\geq n_1\)</span>, <span class="math inline">\(c_1 g(n) \leq f(n) \leq
c_2 g(n)\)</span>. De même, comme <span class="math inline">\(g(n) =
\Theta(h(n))\)</span>, il existe <span class="math inline">\(c_3, c_4
&gt; 0\)</span> et <span class="math inline">\(n_2 \in
\mathbb{N}\)</span> tels que pour tout <span class="math inline">\(n
\geq n_2\)</span>, <span class="math inline">\(c_3 h(n) \leq g(n) \leq
c_4 h(n)\)</span>. En prenant <span class="math inline">\(n_0 =
\max(n_1, n_2)\)</span>, nous avons pour tout <span
class="math inline">\(n \geq n_0\)</span> :</p>
<p><span class="math display">\[c_1 c_3 h(n) \leq f(n) \leq c_2 c_4
h(n)\]</span></p>
<p>Donc <span class="math inline">\(f(n) = \Theta(h(n))\)</span>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>La complexité en temps est un outil essentiel pour l’analyse des
algorithmes. Elle permet de comparer les performances de différents
algorithmes et de choisir celui qui convient le mieux à une tâche
donnée. Les définitions, théorèmes et propriétés présentés dans cet
article fournissent les bases nécessaires pour comprendre et appliquer
cette notion fondamentale en informatique théorique.</p>
</body>
</html>
{% include "footer.html" %}

