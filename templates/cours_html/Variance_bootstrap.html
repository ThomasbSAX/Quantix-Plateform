{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance Bootstrap : Une Approche Non-Paramétrique pour l’Estimation de la Variance</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance Bootstrap : Une Approche Non-Paramétrique
pour l’Estimation de la Variance</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’estimation de la variance est une tâche fondamentale en
statistique. Cependant, dans de nombreux cas, les hypothèses nécessaires
pour les méthodes classiques d’estimation de la variance ne sont pas
satisfaites. Le bootstrap, introduit par Efron (1979), offre une
solution non-paramétrique à ce problème. Le variance bootstrap, en
particulier, permet d’estimer la variance d’un estimateur sans faire
d’hypothèses restrictives sur la distribution sous-jacente des
données.</p>
<p>Le bootstrap est une méthode de rééchantillonnage qui consiste à
tirer un grand nombre d’échantillons aléatoires avec remise à partir des
données observées. En utilisant ces échantillons bootstrap, on peut
estimer la variance de l’estimateur d’intérêt. Cette approche est
particulièrement utile lorsque les méthodes classiques sont
inapplicables ou lorsque l’on souhaite une estimation robuste de la
variance.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant de définir le variance bootstrap, il est essentiel de
comprendre ce que l’on cherche à estimer. Supposons que nous ayons un
échantillon de données <span class="math inline">\(X_1, X_2, \ldots,
X_n\)</span> et un estimateur <span class="math inline">\(\hat{\theta} =
T(X_1, X_2, \ldots, X_n)\)</span>. Nous voulons estimer la variance de
<span class="math inline">\(\hat{\theta}\)</span>, notée <span
class="math inline">\(\text{Var}(\hat{\theta})\)</span>.</p>
<p>La variance bootstrap est une méthode pour estimer cette quantité.
Pour ce faire, nous allons tirer un grand nombre d’échantillons
bootstrap à partir des données observées et calculer l’estimateur <span
class="math inline">\(\hat{\theta}\)</span> pour chaque échantillon
bootstrap. Ensuite, nous utiliserons ces valeurs pour estimer la
variance de <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p>Formellement, le variance bootstrap est défini comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> un
échantillon de données et <span class="math inline">\(\hat{\theta} =
T(X_1, X_2, \ldots, X_n)\)</span> un estimateur. Pour chaque <span
class="math inline">\(b = 1, 2, \ldots, B\)</span>, tirons un
échantillon bootstrap <span class="math inline">\(X_1^*, X_2^*, \ldots,
X_n^*\)</span> en tirant avec remise parmi <span
class="math inline">\(X_1, X_2, \ldots, X_n\)</span>. Calculons ensuite
l’estimateur bootstrap <span class="math inline">\(\hat{\theta}^*_b =
T(X_1^*, X_2^*, \ldots, X_n^*)\)</span>.</p>
<p>La variance bootstrap de <span
class="math inline">\(\hat{\theta}\)</span> est donnée par : <span
class="math display">\[\text{Var}^*(\hat{\theta}) = \frac{1}{B-1}
\sum_{b=1}^B (\hat{\theta}^*_b - \bar{\theta}^*)^2,\]</span> où <span
class="math inline">\(\bar{\theta}^* = \frac{1}{B} \sum_{b=1}^B
\hat{\theta}^*_b\)</span> est la moyenne des estimateurs bootstrap.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Le variance bootstrap est une méthode puissante, mais il est
important de comprendre ses propriétés théoriques. Un résultat clé est
le théorème suivant, qui montre que le variance bootstrap converge vers
la vraie variance sous certaines conditions.</p>
<div class="theorem">
<p>Supposons que <span class="math inline">\(\hat{\theta}\)</span> soit
un estimateur consistant de <span class="math inline">\(\theta\)</span>
et que la fonction <span class="math inline">\(T\)</span> soit
différentiable en un point autour de <span
class="math inline">\(\theta\)</span>. Alors, sous certaines conditions
régulières, nous avons : <span
class="math display">\[\text{Var}^*(\hat{\theta}) \xrightarrow{P}
\text{Var}(\hat{\theta}),\]</span> où <span
class="math inline">\(\xrightarrow{P}\)</span> désigne la convergence en
probabilité.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>La preuve du théorème de convergence du variance bootstrap repose sur
des résultats classiques en théorie du bootstrap. Nous allons esquisser
les étapes principales de la preuve.</p>
<div class="proof">
<p><em>Proof.</em> La preuve repose sur le théorème du bootstrap de
Beran (1982) et les résultats de la théorie des fonctions
différentiables. Supposons que <span
class="math inline">\(\hat{\theta}\)</span> soit un estimateur
consistant de <span class="math inline">\(\theta\)</span> et que la
fonction <span class="math inline">\(T\)</span> soit différentiable en
un point autour de <span class="math inline">\(\theta\)</span>.</p>
<p>En utilisant le théorème du bootstrap, nous pouvons montrer que la
distribution bootstrap de <span
class="math inline">\(\hat{\theta}^*\)</span> converge vers la
distribution asymptotique de <span
class="math inline">\(\hat{\theta}\)</span>. En particulier, nous avons
: <span class="math display">\[\sqrt{n}(\hat{\theta}^* - \hat{\theta})
\xrightarrow{D} N(0, \text{Var}(\hat{\theta})),\]</span> où <span
class="math inline">\(\xrightarrow{D}\)</span> désigne la convergence en
distribution.</p>
<p>Ensuite, nous pouvons utiliser cette convergence pour montrer que la
variance bootstrap converge vers la vraie variance. En effet, nous avons
: <span class="math display">\[\text{Var}^*(\hat{\theta}) =
\text{Var}(\sqrt{n}(\hat{\theta}^* - \hat{\theta})) \xrightarrow{P}
\text{Var}(\sqrt{n}(\hat{\theta} - \theta)) =
\text{Var}(\hat{\theta}).\]</span></p>
<p>Ainsi, sous les conditions énoncées, le variance bootstrap converge
vers la vraie variance. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le variance bootstrap possède plusieurs propriétés intéressantes.
Nous allons en énumérer quelques-unes et les démontrer.</p>
<ol>
<li><p>Le variance bootstrap est une méthode non-paramétrique. Cela
signifie qu’il ne fait pas d’hypothèses sur la distribution sous-jacente
des données.</p>
<div class="proof">
<p><em>Proof.</em> La méthode du variance bootstrap repose uniquement
sur le rééchantillonnage des données observées. Elle ne fait donc pas
d’hypothèses sur la distribution des données. ◻</p>
</div></li>
<li><p>Le variance bootstrap est robuste aux valeurs aberrantes. En
effet, comme il repose sur le rééchantillonnage des données observées,
il est moins sensible aux valeurs aberrantes que les méthodes
classiques.</p>
<div class="proof">
<p><em>Proof.</em> Les méthodes classiques d’estimation de la variance
peuvent être fortement influencées par les valeurs aberrantes. En
revanche, le variance bootstrap, en rééchantillonnant les données
observées, est moins sensible à ces valeurs. ◻</p>
</div></li>
<li><p>Le variance bootstrap peut être utilisé pour estimer la variance
de tout type d’estimateur, qu’il soit linéaire ou non.</p>
<div class="proof">
<p><em>Proof.</em> La méthode du variance bootstrap est générale et peut
être appliquée à tout type d’estimateur. Elle ne nécessite pas que
l’estimateur soit linéaire. ◻</p>
</div></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le variance bootstrap est une méthode puissante et flexible pour
l’estimation de la variance. Elle offre une alternative non-paramétrique
aux méthodes classiques et est particulièrement utile lorsque les
hypothèses nécessaires pour ces méthodes ne sont pas satisfaites. Les
propriétés théoriques du variance bootstrap, telles que sa convergence
vers la vraie variance et sa robustesse aux valeurs aberrantes, en font
un outil précieux pour les statisticiens.</p>
</body>
</html>
{% include "footer.html" %}

