{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance Totale : Décomposition et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance Totale : Décomposition et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La variance totale est une notion fondamentale en théorie des
probabilités et en statistique, permettant de décomposer la variance
d’une variable aléatoire en composantes explicatives. Cette notion
émerge naturellement dans le cadre de l’analyse de la variance (ANOVA),
où l’on cherche à comprendre comment différentes sources de variation
contribuent à la variabilité totale d’une observation.</p>
<p>Historiquement, la décomposition de la variance a été introduite pour
répondre à des besoins en agriculture et en biologie, où les chercheurs
voulaient quantifier l’impact de différents facteurs sur les rendements
des cultures. Aujourd’hui, cette notion est indispensable dans de
nombreux domaines, allant de l’économétrie à la génomique, en passant
par les sciences sociales.</p>
<h1 id="définitions">Définitions</h1>
<p>Considérons une variable aléatoire <span
class="math inline">\(Y\)</span> et deux variables aléatoires <span
class="math inline">\(X_1\)</span> et <span
class="math inline">\(X_2\)</span> telles que <span
class="math inline">\(Y = f(X_1, X_2)\)</span>. Nous cherchons à
comprendre comment la variance de <span
class="math inline">\(Y\)</span>, notée <span
class="math inline">\(\text{Var}(Y)\)</span>, peut être décomposée en
fonction des variances et covariances de <span
class="math inline">\(X_1\)</span> et <span
class="math inline">\(X_2\)</span>.</p>
<p>Pour cela, nous introduisons la notion de variance totale.
Intuitivement, la variance totale de <span
class="math inline">\(Y\)</span> est la somme des variances expliquées
par chaque composante <span class="math inline">\(X_1\)</span> et <span
class="math inline">\(X_2\)</span>, ainsi que de leur interaction.</p>
<div class="definition">
<p>Soient <span class="math inline">\(X_1\)</span> et <span
class="math inline">\(X_2\)</span> deux variables aléatoires
indépendantes de variances respectives <span
class="math inline">\(\sigma_{X_1}^2\)</span> et <span
class="math inline">\(\sigma_{X_2}^2\)</span>, et soit <span
class="math inline">\(Y = aX_1 + bX_2 + c\)</span> où <span
class="math inline">\(a, b, c\)</span> sont des constantes. La variance
totale de <span class="math inline">\(Y\)</span> est donnée par : <span
class="math display">\[\text{Var}(Y) = a^2 \sigma_{X_1}^2 + b^2
\sigma_{X_2}^2\]</span></p>
</div>
<p>Cette définition peut être généralisée à un nombre quelconque de
variables aléatoires. Supposons que <span
class="math inline">\(Y\)</span> soit une fonction linéaire de <span
class="math inline">\(n\)</span> variables aléatoires indépendantes
<span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> : <span
class="math display">\[Y = \sum_{i=1}^n a_i X_i + c\]</span> Alors, la
variance totale de <span class="math inline">\(Y\)</span> est : <span
class="math display">\[\text{Var}(Y) = \sum_{i=1}^n a_i^2
\sigma_{X_i}^2\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Nous présentons maintenant un théorème fondamental concernant la
décomposition de la variance totale.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des
variables aléatoires indépendantes de variances respectives <span
class="math inline">\(\sigma_{X_1}^2, \sigma_{X_2}^2, \ldots,
\sigma_{X_n}^2\)</span>, et soit <span class="math inline">\(Y = f(X_1,
X_2, \ldots, X_n)\)</span>. Si <span class="math inline">\(Y\)</span>
est une fonction linéaire de <span class="math inline">\(X_1, X_2,
\ldots, X_n\)</span>, alors : <span class="math display">\[\text{Var}(Y)
= \sum_{i=1}^n \text{Var}\left( \frac{\partial Y}{\partial X_i} \right)
\sigma_{X_i}^2\]</span> où <span class="math inline">\(\frac{\partial
Y}{\partial X_i}\)</span> désigne la dérivée partielle de <span
class="math inline">\(Y\)</span> par rapport à <span
class="math inline">\(X_i\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Nous allons maintenant démontrer le théorème de décomposition de la
variance totale.</p>
<div class="proof">
<p><em>Proof.</em> Considérons <span class="math inline">\(Y =
\sum_{i=1}^n a_i X_i + c\)</span>. La variance de <span
class="math inline">\(Y\)</span> est donnée par : <span
class="math display">\[\text{Var}(Y) = \text{Var}\left( \sum_{i=1}^n a_i
X_i + c \right) = \text{Var}\left( \sum_{i=1}^n a_i X_i \right)\]</span>
Puisque les <span class="math inline">\(X_i\)</span> sont indépendants,
nous avons : <span class="math display">\[\text{Var}\left( \sum_{i=1}^n
a_i X_i \right) = \sum_{i=1}^n \text{Var}(a_i X_i) = \sum_{i=1}^n a_i^2
\sigma_{X_i}^2\]</span> Ainsi, nous avons démontré que : <span
class="math display">\[\text{Var}(Y) = \sum_{i=1}^n a_i^2
\sigma_{X_i}^2\]</span> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous présentons maintenant quelques propriétés et corollaires
importants liés à la variance totale.</p>
<div class="corollary">
<p>Soient <span class="math inline">\(Y_1\)</span> et <span
class="math inline">\(Y_2\)</span> deux variables aléatoires de
variances respectives <span
class="math inline">\(\text{Var}(Y_1)\)</span> et <span
class="math inline">\(\text{Var}(Y_2)\)</span>, et soit <span
class="math inline">\(Y = aY_1 + bY_2 + c\)</span> où <span
class="math inline">\(a, b, c\)</span> sont des constantes. Alors :
<span class="math display">\[\text{Var}(Y) = a^2 \text{Var}(Y_1) + b^2
\text{Var}(Y_2)\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve suit directement de la définition de la
variance totale. En effet, si <span class="math inline">\(Y_1\)</span>
et <span class="math inline">\(Y_2\)</span> sont indépendants, alors :
<span class="math display">\[\text{Var}(Y) = \text{Var}(aY_1 + bY_2 + c)
= a^2 \text{Var}(Y_1) + b^2 \text{Var}(Y_2)\]</span> ◻</p>
</div>
<div class="corollary">
<p>Soient <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des
variables aléatoires indépendantes de variances respectives <span
class="math inline">\(\sigma_{X_1}^2, \sigma_{X_2}^2, \ldots,
\sigma_{X_n}^2\)</span>, et soit <span class="math inline">\(Y = f(X_1,
X_2, \ldots, X_n)\)</span>. Si <span class="math inline">\(Y\)</span>
est une fonction linéaire de <span class="math inline">\(X_1, X_2,
\ldots, X_n\)</span>, alors : <span class="math display">\[\text{Var}(Y)
= \sum_{i=1}^n \text{Var}\left( \frac{\partial Y}{\partial X_i} \right)
\sigma_{X_i}^2\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve suit directement du théorème de
décomposition de la variance totale. En effet, si <span
class="math inline">\(Y\)</span> est une fonction linéaire de <span
class="math inline">\(X_1, X_2, \ldots, X_n\)</span>, alors : <span
class="math display">\[\text{Var}(Y) = \sum_{i=1}^n \text{Var}\left(
\frac{\partial Y}{\partial X_i} \right) \sigma_{X_i}^2\]</span> ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La variance totale est une notion puissante et polyvalente,
permettant de décomposer la variance d’une variable aléatoire en
composantes explicatives. Cette notion trouve des applications dans de
nombreux domaines, allant de l’analyse statistique à la modélisation
économique. En comprenant comment différentes sources de variation
contribuent à la variabilité totale d’une observation, nous pouvons
mieux interpréter les résultats de nos analyses et prendre des décisions
éclairées.</p>
</body>
</html>
{% include "footer.html" %}

