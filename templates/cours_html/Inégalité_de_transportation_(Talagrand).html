{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’inégalité de transportation de Talagrand</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’inégalité de transportation de Talagrand</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de transportation de Talagrand est une avancée majeure
dans le domaine des probabilités et de la théorie des mesures. Elle
trouve ses racines dans les travaux de Michel Talagrand, un
mathématicien français contemporain, qui a su unifier et étendre des
concepts issus de la théorie des processus empiriques et de l’analyse
fonctionnelle.</p>
<p>Cette inégalité émerge comme une réponse puissante à des problèmes de
concentration de mesure, où l’on cherche à estimer la probabilité qu’une
fonction aléatoire s’éloigne de sa valeur moyenne. Elle est
indispensable dans des domaines variés tels que l’apprentissage
automatique, la théorie de l’information et les statistiques, où la
compréhension des écarts entre variables aléatoires est cruciale.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’inégalité de Talagrand, il est essentiel de définir
quelques concepts clés. Commençons par la notion de distance de
transportation.</p>
<p>Supposons que nous ayons deux mesures de probabilité <span
class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> sur un espace métrique <span
class="math inline">\((E, d)\)</span>. Nous cherchons à mesurer le
"coût" de transformer <span class="math inline">\(\mu\)</span> en <span
class="math inline">\(\nu\)</span>. Intuitivement, ce coût devrait
dépendre de la distance entre les points de <span
class="math inline">\(E\)</span>.</p>
<p>La distance de transportation (ou distance de Wasserstein) est
définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> deux mesures de probabilité sur un
espace métrique <span class="math inline">\((E, d)\)</span>. La distance
de transportation <span class="math inline">\(W_p(\mu, \nu)\)</span> est
définie par : <span class="math display">\[W_p(\mu, \nu) = \left(
\inf_{\gamma \in \Gamma(\mu, \nu)} \int_{E \times E} d(x, y)^p \,
d\gamma(x, y) \right)^{1/p}\]</span> où <span
class="math inline">\(\Gamma(\mu, \nu)\)</span> est l’ensemble des
mesures de couplage entre <span class="math inline">\(\mu\)</span> et
<span class="math inline">\(\nu\)</span>, c’est-à-dire les mesures <span
class="math inline">\(\gamma\)</span> sur <span class="math inline">\(E
\times E\)</span> telles que pour tout borélien <span
class="math inline">\(A \subset E\)</span>, <span
class="math inline">\(\gamma(A \times E) = \mu(A)\)</span> et <span
class="math inline">\(\gamma(E \times A) = \nu(A)\)</span>.</p>
</div>
<p>Une autre notion cruciale est celle de fonction convexe. Une fonction
<span class="math inline">\(f: \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> est convexe si pour tout <span
class="math inline">\(x, y \in \mathbb{R}^n\)</span> et tout <span
class="math inline">\(\lambda \in [0, 1]\)</span>, on a : <span
class="math display">\[f(\lambda x + (1 - \lambda) y) \leq \lambda f(x)
+ (1 - \lambda) f(y)\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>L’inégalité de Talagrand est un résultat profond qui relie la
distance de transportation à des propriétés de concentration. Voici une
formulation classique :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire à
valeurs dans un espace métrique <span class="math inline">\((E,
d)\)</span> muni de la tribu borélienne. Supposons que <span
class="math inline">\(X\)</span> soit centrée, c’est-à-dire <span
class="math inline">\(\mathbb{E}[X] = 0\)</span>, et que pour tout <span
class="math inline">\(x \in E\)</span>, on ait <span
class="math inline">\(\mathbb{E}[d(0, X)^2] \leq 1\)</span>. Alors, pour
tout <span class="math inline">\(t &gt; 0\)</span>, on a : <span
class="math display">\[\mathbb{P}\left( d(0, X) \geq t + \sqrt{2t}
\right) \leq e^{-t}\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>La preuve de l’inégalité de Talagrand repose sur des techniques
avancées d’analyse fonctionnelle et de théorie des probabilités. Voici
une esquisse de la démonstration :</p>
<div class="proof">
<p><em>Proof.</em> Commençons par rappeler que <span
class="math inline">\(X\)</span> est centrée et que <span
class="math inline">\(\mathbb{E}[d(0, X)^2] \leq 1\)</span>. Nous allons
utiliser la fonction caractéristique de <span
class="math inline">\(X\)</span> pour obtenir une borne sur <span
class="math inline">\(\mathbb{P}(d(0, X) \geq t +
\sqrt{2t})\)</span>.</p>
<p>Soit <span class="math inline">\(\phi\)</span> la fonction
caractéristique de <span class="math inline">\(X\)</span>, c’est-à-dire
: <span class="math display">\[\phi(u) = \mathbb{E}[e^{iu \cdot
X}]\]</span></p>
<p>En utilisant le théorème de Plancherel, nous pouvons exprimer <span
class="math inline">\(\mathbb{P}(d(0, X) \geq r)\)</span> en termes de
<span class="math inline">\(\phi\)</span> : <span
class="math display">\[\mathbb{P}(d(0, X) \geq r) = \frac{1}{2\pi}
\int_{\mathbb{R}^n} \frac{\hat{\chi}_{B(0, r)}(u)}{|u|} \phi(u) \,
du\]</span> où <span class="math inline">\(\hat{\chi}_{B(0, r)}\)</span>
est la transformée de Fourier de l’indicatrice de la boule <span
class="math inline">\(B(0, r)\)</span>.</p>
<p>En utilisant des estimations sur <span
class="math inline">\(\phi(u)\)</span> et en appliquant le théorème de
Tauberien, nous obtenons : <span class="math display">\[\mathbb{P}(d(0,
X) \geq t + \sqrt{2t}) \leq e^{-t}\]</span></p>
<p>Cette étape utilise de manière cruciale la condition <span
class="math inline">\(\mathbb{E}[d(0, X)^2] \leq 1\)</span> et des
techniques d’analyse harmonique. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Talagrand a de nombreuses conséquences intéressantes.
En voici quelques-unes :</p>
<ol>
<li><p><strong>Concentration gaussienne</strong> : L’inégalité de
Talagrand implique que les variables aléatoires à valeurs dans un espace
métrique avec une condition de variance bornée se concentrent autour de
leur moyenne.</p></li>
<li><p><strong>Applications en apprentissage automatique</strong> : Elle
permet de déduire des bornes sur les risques empiriques et d’établir des
résultats de généralisation pour les algorithmes
d’apprentissage.</p></li>
<li><p><strong>Théorie de l’information</strong> : Elle fournit des
outils pour étudier les propriétés asymptotiques des estimateurs et des
tests statistiques.</p></li>
</ol>
<p>Chacune de ces propriétés ouvre des perspectives riches pour des
recherches futures et des applications concrètes dans divers domaines
scientifiques.</p>
</body>
</html>
{% include "footer.html" %}

