{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance des effets fixes</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance des effets fixes</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La notion de variance des effets fixes émerge dans le cadre des
modèles linéaires généralisés, où l’on cherche à modéliser la relation
entre une variable dépendante et un ensemble de variables explicatives.
Les effets fixes permettent de capturer des variations systématiques non
observées, mais constantes dans le temps ou l’espace. La variance de ces
effets est cruciale pour comprendre la part de la variabilité totale
expliquée par ces effets, et donc pour évaluer la pertinence du
modèle.</p>
<p>Historiquement, cette notion a été développée dans le contexte des
modèles de panel, où l’on observe les mêmes individus ou entités à
plusieurs reprises dans le temps. Les effets fixes permettent de
contrôler pour des caractéristiques individuelles non observées, mais
constantes, telles que les aptitudes innées ou les préférences stables.
La variance des effets fixes quantifie alors l’importance de ces
caractéristiques non observées dans la détermination du comportement
observé.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir la variance des effets fixes, commençons par considérer
un modèle linéaire généralisé avec effets fixes. Supposons que nous
avons un ensemble de données <span class="math inline">\((y_i,
x_i)\)</span> pour <span class="math inline">\(i = 1, \ldots,
n\)</span>, où <span class="math inline">\(y_i\)</span> est la variable
dépendante et <span class="math inline">\(x_i\)</span> est le vecteur
des variables explicatives. Nous supposons que les effets fixes sont
capturés par un paramètre <span class="math inline">\(\alpha_i\)</span>
pour chaque individu <span class="math inline">\(i\)</span>.</p>
<p>Nous cherchons à mesurer la variabilité des effets fixes <span
class="math inline">\(\alpha_i\)</span> autour de leur moyenne. Pour
cela, nous devons d’abord définir la variance des effets fixes.</p>
<div class="definition">
<p>La variance des effets fixes est définie comme la moyenne des carrés
des écarts entre chaque effet fixe et la moyenne des effets fixes.
Formellement, si <span class="math inline">\(\alpha_i\)</span>
représente l’effet fixe pour l’individu <span
class="math inline">\(i\)</span>, alors la variance des effets fixes est
donnée par :</p>
<p><span class="math display">\[\sigma^2_{\alpha} = \frac{1}{n}
\sum_{i=1}^n (\alpha_i - \bar{\alpha})^2\]</span></p>
<p>où <span class="math inline">\(\bar{\alpha} = \frac{1}{n}
\sum_{i=1}^n \alpha_i\)</span> est la moyenne des effets fixes.</p>
</div>
<p>Une autre formulation équivalente de la variance des effets fixes est
:</p>
<p><span class="math display">\[\sigma^2_{\alpha} = \frac{1}{n}
\sum_{i=1}^n \alpha_i^2 - \left( \frac{1}{n} \sum_{i=1}^n \alpha_i
\right)^2\]</span></p>
<p>Cette formulation montre que la variance des effets fixes peut être
calculée à partir des carrés moyens des effets fixes et du carré de leur
moyenne.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème important lié à la variance des effets fixes est le
théorème de Gauss-Markov, qui fournit les conditions sous lesquelles les
estimateurs des effets fixes sont les meilleurs estimateurs linéaires
non biaisés (BLUE).</p>
<div class="theorem">
<p>Supposons que le modèle linéaire généralisé avec effets fixes peut
être écrit sous la forme :</p>
<p><span class="math display">\[y_i = x_i \beta + \alpha_i +
\epsilon_i\]</span></p>
<p>où <span class="math inline">\(x_i\)</span> est le vecteur des
variables explicatives, <span class="math inline">\(\beta\)</span> est
le vecteur des coefficients, <span
class="math inline">\(\alpha_i\)</span> est l’effet fixe pour l’individu
<span class="math inline">\(i\)</span>, et <span
class="math inline">\(\epsilon_i\)</span> est le terme d’erreur. Si les
hypothèses suivantes sont satisfaites :</p>
<ul>
<li><p><span class="math inline">\(\mathbb{E}[\epsilon_i | x_i,
\alpha_i] = 0\)</span></p></li>
<li><p><span class="math inline">\(\text{Var}(\epsilon_i | x_i,
\alpha_i) = \sigma^2\)</span></p></li>
<li><p><span class="math inline">\(\text{Cov}(\epsilon_i, \epsilon_j |
x_i, x_j, \alpha_i, \alpha_j) = 0\)</span> pour <span
class="math inline">\(i \neq j\)</span></p></li>
<li><p><span class="math inline">\(\text{Var}(\alpha_i) =
\sigma^2_{\alpha}\)</span></p></li>
</ul>
<p>alors l’estimateur des moindres carrés ordinaires (OLS) de <span
class="math inline">\(\beta\)</span> est le meilleur estimateur linéaire
non biaisé.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Gauss-Markov, nous devons montrer que
l’estimateur OLS de <span class="math inline">\(\beta\)</span> est non
biaisé et qu’il a la plus petite variance parmi tous les estimateurs
linéaires non biaisés.</p>
<div class="proof">
<p><em>Proof.</em> Tout d’abord, montrons que l’estimateur OLS de <span
class="math inline">\(\beta\)</span> est non biaisé. L’estimateur OLS de
<span class="math inline">\(\beta\)</span> est donné par :</p>
<p><span class="math display">\[\hat{\beta} =
(X&#39;X)^{-1}X&#39;y\]</span></p>
<p>où <span class="math inline">\(X\)</span> est la matrice des
variables explicatives. En substituant <span class="math inline">\(y_i =
x_i \beta + \alpha_i + \epsilon_i\)</span>, nous avons :</p>
<p><span class="math display">\[\hat{\beta} =
(X&#39;X)^{-1}X&#39;(X\beta + \alpha + \epsilon) = \beta +
(X&#39;X)^{-1}X&#39;(\alpha + \epsilon)\]</span></p>
<p>En prenant l’espérance conditionnelle, nous obtenons :</p>
<p><span class="math display">\[\mathbb{E}[\hat{\beta} | X, \alpha] =
\beta + (X&#39;X)^{-1}X&#39;\mathbb{E}[\alpha + \epsilon | X, \alpha] =
\beta\]</span></p>
<p>car <span class="math inline">\(\mathbb{E}[\epsilon_i | x_i,
\alpha_i] = 0\)</span> et <span
class="math inline">\(\mathbb{E}[\alpha_i | x_i] =
\alpha_i\)</span>.</p>
<p>Ensuite, montrons que l’estimateur OLS de <span
class="math inline">\(\beta\)</span> a la plus petite variance parmi
tous les estimateurs linéaires non biaisés. Considérons un autre
estimateur linéaire non biaisé <span class="math inline">\(b =
Hy\)</span>, où <span class="math inline">\(H\)</span> est une matrice
telle que <span class="math inline">\(\mathbb{E}[b | X, \alpha] =
\beta\)</span>. Nous avons :</p>
<p><span class="math display">\[\mathbb{E}[b - \hat{\beta} | X, \alpha]
= H\mathbb{E}[y | X, \alpha] - (X&#39;X)^{-1}X&#39;\mathbb{E}[y | X,
\alpha] = H(X\beta + \alpha) - (X&#39;X)^{-1}X&#39;(X\beta + \alpha) =
0\]</span></p>
<p>ce qui implique que <span class="math inline">\(HX =
(X&#39;X)^{-1}X&#39;X\)</span>. Par conséquent, <span
class="math inline">\(b - \hat{\beta} = H(y - X\beta) -
(X&#39;X)^{-1}X&#39;(y - X\beta)\)</span>. En prenant la variance
conditionnelle, nous obtenons :</p>
<p><span class="math display">\[\text{Var}(b - \hat{\beta} | X, \alpha)
= H\text{Var}(y - X\beta | X, \alpha)H&#39; -
(X&#39;X)^{-1}X&#39;\text{Var}(y - X\beta | X,
\alpha)((X&#39;X)^{-1}X&#39;)&#39;\]</span></p>
<p>En utilisant les hypothèses sur la variance des termes d’erreur et
des effets fixes, nous pouvons montrer que cette expression est positive
semi-définie, ce qui signifie que <span
class="math inline">\(\text{Var}(\hat{\beta} | X, \alpha) \leq
\text{Var}(b | X, \alpha)\)</span>. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons ci-dessous quelques propriétés importantes de la
variance des effets fixes.</p>
<ol>
<li><p>La variance des effets fixes est toujours non négative,
c’est-à-dire <span class="math inline">\(\sigma^2_{\alpha} \geq
0\)</span>.</p></li>
<li><p>La variance des effets fixes est nulle si et seulement si tous
les effets fixes sont égaux, c’est-à-dire <span
class="math inline">\(\alpha_i = \bar{\alpha}\)</span> pour tout <span
class="math inline">\(i\)</span>.</p></li>
<li><p>La variance des effets fixes est invariante par translation,
c’est-à-dire que si nous ajoutons une constante <span
class="math inline">\(c\)</span> à chaque effet fixe, la variance reste
inchangée : <span class="math inline">\(\text{Var}(\alpha_i + c) =
\text{Var}(\alpha_i)\)</span>.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La variance des effets fixes est une notion fondamentale dans
l’analyse des modèles linéaires généralisés avec effets fixes. Elle
permet de quantifier l’importance des caractéristiques non observées
mais constantes dans la détermination du comportement observé. Le
théorème de Gauss-Markov fournit les conditions sous lesquelles les
estimateurs des effets fixes sont les meilleurs estimateurs linéaires
non biaisés. Les propriétés de la variance des effets fixes permettent
de mieux comprendre son comportement et ses implications pour l’analyse
des données.</p>
</body>
</html>
{% include "footer.html" %}

