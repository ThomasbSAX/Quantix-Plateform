{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Convergence des Chaînes de Markov par Chaînes de Monte Carlo</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Convergence des Chaînes de Markov par Chaînes de Monte
Carlo</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les méthodes de Monte Carlo par Chaînes de Markov (MCMC) ont
révolutionné l’inférence statistique en permettant d’échantillonner des
distributions de probabilité complexes. L’idée fondamentale repose sur
la construction d’une chaîne de Markov dont la distribution stationnaire
est la distribution cible. Cependant, l’efficacité de ces méthodes
dépend cruciairement de leur convergence vers cette distribution
stationnaire.</p>
<p>L’origine des MCMC remonte aux travaux pionniers de Metropolis et al.
(1953) et Hastings (1970), qui ont introduit les algorithmes de
Metropolis-Hastings. Ces méthodes ont été popularisées par Gelfand et
Smith (1990) avec l’introduction de l’échantillonnage de Gibbs. Depuis,
les MCMC sont devenus incontournables en statistique bayésienne, en
physique statistique et en apprentissage automatique.</p>
<p>La convergence des MCMC est un sujet complexe qui combine des
concepts de théorie des probabilités, d’analyse et de statistique.
Comprendre les conditions sous lesquelles une chaîne de Markov converge
vers sa distribution stationnaire est essentiel pour garantir la
validité des résultats obtenus par ces méthodes.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant de discuter de la convergence, il est nécessaire de définir les
concepts fondamentaux.</p>
<h2 id="chaîne-de-markov">Chaîne de Markov</h2>
<p>Considérons un espace d’états <span class="math inline">\(E\)</span>
et une suite de variables aléatoires <span
class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> prenant leurs
valeurs dans <span class="math inline">\(E\)</span>. La suite <span
class="math inline">\((X_n)\)</span> est une chaîne de Markov si pour
tout <span class="math inline">\(n \in \mathbb{N}\)</span>, tout <span
class="math inline">\(x_0, \ldots, x_n, y \in E\)</span>, on a :</p>
<p><span class="math display">\[P(X_{n+1} = y \mid X_n = x_n, \ldots,
X_0 = x_0) = P(X_{n+1} = y \mid X_n = x_n)\]</span></p>
<p>En d’autres termes, la distribution conditionnelle de <span
class="math inline">\(X_{n+1}\)</span> sachant l’histoire passée ne
dépend que de la valeur actuelle <span
class="math inline">\(X_n\)</span>.</p>
<h2 id="distribution-stationnaire">Distribution Stationnaire</h2>
<p>Une distribution de probabilité <span
class="math inline">\(\pi\)</span> sur <span
class="math inline">\(E\)</span> est dite stationnaire pour une chaîne
de Markov <span class="math inline">\((X_n)\)</span> si pour tout <span
class="math inline">\(n \in \mathbb{N}\)</span>, on a :</p>
<p><span class="math display">\[\sum_{x \in E} P(X_n = x) \pi(x) =
\pi(y)\]</span></p>
<p>Pour toute <span class="math inline">\(y \in E\)</span>, cela
signifie que la distribution de <span class="math inline">\(X_n\)</span>
reste inchangée si la chaîne commence avec <span
class="math inline">\(\pi\)</span>.</p>
<h2 id="convergence-en-distribution">Convergence en Distribution</h2>
<p>Une chaîne de Markov <span class="math inline">\((X_n)\)</span>
converge en distribution vers une distribution <span
class="math inline">\(\pi\)</span> si pour toute fonction continue
bornée <span class="math inline">\(f : E \to \mathbb{R}\)</span>, on a
:</p>
<p><span class="math display">\[\lim_{n \to \infty} \mathbb{E}[f(X_n)] =
\int_E f(x) \, d\pi(x)\]</span></p>
<h1 id="théorèmes-de-convergence">Théorèmes de Convergence</h1>
<h2 id="théorème-dergodicité">Théorème d’Ergodicité</h2>
<p>Le théorème d’ergodicité est fondamental pour les MCMC. Il stipule
que sous certaines conditions, la moyenne empirique d’une fonction <span
class="math inline">\(f\)</span> le long de la chaîne converge vers
l’espérance sous la distribution stationnaire.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((X_n)\)</span> une chaîne de Markov
irréductible, apériodique et réversible avec distribution stationnaire
<span class="math inline">\(\pi\)</span>. Alors pour toute fonction
<span class="math inline">\(f : E \to \mathbb{R}\)</span> telle que
<span class="math inline">\(\int_E |f(x)| \, d\pi(x) &lt;
\infty\)</span>, on a :</p>
<p><span class="math display">\[\lim_{n \to \infty} \frac{1}{n}
\sum_{k=0}^{n-1} f(X_k) = \int_E f(x) \, d\pi(x)\]</span></p>
<p>avec probabilité 1.</p>
</div>
<h2 id="théorème-de-convergence-totale">Théorème de Convergence
Totale</h2>
<p>Le théorème de convergence totale fournit des conditions suffisantes
pour la convergence en distribution.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((X_n)\)</span> une chaîne de Markov
irréductible, apériodique et réversible avec distribution stationnaire
<span class="math inline">\(\pi\)</span>. Alors pour toute fonction
continue bornée <span class="math inline">\(f : E \to
\mathbb{R}\)</span>, on a :</p>
<p><span class="math display">\[\lim_{n \to \infty} \mathbb{E}[f(X_n)] =
\int_E f(x) \, d\pi(x)\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<h2 id="preuve-du-théorème-dergodicité">Preuve du Théorème
d’Ergodicité</h2>
<p>La preuve repose sur la théorie des chaînes de Markov et les
propriétés de convergence des martingales.</p>
<div class="proof">
<p><em>Proof.</em> Considérons la chaîne de Markov <span
class="math inline">\((X_n)\)</span> et supposons qu’elle est
irréductible, apériodique et réversible. La distribution stationnaire
<span class="math inline">\(\pi\)</span> existe et est unique.</p>
<p>Pour toute fonction <span class="math inline">\(f : E \to
\mathbb{R}\)</span> telle que <span class="math inline">\(\int_E |f(x)|
\, d\pi(x) &lt; \infty\)</span>, définissons <span
class="math inline">\(S_n = \sum_{k=0}^{n-1} f(X_k)\)</span>. Nous
voulons montrer que :</p>
<p><span class="math display">\[\lim_{n \to \infty} \frac{S_n}{n} =
\int_E f(x) \, d\pi(x)\]</span></p>
<p>avec probabilité 1.</p>
<p>En utilisant le théorème ergodique de Markov, nous savons que pour
une chaîne de Markov irréductible et apériodique, la moyenne empirique
converge vers l’espérance sous la distribution stationnaire. ◻</p>
</div>
<h2 id="preuve-du-théorème-de-convergence-totale">Preuve du Théorème de
Convergence Totale</h2>
<p>La preuve utilise des techniques d’analyse fonctionnelle et de
théorie des probabilités.</p>
<div class="proof">
<p><em>Proof.</em> Considérons une chaîne de Markov <span
class="math inline">\((X_n)\)</span> irréductible, apériodique et
réversible avec distribution stationnaire <span
class="math inline">\(\pi\)</span>. Pour toute fonction continue bornée
<span class="math inline">\(f : E \to \mathbb{R}\)</span>, nous voulons
montrer que :</p>
<p><span class="math display">\[\lim_{n \to \infty} \mathbb{E}[f(X_n)] =
\int_E f(x) \, d\pi(x)\]</span></p>
<p>En utilisant le théorème de convergence des martingales, nous pouvons
montrer que la suite <span
class="math inline">\(\mathbb{E}[f(X_n)]\)</span> converge vers
l’espérance sous <span class="math inline">\(\pi\)</span>. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriété-dirréductibilité">Propriété d’Irréductibilité</h2>
<ol>
<li><p>Une chaîne de Markov est irréductible si pour tout <span
class="math inline">\(x, y \in E\)</span>, il existe un entier <span
class="math inline">\(n\)</span> tel que <span
class="math inline">\(P(X_n = y \mid X_0 = x) &gt; 0\)</span>.</p></li>
<li><p>Cette propriété est cruciale pour garantir l’existence d’une
distribution stationnaire.</p></li>
</ol>
<h2 id="propriété-de-réversibilité">Propriété de Réversibilité</h2>
<ol>
<li><p>Une chaîne de Markov est réversible par rapport à <span
class="math inline">\(\pi\)</span> si pour tout <span
class="math inline">\(x, y \in E\)</span>, on a :</p>
<p><span class="math display">\[P(X_{n+1} = y \mid X_n = x) \pi(x) =
P(X_{n+1} = x \mid X_n = y) \pi(y)\]</span></p></li>
<li><p>La réversibilité simplifie souvent l’analyse des chaînes de
Markov.</p></li>
</ol>
<h2 id="corollaire-de-convergence">Corollaire de Convergence</h2>
<ol>
<li><p>Si une chaîne de Markov est irréductible, apériodique et
réversible, alors elle converge en distribution vers sa distribution
stationnaire.</p></li>
<li><p>Ce corollaire est une conséquence directe des théorèmes de
convergence présentés précédemment.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>Les méthodes MCMC sont des outils puissants pour l’inférence
statistique, mais leur validité repose sur la compréhension de leur
convergence. Les théorèmes et propriétés présentés dans cet article
fournissent les bases théoriques nécessaires pour garantir la
convergence des chaînes de Markov vers leur distribution stationnaire.
Les preuves détaillées illustrent l’importance des concepts de théorie
des probabilités et d’analyse dans l’étude des MCMC.</p>
</body>
</html>
{% include "footer.html" %}

