{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Corrélation interclasse : Une analyse mathématique approfondie</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Corrélation interclasse : Une analyse mathématique
approfondie</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La corrélation interclasse, notion fondamentale en statistique
descriptive, émerge comme un outil indispensable pour quantifier les
relations entre variables catégorielles. Son origine historique remonte
aux travaux pionniers de Karl Pearson, qui a posé les bases de la
corrélation. Cependant, l’adaptation de cette notion aux variables
qualitatives nécessite une approche distincte, donnant naissance à la
corrélation interclasse.</p>
<p>Cette notion est cruciale dans divers domaines, notamment en
sociologie, en biologie et en économie, où l’analyse des relations entre
catégories permet de révéler des tendances cachées. Par exemple, en
sociologie, elle peut mettre en lumière les liens entre différentes
variables démographiques.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la corrélation interclasse, commençons par comprendre ce
que nous cherchons à mesurer. Imaginons deux variables catégorielles,
chacune avec plusieurs modalités. Nous voulons quantifier à quel point
ces modalités sont associées.</p>
<p>Supposons que nous avons deux variables <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, avec <span
class="math inline">\(k\)</span> et <span
class="math inline">\(l\)</span> modalités respectivement. La
corrélation interclasse mesure la dépendance entre ces variables.</p>
<div class="definition">
<p>Soient <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> deux variables catégorielles avec <span
class="math inline">\(k\)</span> et <span
class="math inline">\(l\)</span> modalités respectivement. La
corrélation interclasse est définie comme :</p>
<p><span class="math display">\[\chi^2 = \sum_{i=1}^{k} \sum_{j=1}^{l}
\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\]</span></p>
<p>où <span class="math inline">\(O_{ij}\)</span> est l’effectif observé
dans la cellule <span class="math inline">\((i,j)\)</span>, et <span
class="math inline">\(E_{ij}\)</span> est l’effectif attendu sous
l’hypothèse d’indépendance.</p>
</div>
<p>Une autre formulation équivalente est :</p>
<p><span class="math display">\[\chi^2 = N \sum_{i=1}^{k} \sum_{j=1}^{l}
\frac{(p_{ij} - p_i p_j)^2}{p_i p_j}\]</span></p>
<p>où <span class="math inline">\(N\)</span> est le nombre total
d’observations, <span class="math inline">\(p_{ij}\)</span> est la
proportion observée dans la cellule <span
class="math inline">\((i,j)\)</span>, et <span
class="math inline">\(p_i\)</span> et <span
class="math inline">\(p_j\)</span> sont les proportions marginales.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la corrélation interclasse est le
théorème de l’indépendance, qui stipule que si les variables sont
indépendantes, la statistique du chi-carré suit une loi du chi-carré
avec <span class="math inline">\((k-1)(l-1)\)</span> degrés de
liberté.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> deux variables catégorielles
indépendantes. Alors, sous l’hypothèse nulle d’indépendance, la
statistique du chi-carré suit une loi du chi-carré avec <span
class="math inline">\((k-1)(l-1)\)</span> degrés de liberté.</p>
</div>
<p>Pour démontrer ce théorème, nous commençons par rappeler que sous
l’hypothèse d’indépendance, les effectifs attendus <span
class="math inline">\(E_{ij}\)</span> sont donnés par :</p>
<p><span class="math display">\[E_{ij} = N p_i p_j\]</span></p>
<p>où <span class="math inline">\(p_i\)</span> et <span
class="math inline">\(p_j\)</span> sont les proportions marginales.
Ensuite, nous utilisons le fait que la somme des carrés standardisés
suit une loi du chi-carré.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de l’indépendance, nous procédons comme suit
:</p>
<p>1. **Hypothèse d’indépendance** : Nous supposons que <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont indépendantes. Cela implique que
les effectifs attendus sous l’hypothèse d’indépendance sont donnés par
<span class="math inline">\(E_{ij} = N p_i p_j\)</span>.</p>
<p>2. **Standardisation** : Nous standardisons les différences entre les
effectifs observés et attendus en divisant par l’écart-type des
effectifs attendus. Cela donne :</p>
<p><span class="math display">\[Z_{ij} = \frac{O_{ij} -
E_{ij}}{\sqrt{E_{ij}}}\]</span></p>
<p>3. **Somme des carrés** : Nous calculons la somme des carrés de ces
valeurs standardisées :</p>
<p><span class="math display">\[\chi^2 = \sum_{i=1}^{k} \sum_{j=1}^{l}
Z_{ij}^2\]</span></p>
<p>4. **Loi du chi-carré** : Nous utilisons le fait que la somme des
carrés de variables standardisées normales suit une loi du chi-carré.
Ainsi, sous l’hypothèse d’indépendance, <span
class="math inline">\(\chi^2\)</span> suit une loi du chi-carré avec
<span class="math inline">\((k-1)(l-1)\)</span> degrés de liberté.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Plusieurs propriétés importantes découlent du théorème de
l’indépendance :</p>
<ol>
<li><p>**Propriété de linéarité** : La statistique du chi-carré est
linéaire par rapport aux effectifs observés. Cela signifie que si nous
multiplions tous les effectifs par une constante, la statistique du
chi-carré est également multipliée par cette constante.</p></li>
<li><p>**Propriété de l’indépendance** : Si les variables sont
indépendantes, la statistique du chi-carré suit une loi du chi-carré
avec <span class="math inline">\((k-1)(l-1)\)</span> degrés de liberté.
Cela permet de tester l’hypothèse d’indépendance.</p></li>
<li><p>**Propriété de la consistance** : La statistique du chi-carré est
consistante, ce qui signifie que si l’hypothèse d’indépendance est
fausse, la statistique tendra vers l’infini lorsque le nombre
d’observations augmente.</p></li>
</ol>
<p>Pour prouver la propriété de linéarité, nous considérons un facteur
multiplicatif <span class="math inline">\(c\)</span> appliqué à tous les
effectifs observés. La statistique du chi-carré devient :</p>
<p><span class="math display">\[\chi^2 = c \sum_{i=1}^{k} \sum_{j=1}^{l}
\frac{(O_{ij} - c E_{ij})^2}{c E_{ij}} = c \chi&#39;^2\]</span></p>
<p>où <span class="math inline">\(\chi&#39;^2\)</span> est la
statistique du chi-carré calculée avec les effectifs observés multipliés
par <span class="math inline">\(c\)</span>.</p>
</body>
</html>
{% include "footer.html" %}

