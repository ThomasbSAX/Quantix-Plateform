{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance binomiale : Une exploration approfondie</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance binomiale : Une exploration approfondie</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La variance binomiale émerge naturellement dans le cadre des
expériences aléatoires composées de répétitions indépendantes d’une
épreuve de Bernoulli. Cette notion, bien que simple en apparence, est
fondamentale dans l’analyse des phénomènes aléatoires discrets. Elle
permet de quantifier la dispersion des résultats autour de leur moyenne,
offrant ainsi une mesure essentielle pour évaluer l’incertitude et la
variabilité dans divers contextes scientifiques, économiques et
sociaux.</p>
<p>L’étude de la variance binomiale trouve ses racines dans les travaux
pionniers de Jacob Bernoulli au XVIIe siècle, qui a posé les bases de la
théorie des probabilités. Son importance réside dans sa capacité à
modéliser des situations où un événement peut se produire ou non, avec
une probabilité constante. Cette modélisation est indispensable dans des
domaines tels que la biologie, l’ingénierie, et les sciences sociales,
où l’on cherche à comprendre et prédire des comportements
aléatoires.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la variance binomiale, commençons par comprendre ce
que nous cherchons à mesurer. Imaginons une expérience composée de <span
class="math inline">\(n\)</span> répétitions indépendantes d’une épreuve
de Bernoulli, où chaque répétition peut aboutir à un succès avec une
probabilité <span class="math inline">\(p\)</span> ou à un échec avec
une probabilité <span class="math inline">\(1 - p\)</span>. Nous voulons
quantifier la dispersion des nombres de succès autour de leur
moyenne.</p>
<p>La variance binomiale est définie comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
binomiale de paramètres <span class="math inline">\(n\)</span> et <span
class="math inline">\(p\)</span>, c’est-à-dire que <span
class="math inline">\(X \sim \mathcal{B}(n, p)\)</span>. La variance de
<span class="math inline">\(X\)</span>, notée <span
class="math inline">\(\text{Var}(X)\)</span>, est donnée par : <span
class="math display">\[\text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2]
= n p (1 - p)\]</span></p>
</div>
<p>Cette définition peut être reformulée en utilisant les propriétés des
espérances et des variances :</p>
<div class="definition">
<p>Pour une variable aléatoire binomiale <span class="math inline">\(X
\sim \mathcal{B}(n, p)\)</span>, la variance est également donnée par :
<span class="math display">\[\text{Var}(X) = \mathbb{E}[X^2] -
(\mathbb{E}[X])^2\]</span> où <span class="math inline">\(\mathbb{E}[X]
= n p\)</span> et <span class="math inline">\(\mathbb{E}[X^2] = n p (1 -
p) + (n p)^2\)</span>.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la variance binomiale est celui de la
linéarité de la variance. Ce théorème permet de calculer la variance
d’une somme de variables aléatoires, ce qui est particulièrement utile
pour les variables binomiales.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des
variables aléatoires indépendantes. Alors : <span
class="math display">\[\text{Var}\left(\sum_{i=1}^n X_i\right) =
\sum_{i=1}^n \text{Var}(X_i)\]</span></p>
</div>
<p>Ce théorème peut être appliqué directement à une variable binomiale,
car elle est la somme de <span class="math inline">\(n\)</span>
variables de Bernoulli indépendantes.</p>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver que la variance d’une variable binomiale est <span
class="math inline">\(n p (1 - p)\)</span>, commençons par rappeler que
<span class="math inline">\(X = \sum_{i=1}^n X_i\)</span>, où chaque
<span class="math inline">\(X_i\)</span> est une variable de Bernoulli
de paramètre <span class="math inline">\(p\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Calculons d’abord l’espérance de <span
class="math inline">\(X\)</span> : <span
class="math display">\[\mathbb{E}[X] = \mathbb{E}\left[\sum_{i=1}^n
X_i\right] = \sum_{i=1}^n \mathbb{E}[X_i] = n p\]</span></p>
<p>Ensuite, calculons <span
class="math inline">\(\mathbb{E}[X^2]\)</span> : <span
class="math display">\[\mathbb{E}[X^2] =
\mathbb{E}\left[\left(\sum_{i=1}^n X_i\right)^2\right] =
\mathbb{E}\left[\sum_{i=1}^n X_i^2 + \sum_{i \neq j} X_i X_j\right] = n
p (1 - p) + n(n-1) p^2\]</span></p>
<p>Enfin, la variance est donnée par : <span
class="math display">\[\text{Var}(X) = \mathbb{E}[X^2] -
(\mathbb{E}[X])^2 = n p (1 - p) + n(n-1) p^2 - (n p)^2 = n p (1 -
p)\]</span> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La variance binomiale possède plusieurs propriétés intéressantes, que
nous allons énumérer et démontrer.</p>
<ol>
<li><p>La variance d’une variable binomiale est toujours positive ou
nulle.</p>
<div class="proof">
<p><em>Proof.</em> Puisque <span class="math inline">\(p \in [0,
1]\)</span>, on a <span class="math inline">\(p (1 - p) \geq 0\)</span>.
Donc, <span class="math inline">\(n p (1 - p) \geq 0\)</span>. ◻</p>
</div></li>
<li><p>La variance d’une variable binomiale est maximale lorsque <span
class="math inline">\(p = 0.5\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> La fonction <span class="math inline">\(f(p) = p (1 -
p)\)</span> atteint son maximum en <span class="math inline">\(p =
0.5\)</span>, car : <span class="math display">\[f&#39;(p) = 1 - 2 p = 0
\implies p = 0.5\]</span> et <span class="math inline">\(f&#39;&#39;(p)
= -2 &lt; 0\)</span>, ce qui montre que c’est un maximum. ◻</p>
</div></li>
<li><p>La variance d’une variable binomiale est nulle si et seulement si
<span class="math inline">\(p = 0\)</span> ou <span
class="math inline">\(p = 1\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Si <span class="math inline">\(p = 0\)</span> ou
<span class="math inline">\(p = 1\)</span>, alors <span
class="math inline">\(p (1 - p) = 0\)</span>. Réciproquement, si <span
class="math inline">\(\text{Var}(X) = 0\)</span>, alors <span
class="math inline">\(p (1 - p) = 0\)</span>, ce qui implique <span
class="math inline">\(p = 0\)</span> ou <span class="math inline">\(p =
1\)</span>. ◻</p>
</div></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La variance binomiale est une notion centrale en théorie des
probabilités, offrant une mesure essentielle de la dispersion des
résultats dans les expériences aléatoires composées de répétitions
indépendantes d’une épreuve de Bernoulli. Son étude permet de mieux
comprendre et prédire les comportements aléatoires, ce qui est
indispensable dans de nombreux domaines scientifiques et appliqués.</p>
</body>
</html>
{% include "footer.html" %}

