{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Prototypical Networks: A Deep Learning Approach for Few-Shot Classification</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Prototypical Networks: A Deep Learning Approach for
Few-Shot Classification</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>The field of few-shot learning has gained significant attention due
to its potential applications in scenarios where labeled data is scarce.
Traditional deep learning methods often require large amounts of
annotated data, making them impractical for tasks with limited training
samples. Few-shot learning aims to address this challenge by enabling
models to generalize from a few examples.</p>
<p>Prototypical Networks, introduced by Snell et al. in 2017, represent
a groundbreaking approach to few-shot learning. These networks leverage
the concept of prototypes, which are learned representations of classes
in a metric space. By computing distances between query samples and
these prototypes, Prototypical Networks achieve state-of-the-art
performance in few-shot classification tasks.</p>
<h1 id="definitions">Definitions</h1>
<p>To understand Prototypical Networks, we first need to define some key
concepts:</p>
<div class="definition">
<p>Few-shot learning is a paradigm in machine learning where the goal is
to learn a model that can generalize from a small number of training
examples. Formally, given a set of classes <span
class="math inline">\(C\)</span>, and for each class <span
class="math inline">\(c \in C\)</span>, a support set <span
class="math inline">\(S_c\)</span> containing <span
class="math inline">\(k\)</span> examples, and a query set <span
class="math inline">\(Q_c\)</span> containing <span
class="math inline">\(m\)</span> examples, the task is to classify each
example in <span class="math inline">\(Q_c\)</span> into one of the
classes in <span class="math inline">\(C\)</span>.</p>
</div>
<div class="definition">
<p>A prototype is a learned representation of a class in a metric space.
Given a support set <span class="math inline">\(S_c\)</span> for class
<span class="math inline">\(c\)</span>, the prototype <span
class="math inline">\(p_c\)</span> is computed as the mean of the
embeddings of the samples in <span class="math inline">\(S_c\)</span>.
Mathematically, for a support set <span class="math inline">\(S_c =
\{x_{c1}, x_{c2}, \ldots, x_{ck}\}\)</span>, the prototype <span
class="math inline">\(p_c\)</span> is defined as: <span
class="math display">\[p_c = \frac{1}{k} \sum_{i=1}^{k}
f(x_{ci})\]</span> where <span class="math inline">\(f\)</span> is a
feature embedding function.</p>
</div>
<h1 id="prototypical-networks">Prototypical Networks</h1>
<p>Prototypical Networks are designed to perform few-shot classification
by computing distances between query samples and class prototypes. The
network consists of an embedding function <span
class="math inline">\(f\)</span> that maps input samples to a feature
space, and a classification layer that computes the distances between
query samples and prototypes.</p>
<div class="theorem">
<p>Given a support set <span class="math inline">\(S = \{(x_{ci},
y_i)\}_{i=1}^{N}\)</span> where <span class="math inline">\(N = k \times
C\)</span>, and a query set <span class="math inline">\(Q =
\{x_q\}\)</span>, the probability that a query sample <span
class="math inline">\(x_q\)</span> belongs to class <span
class="math inline">\(c\)</span> is given by: <span
class="math display">\[p(y = c | x_q) = \frac{\exp(-d(f(x_q),
p_c))}{\sum_{c&#39; \in C} \exp(-d(f(x_q), p_{c&#39;}))}\]</span> where
<span class="math inline">\(d\)</span> is a distance metric (e.g.,
Euclidean distance), and <span class="math inline">\(p_c\)</span> is the
prototype for class <span class="math inline">\(c\)</span>.</p>
</div>
<h1 id="proofs">Proofs</h1>
<p>The proof of the Prototypical Network Classification theorem relies
on the computation of distances between query samples and class
prototypes.</p>
<div class="proof">
<p><em>Proof.</em> To classify a query sample <span
class="math inline">\(x_q\)</span>, we first compute its embedding <span
class="math inline">\(f(x_q)\)</span>. Then, for each class <span
class="math inline">\(c\)</span>, we compute the distance between <span
class="math inline">\(f(x_q)\)</span> and the prototype <span
class="math inline">\(p_c\)</span>. The probability that <span
class="math inline">\(x_q\)</span> belongs to class <span
class="math inline">\(c\)</span> is proportional to the negative
exponent of this distance. Specifically: <span
class="math display">\[p(y = c | x_q) \propto \exp(-d(f(x_q),
p_c))\]</span> To obtain a valid probability distribution, we normalize
these values by dividing by the sum of the exponentials for all classes:
<span class="math display">\[p(y = c | x_q) = \frac{\exp(-d(f(x_q),
p_c))}{\sum_{c&#39; \in C} \exp(-d(f(x_q), p_{c&#39;}))}\]</span> ◻</p>
</div>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>Prototypical Networks exhibit several important properties that
contribute to their effectiveness in few-shot learning:</p>
<ul>
<li><p><strong>Metric Learning</strong>: Prototypical Networks learn a
metric space where samples from the same class are close to each other,
and samples from different classes are far apart. This property is
crucial for accurate few-shot classification.</p></li>
<li><p><strong>Generalization</strong>: By computing distances between
query samples and class prototypes, Prototypical Networks can generalize
from a few examples. This ability to generalize is essential for tasks
with limited training data.</p></li>
<li><p><strong>Efficiency</strong>: Prototypical Networks are
computationally efficient, as they only require computing distances
between query samples and prototypes. This efficiency makes them
suitable for real-time applications.</p></li>
</ul>
<h1 id="conclusion">Conclusion</h1>
<p>Prototypical Networks represent a significant advancement in the
field of few-shot learning. By leveraging the concept of prototypes and
computing distances between query samples and class representations,
these networks achieve state-of-the-art performance in few-shot
classification tasks. Their ability to generalize from a few examples
makes them particularly valuable for applications where labeled data is
scarce.</p>
</body>
</html>
{% include "footer.html" %}

