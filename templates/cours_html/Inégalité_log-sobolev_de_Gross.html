{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’inégalité log-Sobolev de Gross : Un pont entre l’analyse et la probabilité</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’inégalité log-Sobolev de Gross : Un pont entre
l’analyse et la probabilité</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’inégalité log-Sobolev, introduite par Leonard Gross en 1975, est
une pierre angulaire de l’analyse fonctionnelle et de la théorie des
probabilités. Elle établit un lien profond entre les propriétés
analytiques d’une mesure de probabilité et ses caractéristiques
géométriques. Cette inégalité émerge naturellement dans l’étude des
semi-groupes de diffusion, des processus de Markov symétriques et des
inégalités fonctionnelles.</p>
<p>L’origine conceptuelle de cette inégalité remonte aux travaux de
Gross sur les mesures gaussiennes et leur comportement sous l’action des
semi-groupes de chaleur. L’inégalité log-Sobolev résout un problème
fondamental : quantifier la vitesse de convergence vers l’équilibre d’un
système dynamique en termes d’entropie relative et d’énergie de
Dirichlet. Elle est indispensable dans l’étude des propriétés
asymptotiques des chaînes de Markov, des équations différentielles
stochastiques et des modèles statistiques complexes.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre l’inégalité log-Sobolev, commençons par définir les
concepts clés. Supposons que nous avons une mesure de probabilité <span
class="math inline">\(\mu\)</span> sur un espace mesurable <span
class="math inline">\((E, \mathcal{E})\)</span>. Nous cherchons à
quantifier la "distance" entre deux mesures de probabilité en termes
d’entropie relative.</p>
<p>L’entropie relative, ou divergence de Kullback-Leibler, est une
mesure de la distance entre deux mesures de probabilité. Elle est
définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> deux mesures de probabilité sur un
espace mesurable <span class="math inline">\((E, \mathcal{E})\)</span>.
L’entropie relative de <span class="math inline">\(\nu\)</span> par
rapport à <span class="math inline">\(\mu\)</span> est définie par <span
class="math display">\[H(\nu|\mu) = \int_E
\log\left(\frac{d\nu}{d\mu}\right) d\nu\]</span> si <span
class="math inline">\(\nu\)</span> est absolument continue par rapport à
<span class="math inline">\(\mu\)</span>, et <span
class="math inline">\(+\infty\)</span> sinon.</p>
</div>
<p>L’énergie de Dirichlet, quant à elle, mesure la régularité d’une
fonction par rapport à une mesure de probabilité. Elle est définie comme
suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mu\)</span> une mesure de
probabilité sur un espace mesurable <span class="math inline">\((E,
\mathcal{E})\)</span> et soit <span
class="math inline">\(\mathcal{A}\)</span> un opérateur de Dirichlet
associé à <span class="math inline">\(\mu\)</span>. L’énergie de
Dirichlet d’une fonction <span class="math inline">\(f \in
L^2(\mu)\)</span> est définie par <span class="math display">\[D(f) =
\int_E f(-\mathcal{A}f) d\mu\]</span> si <span
class="math inline">\(f\)</span> est dans le domaine de <span
class="math inline">\(\mathcal{A}\)</span>, et <span
class="math inline">\(+\infty\)</span> sinon.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>L’inégalité log-Sobolev de Gross établit une relation entre
l’entropie relative et l’énergie de Dirichlet. Pour formuler cette
inégalité, nous avons besoin de quelques hypothèses supplémentaires.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\mu\)</span> une mesure de
probabilité sur un espace mesurable <span class="math inline">\((E,
\mathcal{E})\)</span> et soit <span
class="math inline">\(\mathcal{A}\)</span> un opérateur de Dirichlet
associé à <span class="math inline">\(\mu\)</span>. Supposons que <span
class="math inline">\(\mu\)</span> satisfait une inégalité de
log-Sobolev avec constante <span class="math inline">\(C &gt;
0\)</span>, c’est-à-dire que pour toute fonction <span
class="math inline">\(f \in L^2(\mu)\)</span>, <span
class="math display">\[H(f^2\mu|\mu) \leq C D(f).\]</span> Alors, pour
toute mesure de probabilité <span class="math inline">\(\nu\)</span>
absolument continue par rapport à <span
class="math inline">\(\mu\)</span>, on a <span
class="math display">\[H(\nu|\mu) \leq C
D\left(\sqrt{\frac{d\nu}{d\mu}}\right).\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver l’inégalité log-Sobolev de Gross, nous allons utiliser
des techniques d’analyse fonctionnelle et de théorie des probabilités.
La preuve repose sur plusieurs étapes clés.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\nu\)</span> une
mesure de probabilité absolument continue par rapport à <span
class="math inline">\(\mu\)</span>. Posons <span class="math inline">\(f
= \sqrt{\frac{d\nu}{d\mu}}\)</span>. Nous avons besoin de montrer que
<span class="math display">\[H(\nu|\mu) \leq C D(f).\]</span></p>
<p>Commençons par exprimer l’entropie relative en termes de <span
class="math inline">\(f\)</span> : <span
class="math display">\[H(\nu|\mu) = \int_E f^2 \log(f^2)
d\mu.\]</span></p>
<p>Ensuite, nous utilisons l’inégalité de log-Sobolev pour <span
class="math inline">\(f^2\)</span> : <span
class="math display">\[H(f^2\mu|\mu) \leq C D(f).\]</span></p>
<p>En développant le membre de gauche, nous obtenons : <span
class="math display">\[\int_E f^2 \log(f^2) d\mu + \int_E (1 - f^2)
\log(1 - f^2) d\mu \leq C D(f).\]</span></p>
<p>En utilisant l’inégalité de Jensen, nous pouvons montrer que le
deuxième terme est non négatif. Par conséquent, <span
class="math display">\[\int_E f^2 \log(f^2) d\mu \leq C
D(f).\]</span></p>
<p>Ainsi, nous avons prouvé l’inégalité log-Sobolev de Gross. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’inégalité log-Sobolev de Gross a plusieurs propriétés intéressantes
et corollaires. Nous allons en énumérer quelques-uns.</p>
<ol>
<li><p><strong>Inégalité de Talagrand</strong> : L’inégalité log-Sobolev
implique une inégalité de transport optimal, connue sous le nom
d’inégalité de Talagrand. Cette inégalité donne une borne supérieure sur
la distance de Wasserstein entre deux mesures de probabilité.</p></li>
<li><p><strong>Convergence exponentielle</strong> : L’inégalité
log-Sobolev implique que la convergence vers l’équilibre d’un
semi-groupe de diffusion est exponentielle. Plus précisément, si <span
class="math inline">\(\mu\)</span> satisfait une inégalité log-Sobolev
avec constante <span class="math inline">\(C\)</span>, alors pour toute
mesure initiale <span class="math inline">\(\nu\)</span>, <span
class="math display">\[H(P_t\nu|\mu) \leq e^{-t/C} H(\nu|\mu),\]</span>
où <span class="math inline">\(P_t\)</span> est le semi-groupe de
diffusion associé à <span class="math inline">\(\mu\)</span>.</p></li>
<li><p><strong>Inégalité de Poincaré</strong> : L’inégalité log-Sobolev
implique une inégalité de Poincaré. Plus précisément, si <span
class="math inline">\(\mu\)</span> satisfait une inégalité log-Sobolev
avec constante <span class="math inline">\(C\)</span>, alors pour toute
fonction <span class="math inline">\(f \in L^2(\mu)\)</span>, <span
class="math display">\[\text{Var}_\mu(f) \leq C D(f),\]</span> où <span
class="math inline">\(\text{Var}_\mu(f)\)</span> est la variance de
<span class="math inline">\(f\)</span> sous <span
class="math inline">\(\mu\)</span>.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’inégalité log-Sobolev de Gross est un outil puissant dans l’analyse
fonctionnelle et la théorie des probabilités. Elle établit un lien
profond entre les propriétés analytiques d’une mesure de probabilité et
ses caractéristiques géométriques. Les applications de cette inégalité
sont vastes, allant des chaînes de Markov aux équations différentielles
stochastiques.</p>
<p>En conclusion, l’inégalité log-Sobolev de Gross est une pierre
angulaire de la théorie des probabilités et de l’analyse fonctionnelle,
offrant des insights profonds sur le comportement des systèmes
dynamiques et des processus stochastiques.</p>
</body>
</html>
{% include "footer.html" %}

