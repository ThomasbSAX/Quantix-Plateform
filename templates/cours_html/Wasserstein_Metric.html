{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Wasserstein Metric: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Wasserstein Metric: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>The Wasserstein metric, also known as the Kantorovich-Rubinstein
metric or the Earth Mover’s Distance (EMD), is a fundamental concept in
the field of optimal transport theory. This metric has its roots in the
works of Leonid Kantorovich and Moses Rubinstein in the mid-20th
century, but it has gained significant attention in recent years due to
its applications in various fields such as machine learning, statistics,
and economics.</p>
<p>The Wasserstein metric provides a way to measure the distance between
two probability distributions. Unlike traditional metrics such as the
total variation or the Hellinger distance, the Wasserstein metric takes
into account the geometric structure of the underlying space. This makes
it particularly useful in scenarios where the topology and geometry of
the data are important.</p>
<h1 id="definitions">Definitions</h1>
<p>To understand the Wasserstein metric, let us first consider the
problem of transporting mass from one distribution to another in the
most efficient way possible. This is the essence of optimal transport
theory.</p>
<div class="definition">
<p>Let <span class="math inline">\((\mathcal{X}, d)\)</span> be a metric
space and let <span class="math inline">\(\mu, \nu\)</span> be two
probability measures on <span
class="math inline">\(\mathcal{X}\)</span>. The optimal transport
problem consists in finding a transport plan <span
class="math inline">\(\pi\)</span> that minimizes the total cost of
transporting mass from <span class="math inline">\(\mu\)</span> to <span
class="math inline">\(\nu\)</span>.</p>
<p>Mathematically, this can be expressed as: <span
class="math display">\[\min_{\pi \in \Pi(\mu, \nu)} \int_{\mathcal{X}
\times \mathcal{X}} d(x, y) \, d\pi(x, y),\]</span> where <span
class="math inline">\(\Pi(\mu, \nu)\)</span> denotes the set of all
probability measures on <span class="math inline">\(\mathcal{X} \times
\mathcal{X}\)</span> with marginals <span
class="math inline">\(\mu\)</span> and <span
class="math inline">\(\nu\)</span>.</p>
</div>
<p>The Wasserstein metric is then defined as the solution to this
optimal transport problem.</p>
<div class="definition">
<p>The <span class="math inline">\(p\)</span>-th Wasserstein distance
between two probability measures <span
class="math inline">\(\mu\)</span> and <span
class="math inline">\(\nu\)</span> on a metric space <span
class="math inline">\((\mathcal{X}, d)\)</span> is defined as: <span
class="math display">\[W_p(\mu, \nu) = \left( \inf_{\pi \in \Pi(\mu,
\nu)} \int_{\mathcal{X} \times \mathcal{X}} d(x, y)^p \, d\pi(x, y)
\right)^{1/p},\]</span> for <span class="math inline">\(p \geq
1\)</span>.</p>
<p>In the case where <span class="math inline">\(p = 1\)</span>, we
often refer to it simply as the Wasserstein distance: <span
class="math display">\[W_1(\mu, \nu) = \inf_{\pi \in \Pi(\mu, \nu)}
\int_{\mathcal{X} \times \mathcal{X}} d(x, y) \, d\pi(x,
y).\]</span></p>
</div>
<h1 id="kantorovich-rubinstein-duality-theorem">Kantorovich-Rubinstein
Duality Theorem</h1>
<p>One of the most important results in optimal transport theory is the
Kantorovich-Rubinstein duality theorem, which provides an alternative
characterization of the Wasserstein metric.</p>
<div class="theorem">
<p>Let <span class="math inline">\((\mathcal{X}, d)\)</span> be a
compact metric space and let <span class="math inline">\(\mu,
\nu\)</span> be two probability measures on <span
class="math inline">\(\mathcal{X}\)</span>. The <span
class="math inline">\(1\)</span>-Wasserstein distance can be expressed
as: <span class="math display">\[W_1(\mu, \nu) = \sup_{f \in
\text{Lip}_1(\mathcal{X})} \left( \int_{\mathcal{X}} f \, d\mu -
\int_{\mathcal{X}} f \, d\nu \right),\]</span> where <span
class="math inline">\(\text{Lip}_1(\mathcal{X})\)</span> denotes the set
of all 1-Lipschitz functions on <span
class="math inline">\(\mathcal{X}\)</span>.</p>
</div>
<h1 id="proof-of-the-kantorovich-rubinstein-duality-theorem">Proof of
the Kantorovich-Rubinstein Duality Theorem</h1>
<p>To prove this theorem, we need to establish a connection between the
optimal transport problem and the dual problem involving Lipschitz
functions.</p>
<div class="proof">
<p><em>Proof.</em> We start by considering the optimal transport
problem: <span class="math display">\[W_1(\mu, \nu) = \inf_{\pi \in
\Pi(\mu, \nu)} \int_{\mathcal{X} \times \mathcal{X}} d(x, y) \, d\pi(x,
y).\]</span></p>
<p>By the Riesz representation theorem, any continuous linear functional
on <span class="math inline">\(C(\mathcal{X})\)</span> can be
represented as an integral with respect to a measure. Therefore, we can
consider the dual problem: <span class="math display">\[\sup_{f \in
C(\mathcal{X})} \left( \int_{\mathcal{X}} f \, d\mu - \int_{\mathcal{X}}
f \, d\nu \right).\]</span></p>
<p>To establish the duality, we need to show that the optimal value of
this dual problem is equal to <span class="math inline">\(W_1(\mu,
\nu)\)</span>. This involves showing that the optimal transport plan
<span class="math inline">\(\pi\)</span> can be constructed using a
1-Lipschitz function <span class="math inline">\(f\)</span>.</p>
<p>The key step is to use the fact that for any 1-Lipschitz function
<span class="math inline">\(f\)</span>, we have: <span
class="math display">\[\int_{\mathcal{X}} f \, d\mu - \int_{\mathcal{X}}
f \, d\nu \leq \int_{\mathcal{X} \times \mathcal{X}} d(x, y) \, d\pi(x,
y).\]</span></p>
<p>By taking the supremum over all 1-Lipschitz functions <span
class="math inline">\(f\)</span>, we obtain: <span
class="math display">\[W_1(\mu, \nu) \geq \sup_{f \in
\text{Lip}_1(\mathcal{X})} \left( \int_{\mathcal{X}} f \, d\mu -
\int_{\mathcal{X}} f \, d\nu \right).\]</span></p>
<p>Conversely, for any <span class="math inline">\(\epsilon &gt;
0\)</span>, there exists a transport plan <span
class="math inline">\(\pi\)</span> such that: <span
class="math display">\[\int_{\mathcal{X} \times \mathcal{X}} d(x, y) \,
d\pi(x, y) \leq W_1(\mu, \nu) + \epsilon.\]</span></p>
<p>Using the construction of <span class="math inline">\(f\)</span>
based on <span class="math inline">\(\pi\)</span>, we can show that:
<span class="math display">\[\int_{\mathcal{X}} f \, d\mu -
\int_{\mathcal{X}} f \, d\nu \geq W_1(\mu, \nu) - \epsilon.\]</span></p>
<p>Taking the limit as <span class="math inline">\(\epsilon \to
0\)</span>, we conclude that: <span class="math display">\[W_1(\mu, \nu)
= \sup_{f \in \text{Lip}_1(\mathcal{X})} \left( \int_{\mathcal{X}} f \,
d\mu - \int_{\mathcal{X}} f \, d\nu \right).\]</span> ◻</p>
</div>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>The Wasserstein metric possesses several important properties that
make it a powerful tool in various applications.</p>
<div class="proposition">
<p>The Wasserstein metric <span class="math inline">\(W_p\)</span> is a
metric on the space of probability measures with finite <span
class="math inline">\(p\)</span>-th moment.</p>
</div>
<div class="proof">
<p><em>Proof.</em> To verify the metric properties, we need to check
non-negativity, symmetry, and the triangle inequality.</p>
<p>1. <strong>Non-negativity</strong>: For any two probability measures
<span class="math inline">\(\mu\)</span> and <span
class="math inline">\(\nu\)</span>, we have <span
class="math inline">\(W_p(\mu, \nu) \geq 0\)</span>. Equality holds if
and only if <span class="math inline">\(\mu = \nu\)</span>.</p>
<p>2. <strong>Symmetry</strong>: It is clear that <span
class="math inline">\(W_p(\mu, \nu) = W_p(\nu, \mu)\)</span>.</p>
<p>3. <strong>Triangle Inequality</strong>: For any three probability
measures <span class="math inline">\(\mu, \nu, \rho\)</span>, we have:
<span class="math display">\[W_p(\mu, \rho) \leq W_p(\mu, \nu) +
W_p(\nu, \rho).\]</span></p>
<p>The proof of the triangle inequality follows from the properties of
optimal transport plans and the Minkowski inequality. ◻</p>
</div>
<div class="corollary">
<p>The space of probability measures equipped with the Wasserstein
metric is complete.</p>
</div>
<div class="proof">
<p><em>Proof.</em> This follows from the fact that the space of
probability measures with finite <span
class="math inline">\(p\)</span>-th moment is complete and the
Wasserstein metric induces a topology that is compatible with this
completeness. ◻</p>
</div>
<h1 id="applications">Applications</h1>
<p>The Wasserstein metric has found applications in various fields,
including machine learning, statistics, and economics. In machine
learning, it is used for tasks such as generative modeling, domain
adaptation, and fairness. In statistics, it provides a robust way to
compare distributions. In economics, it is used to study the efficiency
of markets and the allocation of resources.</p>
<h1 id="conclusion">Conclusion</h1>
<p>The Wasserstein metric is a powerful tool that bridges the gap
between optimal transport theory and various applications in modern
mathematics and data science. Its ability to capture the geometric
structure of probability distributions makes it indispensable in many
areas of research.</p>
</body>
</html>
{% include "footer.html" %}

