{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Chaînes de Markov : Théorie et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Chaînes de Markov : Théorie et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>Les chaînes de Markov sont un outil fondamental en théorie des
probabilités, permettant de modéliser des phénomènes aléatoires où
l’état futur dépend uniquement de l’état présent. Introduites par le
mathématicien russe Andrei Markov au début du XXe siècle, elles trouvent
des applications dans des domaines aussi variés que la finance, la
biologie, l’informatique et les sciences sociales.</p>
<p>L’intérêt principal des chaînes de Markov réside dans leur capacité à
capturer des dépendances temporelles tout en simplifiant les modèles
complexes. Elles sont particulièrement utiles pour étudier des systèmes
dynamiques où l’historique complet n’est pas nécessaire pour prédire le
futur. Par exemple, en finance, elles peuvent être utilisées pour
modéliser les transitions entre différents états économiques, tandis
qu’en biologie, elles permettent d’analyser les séquences d’ADN.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre les chaînes de Markov, il est essentiel de définir
quelques concepts clés. Supposons que nous ayons un processus
stochastique <span class="math inline">\(\{X_n\}_{n \geq 0}\)</span> qui
prend ses valeurs dans un ensemble d’états <span
class="math inline">\(S\)</span>. Nous cherchons à modéliser la manière
dont ce processus évolue au fil du temps.</p>
<div class="definition">
<p>Une chaîne de Markov est un processus stochastique <span
class="math inline">\(\{X_n\}_{n \geq 0}\)</span> défini sur un espace
probabilisé <span class="math inline">\((\Omega, \mathcal{F},
P)\)</span> tel que pour tout <span class="math inline">\(n \geq
0\)</span>, tout <span class="math inline">\(i, j \in S\)</span> et tout
ensemble d’états <span class="math inline">\(A \subseteq S\)</span>, la
propriété suivante est vérifiée : <span class="math display">\[P(X_{n+1}
= j | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j |
X_n = i)\]</span> Cette propriété est connue sous le nom de
<em>propriété de Markov</em>.</p>
</div>
<p>Une autre manière de formuler cette définition est d’utiliser la
notion de matrice de transition. Soit <span
class="math inline">\(P\)</span> une matrice carrée d’ordre <span
class="math inline">\(|S|\)</span> où chaque entrée <span
class="math inline">\(P_{ij}\)</span> représente la probabilité de
transition de l’état <span class="math inline">\(i\)</span> à l’état
<span class="math inline">\(j\)</span>. La chaîne de Markov est alors
définie par la relation : <span class="math display">\[P(X_{n+1} = j |
X_n = i) = P_{ij}\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux concernant les chaînes de Markov est le
théorème d’ergodicité, qui décrit le comportement asymptotique des
chaînes de Markov irréductibles et apériodiques.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\{X_n\}_{n \geq 0}\)</span> une
chaîne de Markov irréductible et apériodique avec matrice de transition
<span class="math inline">\(P\)</span>. Alors, il existe une
distribution stationnaire unique <span
class="math inline">\(\pi\)</span> telle que : <span
class="math display">\[\lim_{n \to \infty} P(X_n = j | X_0 = i) =
\pi_j\]</span> pour tout <span class="math inline">\(i, j \in
S\)</span>. De plus, la distribution stationnaire <span
class="math inline">\(\pi\)</span> satisfait l’équation : <span
class="math display">\[\pi = \pi P\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème d’ergodicité, nous devons d’abord établir
l’existence et l’unicité de la distribution stationnaire. Supposons que
<span class="math inline">\(P\)</span> est une matrice de transition
irréductible et apériodique. Nous savons que <span
class="math inline">\(P\)</span> possède une valeur propre égale à 1 et
que la multiplicité de cette valeur propre est égale à 1. Cela implique
que <span class="math inline">\(P\)</span> a un vecteur propre droit
associé à la valeur propre 1, qui est la distribution stationnaire <span
class="math inline">\(\pi\)</span>.</p>
<p>Ensuite, nous devons montrer que pour tout vecteur initial <span
class="math inline">\(\mu\)</span>, la suite <span
class="math inline">\(\mu P^n\)</span> converge vers <span
class="math inline">\(\pi\)</span> lorsque <span class="math inline">\(n
\to \infty\)</span>. Cela peut être démontré en utilisant le théorème de
Perron-Frobenius, qui garantit que les puissances de <span
class="math inline">\(P\)</span> convergent vers une matrice dont les
lignes sont toutes égales à <span
class="math inline">\(\pi\)</span>.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Les chaînes de Markov possèdent plusieurs propriétés intéressantes
qui découlent du théorème d’ergodicité. Voici quelques-unes des
propriétés les plus importantes :</p>
<ol>
<li><p><strong>Convergence vers l’équilibre</strong> : Pour toute chaîne
de Markov irréductible et apériodique, la distribution des états
converge vers une distribution stationnaire unique <span
class="math inline">\(\pi\)</span> lorsque le temps tend vers
l’infini.</p></li>
<li><p><strong>Lois des grands nombres</strong> : Si la chaîne de Markov
est ergodique, alors la moyenne empirique des états converge presque
sûrement vers la moyenne sous la distribution stationnaire <span
class="math inline">\(\pi\)</span>.</p></li>
<li><p><strong>Théorème de récurrence</strong> : Toute chaîne de Markov
irréductible est récurrente, c’est-à-dire que pour tout état <span
class="math inline">\(i\)</span>, la probabilité de retour à <span
class="math inline">\(i\)</span> est égale à 1.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Les chaînes de Markov sont un outil puissant pour modéliser et
analyser des phénomènes aléatoires complexes. Leur simplicité
conceptuelle et leur richesse mathématique en font un sujet de recherche
actif et un outil indispensable dans de nombreuses applications
pratiques. En comprenant les propriétés fondamentales des chaînes de
Markov, nous pouvons mieux appréhender les systèmes dynamiques et
prédire leur comportement à long terme.</p>
</body>
</html>
{% include "footer.html" %}

