{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Loi Beta a posteriori</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Loi Beta <em>a posteriori</em></h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La loi Beta <em>a posteriori</em> émerge naturellement dans le cadre
de l’inférence bayésienne, où elle joue un rôle central dans
l’estimation des paramètres de distributions de probabilité. Son
importance historique remonte aux travaux pionniers de Thomas Bayes au
XVIIIe siècle, bien que sa formalisation moderne soit due à des
mathématiciens tels que Laplace et plus tard aux statisticiens du XXe
siècle.</p>
<p>L’intérêt pour cette loi réside dans sa capacité à modéliser
l’incertitude d’un paramètre de Bernoulli ou Binomiale, en intégrant des
connaissances <em>a priori</em> et des observations empiriques. Elle est
indispensable dans les domaines de la statistique bayésienne, de
l’apprentissage automatique et des sciences des données, où elle permet
d’effectuer des inférences robustes sur des paramètres inconnus.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la loi Beta <em>a posteriori</em>, commençons par
comprendre ce que nous cherchons à modéliser. Supposons que nous avons
un paramètre <span class="math inline">\(\theta\)</span> représentant la
probabilité de succès dans une expérience de Bernoulli. Nous souhaitons
mettre à jour notre croyance sur <span
class="math inline">\(\theta\)</span> après avoir observé un certain
nombre de succès et d’échecs.</p>
<p>La loi Beta <em>a posteriori</em> est alors la distribution de
probabilité qui résulte de cette mise à jour. Formellement, si nous
avons un <em>a priori</em> Beta avec des paramètres <span
class="math inline">\(\alpha\)</span> et <span
class="math inline">\(\beta\)</span>, et que nous observons <span
class="math inline">\(x\)</span> succès et <span
class="math inline">\(n-x\)</span> échecs dans un échantillon de taille
<span class="math inline">\(n\)</span>, alors la loi Beta <em>a
posteriori</em> est définie comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(\theta\)</span> un paramètre inconnu
dans l’intervalle <span class="math inline">\([0,1]\)</span>, et soit
<span class="math inline">\(X_1, X_2, \dots, X_n\)</span> des variables
aléatoires indépendantes et identiquement distribuées selon une loi de
Bernoulli avec paramètre <span class="math inline">\(\theta\)</span>. Si
la distribution <em>a priori</em> de <span
class="math inline">\(\theta\)</span> est une loi Beta avec paramètres
<span class="math inline">\(\alpha\)</span> et <span
class="math inline">\(\beta\)</span>, alors la distribution <em>a
posteriori</em> de <span class="math inline">\(\theta\)</span> après
avoir observé <span class="math inline">\(x = \sum_{i=1}^n X_i\)</span>
succès est une loi Beta avec paramètres <span
class="math inline">\(\alpha + x\)</span> et <span
class="math inline">\(\beta + n - x\)</span>.</p>
<p>En notation mathématique, cela s’écrit : <span
class="math display">\[\theta \mid X_1, X_2, \dots, X_n \sim
\text{Beta}(\alpha + x, \beta + n - x)\]</span></p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Pour comprendre pourquoi la loi Beta <em>a posteriori</em> prend
cette forme, nous devons examiner le théorème de Bayes et ses
conséquences. Supposons que nous avons une distribution <em>a
priori</em> pour <span class="math inline">\(\theta\)</span> et que nous
souhaitons mettre à jour cette distribution en fonction des données
observées.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\theta\)</span> un paramètre inconnu
dans l’intervalle <span class="math inline">\([0,1]\)</span>, et soit
<span class="math inline">\(X_1, X_2, \dots, X_n\)</span> des variables
aléatoires indépendantes et identiquement distribuées selon une loi de
Bernoulli avec paramètre <span class="math inline">\(\theta\)</span>. Si
la distribution <em>a priori</em> de <span
class="math inline">\(\theta\)</span> est une loi Beta avec paramètres
<span class="math inline">\(\alpha\)</span> et <span
class="math inline">\(\beta\)</span>, alors la distribution <em>a
posteriori</em> de <span class="math inline">\(\theta\)</span> après
avoir observé <span class="math inline">\(x = \sum_{i=1}^n X_i\)</span>
succès est donnée par : <span class="math display">\[f(\theta \mid x) =
\frac{f(x \mid \theta) f(\theta)}{f(x)}\]</span> où <span
class="math inline">\(f(x \mid \theta)\)</span> est la vraisemblance,
<span class="math inline">\(f(\theta)\)</span> est la distribution <em>a
priori</em>, et <span class="math inline">\(f(x)\)</span> est la
probabilité marginale des données.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous devons développer chaque composante de
l’expression. Commençons par la vraisemblance <span
class="math inline">\(f(x \mid \theta)\)</span>, qui est le produit des
probabilités de chaque observation : <span class="math display">\[f(x
\mid \theta) = \prod_{i=1}^n f(X_i \mid \theta) = \theta^x (1 -
\theta)^{n - x}\]</span></p>
<p>Ensuite, la distribution <em>a priori</em> <span
class="math inline">\(f(\theta)\)</span> est une loi Beta avec
paramètres <span class="math inline">\(\alpha\)</span> et <span
class="math inline">\(\beta\)</span> : <span
class="math display">\[f(\theta) = \frac{\theta^{\alpha - 1} (1 -
\theta)^{\beta - 1}}{B(\alpha, \beta)}\]</span> où <span
class="math inline">\(B(\alpha, \beta)\)</span> est la fonction
Beta.</p>
<p>La probabilité marginale des données <span
class="math inline">\(f(x)\)</span> est obtenue en intégrant la
vraisemblance pondérée par la distribution <em>a priori</em> : <span
class="math display">\[f(x) = \int_0^1 f(x \mid \theta) f(\theta)
d\theta = \frac{B(\alpha + x, \beta + n - x)}{B(\alpha,
\beta)}\]</span></p>
<p>En substituant ces expressions dans le théorème de Bayes, nous
obtenons : <span class="math display">\[f(\theta \mid x) =
\frac{\theta^x (1 - \theta)^{n - x} \cdot \frac{\theta^{\alpha - 1} (1 -
\theta)^{\beta - 1}}{B(\alpha, \beta)}}{\frac{B(\alpha + x, \beta + n -
x)}{B(\alpha, \beta)}} = \frac{\theta^{\alpha + x - 1} (1 -
\theta)^{\beta + n - x - 1}}{B(\alpha + x, \beta + n - x)}\]</span></p>
<p>Cette expression montre que la distribution <em>a posteriori</em> est
bien une loi Beta avec paramètres <span class="math inline">\(\alpha +
x\)</span> et <span class="math inline">\(\beta + n - x\)</span>.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La loi Beta <em>a posteriori</em> possède plusieurs propriétés
intéressantes qui en font un outil puissant pour l’inférence bayésienne.
Nous listons et développons ces propriétés une par une.</p>
<ol>
<li><p><strong>Conjugaison</strong> : La loi Beta est conjuguée à la loi
Binomiale, ce qui signifie que si la distribution <em>a priori</em> est
Beta, alors la distribution <em>a posteriori</em> sera également Beta.
Cette propriété simplifie considérablement les calculs d’inférence
bayésienne.</p></li>
<li><p><strong>Mise à jour des paramètres</strong> : Les paramètres de
la distribution <em>a posteriori</em> sont obtenus en ajoutant le nombre
de succès observés au paramètre <span
class="math inline">\(\alpha\)</span> et le nombre d’échecs observés au
paramètre <span class="math inline">\(\beta\)</span>. Cela permet une
mise à jour simple et intuitive des croyances <em>a
priori</em>.</p></li>
<li><p><strong>Estimation de point</strong> : L’espérance de la
distribution Beta <em>a posteriori</em> fournit une estimation de point
pour le paramètre <span class="math inline">\(\theta\)</span>. Cette
estimation est donnée par : <span
class="math display">\[\mathbb{E}[\theta \mid x] = \frac{\alpha +
x}{\alpha + \beta + n}\]</span></p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La loi Beta <em>a posteriori</em> est un outil fondamental en
statistique bayésienne, permettant de mettre à jour les croyances sur un
paramètre inconnu en intégrant des observations empiriques. Sa
conjugaison avec la loi Binomiale et ses propriétés intuitives en font
un choix naturel pour l’inférence bayésienne. Les développements
mathématiques détaillés dans cet article montrent comment cette loi
émerge naturellement du théorème de Bayes et illustrent son importance
dans l’analyse des données.</p>
</body>
</html>
{% include "footer.html" %}

