{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Silhouette Score : Une Mesure de la Qualité des Groupes en Analyse de Données</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Silhouette Score : Une Mesure de la Qualité des
Groupes en Analyse de Données</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’analyse des données est un domaine où la compréhension de la
structure sous-jacente des ensembles de données est cruciale. Parmi les
nombreuses techniques disponibles, le clustering ou regroupement en
clusters est une méthode non supervisée largement utilisée pour
découvrir des structures intrinsèques dans les données. Cependant,
évaluer la qualité de ces regroupements reste un défi.</p>
<p>Le Silhouette Score est une mesure qui émerge comme une solution
élégante pour évaluer la qualité des clusters. Introduit par Peter J.
Rousseeuw en 1987, ce score permet de quantifier à quel point un objet
appartient bien à son cluster plutôt qu’à un autre. Il combine deux
concepts fondamentaux : la cohésion, qui mesure à quel point les objets
d’un même cluster sont proches les uns des autres, et la séparation, qui
mesure à quel point les clusters sont distincts.</p>
<p>Dans cet article, nous explorerons en détail le Silhouette Score, ses
définitions, ses théorèmes associés, et ses propriétés. Nous verrons
comment cette mesure peut être utilisée pour optimiser les algorithmes
de clustering et améliorer la compréhension des structures de
données.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre le Silhouette Score, commençons par définir les
concepts de base.</p>
<h2 class="unnumbered" id="distance-intra-cluster">Distance
Intra-Cluster</h2>
<p>Considérons un ensemble de données <span class="math inline">\(X =
\{x_1, x_2, \dots, x_n\}\)</span> et un partitionnement en <span
class="math inline">\(k\)</span> clusters <span class="math inline">\(C
= \{C_1, C_2, \dots, C_k\}\)</span>. La distance intra-cluster pour un
point <span class="math inline">\(x_i\)</span> dans le cluster <span
class="math inline">\(C_j\)</span> est la moyenne des distances entre
<span class="math inline">\(x_i\)</span> et tous les autres points du
même cluster.</p>
<p><span class="math display">\[a(i) = \frac{1}{|C_j| - 1} \sum_{x_j \in
C_j, x_i \neq x_j} d(x_i, x_j)\]</span></p>
<p>où <span class="math inline">\(d(x_i, x_j)\)</span> est une mesure de
distance entre les points <span class="math inline">\(x_i\)</span> et
<span class="math inline">\(x_j\)</span>.</p>
<h2 class="unnumbered" id="distance-inter-cluster">Distance
Inter-Cluster</h2>
<p>La distance inter-cluster pour un point <span
class="math inline">\(x_i\)</span> est la moyenne des distances entre
<span class="math inline">\(x_i\)</span> et tous les points d’un autre
cluster <span class="math inline">\(C_l\)</span>.</p>
<p><span class="math display">\[b(i) = \min_{l \neq j} \left(
\frac{1}{|C_l|} \sum_{x_m \in C_l} d(x_i, x_m) \right)\]</span></p>
<h2 class="unnumbered" id="silhouette-score">Silhouette Score</h2>
<p>Le Silhouette Score pour un point <span
class="math inline">\(x_i\)</span> est défini comme :</p>
<p><span class="math display">\[s(i) = \frac{b(i) - a(i)}{\max(a(i),
b(i))}\]</span></p>
<p>Ce score varie entre <span class="math inline">\(-1\)</span> et <span
class="math inline">\(1\)</span>. Un score proche de <span
class="math inline">\(1\)</span> indique que le point est bien classé,
tandis qu’un score proche de <span class="math inline">\(-1\)</span>
suggère que le point pourrait être mieux classé dans un autre
cluster.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<h2 class="unnumbered"
id="théorème-de-la-cohésion-et-de-la-séparation">Théorème de la Cohésion
et de la Séparation</h2>
<p>Un théorème fondamental lié au Silhouette Score est le suivant :</p>
<div class="theorem">
<p>Pour un partitionnement optimal, le Silhouette Score moyen sur tous
les points est maximisé.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Considérons un partitionnement <span
class="math inline">\(C\)</span> de l’ensemble de données <span
class="math inline">\(X\)</span>. Le Silhouette Score moyen est donné
par :</p>
<p><span class="math display">\[S(C) = \frac{1}{n} \sum_{i=1}^n
s(i)\]</span></p>
<p>Pour maximiser <span class="math inline">\(S(C)\)</span>, nous devons
minimiser les distances intra-cluster et maximiser les distances
inter-cluster. Cela signifie que les points d’un même cluster doivent
être aussi proches que possible, tandis que les clusters eux-mêmes
doivent être bien séparés.</p>
<p>En utilisant des techniques d’optimisation, nous pouvons trouver le
partitionnement qui maximise <span class="math inline">\(S(C)\)</span>.
Cela peut être fait par des méthodes telles que l’algorithme des
k-moyennes avec une fonction de coût basée sur le Silhouette
Score. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<h2 class="unnumbered"
id="preuve-du-théorème-de-la-cohésion-et-de-la-séparation">Preuve du
Théorème de la Cohésion et de la Séparation</h2>
<p>Pour prouver ce théorème, nous devons montrer que le Silhouette Score
moyen est maximisé lorsque les distances intra-cluster sont minimisées
et les distances inter-cluster sont maximisées.</p>
<p>Considérons deux partitionnements <span
class="math inline">\(C_1\)</span> et <span
class="math inline">\(C_2\)</span>. Si <span
class="math inline">\(S(C_1) &gt; S(C_2)\)</span>, alors <span
class="math inline">\(C_1\)</span> est préférable à <span
class="math inline">\(C_2\)</span>. Cela implique que pour tout point
<span class="math inline">\(x_i\)</span>, <span
class="math inline">\(s(i)\)</span> est plus grand dans <span
class="math inline">\(C_1\)</span> que dans <span
class="math inline">\(C_2\)</span>.</p>
<p>En minimisant les distances intra-cluster, nous réduisons <span
class="math inline">\(a(i)\)</span>, ce qui augmente <span
class="math inline">\(s(i)\)</span>. En maximisant les distances
inter-cluster, nous augmentons <span
class="math inline">\(b(i)\)</span>, ce qui augmente également <span
class="math inline">\(s(i)\)</span>. Par conséquent, le partitionnement
optimal est celui qui maximise le Silhouette Score moyen.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<h2 class="unnumbered" id="propriété-de-la-cohésion">Propriété de la
Cohésion</h2>
<div class="property">
<p>Pour un cluster donné, si tous les points sont très proches les uns
des autres, alors le Silhouette Score pour chaque point dans ce cluster
sera élevé.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Si les points d’un cluster <span
class="math inline">\(C_j\)</span> sont très proches, alors <span
class="math inline">\(a(i)\)</span> sera faible pour chaque point <span
class="math inline">\(x_i\)</span> dans <span
class="math inline">\(C_j\)</span>. Cela signifie que <span
class="math inline">\(b(i) - a(i)\)</span> sera grand, et donc <span
class="math inline">\(s(i)\)</span> sera proche de <span
class="math inline">\(1\)</span>. ◻</p>
</div>
<h2 class="unnumbered" id="propriété-de-la-séparation">Propriété de la
Séparation</h2>
<div class="property">
<p>Si les clusters sont bien séparés, alors le Silhouette Score pour
chaque point sera élevé.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Si les clusters sont bien séparés, alors <span
class="math inline">\(b(i)\)</span> sera grand pour chaque point <span
class="math inline">\(x_i\)</span>. Cela signifie que <span
class="math inline">\(b(i) - a(i)\)</span> sera grand, et donc <span
class="math inline">\(s(i)\)</span> sera proche de <span
class="math inline">\(1\)</span>. ◻</p>
</div>
<h2 class="unnumbered" id="corollaire-de-loptimalité">Corollaire de
l’Optimalité</h2>
<div class="corollary">
<p>Un partitionnement est optimal si et seulement si le Silhouette Score
moyen est maximisé.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Cela découle directement du théorème de la cohésion
et de la séparation. Si le Silhouette Score moyen est maximisé, alors
les distances intra-cluster sont minimisées et les distances
inter-cluster sont maximisées, ce qui définit un partitionnement
optimal. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le Silhouette Score est une mesure puissante pour évaluer la qualité
des regroupements en clustering. En combinant les concepts de cohésion
et de séparation, il fournit une évaluation complète de la structure des
clusters. Les théorèmes et propriétés associés montrent comment cette
mesure peut être utilisée pour optimiser les algorithmes de clustering
et améliorer la compréhension des données.</p>
<p>En utilisant le Silhouette Score, les chercheurs et les praticiens
peuvent obtenir des insights précieux sur la structure de leurs données
et améliorer la qualité de leurs analyses.</p>
</body>
</html>
{% include "footer.html" %}

