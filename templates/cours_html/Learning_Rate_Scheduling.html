{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Learning Rate Scheduling: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Learning Rate Scheduling: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’apprentissage automatique, en particulier les méthodes
d’optimisation basées sur le gradient, repose sur un paramètre crucial :
le taux d’apprentissage (learning rate). Ce paramètre détermine la
taille des pas effectués dans l’espace des paramètres lors de la
minimisation d’une fonction de coût. Un taux d’apprentissage trop élevé
peut entraîner une divergence, tandis qu’un taux trop faible peut
ralentir considérablement la convergence.</p>
<p>Le <em>Learning Rate Scheduling</em> (LRS) émerge comme une solution
sophistiquée pour adapter dynamiquement le taux d’apprentissage au cours
de l’entraînement. Cette approche est indispensable dans les cadres où
les paysages des fonctions de coût sont complexes et non convexes, comme
c’est souvent le cas dans les réseaux de neurones profonds.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre le LRS, commençons par définir les concepts
fondamentaux.</p>
<h2 id="taux-dapprentissage">Taux d’apprentissage</h2>
<p>Le taux d’apprentissage, noté <span
class="math inline">\(\eta\)</span>, est un scalaire positif qui
contrôle la mise à jour des paramètres <span
class="math inline">\(\theta\)</span> d’un modèle. Lors de
l’optimisation par descente de gradient, les paramètres sont mis à jour
selon la règle suivante :</p>
<p><span class="math display">\[\theta_{t+1} = \theta_t - \eta
\nabla_{\theta} J(\theta_t)\]</span></p>
<p>où <span class="math inline">\(J(\theta_t)\)</span> est la fonction
de coût évaluée aux paramètres <span
class="math inline">\(\theta_t\)</span> à l’itération <span
class="math inline">\(t\)</span>, et <span
class="math inline">\(\nabla_{\theta} J(\theta_t)\)</span> est le
gradient de la fonction de coût par rapport aux paramètres <span
class="math inline">\(\theta\)</span>.</p>
<h2 id="planificateur-de-taux-dapprentissage">Planificateur de taux
d’apprentissage</h2>
<p>Un planificateur de taux d’apprentissage est une fonction <span
class="math inline">\(\eta : \mathbb{N} \rightarrow
\mathbb{R}^+\)</span> qui associe à chaque itération <span
class="math inline">\(t\)</span> un taux d’apprentissage <span
class="math inline">\(\eta(t)\)</span>. Cette fonction peut dépendre de
divers facteurs, tels que le nombre d’itérations écoulées, la valeur
actuelle du gradient, ou encore des métriques de performance.</p>
<h1 id="théorèmes">Théorèmes</h1>
<h2 id="convergence-de-la-descente-de-gradient-avec-lrs">Convergence de
la descente de gradient avec LRS</h2>
<p>Un théorème fondamental en optimisation est celui de la convergence
de la descente de gradient avec un taux d’apprentissage adaptatif.
Supposons que nous avons une fonction convexe <span
class="math inline">\(J(\theta)\)</span> et que le gradient <span
class="math inline">\(\nabla_{\theta} J(\theta_t)\)</span> est borné.
Alors, sous certaines conditions sur le planificateur <span
class="math inline">\(\eta(t)\)</span>, la séquence des paramètres <span
class="math inline">\(\theta_t\)</span> converge vers un minimum
global.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(J(\theta)\)</span> une fonction
convexe et différentiable, et soit <span class="math inline">\(\eta(t) =
\frac{c}{t}\)</span> pour une constante <span class="math inline">\(c
&gt; 0\)</span>. Alors, la séquence <span
class="math inline">\(\theta_t\)</span> générée par l’algorithme de
descente de gradient avec ce planificateur converge vers un minimum
global de <span class="math inline">\(J(\theta)\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<h2 id="preuve-du-théorème-de-convergence">Preuve du théorème de
convergence</h2>
<p>Pour prouver ce théorème, nous utilisons le lemme suivant :</p>
<div class="lemma">
<p>Pour tout <span class="math inline">\(t \geq 1\)</span>, nous avons
<span class="math inline">\(\sum_{k=1}^t \frac{1}{k} \geq \ln(t) +
\gamma\)</span>, où <span class="math inline">\(\gamma\)</span> est la
constante d’Euler-Mascheroni.</p>
</div>
<p>En utilisant ce lemme, nous pouvons montrer que la somme des taux
d’apprentissage est bornée inférieurement par une fonction
logarithmique. Cela permet de garantir que les mises à jour des
paramètres sont suffisamment petites pour assurer la convergence.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriétés-des-planificateurs-de-taux-dapprentissage">Propriétés
des planificateurs de taux d’apprentissage</h2>
<p>Les planificateurs de taux d’apprentissage possèdent plusieurs
propriétés intéressantes :</p>
<ol>
<li><p><strong>Adaptabilité</strong> : Un bon planificateur doit être
capable de s’adapter aux caractéristiques du paysage de la fonction de
coût. Par exemple, il peut réduire le taux d’apprentissage lorsque le
gradient devient petit.</p></li>
<li><p><strong>Stabilité</strong> : Le planificateur doit garantir que
les mises à jour des paramètres ne deviennent pas trop grandes, ce qui
pourrait entraîner une divergence.</p></li>
<li><p><strong>Efficacité</strong> : Le planificateur doit permettre une
convergence rapide vers un minimum global ou local.</p></li>
</ol>
<h2 id="corollaires-du-théorème-de-convergence">Corollaires du théorème
de convergence</h2>
<p>Le théorème de convergence donne lieu à plusieurs corollaires
importants :</p>
<div class="corollary">
<p>Si la fonction <span class="math inline">\(J(\theta)\)</span> est
fortement convexe, alors la convergence vers le minimum global est
exponentielle.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve repose sur l’utilisation de l’inégalité de
la fonction fortement convexe et des propriétés du planificateur <span
class="math inline">\(\eta(t)\)</span>. ◻</p>
</div>
<div class="corollary">
<p>Si le gradient <span class="math inline">\(\nabla_{\theta}
J(\theta_t)\)</span> est borné, alors la séquence des paramètres <span
class="math inline">\(\theta_t\)</span> converge vers un minimum
local.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve utilise le fait que le gradient borné
garantit que les mises à jour des paramètres ne deviennent pas trop
grandes, assurant ainsi la convergence vers un minimum local. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Le Learning Rate Scheduling est une technique puissante pour
améliorer les performances des algorithmes d’optimisation basés sur le
gradient. En adaptant dynamiquement le taux d’apprentissage, nous
pouvons garantir la convergence vers des minima globaux ou locaux, tout
en évitant les problèmes de divergence et de lenteur. Les théorèmes et
propriétés présentés dans cet article fournissent une base solide pour
la compréhension et l’application de cette technique dans divers
domaines de l’apprentissage automatique.</p>
</body>
</html>
{% include "footer.html" %}

