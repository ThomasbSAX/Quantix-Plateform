{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Ajustement par covariables : Théorie et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Ajustement par covariables : Théorie et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’ajustement par covariables est une technique statistique
fondamentale dans l’analyse des données, permettant de comprendre et de
modéliser les relations entre variables tout en contrôlant l’effet de
facteurs confondants. Cette méthode émerge naturellement dans des
contextes où l’on souhaite isoler l’effet d’une variable explicative sur
une variable réponse, en tenant compte de l’influence d’autres
variables, appelées covariables.</p>
<p>L’origine historique de cette approche remonte aux travaux pionniers
en statistique et en épidémiologie, où l’on cherchait à corriger les
biais introduits par des variables non contrôlées. Aujourd’hui,
l’ajustement par covariables est indispensable dans de nombreux
domaines, tels que la médecine, les sciences sociales et l’économie, où
il permet de réaliser des analyses plus précises et robustes.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire l’ajustement par covariables, considérons une
situation où nous avons une variable réponse <span
class="math inline">\(Y\)</span>, une variable explicative principale
<span class="math inline">\(X\)</span>, et un ensemble de covariables
<span class="math inline">\(Z_1, Z_2, \dots, Z_p\)</span>. L’objectif
est de modéliser la relation entre <span
class="math inline">\(Y\)</span> et <span
class="math inline">\(X\)</span> tout en contrôlant l’effet des
covariables.</p>
<p>Nous cherchons à estimer l’effet de <span
class="math inline">\(X\)</span> sur <span
class="math inline">\(Y\)</span>, noté <span
class="math inline">\(\beta\)</span>, dans un modèle de la forme : <span
class="math display">\[Y = \beta_0 + \beta X + \gamma_1 Z_1 + \gamma_2
Z_2 + \dots + \gamma_p Z_p + \epsilon\]</span> où <span
class="math inline">\(\beta_0\)</span> est l’ordonnée à l’origine, <span
class="math inline">\(\gamma_1, \gamma_2, \dots, \gamma_p\)</span> sont
les coefficients des covariables, et <span
class="math inline">\(\epsilon\)</span> est le terme d’erreur.</p>
<p>Formellement, l’ajustement par covariables consiste à estimer <span
class="math inline">\(\beta\)</span> en utilisant une régression
multiple où les covariables sont incluses dans le modèle. Cela permet de
contrôler leur effet et d’isoler celui de <span
class="math inline">\(X\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème central dans l’ajustement par covariables est le théorème
de Gauss-Markov, qui garantit que les estimateurs des moindres carrés
sont les meilleurs estimateurs linéaires non biaisés (BLUE) sous
certaines hypothèses.</p>
<div class="theorem">
<p>Soit le modèle linéaire <span class="math inline">\(Y = X \beta +
\epsilon\)</span>, où <span class="math inline">\(X\)</span> est une
matrice de design, <span class="math inline">\(\beta\)</span> est le
vecteur des coefficients, et <span
class="math inline">\(\epsilon\)</span> est un vecteur d’erreurs avec
<span class="math inline">\(E(\epsilon) = 0\)</span> et <span
class="math inline">\(Var(\epsilon) = \sigma^2 I\)</span>. Alors,
l’estimateur des moindres carrés <span class="math inline">\(\hat{\beta}
= (X^T X)^{-1} X^T Y\)</span> est sans biais et a la plus petite
variance parmi tous les estimateurs linéaires non biaisés.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Gauss-Markov, nous devons montrer que
<span class="math inline">\(\hat{\beta}\)</span> est sans biais et qu’il
minimise la variance.</p>
<div class="proof">
<p><em>Proof.</em> 1. **Sans biais** : Montrons que <span
class="math inline">\(E(\hat{\beta}) = \beta\)</span>. <span
class="math display">\[E(\hat{\beta}) = E\left( (X^T X)^{-1} X^T Y
\right) = (X^T X)^{-1} X^T E(Y) = (X^T X)^{-1} X^T X \beta =
\beta\]</span></p>
<p>2. **Variance minimale** : Soit <span
class="math inline">\(\tilde{\beta} = A Y\)</span> un autre estimateur
linéaire non biaisé. Alors, <span class="math inline">\(E(\tilde{\beta})
= A X \beta = \beta\)</span>, ce qui implique que <span
class="math inline">\(A X = I\)</span>. La variance de <span
class="math inline">\(\tilde{\beta}\)</span> est : <span
class="math display">\[Var(\tilde{\beta}) = A Var(Y) A^T = \sigma^2 A I
A^T = \sigma^2 A A^T\]</span> Pour minimiser <span
class="math inline">\(Var(\tilde{\beta})\)</span>, nous devons choisir
<span class="math inline">\(A\)</span> tel que <span
class="math inline">\(A A^T\)</span> soit minimal. Cela conduit à <span
class="math inline">\(A = (X^T X)^{-1} X^T\)</span>, ce qui montre que
<span class="math inline">\(\hat{\beta}\)</span> a la plus petite
variance. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Plusieurs propriétés découlent du théorème de Gauss-Markov :</p>
<ol>
<li><p>**Propriété de BLUE** : Les estimateurs des moindres carrés sont
les meilleurs estimateurs linéaires non biaisés.</p></li>
<li><p>**Efficacité** : Sous les hypothèses du théorème de Gauss-Markov,
les estimateurs des moindres carrés sont également efficaces.</p></li>
<li><p>**Robustesse** : Les estimateurs des moindres carrés sont
robustes aux violations mineures des hypothèses, telles que
l’hétéroscédasticité légère.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’ajustement par covariables est une technique puissante et
essentielle en statistique, permettant de contrôler l’effet des
variables confondantes et d’isoler les relations entre variables. Le
théorème de Gauss-Markov fournit une base théorique solide pour cette
méthode, garantissant que les estimateurs obtenus sont optimaux sous
certaines conditions. Les applications de cette technique sont vastes et
variées, faisant de l’ajustement par covariables un outil indispensable
dans de nombreux domaines de recherche.</p>
</body>
</html>
{% include "footer.html" %}

