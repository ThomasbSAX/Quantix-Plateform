{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La distance de Hamming : Une mesure fondamentale en théorie des codes</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La distance de Hamming : Une mesure fondamentale en
théorie des codes</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Hamming trouve ses racines dans les travaux pionniers
de Richard W. Hamming au Bell Labs dans les années 1940 et 1950. À une
époque où les ordinateurs commençaient à émerger, la nécessité de
détecter et corriger les erreurs de transmission devenait cruciale.
Hamming, frustré par la perte de temps due aux erreurs dans ses calculs,
a développé une méthode systématique pour ajouter de la redondance aux
données afin de détecter et corriger les erreurs.</p>
<p>Cette notion révolutionnaire a jeté les bases de la théorie des codes
correcteurs d’erreurs, un domaine essentiel pour les communications
numériques, le stockage de données et la cryptographie. La distance de
Hamming est indispensable dans des applications allant des transmissions
satellitaires aux disques durs, en passant par les mémoires flash et les
réseaux de communication.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la distance de Hamming, considérons deux chaînes de
bits de même longueur. Nous cherchons une mesure qui quantifie le nombre
de positions où ces chaînes diffèrent. Cette mesure doit être
symétrique, c’est-à-dire que la distance entre deux chaînes doit être la
même quel que soit l’ordre des chaînes. De plus, elle doit satisfaire
les inégalités triangulaires.</p>
<p>Formellement, soit <span
class="math inline">\(\mathbb{F}_2^n\)</span> l’espace vectoriel de
dimension <span class="math inline">\(n\)</span> sur le corps fini <span
class="math inline">\(\mathbb{F}_2 = \{0, 1\}\)</span>. La distance de
Hamming entre deux vecteurs <span class="math inline">\(\mathbf{u} =
(u_1, u_2, \ldots, u_n)\)</span> et <span
class="math inline">\(\mathbf{v} = (v_1, v_2, \ldots, v_n)\)</span> est
définie par :</p>
<p><span class="math display">\[d_H(\mathbf{u}, \mathbf{v}) =
\sum_{i=1}^n |u_i - v_i|\]</span></p>
<p>Cette définition peut également être exprimée en termes de
cardinalité :</p>
<p><span class="math display">\[d_H(\mathbf{u}, \mathbf{v}) = |\{(i \in
\{1, 2, \ldots, n\}) : u_i \neq v_i\}|\]</span></p>
<p>En d’autres termes, la distance de Hamming compte le nombre de
positions où les bits des deux vecteurs diffèrent.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la distance de Hamming est le théorème
de codage de Hamming, qui établit une relation entre la distance
minimale d’un code et sa capacité à corriger les erreurs. Avant de
formuler ce théorème, considérons la notion de code linéaire.</p>
<p>Un code <span class="math inline">\(C\)</span> est un sous-espace
vectoriel de <span class="math inline">\(\mathbb{F}_2^n\)</span>. La
distance minimale d’un code <span class="math inline">\(C\)</span> est
définie par :</p>
<p><span class="math display">\[d_{\text{min}}(C) = \min \{
d_H(\mathbf{u}, \mathbf{v}) : \mathbf{u}, \mathbf{v} \in C, \mathbf{u}
\neq \mathbf{v} \}\]</span></p>
<p>Le théorème de codage de Hamming stipule que :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(C\)</span> un code linéaire de
longueur <span class="math inline">\(n\)</span> et de dimension <span
class="math inline">\(k\)</span>. Alors, le nombre maximal d’erreurs que
<span class="math inline">\(C\)</span> peut corriger est donné par :</p>
<p><span class="math display">\[t = \left\lfloor \frac{d_{\text{min}}(C)
- 1}{2} \right\rfloor\]</span></p>
</div>
<p>Pour démontrer ce théorème, nous utilisons le principe des boules de
Hamming. Soit <span class="math inline">\(B(\mathbf{u}, t)\)</span> la
boule de rayon <span class="math inline">\(t\)</span> centrée en <span
class="math inline">\(\mathbf{u}\)</span>, définie par :</p>
<p><span class="math display">\[B(\mathbf{u}, t) = \{ \mathbf{v} \in
\mathbb{F}_2^n : d_H(\mathbf{u}, \mathbf{v}) \leq t \}\]</span></p>
<p>La taille de cette boule est donnée par :</p>
<p><span class="math display">\[|B(\mathbf{u}, t)| = \sum_{i=0}^t
\binom{n}{i}\]</span></p>
<p>Pour que le code <span class="math inline">\(C\)</span> puisse
corriger <span class="math inline">\(t\)</span> erreurs, les boules de
Hamming de rayon <span class="math inline">\(t\)</span> autour des
codewords doivent être disjointes. Par conséquent, nous avons :</p>
<p><span class="math display">\[|C| \cdot |B(\mathbf{u}, t)| \leq
2^n\]</span></p>
<p>En utilisant la borne de Hamming, nous obtenons :</p>
<p><span class="math display">\[|C| \leq \frac{2^n}{\sum_{i=0}^t
\binom{n}{i}}\]</span></p>
<p>Cette borne est atteinte lorsque <span
class="math inline">\(d_{\text{min}}(C) = 2t + 1\)</span>.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de codage de Hamming, nous devons montrer
que si <span class="math inline">\(d_{\text{min}}(C) = 2t + 1\)</span>,
alors <span class="math inline">\(C\)</span> peut corriger <span
class="math inline">\(t\)</span> erreurs. Supposons que deux codewords
<span class="math inline">\(\mathbf{u}, \mathbf{v} \in C\)</span> soient
tels que <span class="math inline">\(d_H(\mathbf{u}, \mathbf{v}) = 2t +
1\)</span>. Si une erreur de poids <span
class="math inline">\(t\)</span> ou moins est introduite dans <span
class="math inline">\(\mathbf{u}\)</span>, le mot reçu sera à une
distance de Hamming au plus <span class="math inline">\(t\)</span> de
<span class="math inline">\(\mathbf{u}\)</span>. En revanche, ce mot
reçu sera à une distance de Hamming au moins <span
class="math inline">\(2t + 1 - t = t + 1\)</span> de <span
class="math inline">\(\mathbf{v}\)</span>. Par conséquent, le décodeur
peut corriger l’erreur en choisissant le codeword le plus proche.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
distance de Hamming :</p>
<ol>
<li><p>La distance de Hamming est une métrique sur <span
class="math inline">\(\mathbb{F}_2^n\)</span>. Cela signifie qu’elle
satisfait les propriétés suivantes : <span
class="math display">\[d_H(\mathbf{u}, \mathbf{v}) \geq 0, \quad
d_H(\mathbf{u}, \mathbf{v}) = 0 \iff \mathbf{u} = \mathbf{v}, \quad
d_H(\mathbf{u}, \mathbf{v}) = d_H(\mathbf{v}, \mathbf{u}), \quad
d_H(\mathbf{u}, \mathbf{w}) \leq d_H(\mathbf{u}, \mathbf{v}) +
d_H(\mathbf{v}, \mathbf{w})\]</span></p></li>
<li><p>Pour tout <span class="math inline">\(\mathbf{u} \in
\mathbb{F}_2^n\)</span>, nous avons : <span
class="math display">\[d_H(\mathbf{u}, \mathbf{0}) =
w_H(\mathbf{u})\]</span> où <span
class="math inline">\(w_H(\mathbf{u})\)</span> est le poids de Hamming
de <span class="math inline">\(\mathbf{u}\)</span>, c’est-à-dire le
nombre de bits non nuls dans <span
class="math inline">\(\mathbf{u}\)</span>.</p></li>
<li><p>La distance de Hamming est invariante par translation. Cela
signifie que pour tout <span class="math inline">\(\mathbf{a} \in
\mathbb{F}_2^n\)</span>, nous avons : <span
class="math display">\[d_H(\mathbf{u} + \mathbf{a}, \mathbf{v} +
\mathbf{a}) = d_H(\mathbf{u}, \mathbf{v})\]</span></p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La distance de Hamming est un concept fondamental en théorie des
codes correcteurs d’erreurs. Elle joue un rôle crucial dans la
conception de codes capables de détecter et corriger les erreurs de
transmission. Les propriétés et théorèmes associés à la distance de
Hamming fournissent des outils puissants pour analyser et optimiser les
performances des codes. En comprenant profondément cette notion, nous
pouvons apprécier l’ingéniosité des solutions développées pour garantir
la fiabilité des communications numériques.</p>
</body>
</html>
{% include "footer.html" %}

