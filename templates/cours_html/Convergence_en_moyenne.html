{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Convergence en moyenne</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Convergence en moyenne</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La notion de convergence en moyenne émerge naturellement dans le
cadre des espaces fonctionnels, où l’on cherche à généraliser les
concepts de convergence classiques (comme la convergence ponctuelle ou
uniforme) à des contextes plus larges. Historiquement, cette notion a
été introduite pour étudier le comportement asymptotique des suites de
fonctions dans des espaces de Lebesgue, notamment <span
class="math inline">\(L^p\)</span>, où les outils traditionnels de
l’analyse ne suffisent plus.</p>
<p>La convergence en moyenne est indispensable dans de nombreuses
applications, notamment en théorie des probabilités, en analyse
numérique et en traitement du signal. Elle permet de formaliser
rigoureusement des concepts tels que la stabilité numérique,
l’approximation de fonctions et la convergence de processus
stochastiques.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la notion de convergence en moyenne, commençons par
considérer une suite de fonctions <span class="math inline">\((f_n)_{n
\in \mathbb{N}}\)</span> définies sur un ensemble mesurable <span
class="math inline">\(\Omega\)</span> et à valeurs dans <span
class="math inline">\(\mathbb{R}\)</span> ou <span
class="math inline">\(\mathbb{C}\)</span>. Nous cherchons à comprendre
comment cette suite peut converger vers une fonction <span
class="math inline">\(f\)</span> dans un sens qui généralise la
convergence ponctuelle.</p>
<p>Intuitivement, on souhaite que l’écart entre <span
class="math inline">\(f_n\)</span> et <span
class="math inline">\(f\)</span> soit "petit" en moyenne, c’est-à-dire
que l’intégrale de cet écart soit petite. Cela nous amène à la
définition formelle suivante :</p>
<div class="definition">
<p>Soit <span class="math inline">\((\Omega, \mathcal{A}, \mu)\)</span>
un espace mesuré et <span class="math inline">\((f_n)_{n \in
\mathbb{N}}\)</span> une suite de fonctions intégrables sur <span
class="math inline">\(\Omega\)</span>. On dit que la suite <span
class="math inline">\((f_n)\)</span> converge en moyenne vers une
fonction <span class="math inline">\(f\)</span> si : <span
class="math display">\[\lim_{n \to \infty} \int_{\Omega} |f_n(x) - f(x)|
\, d\mu(x) = 0.\]</span> En notation quantifiée, cela s’écrit : <span
class="math display">\[\forall \epsilon &gt; 0, \exists N \in
\mathbb{N}, \forall n \geq N, \int_{\Omega} |f_n(x) - f(x)| \, d\mu(x)
&lt; \epsilon.\]</span></p>
</div>
<p>Une autre manière de formuler cette définition est d’utiliser la
norme <span class="math inline">\(L^1\)</span> sur l’espace des
fonctions intégrables. La convergence en moyenne est alors équivalente à
la convergence de la suite <span class="math inline">\((f_n)\)</span>
vers <span class="math inline">\(f\)</span> pour la norme <span
class="math inline">\(L^1\)</span>. Formellement : <span
class="math display">\[\lim_{n \to \infty} \|f_n - f\|_{L^1} =
0,\]</span> où <span class="math inline">\(\|f\|_{L^1} = \int_{\Omega}
|f(x)| \, d\mu(x)\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux concernant la convergence en moyenne
est le théorème de convergence dominée de Lebesgue, qui fournit des
conditions suffisantes pour que la convergence ponctuelle implique la
convergence en moyenne.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((\Omega, \mathcal{A}, \mu)\)</span>
un espace mesuré et <span class="math inline">\((f_n)_{n \in
\mathbb{N}}\)</span> une suite de fonctions intégrables sur <span
class="math inline">\(\Omega\)</span>. Supposons que :</p>
<ul>
<li><p>La suite <span class="math inline">\((f_n)\)</span> converge
ponctuellement vers une fonction <span class="math inline">\(f\)</span>
sur <span class="math inline">\(\Omega\)</span>.</p></li>
<li><p>Il existe une fonction <span class="math inline">\(g \in
L^1(\Omega)\)</span> telle que <span class="math inline">\(|f_n(x)| \leq
g(x)\)</span> pour tout <span class="math inline">\(n \in
\mathbb{N}\)</span> et presque tout <span class="math inline">\(x \in
\Omega\)</span>.</p></li>
</ul>
<p>Alors, la suite <span class="math inline">\((f_n)\)</span> converge
vers <span class="math inline">\(f\)</span> en moyenne, c’est-à-dire :
<span class="math display">\[\lim_{n \to \infty} \int_{\Omega} |f_n(x) -
f(x)| \, d\mu(x) = 0.\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de convergence dominée de Lebesgue, nous
allons procéder en plusieurs étapes. Tout d’abord, nous utilisons le
fait que la suite <span class="math inline">\((f_n)\)</span> converge
ponctuellement vers <span class="math inline">\(f\)</span> et que <span
class="math inline">\(|f_n(x)| \leq g(x)\)</span> pour tout <span
class="math inline">\(n \in \mathbb{N}\)</span> et presque tout <span
class="math inline">\(x \in \Omega\)</span>.</p>
<p>Ensuite, nous appliquons le théorème de convergence monótonée pour
les suites positives. Considérons la suite <span
class="math inline">\((h_n)\)</span> définie par <span
class="math inline">\(h_n(x) = |f_n(x) - f(x)|\)</span>. Nous avons :
<span class="math display">\[\lim_{n \to \infty} h_n(x) = 0 \quad
\text{p.p.}\]</span> et <span class="math display">\[|h_n(x)| \leq 2g(x)
\quad \text{p.p.}\]</span> Puisque <span class="math inline">\(2g \in
L^1(\Omega)\)</span>, nous pouvons appliquer le théorème de convergence
dominée pour obtenir : <span class="math display">\[\lim_{n \to \infty}
\int_{\Omega} h_n(x) \, d\mu(x) = 0.\]</span> Cela conclut la preuve du
théorème.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
convergence en moyenne :</p>
<ol>
<li><p>La convergence en moyenne implique la convergence en mesure. Plus
précisément, si une suite <span class="math inline">\((f_n)\)</span>
converge vers <span class="math inline">\(f\)</span> en moyenne, alors
pour tout <span class="math inline">\(\epsilon &gt; 0\)</span>, nous
avons : <span class="math display">\[\lim_{n \to \infty} \mu(\{x \in
\Omega : |f_n(x) - f(x)| \geq \epsilon\}) = 0.\]</span></p></li>
<li><p>La convergence en moyenne est préservée par les opérations
linéaires. Si <span class="math inline">\((f_n)\)</span> converge vers
<span class="math inline">\(f\)</span> en moyenne et <span
class="math inline">\((g_n)\)</span> converge vers <span
class="math inline">\(g\)</span> en moyenne, alors les suites <span
class="math inline">\((\alpha f_n + \beta g_n)\)</span> convergent vers
<span class="math inline">\(\alpha f + \beta g\)</span> en moyenne pour
tout <span class="math inline">\(\alpha, \beta \in
\mathbb{R}\)</span>.</p></li>
<li><p>La convergence en moyenne implique la convergence ponctuelle
presque partout. Cependant, la réciproque n’est pas vraie en général. Le
théorème de convergence dominée de Lebesgue fournit une condition
suffisante pour que la convergence ponctuelle implique la convergence en
moyenne.</p></li>
</ol>
<p>Pour prouver la propriété (i), nous utilisons l’inégalité de Markov.
Pour tout <span class="math inline">\(\epsilon &gt; 0\)</span>, nous
avons : <span class="math display">\[\mu(\{x \in \Omega : |f_n(x) -
f(x)| \geq \epsilon\}) \leq \frac{1}{\epsilon} \int_{\Omega} |f_n(x) -
f(x)| \, d\mu(x).\]</span> En prenant la limite lorsque <span
class="math inline">\(n \to \infty\)</span> et en utilisant la
convergence en moyenne, nous obtenons le résultat souhaité.</p>
<p>Pour prouver la propriété (ii), nous utilisons les inégalités
triangulaires pour les intégrales. Nous avons : <span
class="math display">\[\int_{\Omega} |\alpha f_n(x) + \beta g_n(x) -
(\alpha f(x) + \beta g(x))| \, d\mu(x) \leq |\alpha| \int_{\Omega}
|f_n(x) - f(x)| \, d\mu(x) + |\beta| \int_{\Omega} |g_n(x) - g(x)| \,
d\mu(x).\]</span> En prenant la limite lorsque <span
class="math inline">\(n \to \infty\)</span> et en utilisant les
hypothèses de convergence, nous obtenons le résultat souhaité.</p>
<p>Enfin, pour la propriété (iii), nous renvoyons à la preuve du
théorème de convergence dominée de Lebesgue, qui montre que la
convergence ponctuelle sous une hypothèse de domination implique la
convergence en moyenne.</p>
</body>
</html>
{% include "footer.html" %}

