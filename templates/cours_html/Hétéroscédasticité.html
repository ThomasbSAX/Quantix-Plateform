{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’hétéroscédasticité : Une analyse mathématique et statistique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’hétéroscédasticité : Une analyse mathématique et
statistique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’hétéroscédasticité est un concept fondamental en statistique,
particulièrement dans le cadre des modèles de régression. Ce terme,
dérivé du grec "heteros" (différent) et "skedasis" (dispersion), décrit
une situation où la variance des erreurs n’est pas constante à travers
les observations. Cette non-constance de la variance peut avoir des
implications profondes sur l’efficacité et la validité des estimations
statistiques.</p>
<p>L’hétéroscédasticité émerge naturellement dans de nombreux contextes
empiriques. Par exemple, en économie, les données financières peuvent
présenter une variance croissante avec le temps, reflétant des périodes
de plus grande volatilité. En biologie, les mesures expérimentales
peuvent avoir des variances différentes selon les conditions
environnementales. Comprendre et modéliser l’hétéroscédasticité est donc
indispensable pour éviter des biais dans les analyses et pour améliorer
la précision des prédictions.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre l’hétéroscédasticité, commençons par considérer un
modèle de régression linéaire simple : <span class="math display">\[y_i
= \beta_0 + \beta_1 x_i + \epsilon_i\]</span> où <span
class="math inline">\(y_i\)</span> est la variable dépendante, <span
class="math inline">\(x_i\)</span> est la variable indépendante, <span
class="math inline">\(\beta_0\)</span> et <span
class="math inline">\(\beta_1\)</span> sont les coefficients de
régression, et <span class="math inline">\(\epsilon_i\)</span> est le
terme d’erreur.</p>
<p>Nous cherchons à modéliser la variance des termes d’erreur <span
class="math inline">\(\epsilon_i\)</span>. Dans le cas de
l’homoscédasticité, on suppose que : <span
class="math display">\[\text{Var}(\epsilon_i) = \sigma^2\]</span> pour
tout <span class="math inline">\(i\)</span>, où <span
class="math inline">\(\sigma^2\)</span> est une constante.</p>
<p>En revanche, dans le cas de l’hétéroscédasticité, la variance des
termes d’erreur n’est pas constante. Formellement, nous définissons
l’hétéroscédasticité comme suit :</p>
<div class="definition">
<p>Un modèle de régression présente une hétéroscédasticité si la
variance des termes d’erreur <span
class="math inline">\(\epsilon_i\)</span> dépend de certaines variables
explicatives. Mathématiquement, cela s’exprime par : <span
class="math display">\[\text{Var}(\epsilon_i | x_i) =
\sigma_i^2\]</span> où <span class="math inline">\(\sigma_i^2\)</span>
peut varier en fonction de <span class="math inline">\(x_i\)</span>.</p>
</div>
<p>Une autre formulation possible est : <span
class="math display">\[\text{Var}(\epsilon_i) = \sigma^2(x_i)\]</span>
où <span class="math inline">\(\sigma^2(\cdot)\)</span> est une fonction
déterministe de <span class="math inline">\(x_i\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental en statistique concerne les conséquences de
l’hétéroscédasticité sur les estimations des moindres carrés ordinaires
(MCO). Considérons le modèle de régression linéaire général : <span
class="math display">\[y = X \beta + \epsilon\]</span> où <span
class="math inline">\(y\)</span> est un vecteur <span
class="math inline">\(n \times 1\)</span>, <span
class="math inline">\(X\)</span> est une matrice <span
class="math inline">\(n \times k\)</span>, <span
class="math inline">\(\beta\)</span> est un vecteur <span
class="math inline">\(k \times 1\)</span>, et <span
class="math inline">\(\epsilon\)</span> est un vecteur <span
class="math inline">\(n \times 1\)</span> de termes d’erreur.</p>
<div class="theorem">
<p>Si le modèle présente une hétéroscédasticité, l’estimateur des
moindres carrés ordinaires <span class="math inline">\(\hat{\beta} =
(X^T X)^{-1} X^T y\)</span> reste non biaisé, mais il n’est plus
efficace. En particulier, la matrice de variance-covariance de <span
class="math inline">\(\hat{\beta}\)</span> est donnée par : <span
class="math display">\[\text{Var}(\hat{\beta}) = (X^T X)^{-1} X^T \Omega
X (X^T X)^{-1}\]</span> où <span class="math inline">\(\Omega\)</span>
est une matrice diagonale contenant les variances des termes
d’erreur.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, commençons par rappeler que l’estimateur
des MCO est non biaisé : <span
class="math display">\[\mathbb{E}[\hat{\beta}] = \beta\]</span></p>
<p>Ensuite, la variance de <span
class="math inline">\(\hat{\beta}\)</span> est donnée par : <span
class="math display">\[\text{Var}(\hat{\beta}) = (X^T X)^{-1} X^T
\text{Var}(y) X (X^T X)^{-1}\]</span></p>
<p>Sous l’hypothèse d’hétéroscédasticité, <span
class="math inline">\(\text{Var}(y) = X \text{Var}(\beta) X^T +
\Omega\)</span>, où <span class="math inline">\(\Omega\)</span> est la
matrice des variances des termes d’erreur. En supposant que <span
class="math inline">\(\text{Var}(\beta) = 0\)</span>, nous obtenons :
<span class="math display">\[\text{Var}(y) = \Omega\]</span></p>
<p>Ainsi, la matrice de variance-covariance de <span
class="math inline">\(\hat{\beta}\)</span> devient : <span
class="math display">\[\text{Var}(\hat{\beta}) = (X^T X)^{-1} X^T \Omega
X (X^T X)^{-1}\]</span></p>
<p>Cette expression montre que la variance des estimations est
influencée par l’hétéroscédasticité, ce qui peut rendre les tests
statistiques moins puissants.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Plusieurs propriétés et corollaires découlent de l’hétéroscédasticité
:</p>
<ol>
<li><p>Les intervalles de confiance et les tests d’hypothèse basés sur
les MCO peuvent être incorrects en présence d’hétéroscédasticité. Pour
corriger cela, on peut utiliser des méthodes robustes comme les moindres
carrés généralisés (GLS) ou les moindres carrés pondérés.</p></li>
<li><p>L’hétéroscédasticité peut être détectée à l’aide de tests
statistiques tels que le test de Breusch-Pagan ou le test de White. Ces
tests vérifient si la variance des termes d’erreur est
constante.</p></li>
<li><p>En présence d’hétéroscédasticité, les résidus du modèle de
régression peuvent présenter des motifs spécifiques. Par exemple, un
graphique des résidus en fonction des variables explicatives peut
révéler une tendance non linéaire.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’hétéroscédasticité est un phénomène complexe qui nécessite une
attention particulière dans l’analyse statistique. Comprendre ses
implications et savoir la détecter est essentiel pour garantir la
validité des modèles de régression. Les méthodes de correction, telles
que les moindres carrés pondérés, offrent des solutions efficaces pour
atténuer les effets de l’hétéroscédasticité et améliorer la précision
des estimations.</p>
</body>
</html>
{% include "footer.html" %}

