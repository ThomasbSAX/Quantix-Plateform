{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variational Autoencoders: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variational Autoencoders: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>The field of machine learning has witnessed a surge in the
development of generative models, which aim to learn the underlying
distribution of data. Among these models, Variational Autoencoders
(VAEs) have emerged as a powerful tool for unsupervised learning and
data generation. Originating from the fusion of variational inference
and autoencoder architectures, VAEs provide a probabilistic framework
for learning latent representations of data. This approach is
indispensable in scenarios where the underlying data distribution is
complex and high-dimensional, such as in image generation, anomaly
detection, and collaborative filtering.</p>
<p>The motivation behind VAEs stems from the need to address the
limitations of traditional autoencoders. While autoencoders excel at
encoding and decoding data, they lack the ability to generate new
samples that resemble the training data. VAEs overcome this limitation
by introducing a probabilistic latent space, enabling the generation of
novel data points that adhere to the learned distribution.</p>
<h1 id="definitions">Definitions</h1>
<p>To understand VAEs, we first need to grasp the concept of variational
inference. Variational inference is a method used to approximate complex
probability distributions by optimizing a simpler, tractable
distribution. In the context of VAEs, we aim to approximate the
posterior distribution <span class="math inline">\(p(z|x)\)</span>,
where <span class="math inline">\(x\)</span> is the input data and <span
class="math inline">\(z\)</span> is the latent variable.</p>
<p>Consider a dataset <span
class="math inline">\(\{x_i\}_{i=1}^N\)</span> drawn from an unknown
distribution <span class="math inline">\(p(x)\)</span>. We seek to learn
a latent representation <span class="math inline">\(z\)</span> such that
the marginal distribution <span class="math inline">\(p(x) = \int p(x|z)
p(z) dz\)</span> can be approximated. The variational approach involves
defining a family of distributions <span
class="math inline">\(q_\phi(z|x)\)</span>, parameterized by <span
class="math inline">\(\phi\)</span>, and optimizing the parameters to
minimize the difference between <span
class="math inline">\(q_\phi(z|x)\)</span> and the true posterior <span
class="math inline">\(p(z|x)\)</span>.</p>
<p>Formally, the variational distribution is defined as: <span
class="math display">\[q_\phi(z|x) = \mathcal{N}(z; \mu_\phi(x),
\text{diag}(\sigma^2_\phi(x)))\]</span> where <span
class="math inline">\(\mu_\phi(x)\)</span> and <span
class="math inline">\(\sigma^2_\phi(x)\)</span> are the mean and
variance of the Gaussian distribution, parameterized by <span
class="math inline">\(\phi\)</span>.</p>
<p>The VAE framework introduces an encoder-decoder architecture. The
encoder maps the input data <span class="math inline">\(x\)</span> to a
latent space, while the decoder reconstructs the input from the latent
representation. The encoder and decoder are parameterized by neural
networks, with the encoder outputting the parameters of the variational
distribution <span class="math inline">\(q_\phi(z|x)\)</span>.</p>
<h1 id="the-vae-framework">The VAE Framework</h1>
<p>The VAE framework consists of two main components: the encoder and
the decoder. The encoder is responsible for mapping the input data <span
class="math inline">\(x\)</span> to a latent space, while the decoder
reconstructs the input from the latent representation.</p>
<p>The encoder is parameterized by a neural network <span
class="math inline">\(q_\phi(z|x)\)</span>, which outputs the parameters
of the variational distribution. The decoder is parameterized by another
neural network <span class="math inline">\(p_\theta(x|z)\)</span>, which
generates the reconstructed data from the latent representation.</p>
<p>The VAE framework is trained by optimizing the evidence lower bound
(ELBO), which is a lower bound on the log-likelihood of the data. The
ELBO is defined as: <span class="math display">\[\mathcal{L}(\theta,
\phi; x) = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] -
D_{KL}(q_\phi(z|x) \| p(z))\]</span> where <span
class="math inline">\(D_{KL}\)</span> is the Kullback-Leibler
divergence, measuring the difference between the variational
distribution and a prior distribution <span
class="math inline">\(p(z)\)</span>.</p>
<h1 id="theorems">Theorems</h1>
<p>One of the key theorems in the VAE framework is the evidence lower
bound (ELBO) theorem, which provides a lower bound on the log-likelihood
of the data. The ELBO theorem states that for any variational
distribution <span class="math inline">\(q_\phi(z|x)\)</span>, the
following inequality holds: <span class="math display">\[\log p(x) \geq
\mathcal{L}(\theta, \phi; x)\]</span> where <span
class="math inline">\(\mathcal{L}(\theta, \phi; x)\)</span> is the ELBO
defined as: <span class="math display">\[\mathcal{L}(\theta, \phi; x) =
\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) \|
p(z))\]</span></p>
<p>The ELBO theorem is crucial for the training of VAEs, as it provides
a tractable objective function to optimize. By maximizing the ELBO, we
can indirectly maximize the log-likelihood of the data, leading to
better generative models.</p>
<h1 id="proofs">Proofs</h1>
<p>To prove the ELBO theorem, we start by expressing the log-likelihood
of the data as: <span class="math display">\[\log p(x) = \log \int
p_\theta(x|z) p(z) dz\]</span></p>
<p>Using the variational distribution <span
class="math inline">\(q_\phi(z|x)\)</span>, we can rewrite the
log-likelihood as: <span class="math display">\[\log p(x) = \log \int
q_\phi(z|x) \frac{p_\theta(x|z) p(z)}{q_\phi(z|x)} dz\]</span></p>
<p>By the properties of logarithms and expectations, we have: <span
class="math display">\[\log p(x) = \log \mathbb{E}_{q_\phi(z|x)} \left[
\frac{p_\theta(x|z) p(z)}{q_\phi(z|x)} \right]\]</span></p>
<p>Applying Jensenâ€™s inequality, we obtain: <span
class="math display">\[\log p(x) \geq \mathbb{E}_{q_\phi(z|x)} \left[
\log \frac{p_\theta(x|z) p(z)}{q_\phi(z|x)} \right]\]</span></p>
<p>Simplifying the right-hand side, we get: <span
class="math display">\[\log p(x) \geq \mathbb{E}_{q_\phi(z|x)}[\log
p_\theta(x|z)] - D_{KL}(q_\phi(z|x) \| p(z))\]</span></p>
<p>This completes the proof of the ELBO theorem.</p>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>The VAE framework has several important properties and corollaries
that enhance its utility in generative modeling.</p>
<p>(i) **Latent Space Continuity**: The latent space learned by VAEs is
continuous, allowing for smooth interpolation between data points. This
property is crucial for generating novel samples that adhere to the
learned distribution.</p>
<p>(ii) **Probabilistic Interpretation**: The VAE framework provides a
probabilistic interpretation of the latent space, enabling the
generation of samples from the learned distribution. This is in contrast
to traditional autoencoders, which lack a probabilistic framework.</p>
<p>(iii) **Regularization**: The Kullback-Leibler divergence term in the
ELBO acts as a regularizer, preventing the variational distribution from
deviating too far from the prior distribution. This ensures that the
latent space remains well-structured and interpretable.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Variational Autoencoders represent a significant advancement in the
field of generative modeling. By combining variational inference with
autoencoder architectures, VAEs provide a powerful framework for
learning latent representations of data. The ELBO theorem serves as the
foundation for training VAEs, enabling the generation of novel samples
that adhere to the learned distribution. The properties and corollaries
of VAEs further enhance their utility in various applications, making
them an indispensable tool for unsupervised learning and data
generation.</p>
</body>
</html>
{% include "footer.html" %}

