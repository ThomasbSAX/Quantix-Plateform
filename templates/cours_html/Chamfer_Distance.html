{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Chamfer Distance: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Chamfer Distance: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>The concept of Chamfer Distance emerges from the need for efficient
and robust shape matching in computer vision and pattern recognition.
Historically, it has been indispensable in various applications such as
object recognition, medical imaging, and robotics. The Chamfer Distance
is a measure of similarity between two shapes, often used to match a
template image against an input image. Its origin can be traced back to
the early days of digital image processing, where the need for fast and
accurate shape matching became paramount.</p>
<p>The Chamfer Distance is particularly useful because it can handle
partial occlusions and noise, making it a robust tool for real-world
applications. It is computed by transforming the input image into a
distance transform, which represents the distance of each pixel to the
nearest object boundary. This transformation allows for efficient
matching and alignment of shapes.</p>
<h1 id="definitions">Definitions</h1>
<p>To understand the Chamfer Distance, let’s first consider what we aim
to achieve. We want a measure that quantifies how similar two shapes
are, even if they are partially occluded or noisy. The Chamfer Distance
achieves this by comparing the edges of two shapes and summing the
distances between corresponding points.</p>
<p>Formally, let <span class="math inline">\(I\)</span> be a binary
image representing the template shape, and <span
class="math inline">\(J\)</span> be a binary image representing the
input shape. The Chamfer Distance between <span
class="math inline">\(I\)</span> and <span
class="math inline">\(J\)</span> is defined as:</p>
<p><span class="math display">\[D(I, J) = \frac{1}{N} \sum_{i \in I}
d(i, J)\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the number of pixels
in <span class="math inline">\(I\)</span>, and <span
class="math inline">\(d(i, J)\)</span> is the distance from pixel <span
class="math inline">\(i\)</span> in <span
class="math inline">\(I\)</span> to the nearest pixel in <span
class="math inline">\(J\)</span>.</p>
<p>Alternatively, we can express this using quantifiers:</p>
<p><span class="math display">\[D(I, J) = \frac{1}{N} \sum_{i \in I}
\min_{j \in J} \| i - j \|\]</span></p>
<p>Here, <span class="math inline">\(\| i - j \|\)</span> represents the
Euclidean distance between pixels <span class="math inline">\(i\)</span>
and <span class="math inline">\(j\)</span>.</p>
<h1 id="theorems">Theorems</h1>
<p>One of the key theorems related to Chamfer Distance is the
following:</p>
<p><strong>Theorem (Chamfer Distance Properties)</strong>: The Chamfer
Distance satisfies the following properties:</p>
<ol>
<li><p>(Non-negativity) <span class="math inline">\(D(I, J) \geq
0\)</span></p></li>
<li><p>(Symmetry) <span class="math inline">\(D(I, J) = D(J,
I)\)</span></p></li>
<li><p>(Triangle Inequality) <span class="math inline">\(D(I, K) \leq
D(I, J) + D(J, K)\)</span></p></li>
</ol>
<p>Let’s prove these properties one by one.</p>
<h2 id="proof-of-non-negativity">Proof of Non-negativity</h2>
<p>The non-negativity of the Chamfer Distance follows directly from the
definition. Since distances are always non-negative, the sum of
non-negative values is also non-negative:</p>
<p><span class="math display">\[D(I, J) = \frac{1}{N} \sum_{i \in I}
d(i, J) \geq 0\]</span></p>
<h2 id="proof-of-symmetry">Proof of Symmetry</h2>
<p>The symmetry property can be shown by swapping the roles of <span
class="math inline">\(I\)</span> and <span
class="math inline">\(J\)</span>:</p>
<p><span class="math display">\[D(I, J) = \frac{1}{N} \sum_{i \in I}
d(i, J) = \frac{1}{N} \sum_{j \in J} d(j, I) = D(J, I)\]</span></p>
<p>Here, we used the fact that the number of pixels <span
class="math inline">\(N\)</span> is the same for both images.</p>
<h2 id="proof-of-triangle-inequality">Proof of Triangle Inequality</h2>
<p>The triangle inequality can be proven using the properties of
distances:</p>
<p><span class="math display">\[D(I, K) = \frac{1}{N} \sum_{i \in I}
d(i, K) \leq \frac{1}{N} \sum_{i \in I} (d(i, J) + d(j, K)) = D(I, J) +
D(J, K)\]</span></p>
<p>This follows from the triangle inequality for distances.</p>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>The Chamfer Distance has several important properties and corollaries
that make it a powerful tool for shape matching.</p>
<ol>
<li><p>(Translation Invariance) The Chamfer Distance is invariant to
translations of the input image. This means that shifting the input
image does not affect the distance measure.</p></li>
<li><p>(Rotation Invariance) The Chamfer Distance can be made invariant
to rotations by applying a rotation to the input image and computing the
distance for multiple angles.</p></li>
<li><p>(Scale Invariance) The Chamfer Distance can be made invariant to
scaling by resizing the input image and computing the distance for
multiple scales.</p></li>
</ol>
<p>Let’s discuss each of these properties in more detail.</p>
<h2 id="translation-invariance">Translation Invariance</h2>
<p>The translation invariance of the Chamfer Distance follows from the
fact that the distance transform is computed relative to the nearest
object boundary. Shifting the input image does not change the relative
positions of the boundaries, and thus the distance measure remains
unchanged.</p>
<h2 id="rotation-invariance">Rotation Invariance</h2>
<p>To achieve rotation invariance, we can compute the Chamfer Distance
for multiple rotations of the input image and take the minimum distance.
This ensures that the distance measure is not affected by the
orientation of the input image.</p>
<h2 id="scale-invariance">Scale Invariance</h2>
<p>Similarly, to achieve scale invariance, we can compute the Chamfer
Distance for multiple scales of the input image and take the minimum
distance. This ensures that the distance measure is not affected by the
size of the input image.</p>
<h1 id="conclusion">Conclusion</h1>
<p>The Chamfer Distance is a powerful and versatile tool for shape
matching in computer vision and pattern recognition. Its ability to
handle partial occlusions and noise makes it indispensable for
real-world applications. By understanding its definitions, theorems, and
properties, we can effectively utilize the Chamfer Distance to solve
complex shape matching problems.</p>
</body>
</html>
{% include "footer.html" %}

