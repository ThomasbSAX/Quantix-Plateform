{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Variance Robuste aux Outliers : Une Exploration Mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Variance Robuste aux Outliers : Une Exploration
Mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La variance est une mesure fondamentale en statistique, quantifiant
la dispersion des données autour de leur moyenne. Cependant, cette
mesure est extrêmement sensible aux <em>outliers</em>, c’est-à-dire des
valeurs aberrantes qui peuvent fausser la perception de la dispersion
globale. Dans ce contexte, l’idée d’une variance <em>robuste aux
outliers</em> émerge comme une nécessité pour les applications où la
présence de telles valeurs est inévitable, que ce soit en économie, en
ingénierie, ou dans les sciences sociales.</p>
<p>L’origine de cette notion remonte aux travaux pionniers de Tukey et
Huber sur la statistique robuste. Ces chercheurs ont cherché à
développer des méthodes moins sensibles aux perturbations extrêmes, tout
en conservant les propriétés essentielles de la variance classique. La
robustesse aux outliers est devenue un enjeu majeur avec l’avènement des
grands jeux de données, où les anomalies sont fréquentes et peuvent
avoir un impact significatif sur les analyses.</p>
<p>Dans cet article, nous explorerons les définitions formelles de la
variance robuste, les théorèmes clés qui en découlent, et leurs preuves
détaillées. Nous verrons comment ces concepts permettent de mieux
comprendre et manipuler les données en présence d’outliers.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la notion de variance robuste, commençons par
rappeler la définition classique de la variance. Considérons un ensemble
de données <span class="math inline">\(X = \{x_1, x_2, \ldots,
x_n\}\)</span> de taille <span class="math inline">\(n\)</span>. La
variance classique est définie comme :</p>
<p><span class="math display">\[\sigma^2 = \frac{1}{n} \sum_{i=1}^n (x_i
- \mu)^2\]</span></p>
<p>où <span class="math inline">\(\mu\)</span> est la moyenne des
données. Cette définition est sensible aux outliers car les valeurs
extrêmes sont mises au carré, amplifiant leur impact.</p>
<p>Pour rendre la variance robuste aux outliers, nous devons atténuer
l’influence de ces valeurs. Une approche consiste à utiliser une
fonction de poids qui réduit l’impact des données extrêmes.
Formellement, nous définissons la variance robuste comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(X = \{x_1, x_2, \ldots,
x_n\}\)</span> un ensemble de données et <span
class="math inline">\(w_i\)</span> une fonction de poids telle que <span
class="math inline">\(0 \leq w_i \leq 1\)</span>. La variance robuste
est définie par :</p>
<p><span class="math display">\[\sigma_R^2 = \frac{1}{\sum_{i=1}^n w_i}
\sum_{i=1}^n w_i (x_i - \mu_R)^2\]</span></p>
<p>où <span class="math inline">\(\mu_R\)</span> est la moyenne robuste,
définie comme :</p>
<p><span class="math display">\[\mu_R = \frac{\sum_{i=1}^n w_i
x_i}{\sum_{i=1}^n w_i}\]</span></p>
</div>
<p>Les poids <span class="math inline">\(w_i\)</span> peuvent être
choisis de manière à atténuer l’impact des outliers. Par exemple, une
fonction de poids couramment utilisée est la fonction biweight :</p>
<p><span class="math display">\[w_i = \begin{cases}
\left(1 - \left(\frac{x_i - \mu_R}{c \cdot MAD}\right)^2\right)^2 &amp;
\text{si } |x_i - \mu_R| \leq c \cdot MAD \\
0 &amp; \text{sinon}
\end{cases}\]</span></p>
<p>où <span class="math inline">\(MAD\)</span> est la médiane des écarts
absolus et <span class="math inline">\(c\)</span> est une constante de
réglage.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Pour mieux comprendre les propriétés de la variance robuste, nous
présentons quelques théorèmes clés. Le premier théorème montre que la
variance robuste est une généralisation de la variance classique.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> un ensemble de données et
<span class="math inline">\(w_i = 1\)</span> pour tout <span
class="math inline">\(i\)</span>. Alors la variance robuste coïncide
avec la variance classique, c’est-à-dire :</p>
<p><span class="math display">\[\sigma_R^2 = \sigma^2\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Si <span class="math inline">\(w_i = 1\)</span> pour
tout <span class="math inline">\(i\)</span>, alors la moyenne robuste
<span class="math inline">\(\mu_R\)</span> devient la moyenne classique
<span class="math inline">\(\mu\)</span>. De plus, le dénominateur dans
la définition de la variance robuste devient <span
class="math inline">\(n\)</span>, ce qui donne :</p>
<p><span class="math display">\[\sigma_R^2 = \frac{1}{n} \sum_{i=1}^n
(x_i - \mu)^2 = \sigma^2\]</span></p>
<p>Ainsi, la variance robuste généralise la variance classique. ◻</p>
</div>
<p>Un autre théorème important concerne les propriétés de convergence de
la variance robuste. Ce théorème montre que, sous certaines conditions,
la variance robuste converge vers une valeur finie lorsque le nombre de
données tend vers l’infini.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> une suite de variables
aléatoires indépendantes et identiquement distribuées (i.i.d.) avec une
fonction de densité <span class="math inline">\(f\)</span>. Supposons
que la fonction de poids <span class="math inline">\(w_i\)</span> soit
telle que <span class="math inline">\(0 &lt; w_i \leq 1\)</span>. Alors,
lorsque <span class="math inline">\(n \to \infty\)</span>, la variance
robuste converge presque sûrement vers une valeur finie <span
class="math inline">\(\sigma_R^*\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve de ce théorème repose sur le théorème des
valeurs extrêmes et les propriétés des fonctions de poids. En
particulier, nous utilisons le fait que la fonction de poids atténue
l’impact des outliers, ce qui permet à la variance robuste de converger
vers une valeur finie.</p>
<p>Les détails techniques de cette preuve sont complexes et impliquent
des outils avancés en théorie des probabilités, tels que les inégalités
de concentration et les théorèmes de convergence presque sûre. ◻</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour illustrer les preuves détaillées, nous considérons un exemple
simple de variance robuste avec une fonction de poids spécifique.
Supposons que nous utilisions la fonction de poids Huber, définie comme
suit :</p>
<p><span class="math display">\[w_i = \begin{cases}
1 &amp; \text{si } |x_i - \mu_R| \leq c \\
\frac{c}{|x_i - \mu_R|} &amp; \text{si } |x_i - \mu_R| &gt; c
\end{cases}\]</span></p>
<p>Nous voulons montrer que cette fonction de poids réduit l’impact des
outliers. Pour ce faire, nous calculons la variance robuste avec cette
fonction de poids.</p>
<div class="proof">
<p><em>Proof.</em> Considérons un ensemble de données <span
class="math inline">\(X = \{x_1, x_2, \ldots, x_n\}\)</span> et
supposons que <span class="math inline">\(k\)</span> des données soient
des outliers. La moyenne robuste <span
class="math inline">\(\mu_R\)</span> est définie comme :</p>
<p><span class="math display">\[\mu_R = \frac{\sum_{i=1}^n w_i
x_i}{\sum_{i=1}^n w_i}\]</span></p>
<p>Pour les outliers, <span class="math inline">\(w_i = \frac{c}{|x_i -
\mu_R|}\)</span>, ce qui réduit leur impact sur la moyenne. La variance
robuste est alors :</p>
<p><span class="math display">\[\sigma_R^2 = \frac{1}{\sum_{i=1}^n w_i}
\sum_{i=1}^n w_i (x_i - \mu_R)^2\]</span></p>
<p>En utilisant les propriétés de la fonction de poids Huber, nous
pouvons montrer que <span class="math inline">\(\sigma_R^2\)</span> est
moins sensible aux outliers que la variance classique. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
variance robuste, suivies de leurs preuves détaillées.</p>
<ol>
<li><p>La variance robuste est toujours inférieure ou égale à la
variance classique, c’est-à-dire :</p>
<p><span class="math display">\[\sigma_R^2 \leq \sigma^2\]</span></p>
<div class="proof">
<p><em>Proof.</em> Cette propriété découle du fait que les fonctions de
poids atténuent l’impact des outliers, réduisant ainsi la dispersion
globale. Formellement, nous avons :</p>
<p><span class="math display">\[\sigma_R^2 = \frac{1}{\sum_{i=1}^n w_i}
\sum_{i=1}^n w_i (x_i - \mu_R)^2 \leq \frac{1}{n} \sum_{i=1}^n (x_i -
\mu)^2 = \sigma^2\]</span></p>
<p>où la dernière inégalité vient du fait que <span
class="math inline">\(w_i \leq 1\)</span> et <span
class="math inline">\(\mu_R\)</span> est une moyenne pondérée. ◻</p>
</div></li>
<li><p>La variance robuste est invariante par translation, c’est-à-dire
que si nous ajoutons une constante <span
class="math inline">\(a\)</span> à toutes les données, la variance
robuste reste inchangée :</p>
<p><span class="math display">\[\sigma_R^2(X + a) =
\sigma_R^2(X)\]</span></p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(Y = X + a\)</span>.
La moyenne robuste de <span class="math inline">\(Y\)</span> est :</p>
<p><span class="math display">\[\mu_R(Y) = \frac{\sum_{i=1}^n w_i (x_i +
a)}{\sum_{i=1}^n w_i} = \mu_R(X) + a\]</span></p>
<p>La variance robuste de <span class="math inline">\(Y\)</span> est
alors :</p>
<p><span class="math display">\[\sigma_R^2(Y) = \frac{1}{\sum_{i=1}^n
w_i} \sum_{i=1}^n w_i ((x_i + a) - (\mu_R(X) + a))^2 =
\sigma_R^2(X)\]</span></p>
<p>Ainsi, la variance robuste est invariante par translation. ◻</p>
</div></li>
<li><p>La variance robuste est positive, c’est-à-dire :</p>
<p><span class="math display">\[\sigma_R^2 \geq 0\]</span></p>
<div class="proof">
<p><em>Proof.</em> La positivité de la variance robuste découle du fait
que les carrés des différences sont toujours non négatifs, et que la
somme pondérée de nombres non négatifs est également non négative. ◻</p>
</div></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>Dans cet article, nous avons exploré la notion de variance robuste
aux outliers, une généralisation de la variance classique qui atténue
l’impact des valeurs aberrantes. Nous avons présenté les définitions
formelles, les théorèmes clés, et leurs preuves détaillées. Nous avons
également discuté des propriétés importantes de la variance robuste.</p>
<p>La variance robuste est un outil puissant pour les applications où la
présence d’outliers est fréquente. Elle permet de mieux comprendre et
manipuler les données, tout en conservant les propriétés essentielles de
la variance classique. Les travaux futurs pourraient explorer des
fonctions de poids plus sophistiquées et leurs implications pour la
variance robuste.</p>
</body>
</html>
{% include "footer.html" %}

