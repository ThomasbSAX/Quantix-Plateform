{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Lévy-Prokhorov : Une Mesure de Proximité Entre Lois de Probabilité</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Lévy-Prokhorov : Une Mesure de Proximité
Entre Lois de Probabilité</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Lévy-Prokhorov émerge comme une réponse élégante à un
problème fondamental en théorie des probabilités : comment mesurer la
proximité entre deux lois de probabilité ? Cette notion, introduite
indépendamment par Paul Lévy et Yury Prokhorov, trouve ses racines dans
l’étude des espaces métriques probabilistes. Elle est indispensable pour
comprendre la convergence faible de mesures, un concept central en
analyse stochastique et en statistique mathématique.</p>
<p>L’intérêt pour cette distance réside dans sa capacité à capturer la
convergence de lois de probabilité sur des espaces métriques, en
particulier lorsque les espaces considérés sont complets. Elle offre une
alternative robuste à la distance de Prokhorov, tout en conservant des
propriétés métriques essentielles.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la distance de Lévy-Prokhorov, commençons par
comprendre ce que nous cherchons à mesurer. Imaginons deux lois de
probabilité <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> sur un espace métrique <span
class="math inline">\((E, d)\)</span>. Nous voulons quantifier à quel
point ces deux lois sont proches l’une de l’autre. Intuitivement, deux
lois sont proches si les événements "grands" sous <span
class="math inline">\(\mu\)</span> le sont aussi sous <span
class="math inline">\(\nu\)</span>, et vice versa.</p>
<p>Formellement, la distance de Lévy-Prokhorov entre deux lois de
probabilité <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> sur un espace métrique <span
class="math inline">\((E, d)\)</span> est définie comme suit :</p>
<div class="definition">
<p>La distance de Lévy-Prokhorov entre <span
class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span>, notée <span
class="math inline">\(\pi(\mu, \nu)\)</span>, est donnée par : <span
class="math display">\[\pi(\mu, \nu) = \inf \left\{ \epsilon &gt; 0 :
\mu(F) \leq \nu(F^\epsilon) + \epsilon \text{ et } \nu(F) \leq
\mu(F^\epsilon) + \epsilon \text{ pour tout fermé } F \subseteq E
\right\},\]</span> où <span class="math inline">\(F^\epsilon = \{ x \in
E : d(x, F) &lt; \epsilon \}\)</span> est le <span
class="math inline">\(\epsilon\)</span>-voisinage de <span
class="math inline">\(F\)</span>.</p>
</div>
<p>Cette définition peut également être reformulée en termes d’ouverts
:</p>
<div class="definition">
<p>La distance de Lévy-Prokhorov peut aussi s’exprimer comme : <span
class="math display">\[\pi(\mu, \nu) = \inf \left\{ \epsilon &gt; 0 :
\mu(G) \leq \nu(G^\epsilon) + \epsilon \text{ et } \nu(G) \leq
\mu(G^\epsilon) + \epsilon \text{ pour tout ouvert } G \subseteq E
\right\},\]</span> où <span class="math inline">\(G^\epsilon = \{ x \in
E : d(x, G) &lt; \epsilon \}\)</span>.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux concernant la distance de
Lévy-Prokhorov est le suivant, dû à Prokhorov :</p>
<div class="theorem">
<p>Soit <span class="math inline">\((E, d)\)</span> un espace métrique
complet et séparable. Une famille de lois de probabilité <span
class="math inline">\(\{ \mu_\alpha \}_{\alpha \in I}\)</span> est
relativement compacte pour la topologie de la convergence faible si et
seulement si : <span class="math display">\[\lim_{\epsilon \to 0}
\sup_{\alpha, \beta \in I} \pi(\mu_\alpha, \mu_\beta) = 0.\]</span></p>
</div>
<p>La preuve de ce théorème repose sur des arguments de compacité et
utilise des propriétés métriques de l’espace <span
class="math inline">\((E, d)\)</span>. Nous allons maintenant détailler
cette preuve.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Prokhorov, nous avons besoin de plusieurs
étapes intermédiaires. Commençons par un lemme technique :</p>
<div class="lemma">
<p>Soit <span class="math inline">\((E, d)\)</span> un espace métrique
complet et séparable. Pour tout <span class="math inline">\(\epsilon
&gt; 0\)</span>, il existe un ensemble fini <span
class="math inline">\(\{ x_1, \ldots, x_n \} \subseteq E\)</span> tel
que : <span class="math display">\[E = \bigcup_{i=1}^n B(x_i,
\epsilon),\]</span> où <span class="math inline">\(B(x_i,
\epsilon)\)</span> désigne la boule ouverte de centre <span
class="math inline">\(x_i\)</span> et de rayon <span
class="math inline">\(\epsilon\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Puisque <span class="math inline">\(E\)</span> est
séparable, il existe une suite dense <span class="math inline">\(\{ y_n
\}_{n \in \mathbb{N}}\)</span> dans <span
class="math inline">\(E\)</span>. Pour chaque <span
class="math inline">\(n\)</span>, choisissons un point <span
class="math inline">\(x_n \in \{ y_1, \ldots, y_n \}\)</span> tel que
<span class="math inline">\(B(x_n, \epsilon)\)</span> ne soit pas
couvert par les boules précédentes. Comme <span
class="math inline">\(E\)</span> est complet, cette construction
s’arrête après un nombre fini d’étapes, prouvant ainsi le lemme. ◻</p>
</div>
<p>Nous pouvons maintenant prouver le théorème de Prokhorov :</p>
<div class="proof">
<p><em>Proof.</em> Supposons que <span class="math inline">\(\{
\mu_\alpha \}_{\alpha \in I}\)</span> soit relativement compacte pour la
topologie de la convergence faible. Alors, pour tout <span
class="math inline">\(\epsilon &gt; 0\)</span>, il existe un ensemble
fini <span class="math inline">\(\{ \alpha_1, \ldots, \alpha_n \}
\subseteq I\)</span> tel que pour toute <span
class="math inline">\(\alpha \in I\)</span>, il existe un <span
class="math inline">\(i\)</span> tel que <span
class="math inline">\(\pi(\mu_\alpha, \mu_{\alpha_i}) &lt;
\epsilon\)</span>. Cela montre que : <span
class="math display">\[\lim_{\epsilon \to 0} \sup_{\alpha, \beta \in I}
\pi(\mu_\alpha, \mu_\beta) = 0.\]</span></p>
<p>Réciproquement, supposons que <span
class="math inline">\(\lim_{\epsilon \to 0} \sup_{\alpha, \beta \in I}
\pi(\mu_\alpha, \mu_\beta) = 0\)</span>. Pour tout <span
class="math inline">\(\epsilon &gt; 0\)</span>, choisissons un ensemble
fini <span class="math inline">\(\{ x_1, \ldots, x_n \}\)</span> tel que
<span class="math inline">\(E = \bigcup_{i=1}^n B(x_i,
\epsilon)\)</span>. Pour chaque <span class="math inline">\(i\)</span>,
définissons : <span class="math display">\[A_i = \{ \alpha \in I :
\mu_\alpha(B(x_i, \epsilon)) &gt; 1 - \epsilon \}.\]</span> Par le lemme
précédent, au moins un des <span class="math inline">\(A_i\)</span> est
infini. Ainsi, la famille <span class="math inline">\(\{ \mu_\alpha
\}_{\alpha \in I}\)</span> est relativement compacte. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La distance de Lévy-Prokhorov possède plusieurs propriétés
intéressantes :</p>
<ol>
<li><p>La distance <span class="math inline">\(\pi\)</span> est une
métrique sur l’ensemble des lois de probabilité sur un espace métrique
<span class="math inline">\((E, d)\)</span>. Cela signifie qu’elle est
symétrique, satisfait l’inégalité triangulaire et est définie
positive.</p></li>
<li><p>La distance de Lévy-Prokhorov métrise la topologie de la
convergence faible sur l’ensemble des lois de probabilité sur un espace
métrique polonais (complet et séparable).</p></li>
<li><p>Pour deux lois de probabilité <span
class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span>, on a : <span
class="math display">\[\pi(\mu, \nu) \leq \inf \{ \epsilon &gt; 0 :
\mu(F) \leq \nu(F^\epsilon) + \epsilon \text{ et } \nu(F) \leq
\mu(F^\epsilon) + \epsilon \text{ pour tout fermé } F
\}.\]</span></p></li>
</ol>
<p>Ces propriétés font de la distance de Lévy-Prokhorov un outil
puissant pour l’étude des convergences faibles et des espaces
probabilistes.</p>
</body>
</html>
{% include "footer.html" %}

