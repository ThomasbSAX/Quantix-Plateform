{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Minimisation alternée : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Minimisation alternée : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La minimisation alternée, également connue sous le nom d’algorithme
de minimisation par blocs ou d’optimisation séquentielle, est une
méthode puissante pour résoudre des problèmes d’optimisation complexes.
Cette approche émerge naturellement lorsque le problème d’optimisation
est trop complexe pour être traité en une seule étape. L’idée centrale
est de décomposer le problème en sous-problèmes plus simples, que l’on
résout alternativement.</p>
<p>L’origine de cette méthode remonte aux travaux pionniers en
traitement d’images et en apprentissage automatique, où elle a été
utilisée pour des problèmes de reconstruction d’images et de clustering.
Aujourd’hui, la minimisation alternée est largement utilisée dans divers
domaines tels que l’apprentissage automatique, l’optimisation convexe,
et la science des données.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la minimisation alternée, considérons un problème
d’optimisation général :</p>
<p><span class="math display">\[\min_{x \in X} f(x)\]</span></p>
<p>où <span class="math inline">\(f: X \to \mathbb{R}\)</span> est une
fonction à minimiser, et <span class="math inline">\(X\)</span> est un
ensemble de contraintes. Supposons que la variable <span
class="math inline">\(x\)</span> peut être décomposée en plusieurs blocs
<span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>. L’idée est
de minimiser <span class="math inline">\(f\)</span> en mettant à jour
chaque bloc <span class="math inline">\(x_i\)</span> alternativement,
tout en gardant les autres blocs fixes.</p>
<p>Formellement, l’algorithme de minimisation alternée peut être décrit
comme suit :</p>
<p>1. Initialiser les variables <span class="math inline">\(x_1^{(0)},
x_2^{(0)}, \ldots, x_n^{(0)}\)</span>. 2. Pour <span
class="math inline">\(k = 0, 1, 2, \ldots\)</span>, répéter jusqu’à
convergence : <span class="math display">\[x_1^{(k+1)} = \arg\min_{x_1}
f(x_1, x_2^{(k)}, \ldots, x_n^{(k)})\]</span> <span
class="math display">\[x_2^{(k+1)} = \arg\min_{x_2} f(x_1^{(k+1)}, x_2,
\ldots, x_n^{(k)})\]</span> <span class="math display">\[\vdots\]</span>
<span class="math display">\[x_n^{(k+1)} = \arg\min_{x_n} f(x_1^{(k+1)},
x_2^{(k+1)}, \ldots, x_n)\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental concernant la minimisation alternée est le
suivant :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(f: X \to \mathbb{R}\)</span> une
fonction convexe et continue, où <span class="math inline">\(X = X_1
\times X_2 \times \ldots \times X_n\)</span>. Supposons que chaque
sous-problème de minimisation pour <span
class="math inline">\(x_i\)</span> a une solution unique et que la
séquence générée par l’algorithme de minimisation alternée est bornée.
Alors, toute suite générée par cet algorithme converge vers un point
fixe.</p>
</div>
<p>La preuve de ce théorème repose sur des résultats classiques en
optimisation convexe et en théorie de la convergence des algorithmes.
Nous allons maintenant détailler cette preuve.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de convergence, nous avons besoin des lemmes
suivants :</p>
<div class="lemma">
<p>La suite <span class="math inline">\(\{ f(x^{(k)}) \}\)</span>
générée par l’algorithme de minimisation alternée est décroissante.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Par construction, à chaque itération <span
class="math inline">\(k\)</span>, nous avons : <span
class="math display">\[f(x_1^{(k+1)}, x_2^{(k)}, \ldots, x_n^{(k)}) \leq
f(x_1^{(k)}, x_2^{(k)}, \ldots, x_n^{(k)})\]</span> <span
class="math display">\[f(x_1^{(k+1)}, x_2^{(k+1)}, \ldots, x_n^{(k)})
\leq f(x_1^{(k+1)}, x_2^{(k)}, \ldots, x_n^{(k)})\]</span> <span
class="math display">\[\vdots\]</span> <span
class="math display">\[f(x_1^{(k+1)}, x_2^{(k+1)}, \ldots, x_n^{(k+1)})
\leq f(x_1^{(k+1)}, x_2^{(k+1)}, \ldots, x_n^{(k)})\]</span> En
combinant ces inégalités, nous obtenons : <span
class="math display">\[f(x_1^{(k+1)}, x_2^{(k+1)}, \ldots, x_n^{(k+1)})
\leq f(x_1^{(k)}, x_2^{(k)}, \ldots, x_n^{(k)})\]</span> Ce qui prouve
que la suite <span class="math inline">\(\{ f(x^{(k)}) \}\)</span> est
décroissante. ◻</p>
</div>
<div class="lemma">
<p>La suite <span class="math inline">\(\{ x^{(k)} \}\)</span> générée
par l’algorithme de minimisation alternée est bornée.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Puisque <span class="math inline">\(f\)</span> est
convexe et continue, et que la suite <span class="math inline">\(\{
f(x^{(k)}) \}\)</span> est décroissante et bornée inférieurement, elle
converge vers une valeur <span class="math inline">\(f^*\)</span>. Par
conséquent, la suite <span class="math inline">\(\{ x^{(k)} \}\)</span>
doit être bornée. ◻</p>
</div>
<p>Maintenant, nous pouvons prouver le théorème de convergence :</p>
<div class="proof">
<p><em>Preuve du Théorème de Convergence.</em> Soit <span
class="math inline">\(\{ x^{(k)} \}\)</span> une suite générée par
l’algorithme de minimisation alternée. Par le lemme de monotonie, nous
savons que <span class="math inline">\(\{ f(x^{(k)}) \}\)</span> est
décroissante. Par le lemme de bornitude, <span class="math inline">\(\{
x^{(k)} \}\)</span> est bornée.</p>
<p>Puisque <span class="math inline">\(X\)</span> est un ensemble fermé
et convexe, toute suite bornée dans <span
class="math inline">\(X\)</span> a une sous-suite convergente. Supposons
que <span class="math inline">\(\{ x^{(k_j)} \}\)</span> soit une
sous-suite convergente vers un point <span
class="math inline">\(x^*\)</span>.</p>
<p>Par continuité de <span class="math inline">\(f\)</span>, nous avons
: <span class="math display">\[f(x^*) = \lim_{j \to \infty} f(x^{(k_j)})
= f^*\]</span></p>
<p>De plus, par construction de l’algorithme, <span
class="math inline">\(x^*\)</span> est un point fixe, c’est-à-dire :
<span class="math display">\[x_1^* = \arg\min_{x_1} f(x_1, x_2^*,
\ldots, x_n^*)\]</span> <span class="math display">\[x_2^* =
\arg\min_{x_2} f(x_1^*, x_2, \ldots, x_n^*)\]</span> <span
class="math display">\[\vdots\]</span> <span
class="math display">\[x_n^* = \arg\min_{x_n} f(x_1^*, x_2^*, \ldots,
x_n)\]</span></p>
<p>Ainsi, toute suite générée par l’algorithme de minimisation alternée
converge vers un point fixe. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
minimisation alternée :</p>
<ol type="i">
<li><p><strong>Convergence Vers un Optimum Local</strong> : Si <span
class="math inline">\(f\)</span> est convexe, alors la minimisation
alternée converge vers un optimum global. Sinon, elle peut converger
vers un optimum local.</p></li>
<li><p><strong>Rate de Convergence</strong> : Le taux de convergence de
la minimisation alternée dépend fortement de la structure du problème et
des sous-problèmes. Dans certains cas, il peut être linéaire ou même
superlinéaire.</p></li>
<li><p><strong>Applicabilité</strong> : La minimisation alternée est
particulièrement utile pour les problèmes où la fonction objectif ou les
contraintes sont séparables en blocs.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La minimisation alternée est une méthode puissante et flexible pour
résoudre des problèmes d’optimisation complexes. Son succès repose sur
la décomposition du problème en sous-problèmes plus simples, qui peuvent
être résolus alternativement. Les théorèmes de convergence et les
propriétés discutées dans cet article montrent que cette méthode est non
seulement intuitive mais aussi rigoureusement fondée.</p>
</body>
</html>
{% include "footer.html" %}

