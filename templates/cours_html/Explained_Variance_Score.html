{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Explained Variance Score : Mesure de Performance en Régression</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Explained Variance Score : Mesure de Performance en
Régression</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’Explained Variance Score (EVS) émerge comme une mesure fondamentale
dans l’évaluation des modèles de régression. Son importance réside dans
sa capacité à quantifier la proportion de variance de la variable cible
expliquée par le modèle. Historiquement, cette notion s’inscrit dans le
cadre plus large de l’analyse de la variance, un pilier de la
statistique inférentielle. L’EVS se distingue par sa simplicité et son
interprétation intuitive, rendant indispensable son étude pour tout
praticien en apprentissage automatique.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’EVS, considérons un modèle de régression qui prédit
une variable cible <span class="math inline">\(y\)</span> à partir d’un
ensemble de caractéristiques <span class="math inline">\(X\)</span>.
L’objectif est de mesurer dans quelle mesure le modèle réduit
l’incertitude sur <span class="math inline">\(y\)</span>.</p>
<div class="definition">
<p>Soit <span class="math inline">\(y_i\)</span> la valeur réelle de la
variable cible pour l’observation <span
class="math inline">\(i\)</span>, et <span
class="math inline">\(\hat{y}_i\)</span> la prédiction correspondante.
La variance totale des valeurs réelles est donnée par : <span
class="math display">\[\text{Var}(y) = \frac{1}{n} \sum_{i=1}^n (y_i -
\bar{y})^2\]</span> où <span class="math inline">\(\bar{y}\)</span> est
la moyenne des valeurs réelles.</p>
</div>
<p>La variance expliquée par le modèle est quant à elle définie comme :
<span class="math display">\[\text{Var}_{\text{explained}} = \frac{1}{n}
\sum_{i=1}^n (\hat{y}_i - \bar{y})^2\]</span></p>
<div class="definition">
<p>L’Explained Variance Score est alors défini comme le rapport entre la
variance expliquée et la variance totale : <span
class="math display">\[\text{EVS} = 1 - \frac{\text{Var}(y -
\hat{y})}{\text{Var}(y)}\]</span> où <span
class="math inline">\(\text{Var}(y - \hat{y})\)</span> est la variance
des résidus.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème central lié à l’EVS est celui de la décomposition de la
variance, qui stipule que la variance totale peut être décomposée en une
partie expliquée par le modèle et une partie résiduelle.</p>
<div class="theorem">
<p>Pour tout modèle de régression, on a : <span
class="math display">\[\text{Var}(y) = \text{Var}(\hat{y}) +
\text{Var}(y - \hat{y})\]</span> où <span
class="math inline">\(\text{Var}(\hat{y})\)</span> est la variance des
prédictions et <span class="math inline">\(\text{Var}(y -
\hat{y})\)</span> est la variance des résidus.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>La preuve du théorème de décomposition de la variance repose sur des
propriétés fondamentales de la variance.</p>
<div class="proof">
<p><em>Proof.</em> Considérons l’identité suivante : <span
class="math display">\[y_i - \bar{y} = (\hat{y}_i - \bar{\hat{y}}) +
(y_i - \hat{y}_i) + (\bar{\hat{y}} - \bar{y})\]</span> où <span
class="math inline">\(\bar{\hat{y}}\)</span> est la moyenne des
prédictions. En prenant la variance de chaque côté, nous obtenons :
<span class="math display">\[\text{Var}(y) = \text{Var}(\hat{y}) +
\text{Var}(y - \hat{y})\]</span> Cette égalité découle du fait que la
covariance entre <span class="math inline">\(\hat{y}\)</span> et <span
class="math inline">\(y - \hat{y}\)</span> est nulle, car <span
class="math inline">\(y - \hat{y}\)</span> représente les résidus du
modèle. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’EVS possède plusieurs propriétés intéressantes :</p>
<ol>
<li><p>L’EVS est borné entre 0 et 1. Un score de 1 indique que le modèle
explique parfaitement la variance de la variable cible, tandis qu’un
score de 0 indique que le modèle n’explique aucune variance.</p></li>
<li><p>L’EVS est invariant par translation et par scaling de la variable
cible. Cela signifie que l’EVS reste le même si on ajoute une constante
à <span class="math inline">\(y\)</span> ou si on multiplie <span
class="math inline">\(y\)</span> par un facteur non nul.</p></li>
<li><p>Pour un modèle de régression linéaire simple, l’EVS est égal au
carré du coefficient de corrélation entre <span
class="math inline">\(y\)</span> et <span
class="math inline">\(\hat{y}\)</span>.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’Explained Variance Score est une mesure puissante et intuitive pour
évaluer la performance des modèles de régression. Sa simplicité et ses
propriétés mathématiques en font un outil indispensable dans l’arsenal
du data scientist. En comprenant profondément l’EVS, on peut mieux
interpréter les résultats des modèles et améliorer leur performance.</p>
</body>
</html>
{% include "footer.html" %}

