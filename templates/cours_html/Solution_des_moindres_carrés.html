{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Solution des moindres carrés</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Solution des moindres carrés</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les méthodes des moindres carrés sont omniprésentes en mathématiques
appliquées, en statistique et en ingénierie. Elles trouvent leur origine
dans les travaux de Carl Friedrich Gauss au début du XIXème siècle, bien
que le concept ait été formalisé plus tard par Adrien-Marie Legendre.
L’idée sous-jacente est de minimiser la somme des carrés des écarts
entre les valeurs observées et celles prédites par un modèle. Cette
approche est indispensable dans de nombreux domaines, allant de la
régression linéaire à l’ajustement de courbes, en passant par le
traitement du signal et la robotique.</p>
<h1 id="définitions">Définitions</h1>
<p>Nous cherchons à résoudre un système d’équations linéaires
surdéterminé, c’est-à-dire un système où il y a plus d’équations que
d’inconnues. Supposons que nous ayons un système de la forme <span
class="math inline">\(A \mathbf{x} = \mathbf{b}\)</span>, où <span
class="math inline">\(A\)</span> est une matrice <span
class="math inline">\(m \times n\)</span> avec <span
class="math inline">\(m &gt; n\)</span>, et <span
class="math inline">\(\mathbf{b}\)</span> est un vecteur de dimension
<span class="math inline">\(m\)</span>. La solution des moindres carrés
consiste à trouver le vecteur <span
class="math inline">\(\mathbf{x}\)</span> qui minimise la norme
euclidienne du résidu <span class="math inline">\(\| A \mathbf{x} -
\mathbf{b} \|_2\)</span>.</p>
<p>Formellement, nous cherchons à minimiser la fonction de coût suivante
:</p>
<p><span class="math display">\[\mathcal{J}(\mathbf{x}) = \frac{1}{2} \|
A \mathbf{x} - \mathbf{b} \|_2^2 = \frac{1}{2} (A \mathbf{x} -
\mathbf{b})^T (A \mathbf{x} - \mathbf{b})\]</span></p>
<p>où <span class="math inline">\(\| \cdot \|_2\)</span> désigne la
norme euclidienne.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Le théorème fondamental des moindres carrés stipule que la solution
minimisant <span class="math inline">\(\mathcal{J}(\mathbf{x})\)</span>
est donnée par :</p>
<p><span class="math display">\[\mathbf{x}^* = (A^T A)^{-1} A^T
\mathbf{b}\]</span></p>
<p>à condition que <span class="math inline">\(A^T A\)</span> soit
inversible. Pour démontrer ce théorème, nous commençons par trouver le
gradient de <span class="math inline">\(\mathcal{J}(\mathbf{x})\)</span>
:</p>
<p><span class="math display">\[\nabla \mathcal{J}(\mathbf{x}) = A^T (A
\mathbf{x} - \mathbf{b})\]</span></p>
<p>En annulant le gradient, nous obtenons :</p>
<p><span class="math display">\[A^T A \mathbf{x} = A^T
\mathbf{b}\]</span></p>
<p>Cette équation est connue sous le nom d’équations normales. Si <span
class="math inline">\(A^T A\)</span> est inversible, la solution unique
est donnée par :</p>
<p><span class="math display">\[\mathbf{x}^* = (A^T A)^{-1} A^T
\mathbf{b}\]</span></p>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer que <span class="math inline">\(\mathbf{x}^*\)</span>
minimise effectivement <span
class="math inline">\(\mathcal{J}(\mathbf{x})\)</span>, nous pouvons
utiliser le fait que la hessienne de <span
class="math inline">\(\mathcal{J}(\mathbf{x})\)</span> est positive
définie. La hessienne est donnée par :</p>
<p><span class="math display">\[H = A^T A\]</span></p>
<p>Puisque <span class="math inline">\(H\)</span> est symétrique et
positive définie (car <span class="math inline">\(A^T A\)</span> est
toujours symétrique et positive semi-définie, et inversible dans ce
cas), la fonction <span
class="math inline">\(\mathcal{J}(\mathbf{x})\)</span> est convexe et
admet un minimum global en <span
class="math inline">\(\mathbf{x}^*\)</span>.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
solution des moindres carrés :</p>
<ol>
<li><p>Si <span class="math inline">\(A\)</span> est une matrice pleine
colonne rang (c’est-à-dire que les colonnes de <span
class="math inline">\(A\)</span> sont linéairement indépendantes), alors
<span class="math inline">\(A^T A\)</span> est inversible et la solution
des moindres carrés est unique.</p></li>
<li><p>La solution des moindres carrés minimise également la somme des
carrés des résidus, c’est-à-dire <span
class="math inline">\(\sum_{i=1}^m (A \mathbf{x} -
\mathbf{b})_i^2\)</span>.</p></li>
<li><p>Si <span class="math inline">\(A\)</span> n’est pas de plein
rang, la solution des moindres carrés n’est pas unique. Cependant, il
existe une solution de norme minimale donnée par <span
class="math inline">\(\mathbf{x}^* = A^\dagger \mathbf{b}\)</span>, où
<span class="math inline">\(A^\dagger\)</span> est la pseudo-inverse de
Moore-Penrose de <span class="math inline">\(A\)</span>.</p></li>
</ol>
<p>Pour démontrer la propriété (i), nous remarquons que si <span
class="math inline">\(A\)</span> est de plein rang, alors <span
class="math inline">\(A^T A\)</span> est inversible. En effet, si <span
class="math inline">\(\mathbf{y} \neq 0\)</span> tel que <span
class="math inline">\(A^T A \mathbf{y} = 0\)</span>, alors <span
class="math inline">\((A \mathbf{y})^T (A \mathbf{y}) = 0\)</span>, ce
qui implique <span class="math inline">\(A \mathbf{y} = 0\)</span>.
Puisque <span class="math inline">\(A\)</span> est de plein rang, nous
avons <span class="math inline">\(\mathbf{y} = 0\)</span>, ce qui
contredit l’hypothèse initiale. Par conséquent, <span
class="math inline">\(A^T A\)</span> est inversible.</p>
<p>Pour la propriété (ii), nous observons que :</p>
<p><span class="math display">\[\sum_{i=1}^m (A \mathbf{x} -
\mathbf{b})_i^2 = \| A \mathbf{x} - \mathbf{b} \|_2^2 = 2
\mathcal{J}(\mathbf{x})\]</span></p>
<p>Ainsi, minimiser <span
class="math inline">\(\mathcal{J}(\mathbf{x})\)</span> revient à
minimiser la somme des carrés des résidus.</p>
<p>Enfin, pour la propriété (iii), nous utilisons le fait que la
pseudo-inverse de Moore-Penrose <span
class="math inline">\(A^\dagger\)</span> est définie comme la solution
de l’équation <span class="math inline">\(A^\dagger A A^\dagger =
A^\dagger\)</span>. La solution des moindres carrés de norme minimale
est alors donnée par <span class="math inline">\(\mathbf{x}^* =
A^\dagger \mathbf{b}\)</span>.</p>
</body>
</html>
{% include "footer.html" %}

