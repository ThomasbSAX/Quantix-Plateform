{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Encodage par extraction de caractéristiques de tendance</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Encodage par extraction de caractéristiques de
tendance</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’encodage par extraction de caractéristiques de tendance est une
méthode puissante dans le traitement du signal et l’analyse des données
temporelles. Cette technique émerge de la nécessité de capturer les
motifs sous-jacents dans des séries temporelles, souvent bruitées ou
incomplètes. L’idée centrale est de transformer des séquences
temporelles brutes en un ensemble de caractéristiques significatives qui
préservent les tendances et les motifs essentiels.</p>
<p>L’extraction de caractéristiques de tendance est indispensable dans
des domaines tels que la finance, où les tendances des marchés sont
cruciales pour la prise de décision, ou en médecine, où l’analyse des
signaux biologiques peut révéler des pathologies. Cette méthode permet
non seulement de réduire la dimensionnalité des données, mais aussi
d’améliorer la performance des modèles prédictifs en se concentrant sur
les aspects les plus informatifs des séries temporelles.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre l’encodage par extraction de caractéristiques de
tendance, commençons par définir ce que nous cherchons à capturer.
Imaginons une série temporelle <span class="math inline">\(X = (x_1,
x_2, \ldots, x_n)\)</span>. Nous voulons identifier les tendances,
c’est-à-dire les variations systématiques de <span
class="math inline">\(X\)</span> sur différentes échelles de temps. Une
tendance peut être une augmentation ou une diminution progressive, ou
même des motifs cycliques.</p>
<p>Formellement, une caractéristique de tendance peut être définie comme
suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(X = (x_1, x_2, \ldots, x_n)\)</span>
une série temporelle. Une caractéristique de tendance est une fonction
<span class="math inline">\(T: \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> qui capture une propriété spécifique de la tendance
de <span class="math inline">\(X\)</span>. Par exemple, la pente moyenne
sur une fenêtre glissante peut être une caractéristique de tendance.</p>
</div>
<p>Une autre manière de formaliser cela est :</p>
<div class="definition">
<p>Pour toute série temporelle <span class="math inline">\(X = (x_1,
x_2, \ldots, x_n)\)</span>, une caractéristique de tendance est un
vecteur <span class="math inline">\(T(X) = (t_1, t_2, \ldots,
t_k)\)</span>, où chaque <span class="math inline">\(t_i\)</span> est
une mesure quantifiée de la tendance de <span
class="math inline">\(X\)</span> sur une certaine période ou selon un
certain critère.</p>
</div>
<h1 id="théorèmes-et-propriétés">Théorèmes et Propriétés</h1>
<p>L’extraction de caractéristiques de tendance repose sur plusieurs
théorèmes et propriétés fondamentales. Considérons par exemple le
théorème de la pente moyenne, qui est souvent utilisé pour capturer les
tendances linéaires.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X = (x_1, x_2, \ldots, x_n)\)</span>
une série temporelle et <span class="math inline">\(w\)</span> une
fenêtre glissante de taille <span class="math inline">\(m\)</span>. La
pente moyenne sur la fenêtre <span class="math inline">\(i\)</span> est
définie par : <span class="math display">\[T_i(X) = \frac{x_{i+m} -
x_i}{m}\]</span> Pour toute série temporelle <span
class="math inline">\(X\)</span>, la pente moyenne sur une fenêtre
glissante de taille <span class="math inline">\(m\)</span> capture une
tendance linéaire locale.</p>
</div>
<p>Une autre propriété importante est la propriété de lissage
exponentiel, qui permet de capturer les tendances à long terme.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X = (x_1, x_2, \ldots, x_n)\)</span>
une série temporelle et <span class="math inline">\(\alpha\)</span> un
facteur de lissage. La tendance lissée exponentiellement est définie par
: <span class="math display">\[T_i(X) = \alpha x_i + (1 - \alpha)
T_{i-1}(X)\]</span> Pour toute série temporelle <span
class="math inline">\(X\)</span>, la tendance lissée exponentiellement
capture une tendance à long terme en atténuant les variations à court
terme.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de la pente moyenne, nous devons montrer que
la pente moyenne sur une fenêtre glissante capture effectivement une
tendance linéaire locale.</p>
<div class="proof">
<p><em>Proof.</em> Considérons une série temporelle <span
class="math inline">\(X = (x_1, x_2, \ldots, x_n)\)</span> et une
fenêtre glissante de taille <span class="math inline">\(m\)</span>. La
pente moyenne sur la fenêtre <span class="math inline">\(i\)</span> est
définie par : <span class="math display">\[T_i(X) = \frac{x_{i+m} -
x_i}{m}\]</span></p>
<p>Supposons que <span class="math inline">\(X\)</span> suit une
tendance linéaire locale sur la fenêtre <span
class="math inline">\(i\)</span>, c’est-à-dire que <span
class="math inline">\(x_{i+k} = x_i + k \cdot \delta\)</span> pour tout
<span class="math inline">\(k \leq m\)</span>, où <span
class="math inline">\(\delta\)</span> est la pente locale. Alors : <span
class="math display">\[T_i(X) = \frac{x_i + m \cdot \delta - x_i}{m} =
\delta\]</span></p>
<p>Ainsi, la pente moyenne capture effectivement la tendance linéaire
locale. ◻</p>
</div>
<p>Pour prouver la propriété de lissage exponentiel, nous devons montrer
que la tendance lissée exponentiellement capture une tendance à long
terme.</p>
<div class="proof">
<p><em>Proof.</em> Considérons une série temporelle <span
class="math inline">\(X = (x_1, x_2, \ldots, x_n)\)</span> et un facteur
de lissage <span class="math inline">\(\alpha\)</span>. La tendance
lissée exponentiellement est définie par : <span
class="math display">\[T_i(X) = \alpha x_i + (1 - \alpha)
T_{i-1}(X)\]</span></p>
<p>Pour <span class="math inline">\(i = 1\)</span>, nous avons <span
class="math inline">\(T_1(X) = x_1\)</span>. Pour <span
class="math inline">\(i &gt; 1\)</span>, la tendance lissée
exponentiellement est une combinaison convexe des valeurs actuelles et
passées. En développant récursivement, nous obtenons : <span
class="math display">\[T_i(X) = \alpha \sum_{k=0}^{i-1} (1 - \alpha)^k
x_{i-k}\]</span></p>
<p>Cette formule montre que la tendance lissée exponentiellement donne
plus de poids aux valeurs récentes, atténuant ainsi les variations à
court terme et capturant une tendance à long terme. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’encodage par extraction de caractéristiques de tendance possède
plusieurs propriétés intéressantes. En voici quelques-unes :</p>
<div class="proposition">
<p>(i) <strong>Invariance par translation</strong> : Si <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont deux séries temporelles telles que
<span class="math inline">\(Y = X + c\)</span> pour une constante <span
class="math inline">\(c\)</span>, alors les caractéristiques de tendance
de <span class="math inline">\(Y\)</span> sont identiques à celles de
<span class="math inline">\(X\)</span>.</p>
<p>(ii) <strong>Invariance par échelle</strong> : Si <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont deux séries temporelles telles que
<span class="math inline">\(Y = aX\)</span> pour une constante <span
class="math inline">\(a &gt; 0\)</span>, alors les caractéristiques de
tendance de <span class="math inline">\(Y\)</span> sont proportionnelles
à celles de <span class="math inline">\(X\)</span>.</p>
<p>(iii) <strong>Stabilité aux bruits</strong> : Les caractéristiques de
tendance sont robustes aux petits bruits ajoutés à la série temporelle,
car elles capturent les motifs sous-jacents plutôt que les variations
aléatoires.</p>
</div>
<div class="proof">
<p><em>Proof.</em> (i) Soit <span class="math inline">\(X = (x_1, x_2,
\ldots, x_n)\)</span> et <span class="math inline">\(Y = (y_1, y_2,
\ldots, y_n)\)</span> avec <span class="math inline">\(y_i = x_i +
c\)</span>. La pente moyenne sur une fenêtre glissante pour <span
class="math inline">\(Y\)</span> est : <span
class="math display">\[T_i(Y) = \frac{y_{i+m} - y_i}{m} = \frac{x_{i+m}
+ c - x_i - c}{m} = T_i(X)\]</span></p>
<p>(ii) Soit <span class="math inline">\(X = (x_1, x_2, \ldots,
x_n)\)</span> et <span class="math inline">\(Y = (y_1, y_2, \ldots,
y_n)\)</span> avec <span class="math inline">\(y_i = a x_i\)</span>. La
pente moyenne sur une fenêtre glissante pour <span
class="math inline">\(Y\)</span> est : <span
class="math display">\[T_i(Y) = \frac{y_{i+m} - y_i}{m} = \frac{a
x_{i+m} - a x_i}{m} = a T_i(X)\]</span></p>
<p>(iii) La robustesse aux bruits découle du fait que les
caractéristiques de tendance capturent les motifs sous-jacents plutôt
que les variations aléatoires. Par exemple, la pente moyenne sur une
fenêtre glissante lisse les petits bruits et met en évidence les
tendances principales. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>L’encodage par extraction de caractéristiques de tendance est une
méthode puissante pour capturer les motifs sous-jacents dans des séries
temporelles. En transformant des séquences temporelles brutes en un
ensemble de caractéristiques significatives, cette technique permet de
réduire la dimensionnalité des données et d’améliorer la performance des
modèles prédictifs. Les théorèmes et propriétés présentés dans cet
article montrent que cette méthode est robuste et efficace pour
l’analyse des tendances.</p>
</body>
</html>
{% include "footer.html" %}

