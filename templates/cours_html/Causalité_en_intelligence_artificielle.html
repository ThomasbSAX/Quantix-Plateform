{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Causalité en intelligence artificielle : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Causalité en intelligence artificielle : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’intelligence artificielle (IA) a connu des avancées spectaculaires
ces dernières décennies, notamment grâce aux méthodes d’apprentissage
automatique (machine learning). Cependant, ces méthodes reposent souvent
sur des corrélations plutôt que sur une compréhension profonde des
relations causales. La causalité en IA émerge comme un domaine crucial
pour dépasser les limites des approches purement corrélationnelles et
pour permettre aux systèmes d’IA de raisonner comme des humains.</p>
<p>L’idée centrale est que comprendre les causes et les effets permet de
prédire non seulement ce qui se passera, mais aussi ce qui se passerait
si une intervention était effectuée. Cela est particulièrement important
dans des domaines comme la médecine, où il est crucial de comprendre
l’effet d’un traitement sur un patient, ou en économie, où les
politiques publiques doivent être évaluées en termes de leur impact
causal.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la causalité en IA, il est essentiel de définir
certains concepts clés.</p>
<h2 id="variables-et-relations">Variables et Relations</h2>
<p>Considérons un ensemble de variables aléatoires <span
class="math inline">\(V = \{V_1, V_2, \ldots, V_n\}\)</span>. Nous
cherchons à comprendre les relations causales entre ces variables. Par
exemple, dans un contexte médical, <span
class="math inline">\(V_1\)</span> pourrait représenter la prise d’un
médicament, et <span class="math inline">\(V_2\)</span> pourrait
représenter la guérison du patient.</p>
<h2 id="graphes-causaux">Graphes Causaux</h2>
<p>Un graphe causal est un outil puissant pour représenter les relations
causales entre des variables. Formellement, un graphe causal <span
class="math inline">\(G\)</span> est un triplet <span
class="math inline">\((V, E, P)\)</span>, où:</p>
<ul>
<li><p><span class="math inline">\(V\)</span> est un ensemble de nœuds
représentant les variables.</p></li>
<li><p><span class="math inline">\(E\)</span> est un ensemble d’arêtes
dirigées représentant les relations causales.</p></li>
<li><p><span class="math inline">\(P\)</span> est un ensemble de
distributions de probabilité conditionnelles associées à chaque
nœud.</p></li>
</ul>
<p>Par exemple, si <span class="math inline">\(V_1\)</span> cause <span
class="math inline">\(V_2\)</span>, nous écrivons <span
class="math inline">\(V_1 \rightarrow V_2\)</span>.</p>
<h2 id="causalité-vs-corrélation">Causalité vs Corrélation</h2>
<p>Il est crucial de distinguer la causalité de la corrélation. Deux
variables peuvent être corrélées sans qu’il y ait une relation causale
entre elles. Par exemple, la consommation de glace et les noyades sont
corrélées en été, mais ce n’est pas parce que la consommation de glace
cause les noyades.</p>
<h1 id="théorèmes">Théorèmes</h1>
<h2 id="théorème-de-do-calculus">Théorème de Do-Calculus</h2>
<p>Le théorème de Do-Calculus, développé par Judea Pearl, est un outil
fondamental pour l’inférence causale. Il permet de calculer les effets
d’une intervention sur un système causal.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(G\)</span> un graphe causal et <span
class="math inline">\(P\)</span> une distribution de probabilité
compatible avec <span class="math inline">\(G\)</span>. Pour toute
variable <span class="math inline">\(Y\)</span> et tout ensemble de
variables <span class="math inline">\(X\)</span>, l’effet causal de
<span class="math inline">\(X\)</span> sur <span
class="math inline">\(Y\)</span> peut être calculé en utilisant les
opérations suivantes:</p>
<ol>
<li><p>Insertion/Retrait d’arêtes: <span
class="math inline">\(do(X)\)</span> remplace les parents de <span
class="math inline">\(X\)</span> par des nœuds exogènes.</p></li>
<li><p>Conditionnement: <span class="math inline">\(P(Y |
do(X))\)</span> peut être calculé en conditionnant sur les variables
appropriées.</p></li>
<li><p>Marginalisation: <span class="math inline">\(P(Y |
do(X))\)</span> peut être obtenu en marginalisant sur les variables non
observées.</p></li>
</ol>
</div>
<h2 id="démonstration-du-théorème-de-do-calculus">Démonstration du
Théorème de Do-Calculus</h2>
<p>La démonstration du théorème de Do-Calculus repose sur plusieurs
étapes clés:</p>
<p>1. **Insertion/Retrait d’arêtes**: L’opération <span
class="math inline">\(do(X)\)</span> modifie le graphe causal en
retirant les arêtes entrantes vers <span
class="math inline">\(X\)</span> et en remplaçant les parents de <span
class="math inline">\(X\)</span> par des nœuds exogènes. Cela permet de
modéliser l’intervention sur <span class="math inline">\(X\)</span>.</p>
<p>2. **Conditionnement**: En conditionnant sur les variables
appropriées, nous pouvons isoler l’effet causal de <span
class="math inline">\(X\)</span> sur <span
class="math inline">\(Y\)</span>. Par exemple, si <span
class="math inline">\(Z\)</span> est un confondant, nous devons
conditionner sur <span class="math inline">\(Z\)</span> pour éliminer
son effet.</p>
<p>3. **Marginalisation**: Si certaines variables ne sont pas observées,
nous devons marginaliser sur ces variables pour obtenir la distribution
de probabilité conditionnelle souhaitée.</p>
<h1 id="preuves">Preuves</h1>
<h2 id="preuve-du-théorème-de-do-calculus">Preuve du Théorème de
Do-Calculus</h2>
<p>Pour démontrer le théorème de Do-Calculus, nous devons montrer que
les opérations décrites permettent de calculer correctement l’effet
causal. Considérons un exemple simple où <span
class="math inline">\(X\)</span> cause <span
class="math inline">\(Y\)</span> directement.</p>
<p>1. **Insertion/Retrait d’arêtes**: Nous appliquons <span
class="math inline">\(do(X)\)</span>, ce qui retire l’arête entrante
vers <span class="math inline">\(X\)</span> et remplace les parents de
<span class="math inline">\(X\)</span> par des nœuds exogènes. Le graphe
modifié est maintenant <span class="math inline">\(G&#39;\)</span>.</p>
<p>2. **Conditionnement**: Nous conditionnons sur les variables qui ne
sont pas affectées par <span class="math inline">\(do(X)\)</span>. Dans
ce cas, nous n’avons pas besoin de conditionner sur d’autres
variables.</p>
<p>3. **Marginalisation**: Nous marginalisons sur les variables non
observées pour obtenir <span class="math inline">\(P(Y |
do(X))\)</span>.</p>
<p>Ainsi, nous avons démontré que le théorème de Do-Calculus permet de
calculer l’effet causal de <span class="math inline">\(X\)</span> sur
<span class="math inline">\(Y\)</span>.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriétés-du-théorème-de-do-calculus">Propriétés du Théorème de
Do-Calculus</h2>
<ol>
<li><p>**Invariance sous interventions**: Le théorème de Do-Calculus
permet de calculer les effets d’interventions même si le graphe causal
n’est pas complètement connu.</p></li>
<li><p>**Robustesse aux confondants**: Le théorème permet de prendre en
compte les confondants et de les éliminer par conditionnement.</p></li>
<li><p>**Généralisation**: Le théorème peut être généralisé à des
graphes causaux plus complexes avec plusieurs niveaux
d’interventions.</p></li>
</ol>
<h2 id="corollaires-du-théorème-de-do-calculus">Corollaires du Théorème
de Do-Calculus</h2>
<div class="corollary">
<p>Si <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont indépendantes dans le graphe
causal <span class="math inline">\(G\)</span>, alors <span
class="math inline">\(P(Y | do(X)) = P(Y)\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Puisque <span class="math inline">\(X\)</span> et
<span class="math inline">\(Y\)</span> sont indépendantes,
l’intervention sur <span class="math inline">\(X\)</span> n’affecte pas
<span class="math inline">\(Y\)</span>. Par conséquent, <span
class="math inline">\(P(Y | do(X)) = P(Y)\)</span>. ◻</p>
</div>
<div class="corollary">
<p>Si <span class="math inline">\(X\)</span> cause <span
class="math inline">\(Y\)</span> directement, alors <span
class="math inline">\(P(Y | do(X)) \neq P(Y)\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Si <span class="math inline">\(X\)</span> cause <span
class="math inline">\(Y\)</span> directement, l’intervention sur <span
class="math inline">\(X\)</span> change la distribution de <span
class="math inline">\(Y\)</span>. Par conséquent, <span
class="math inline">\(P(Y | do(X)) \neq P(Y)\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La causalité en intelligence artificielle est un domaine fascinant et
crucial pour le développement de systèmes d’IA plus robustes et
intelligents. En comprenant les relations causales, nous pouvons aller
au-delà des simples corrélations et développer des modèles capables de
raisonner comme des humains. Le théorème de Do-Calculus est un outil
puissant pour l’inférence causale, et ses propriétés et corollaires
ouvrent la voie à de nombreuses applications pratiques.</p>
</body>
</html>
{% include "footer.html" %}

