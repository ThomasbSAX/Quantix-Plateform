{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Corrélation nulle : Une exploration mathématique et statistique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Corrélation nulle : Une exploration mathématique et
statistique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La notion de corrélation nulle émerge naturellement dans le paysage
statistique comme une pierre angulaire pour comprendre les relations
entre variables aléatoires. Historiquement, cette idée trouve ses
racines dans les travaux pionniers de Francis Galton et Karl Pearson à
la fin du XIXe siècle, qui cherchaient à quantifier l’intensité des
liens entre phénomènes observables. La corrélation nulle, en
particulier, se distingue par son pouvoir discriminant : elle permet
d’affirmer l’absence de relation linéaire entre deux variables, ouvrant
ainsi la voie à des analyses plus fines et nuancées.</p>
<p>Pourquoi cette notion est-elle indispensable ? Dans un monde où les
données abondent et où l’interprétation des résultats statistiques guide
des décisions cruciales, la corrélation nulle sert de garde-fou. Elle
évite les conclusions hâtives et les erreurs d’interprétation, tout en
offrant un cadre rigoureux pour explorer des dépendances plus complexes.
Son importance est d’autant plus marquée dans des domaines tels que
l’économie, la biologie ou les sciences sociales, où les variables sont
souvent interdépendantes de manière non linéaire.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour aborder la corrélation nulle, commençons par comprendre ce que
nous cherchons à capturer. Imaginons deux variables aléatoires <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>. Nous voulons savoir si, en moyenne,
les valeurs de <span class="math inline">\(X\)</span> n’ont aucun impact
sur celles de <span class="math inline">\(Y\)</span>, et vice versa.
Plus précisément, nous cherchons une mesure qui quantifie l’absence de
relation linéaire entre <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>.</p>
<p>La corrélation nulle se définit formellement comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> deux variables aléatoires réelles de
variances non nulles. On dit que <span class="math inline">\(X\)</span>
et <span class="math inline">\(Y\)</span> sont non corrélées (ou de
corrélation nulle) s’il existe un réel <span
class="math inline">\(\rho(X, Y)\)</span> tel que : <span
class="math display">\[\rho(X, Y) = \frac{\text{Cov}(X,
Y)}{\sqrt{\text{Var}(X) \text{Var}(Y)}} = 0\]</span> où <span
class="math inline">\(\text{Cov}(X, Y)\)</span> désigne la covariance
entre <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, et <span
class="math inline">\(\text{Var}(X)\)</span> (respectivement <span
class="math inline">\(\text{Var}(Y)\)</span>) la variance de <span
class="math inline">\(X\)</span> (respectivement <span
class="math inline">\(Y\)</span>).</p>
<p>De manière équivalente, on peut exprimer cette condition par : <span
class="math display">\[\mathbb{E}[(X - \mathbb{E}[X])(Y -
\mathbb{E}[Y])] = 0\]</span> où <span
class="math inline">\(\mathbb{E}\)</span> représente l’espérance
mathématique.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la corrélation nulle est celui de
l’indépendance linéaire. Ce théorème établit une condition nécessaire,
mais non suffisante, pour que deux variables aléatoires soient
indépendantes.</p>
<p>Commençons par comprendre ce théorème. Si deux variables <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont indépendantes, alors toute
relation linéaire entre elles est exclue. Cependant, l’absence de
corrélation ne signifie pas nécessairement que les variables sont
indépendantes.</p>
<p>Le théorème peut être énoncé comme suit :</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> deux variables aléatoires réelles. Si
<span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont indépendantes, alors elles sont
non corrélées. En d’autres termes : <span
class="math display">\[\text{Ind}(X, Y) \implies \rho(X, Y) = 0\]</span>
où <span class="math inline">\(\text{Ind}(X, Y)\)</span> signifie que
<span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont indépendantes.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de l’indépendance linéaire, nous allons
utiliser les propriétés de l’espérance et de la covariance.</p>
<div class="proof">
<p><em>Proof.</em> Supposons que <span class="math inline">\(X\)</span>
et <span class="math inline">\(Y\)</span> sont indépendantes. Nous
voulons montrer que <span class="math inline">\(\rho(X, Y) =
0\)</span>.</p>
<p>Par définition de l’indépendance, nous avons : <span
class="math display">\[\mathbb{E}[XY] =
\mathbb{E}[X]\mathbb{E}[Y]\]</span></p>
<p>La covariance entre <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> est donnée par : <span
class="math display">\[\text{Cov}(X, Y) = \mathbb{E}[XY] -
\mathbb{E}[X]\mathbb{E}[Y]\]</span></p>
<p>En substituant l’expression de <span
class="math inline">\(\mathbb{E}[XY]\)</span> obtenue à partir de
l’indépendance, nous obtenons : <span
class="math display">\[\text{Cov}(X, Y) = \mathbb{E}[X]\mathbb{E}[Y] -
\mathbb{E}[X]\mathbb{E}[Y] = 0\]</span></p>
<p>Par conséquent, le coefficient de corrélation <span
class="math inline">\(\rho(X, Y)\)</span> est : <span
class="math display">\[\rho(X, Y) = \frac{\text{Cov}(X,
Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}} =
\frac{0}{\sqrt{\text{Var}(X)\text{Var}(Y)}} = 0\]</span></p>
<p>Ainsi, nous avons montré que si <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont indépendantes, alors elles sont
non corrélées. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous allons maintenant explorer quelques propriétés importantes de la
corrélation nulle.</p>
<div class="proposition">
<p>La relation de non-corrélation est symétrique. C’est-à-dire, si <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont non corrélées, alors <span
class="math inline">\(Y\)</span> et <span
class="math inline">\(X\)</span> le sont également.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Par définition, si <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont non corrélées, alors : <span
class="math display">\[\text{Cov}(X, Y) = 0\]</span></p>
<p>Or, la covariance est symétrique, c’est-à-dire : <span
class="math display">\[\text{Cov}(X, Y) = \text{Cov}(Y, X)\]</span></p>
<p>Par conséquent : <span class="math display">\[\text{Cov}(Y, X) =
0\]</span></p>
<p>Ainsi, <span class="math inline">\(Y\)</span> et <span
class="math inline">\(X\)</span> sont non corrélées. ◻</p>
</div>
<div class="proposition">
<p>La relation de non-corrélation est stable par transformation
linéaire. C’est-à-dire, si <span class="math inline">\(X\)</span> et
<span class="math inline">\(Y\)</span> sont non corrélées, alors pour
tout <span class="math inline">\(a, b, c, d \in \mathbb{R}\)</span> avec
<span class="math inline">\(b, d \neq 0\)</span>, les variables <span
class="math inline">\(aX + b\)</span> et <span class="math inline">\(cY
+ d\)</span> sont également non corrélées.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Supposons que <span class="math inline">\(X\)</span>
et <span class="math inline">\(Y\)</span> sont non corrélées. Nous
voulons montrer que <span class="math inline">\(aX + b\)</span> et <span
class="math inline">\(cY + d\)</span> sont non corrélées.</p>
<p>Calculons la covariance entre <span class="math inline">\(aX +
b\)</span> et <span class="math inline">\(cY + d\)</span> : <span
class="math display">\[\text{Cov}(aX + b, cY + d) = \mathbb{E}[(aX +
b)(cY + d)] - \mathbb{E}[aX + b]\mathbb{E}[cY + d]\]</span></p>
<p>En développant le produit, nous obtenons : <span
class="math display">\[\mathbb{E}[(aX + b)(cY + d)] = ac\mathbb{E}[XY] +
ad\mathbb{E}[X] + bc\mathbb{E}[Y] + bd\]</span></p>
<p>De même, l’espérance du produit des espérances est : <span
class="math display">\[\mathbb{E}[aX + b]\mathbb{E}[cY + d] =
(a\mathbb{E}[X] + b)(c\mathbb{E}[Y] + d) = ac\mathbb{E}[X]\mathbb{E}[Y]
+ ad\mathbb{E}[X] + bc\mathbb{E}[Y] + bd\]</span></p>
<p>En substituant ces expressions dans la formule de la covariance, nous
obtenons : <span class="math display">\[\text{Cov}(aX + b, cY + d) =
ac\mathbb{E}[XY] - ac\mathbb{E}[X]\mathbb{E}[Y]\]</span></p>
<p>Or, comme <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont non corrélées, nous avons <span
class="math inline">\(\mathbb{E}[XY] =
\mathbb{E}[X]\mathbb{E}[Y]\)</span>. Par conséquent : <span
class="math display">\[\text{Cov}(aX + b, cY + d) = ac(\mathbb{E}[XY] -
\mathbb{E}[X]\mathbb{E}[Y]) = 0\]</span></p>
<p>Ainsi, <span class="math inline">\(aX + b\)</span> et <span
class="math inline">\(cY + d\)</span> sont non corrélées. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La notion de corrélation nulle est un pilier fondamental en
statistique, offrant un cadre rigoureux pour analyser les relations
entre variables aléatoires. À travers ce chapitre, nous avons exploré
ses définitions, théorèmes associés et propriétés essentielles. La
compréhension approfondie de cette notion permet non seulement d’éviter
les erreurs d’interprétation, mais aussi d’ouvrir la voie à des analyses
plus sophistiquées et nuancées.</p>
</body>
</html>
{% include "footer.html" %}

