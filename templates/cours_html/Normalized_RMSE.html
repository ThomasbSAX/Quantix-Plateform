{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Normalized Root Mean Square Error: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Normalized Root Mean Square Error: A Comprehensive
Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-and-motivations">1. Introduction
and Motivations</h1>
<p>The Normalized Root Mean Square Error (NRMSE) stands as a pivotal
metric in the realm of statistical analysis and model evaluation.
Emerging from the need to standardize error measurements across diverse
datasets, NRMSE provides a relative measure of model performance. This
normalization is indispensable when comparing models across different
scales or units, ensuring that the evaluation metric itself does not
bias the comparison. Historically, the RMSE has been a cornerstone in
assessing the accuracy of predictive models, but its absolute nature
limits its applicability across varied contexts. The advent of NRMSE
addressed this limitation, offering a dimensionless quantity that
facilitates fair and meaningful comparisons.</p>
<h1 class="unnumbered" id="definitions">2. Definitions</h1>
<p>To understand NRMSE, let us first consider the Root Mean Square Error
(RMSE). Suppose we have a set of observed values <span
class="math inline">\(y_i\)</span> and predicted values <span
class="math inline">\(\hat{y}_i\)</span> for <span
class="math inline">\(i = 1, 2, \dots, n\)</span>. The RMSE is defined
as the square root of the average of the squared differences between
observed and predicted values:</p>
<p><span class="math display">\[\text{RMSE} = \sqrt{\frac{1}{n}
\sum_{i=1}^n (y_i - \hat{y}_i)^2}\]</span></p>
<p>However, RMSE is sensitive to the scale of the data. To normalize
this error, we introduce a reference value that represents the range or
standard deviation of the observed data. The most common reference is
the range of the observed values, defined as:</p>
<p><span class="math display">\[\text{Range} = \max(y_i) -
\min(y_i)\]</span></p>
<p>Alternatively, the standard deviation of the observed values can be
used:</p>
<p><span class="math display">\[\sigma = \sqrt{\frac{1}{n} \sum_{i=1}^n
(y_i - \bar{y})^2}\]</span></p>
<p>where <span class="math inline">\(\bar{y}\)</span> is the mean of the
observed values. With these references, the NRMSE can be formally
defined as:</p>
<p><span class="math display">\[\text{NRMSE} =
\frac{\text{RMSE}}{\text{Reference}}\]</span></p>
<p>Substituting the range as the reference:</p>
<p><span class="math display">\[\text{NRMSE}_{\text{range}} =
\frac{\sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}}{\max(y_i) -
\min(y_i)}\]</span></p>
<p>Substituting the standard deviation as the reference:</p>
<p><span class="math display">\[\text{NRMSE}_{\sigma} =
\frac{\sqrt{\frac{1}{n} \sum_{i=1}^n (y_i -
\hat{y}_i)^2}}{\sqrt{\frac{1}{n} \sum_{i=1}^n (y_i -
\bar{y})^2}}\]</span></p>
<h1 class="unnumbered" id="theorems">3. Theorems</h1>
<p>One of the fundamental theorems related to NRMSE is the Normalization
Theorem, which states that for any set of observed and predicted values,
the NRMSE provides a scale-invariant measure of error. This theorem can
be formalized as follows:</p>
<p><strong>Theorem 1 (Normalization Theorem):</strong> For any two
datasets <span class="math inline">\(\{y_i\}\)</span> and <span
class="math inline">\(\{\hat{y}_i\}\)</span>, and any non-zero constant
<span class="math inline">\(c\)</span>, the NRMSE remains unchanged
under scaling:</p>
<p><span class="math display">\[\text{NRMSE}(c y_i, c \hat{y}_i) =
\text{NRMSE}(y_i, \hat{y}_i)\]</span></p>
<p><strong>Proof:</strong></p>
<p>Consider the NRMSE with range as the reference:</p>
<p><span class="math display">\[\text{NRMSE}(c y_i, c \hat{y}_i) =
\frac{\sqrt{\frac{1}{n} \sum_{i=1}^n (c y_i - c \hat{y}_i)^2}}{\max(c
y_i) - \min(c y_i)} = \frac{\sqrt{c^2 \cdot \frac{1}{n} \sum_{i=1}^n
(y_i - \hat{y}_i)^2}}{c (\max(y_i) - \min(y_i))} = \frac{c
\sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}}{c (\max(y_i) -
\min(y_i))} = \text{NRMSE}(y_i, \hat{y}_i)\]</span></p>
<p>Similarly, for the standard deviation reference:</p>
<p><span class="math display">\[\text{NRMSE}_{\sigma}(c y_i, c
\hat{y}_i) = \frac{\sqrt{\frac{1}{n} \sum_{i=1}^n (c y_i - c
\hat{y}_i)^2}}{\sqrt{\frac{1}{n} \sum_{i=1}^n (c y_i - c \bar{y})^2}} =
\frac{\sqrt{c^2 \cdot \frac{1}{n} \sum_{i=1}^n (y_i -
\hat{y}_i)^2}}{\sqrt{c^2 \cdot \frac{1}{n} \sum_{i=1}^n (y_i -
\bar{y})^2}} = \frac{c \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i -
\hat{y}_i)^2}}{c \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})^2}} =
\text{NRMSE}_{\sigma}(y_i, \hat{y}_i)\]</span></p>
<p>This proves the Normalization Theorem.</p>
<h1 class="unnumbered" id="properties-and-corollaries">4. Properties and
Corollaries</h1>
<p><strong>Property 1:</strong> The NRMSE is always non-negative.</p>
<p><span class="math display">\[\forall y_i, \hat{y}_i \in \mathbb{R},
\text{NRMSE}(y_i, \hat{y}_i) \geq 0\]</span></p>
<p><strong>Proof:</strong> Since the RMSE is non-negative and the
reference (range or standard deviation) is positive, their ratio is also
non-negative.</p>
<p><strong>Property 2:</strong> The NRMSE attains its minimum value of 0
if and only if all predicted values match the observed values.</p>
<p><span class="math display">\[\text{NRMSE}(y_i, \hat{y}_i) = 0 \iff
y_i = \hat{y}_i \forall i\]</span></p>
<p><strong>Proof:</strong> If <span class="math inline">\(y_i =
\hat{y}_i \forall i\)</span>, then RMSE = 0, and thus NRMSE = 0.
Conversely, if NRMSE = 0, then RMSE = 0, implying <span
class="math inline">\(y_i = \hat{y}_i \forall i\)</span>.</p>
<p><strong>Property 3:</strong> The NRMSE is scale-invariant.</p>
<p><span class="math display">\[\text{NRMSE}(c y_i, c \hat{y}_i) =
\text{NRMSE}(y_i, \hat{y}_i)\]</span></p>
<p>This property has already been proven in the context of the
Normalization Theorem.</p>
<h1 class="unnumbered" id="conclusion">5. Conclusion</h1>
<p>The Normalized Root Mean Square Error (NRMSE) is a powerful and
versatile metric for evaluating the performance of predictive models.
Its ability to provide a scale-invariant measure of error makes it
indispensable in comparative analyses across diverse datasets. By
understanding its definitions, theorems, and properties, we can
appreciate the robustness and utility of NRMSE in statistical modeling
and data analysis.</p>
</body>
</html>
{% include "footer.html" %}

