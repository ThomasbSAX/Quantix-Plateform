{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Cumulative Accuracy Profile (CAP) : Une Analyse Approfondie</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Cumulative Accuracy Profile (CAP) : Une Analyse
Approfondie</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’évaluation des modèles de prédiction, notamment dans le domaine du
crédit ou de l’assurance, est cruciale pour comprendre leur performance.
Le Cumulative Accuracy Profile (CAP) émerge comme un outil puissant pour
visualiser et quantifier cette performance. Historiquement, les courbes
ROC ont dominé ce domaine, mais le CAP offre une perspective plus
intuitive et directement interprétable.</p>
<p>Le CAP résout plusieurs problèmes clés :</p>
<ul>
<li><p>Il permet de visualiser la performance du modèle sur l’ensemble
des données, pas seulement sur un seuil particulier.</p></li>
<li><p>Il offre une comparaison directe entre le modèle et un modèle de
référence, souvent un modèle aléatoire.</p></li>
<li><p>Il est particulièrement utile pour les modèles binaires et
multiclasses, où la précision de prédiction est cruciale.</p></li>
</ul>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre le CAP, commençons par définir les concepts de base.
Supposons que nous avons un ensemble de données <span
class="math inline">\(\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n\)</span>, où
<span class="math inline">\(y_i \in \{0, 1\}\)</span> est la variable
cible et <span class="math inline">\(x_i\)</span> les
caractéristiques.</p>
<p>Nous cherchons à prédire <span
class="math inline">\(\hat{y}_i\)</span> à partir de <span
class="math inline">\(x_i\)</span>. La performance du modèle peut être
évaluée en comparant <span class="math inline">\(\hat{y}_i\)</span> et
<span class="math inline">\(y_i\)</span>.</p>
<p>Définissons formellement le CAP :</p>
<div class="definition">
<p>Le Cumulative Accuracy Profile (CAP) est une courbe qui représente la
proportion de positifs correctement prédits par un modèle en fonction de
la proportion totale des positifs dans l’ensemble de données.</p>
<p>Soit <span class="math inline">\(\hat{y}_i\)</span> la probabilité
prédite par le modèle pour l’observation <span
class="math inline">\(i\)</span>, et <span
class="math inline">\(y_i\)</span> la vraie classe. On trie les
observations par ordre décroissant de <span
class="math inline">\(\hat{y}_i\)</span>.</p>
<p>Le CAP est défini comme : <span class="math display">\[\text{CAP}(p)
= \frac{1}{n^+} \sum_{i=1}^{\lfloor p n \rfloor} y_{\sigma(i)}\]</span>
où <span class="math inline">\(n^+\)</span> est le nombre total de
positifs dans l’ensemble de données, <span
class="math inline">\(n\)</span> est la taille totale de l’ensemble de
données, et <span class="math inline">\(\sigma\)</span> est le tri
décroissant des probabilités prédites.</p>
</div>
<h1 id="théorèmes-et-propriétés">Théorèmes et Propriétés</h1>
<p>Le CAP possède plusieurs propriétés intéressantes qui le rendent
utile pour l’évaluation des modèles.</p>
<div class="theorem">
<p>La courbe CAP est convexe. Cela signifie que pour tout <span
class="math inline">\(p_1, p_2 \in [0, 1]\)</span> et <span
class="math inline">\(\lambda \in [0, 1]\)</span>, on a : <span
class="math display">\[\text{CAP}(\lambda p_1 + (1 - \lambda) p_2) \geq
\lambda \text{CAP}(p_1) + (1 - \lambda) \text{CAP}(p_2)\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La convexité du CAP découle du fait que le tri des
probabilités prédites est un processus ordonné. En effet, la fonction
CAP est une somme cumulative de valeurs binaires triées par ordre
décroissant, ce qui garantit la convexité. ◻</p>
</div>
<div class="theorem">
<p>Pour un modèle aléatoire, la courbe CAP est une droite de pente 1.
Cela signifie que : <span
class="math display">\[\text{CAP}_{\text{aléatoire}}(p) = p\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour un modèle aléatoire, les probabilités prédites
sont uniformément distribuées entre 0 et 1. Par conséquent, la
proportion de positifs correctement prédits est égale à la proportion
totale des positifs dans l’ensemble de données, d’où la droite de pente
1. ◻</p>
</div>
<h1 id="preuves-et-développements">Preuves et Développements</h1>
<p>Pour illustrer davantage, développons une preuve détaillée de la
propriété de convexité.</p>
<div class="proof">
<p><em>Proof.</em> Considérons deux points <span
class="math inline">\(p_1\)</span> et <span
class="math inline">\(p_2\)</span> sur la courbe CAP, avec <span
class="math inline">\(p_1 &lt; p_2\)</span>. La valeur de CAP en ces
points est donnée par : <span class="math display">\[\text{CAP}(p_1) =
\frac{1}{n^+} \sum_{i=1}^{\lfloor p_1 n \rfloor} y_{\sigma(i)}\]</span>
<span class="math display">\[\text{CAP}(p_2) = \frac{1}{n^+}
\sum_{i=1}^{\lfloor p_2 n \rfloor} y_{\sigma(i)}\]</span></p>
<p>Pour un <span class="math inline">\(\lambda \in [0, 1]\)</span>, la
valeur de CAP en <span class="math inline">\(\lambda p_1 + (1 - \lambda)
p_2\)</span> est : <span class="math display">\[\text{CAP}(\lambda p_1 +
(1 - \lambda) p_2) = \frac{1}{n^+} \sum_{i=1}^{\lfloor (\lambda p_1 + (1
- \lambda) p_2) n \rfloor} y_{\sigma(i)}\]</span></p>
<p>En utilisant la convexité de la somme cumulative, on obtient : <span
class="math display">\[\text{CAP}(\lambda p_1 + (1 - \lambda) p_2) \geq
\lambda \text{CAP}(p_1) + (1 - \lambda) \text{CAP}(p_2)\]</span> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Le CAP possède plusieurs propriétés supplémentaires qui en font un
outil puissant pour l’évaluation des modèles.</p>
<ol>
<li><p><strong>Proportion de Positifs Corrects</strong> : Le CAP en
<span class="math inline">\(p=1\)</span> donne la proportion totale de
positifs correctement prédits par le modèle. <span
class="math display">\[\text{CAP}(1) = \frac{1}{n^+} \sum_{i=1}^n
y_{\sigma(i)}\]</span></p></li>
<li><p><strong>Comparaison des Modèles</strong> : Deux modèles peuvent
être comparés en comparant leurs courbes CAP. Le modèle avec la courbe
CAP au-dessus de l’autre est considéré comme meilleur.</p></li>
<li><p><strong>Intégrale du CAP</strong> : L’aire sous la courbe CAP
(CAP AUC) peut être utilisée comme une mesure globale de performance.
Plus cette aire est grande, meilleur est le modèle. <span
class="math display">\[\text{CAP AUC} = \int_0^1 \text{CAP}(p) \,
dp\]</span></p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>Le Cumulative Accuracy Profile (CAP) est un outil puissant et
intuitif pour évaluer la performance des modèles de prédiction. Ses
propriétés de convexité, sa comparaison avec un modèle aléatoire, et son
utilisation pour la comparaison des modèles en font un outil
indispensable dans l’arsenal de l’évaluateur de modèles.</p>
</body>
</html>
{% include "footer.html" %}

