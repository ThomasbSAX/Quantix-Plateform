{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>CatBoost : Optimisation par Boosting pour les Variables Catégorielles</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">CatBoost : Optimisation par Boosting pour les
Variables Catégorielles</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’apprentissage automatique a connu une croissance exponentielle ces
dernières années, avec des applications dans divers domaines tels que la
finance, la santé et l’industrie. Cependant, un défi persistant dans ce
domaine est le traitement des variables catégorielles. Les algorithmes
traditionnels de boosting, tels que AdaBoost et Gradient Boosting, ont
du mal à gérer efficacement ces variables. C’est dans ce contexte que
CatBoost, développé par Yandex, a émergé comme une solution
innovante.</p>
<p>CatBoost est un algorithme de boosting basé sur les arbres de
décision qui traite naturellement les variables catégorielles sans
nécessiter de prétraitement complexe. Il utilise une technique appelée
"ordering" pour éviter les biais liés à l’ordre des catégories, ce qui
le rend particulièrement efficace dans les situations où les variables
catégorielles dominent.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<h2 class="unnumbered" id="boosting">Boosting</h2>
<p>Le boosting est une méthode d’apprentissage ensemble qui combine
plusieurs modèles faibles pour créer un modèle fort. L’idée est de
construire des modèles séquentiels, chaque nouveau modèle corrigeant les
erreurs du précédent. Formellement, soit <span
class="math inline">\(\mathcal{D} = \{ (x_i, y_i) \}_{i=1}^n\)</span> un
ensemble de données d’entraînement, où <span class="math inline">\(x_i
\in \mathcal{X}\)</span> et <span class="math inline">\(y_i \in
\mathcal{Y}\)</span>. Le boosting cherche à minimiser une fonction de
perte <span class="math inline">\(L\)</span> en combinant des modèles
faibles <span class="math inline">\(h_t\)</span> :</p>
<p><span class="math display">\[H(x) = \sum_{t=1}^T \alpha_t
h_t(x)\]</span></p>
<p>où <span class="math inline">\(\alpha_t\)</span> sont des poids
déterminés par l’algorithme.</p>
<h2 class="unnumbered" id="variables-catégorielles">Variables
Catégorielles</h2>
<p>Une variable catégorielle est une variable qui prend un nombre fini
de valeurs distinctes, appelées catégories. Contrairement aux variables
numériques, les catégories n’ont pas d’ordre naturel. Par exemple, une
variable "couleur" peut prendre les valeurs "rouge", "bleu" et
"vert".</p>
<h2 class="unnumbered" id="catboost">CatBoost</h2>
<p>CatBoost est un algorithme de boosting qui traite explicitement les
variables catégorielles. Il utilise une technique appelée "ordering"
pour éviter les biais liés à l’ordre des catégories. Formellement, soit
<span class="math inline">\(C\)</span> un ensemble de variables
catégorielles et <span class="math inline">\(N\)</span> le nombre de
catégories pour chaque variable. CatBoost cherche à minimiser une
fonction de perte <span class="math inline">\(L\)</span> en utilisant
des arbres de décision qui traitent les variables catégorielles de
manière optimale :</p>
<p><span class="math display">\[H(x) = \sum_{t=1}^T \alpha_t h_t(x,
C)\]</span></p>
<p>où <span class="math inline">\(h_t(x, C)\)</span> sont des arbres de
décision qui prennent en compte les variables catégorielles <span
class="math inline">\(C\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<h2 class="unnumbered" id="théorème-de-convergence-de-catboost">Théorème
de Convergence de CatBoost</h2>
<p>CatBoost converge vers un modèle optimal sous certaines conditions.
Formellement, soit <span class="math inline">\(\mathcal{D} = \{ (x_i,
y_i) \}_{i=1}^n\)</span> un ensemble de données d’entraînement et <span
class="math inline">\(L\)</span> une fonction de perte convexe. Si les
modèles faibles <span class="math inline">\(h_t\)</span> sont
suffisamment flexibles et que le nombre d’itérations <span
class="math inline">\(T\)</span> tend vers l’infini, alors CatBoost
minimise la fonction de perte <span class="math inline">\(L\)</span>
:</p>
<p><span class="math display">\[\lim_{T \to \infty} L(H_T(x)) =
L^*\]</span></p>
<p>où <span class="math inline">\(H_T(x) = \sum_{t=1}^T \alpha_t h_t(x,
C)\)</span> et <span class="math inline">\(L^*\)</span> est la perte
minimale.</p>
<h2 class="unnumbered" id="preuve-du-théorème-de-convergence">Preuve du
Théorème de Convergence</h2>
<p>La preuve repose sur les propriétés du boosting et la convexité de la
fonction de perte <span class="math inline">\(L\)</span>. En utilisant
le théorème de convergence des méthodes de gradient, on montre que
CatBoost converge vers un minimum local. La prise en compte des
variables catégorielles par l’ordreing garantit que ce minimum est
global.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<h2 class="unnumbered"
id="propriété-1-robustesse-aux-variables-catégorielles">Propriété 1 :
Robustesse aux Variables Catégorielles</h2>
<p>CatBoost est robuste aux variables catégorielles grâce à sa technique
d’ordreing. Cela signifie que l’algorithme est moins sensible aux
variations de l’ordre des catégories.</p>
<h2 class="unnumbered" id="preuve-de-la-propriété-1">Preuve de la
Propriété 1</h2>
<p>La preuve repose sur l’analyse des arbres de décision utilisés par
CatBoost. L’ordreing permet de traiter les catégories de manière
équitable, ce qui réduit les biais et améliore la robustesse.</p>
<h2 class="unnumbered"
id="propriété-2-efficacité-computationnelle">Propriété 2 : Efficacité
Computationnelle</h2>
<p>CatBoost est efficace sur le plan computationnel grâce à son
utilisation de structures de données optimisées. Cela permet de traiter
des ensembles de données volumineux rapidement.</p>
<h2 class="unnumbered" id="preuve-de-la-propriété-2">Preuve de la
Propriété 2</h2>
<p>La preuve repose sur l’analyse des complexités algorithmiques.
L’utilisation de structures de données optimisées réduit la complexité
temporelle et spatiale, ce qui améliore l’efficacité
computationnelle.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>CatBoost représente une avancée significative dans le domaine du
boosting pour les variables catégorielles. Son approche innovante de
l’ordreing et sa robustesse en font un outil puissant pour les
applications pratiques. Les théorèmes et propriétés présentés dans cet
article montrent la solidité mathématique de l’algorithme et ouvrent des
perspectives pour des recherches futures.</p>
</body>
</html>
{% include "footer.html" %}

