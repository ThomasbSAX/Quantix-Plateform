{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Inégalité de Chernoff : Un outil fondamental en probabilités</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Inégalité de Chernoff : Un outil fondamental en
probabilités</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’inégalité de Chernoff, nommée en l’honneur du mathématicien
américain Herman Chernoff, est un résultat central en théorie des
probabilités. Elle généralise les inégalités de Markov et Chebyshev,
permettant d’estimer la probabilité qu’une somme de variables aléatoires
s’écarte significativement de sa valeur attendue. Cette inégalité est
particulièrement utile en analyse statistique, en théorie des graphes
aléatoires, et dans de nombreuses applications en informatique
théorique.</p>
<p>L’émergence de l’inégalité de Chernoff est motivée par le besoin de
contrôles probabilistes plus fins que ceux fournis par les inégalités
classiques. Elle est indispensable dans des contextes où l’on doit
garantir des bornes strictes sur les déviations, comme dans les
algorithmes de approximation ou les protocoles de communication.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire l’inégalité de Chernoff, commençons par rappeler
quelques notions fondamentales. Considérons une suite de variables
aléatoires indépendantes <span class="math inline">\(X_1, X_2, \ldots,
X_n\)</span> à valeurs dans <span
class="math inline">\(\mathbb{R}\)</span>, chacune ayant une espérance
<span class="math inline">\(\mathbb{E}[X_i] = \mu_i\)</span> et une
variance finie. Nous cherchons à estimer la probabilité que leur somme
<span class="math inline">\(S_n = X_1 + X_2 + \ldots + X_n\)</span>
s’écarte de son espérance <span class="math inline">\(\mu = \sum_{i=1}^n
\mu_i\)</span>.</p>
<p>Formellement, l’inégalité de Chernoff s’énonce comme suit :</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des
variables aléatoires indépendantes à valeurs dans <span
class="math inline">\(\mathbb{R}^+\)</span>, et <span
class="math inline">\(S_n = \sum_{i=1}^n X_i\)</span>. Pour tout <span
class="math inline">\(t &gt; 0\)</span>, on a : <span
class="math display">\[\mathbb{P}(S_n \geq (1 + t)\mu) \leq \left(
\frac{e^t}{(1 + t)^{1 + t}} \right)^\mu\]</span> où <span
class="math inline">\(\mu = \mathbb{E}[S_n]\)</span>.</p>
</div>
<p>Une autre formulation, plus générale, est la suivante :</p>
<div class="theorem">
<p>Pour tout <span class="math inline">\(t &gt; 0\)</span>, on a : <span
class="math display">\[\mathbb{P}(S_n - \mu \geq t) \leq e^{-t^2 /
(2\sigma^2)}\]</span> où <span class="math inline">\(\sigma^2 =
\text{Var}(S_n)\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer l’inégalité de Chernoff, nous utilisons la fonction
génératrice des moments. Soit <span class="math inline">\(M_X(s) =
\mathbb{E}[e^{sX}]\)</span> la fonction génératrice des moments d’une
variable aléatoire <span class="math inline">\(X\)</span>. Par
indépendance, la fonction génératrice de <span
class="math inline">\(S_n\)</span> est donnée par : <span
class="math display">\[M_{S_n}(s) = \prod_{i=1}^n
M_{X_i}(s)\]</span></p>
<p>Nous cherchons à borner <span class="math inline">\(\mathbb{P}(S_n
\geq (1 + t)\mu)\)</span>. Par l’inégalité de Markov, nous avons : <span
class="math display">\[\mathbb{P}(S_n \geq (1 + t)\mu) =
\mathbb{P}(e^{sS_n} \geq e^{s(1 + t)\mu}) \leq e^{-s(1 + t)\mu}
\mathbb{E}[e^{sS_n}] = e^{-s(1 + t)\mu} M_{S_n}(s)\]</span></p>
<p>Choisissons <span class="math inline">\(s\)</span> de manière à
minimiser cette borne. En prenant la dérivée par rapport à <span
class="math inline">\(s\)</span>, nous trouvons que le choix optimal est
<span class="math inline">\(s = t/(1 + t)\)</span>. En substituant cette
valeur, nous obtenons : <span class="math display">\[\mathbb{P}(S_n \geq
(1 + t)\mu) \leq e^{-t\mu/(1 + t)} M_{S_n}\left( \frac{t}{1 + t}
\right)\]</span></p>
<p>En utilisant l’inégalité <span class="math inline">\(M_{X_i}(s) \leq
e^{s\mu_i}\)</span>, nous avons : <span
class="math display">\[M_{S_n}\left( \frac{t}{1 + t} \right) \leq
e^{(t/(1 + t))\mu}\]</span></p>
<p>En combinant ces résultats, nous obtenons finalement : <span
class="math display">\[\mathbb{P}(S_n \geq (1 + t)\mu) \leq e^{-t\mu/(1
+ t)} e^{(t/(1 + t))\mu} = \left( \frac{e^t}{(1 + t)^{1 + t}}
\right)^\mu\]</span></p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’inégalité de Chernoff possède plusieurs propriétés intéressantes,
que nous énumérons ci-dessous :</p>
<ol>
<li><p>**Symétrie** : L’inégalité de Chernoff peut également être
formulée pour les déviations négatives. Pour tout <span
class="math inline">\(t &gt; 0\)</span>, on a : <span
class="math display">\[\mathbb{P}(S_n \leq (1 - t)\mu) \leq \left(
\frac{e^{-t}}{(1 - t)^{1 - t}} \right)^\mu\]</span></p></li>
<li><p>**Bornes exponentielles** : Pour des déviations plus importantes,
l’inégalité de Chernoff fournit des bornes exponentielles. Par exemple,
pour tout <span class="math inline">\(t &gt; 0\)</span>, on a : <span
class="math display">\[\mathbb{P}(S_n - \mu \geq t) \leq e^{-t^2 /
(2\sigma^2)}\]</span> où <span class="math inline">\(\sigma^2 =
\text{Var}(S_n)\)</span>.</p></li>
<li><p>**Application aux variables de Bernoulli** : L’inégalité de
Chernoff est particulièrement utile pour les sommes de variables de
Bernoulli. Si <span class="math inline">\(X_i\)</span> sont des
variables de Bernoulli de paramètre <span
class="math inline">\(p\)</span>, alors pour tout <span
class="math inline">\(t &gt; 0\)</span>, on a : <span
class="math display">\[\mathbb{P}\left( \sum_{i=1}^n X_i - np \geq t
\right) \leq e^{-t^2 / (2np(1 - p))}\]</span></p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’inégalité de Chernoff est un outil puissant et polyvalent en
théorie des probabilités. Ses applications vont des bornes de
concentration aux algorithmes aléatoires, en passant par l’analyse des
graphes. Grâce à ses bornes exponentielles, elle permet de garantir des
déviations strictes avec une grande précision, ce qui en fait un
résultat fondamental dans de nombreux domaines des mathématiques
appliquées.</p>
</body>
</html>
{% include "footer.html" %}

