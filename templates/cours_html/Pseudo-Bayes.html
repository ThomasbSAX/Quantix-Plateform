{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Pseudo-Bayes : Une Approche Innovante en Théorie de la Décision</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Pseudo-Bayes : Une Approche Innovante en Théorie de la
Décision</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La théorie de la décision bayésienne est un pilier fondamental en
statistique et en apprentissage automatique. Elle permet de prendre des
décisions optimales sous incertitude en utilisant les probabilités a
posteriori. Cependant, dans de nombreux contextes pratiques, le calcul
exact des distributions a posteriori est soit impossible, soit trop
coûteux. C’est ici qu’intervient l’approche pseudo-bayésienne, une
méthode qui cherche à approximer les résultats bayésiens tout en étant
plus efficace computationnellement.</p>
<p>L’idée centrale derrière l’approche pseudo-bayésienne est de
remplacer les distributions a posteriori exactes par des approximations
qui préservent certaines propriétés souhaitables. Cette approche est
particulièrement utile dans les problèmes de grande dimension, où les
méthodes bayésiennes traditionnelles deviennent intraitables.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant de définir formellement l’approche pseudo-bayésienne, il est
essentiel de comprendre ce que nous cherchons à accomplir. Supposons que
nous ayons un modèle statistique paramétré par un vecteur <span
class="math inline">\(\theta \in \Theta\)</span>. En théorie bayésienne
classique, nous cherchons à inférer la distribution a posteriori de
<span class="math inline">\(\theta\)</span> donnée des données observées
<span class="math inline">\(X\)</span>. Cette distribution est
proportionnelle au produit de la vraisemblance et de la distribution a
priori :</p>
<p><span class="math display">\[p(\theta | X) \propto p(X | \theta)
p(\theta).\]</span></p>
<p>Cependant, dans de nombreux cas, le calcul exact de cette
distribution est impossible. L’approche pseudo-bayésienne vise à trouver
une approximation <span class="math inline">\(\tilde{p}(\theta |
X)\)</span> qui soit plus facile à calculer, tout en préservant
certaines propriétés de la distribution a posteriori exacte.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathcal{M}\)</span> une famille de
distributions paramétrées par un vecteur <span
class="math inline">\(\theta \in \Theta\)</span>. Une approximation
pseudo-bayésienne est une distribution <span
class="math inline">\(\tilde{p}(\theta | X)\)</span> telle que :</p>
<p><span class="math display">\[\tilde{p}(\theta | X) =
\arg\min_{q(\theta) \in \mathcal{Q}} D(q(\theta) \| p(\theta |
X)),\]</span></p>
<p>où <span class="math inline">\(D\)</span> est une divergence
appropriée (par exemple, la divergence de Kullback-Leibler) et <span
class="math inline">\(\mathcal{Q}\)</span> est une famille de
distributions plus simple que la distribution a posteriori exacte.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux en théorie pseudo-bayésienne est le
théorème de l’approximation optimale, qui garantit que sous certaines
conditions, l’approximation pseudo-bayésienne est asymptotiquement
équivalente à la distribution a posteriori exacte.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\mathcal{M}\)</span> une famille de
modèles paramétrés par <span class="math inline">\(\theta \in
\Theta\)</span> et soit <span class="math inline">\(X^n = (X_1, \dots,
X_n)\)</span> un échantillon i.i.d. de distribution <span
class="math inline">\(p(X | \theta)\)</span>. Supposons que la famille
<span class="math inline">\(\mathcal{Q}\)</span> des approximations
pseudo-bayésiennes soit suffisamment riche pour contenir une
approximation de la distribution a posteriori exacte. Alors, sous
certaines conditions régularité, nous avons :</p>
<p><span class="math display">\[\lim_{n \to \infty} D(\tilde{p}(\theta |
X^n) \| p(\theta | X^n)) = 0,\]</span></p>
<p>où <span class="math inline">\(\tilde{p}(\theta | X^n)\)</span> est
l’approximation pseudo-bayésienne de la distribution a posteriori <span
class="math inline">\(p(\theta | X^n)\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de l’approximation optimale, nous devons
montrer que la divergence entre l’approximation pseudo-bayésienne et la
distribution a posteriori exacte tend vers zéro lorsque le nombre de
données <span class="math inline">\(n\)</span> tend vers l’infini.</p>
<div class="proof">
<p><em>Proof.</em> Considérons la divergence de Kullback-Leibler entre
l’approximation pseudo-bayésienne <span
class="math inline">\(\tilde{p}(\theta | X^n)\)</span> et la
distribution a posteriori exacte <span class="math inline">\(p(\theta |
X^n)\)</span> :</p>
<p><span class="math display">\[D(\tilde{p}(\theta | X^n) \| p(\theta |
X^n)) = \mathbb{E}_{\tilde{p}(\theta | X^n)} \left[ \log
\frac{\tilde{p}(\theta | X^n)}{p(\theta | X^n)} \right].\]</span></p>
<p>En utilisant le fait que <span class="math inline">\(\tilde{p}(\theta
| X^n)\)</span> minimise la divergence de Kullback-Leibler parmi toutes
les distributions dans <span class="math inline">\(\mathcal{Q}\)</span>,
nous avons :</p>
<p><span class="math display">\[D(\tilde{p}(\theta | X^n) \| p(\theta |
X^n)) \leq D(q(\theta) \| p(\theta | X^n)),\]</span></p>
<p>pour toute distribution <span class="math inline">\(q(\theta) \in
\mathcal{Q}\)</span>. En choisissant <span
class="math inline">\(q(\theta)\)</span> suffisamment proche de <span
class="math inline">\(p(\theta | X^n)\)</span>, nous pouvons faire
tendre la divergence vers zéro lorsque <span
class="math inline">\(n\)</span> tend vers l’infini. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’approche pseudo-bayésienne possède plusieurs propriétés
intéressantes qui la rendent attrayante pour de nombreuses
applications.</p>
<ol>
<li><p><strong>Propriété d’Approximation</strong> : Sous certaines
conditions, l’approximation pseudo-bayésienne peut être aussi précise
que la distribution a posteriori exacte, tout en étant plus facile à
calculer.</p>
<div class="proof">
<p><em>Proof.</em> Cette propriété découle directement du théorème de
l’approximation optimale. En effet, si la famille <span
class="math inline">\(\mathcal{Q}\)</span> est suffisamment riche,
l’approximation pseudo-bayésienne peut approcher la distribution a
posteriori exacte avec une précision arbitraire. ◻</p>
</div></li>
<li><p><strong>Efficacité Computationnelle</strong> : L’approche
pseudo-bayésienne permet de réduire la complexité computationnelle des
inférences bayésiennes, ce qui est particulièrement utile dans les
problèmes de grande dimension.</p>
<div class="proof">
<p><em>Proof.</em> En utilisant des familles <span
class="math inline">\(\mathcal{Q}\)</span> plus simples que la
distribution a posteriori exacte, l’approche pseudo-bayésienne permet de
réduire le coût computationnel tout en préservant certaines propriétés
souhaitables. ◻</p>
</div></li>
<li><p><strong>Robustesse</strong> : L’approche pseudo-bayésienne est
souvent plus robuste aux choix des distributions a priori que les
méthodes bayésiennes traditionnelles.</p>
<div class="proof">
<p><em>Proof.</em> Cela est dû au fait que l’approximation
pseudo-bayésienne dépend moins fortement de la distribution a priori,
car elle minimise une divergence par rapport à la distribution a
posteriori exacte. ◻</p>
</div></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’approche pseudo-bayésienne offre une alternative prometteuse aux
méthodes bayésiennes traditionnelles, en particulier dans les contextes
où le calcul exact des distributions a posteriori est intraitable. En
approximant ces distributions tout en préservant certaines propriétés
souhaitables, l’approche pseudo-bayésienne permet de tirer parti des
avantages de la théorie bayésienne tout en étant plus efficace
computationnellement. Les propriétés et théorèmes présentés dans cet
article montrent que cette approche est non seulement viable, mais aussi
potentiellement supérieure dans de nombreuses applications
pratiques.</p>
</body>
</html>
{% include "footer.html" %}

