{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Encodage par Extraction de Caractéristiques de Dispersion</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Encodage par Extraction de Caractéristiques de
Dispersion</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’encodage par extraction de caractéristiques de dispersion est une
technique avancée en traitement du signal et en analyse de données. Elle
trouve ses racines dans la théorie des ondelettes et les méthodes
d’analyse spectrale, mais son développement récent est fortement
influencé par l’essor des techniques d’apprentissage automatique et de
traitement du signal non stationnaire.</p>
<p>L’idée centrale derrière cette méthode est d’extraire des
caractéristiques pertinentes à partir de signaux ou de données, en se
concentrant sur les variations et les dispersions observées. Ces
caractéristiques peuvent ensuite être utilisées pour des tâches telles
que la classification, la reconnaissance de motifs ou la compression de
données.</p>
<p>Cette technique est particulièrement indispensable dans des domaines
où les signaux sont complexes et non stationnaires, comme en biologie
(analyse de signaux EEG), en finance (prévision de séries temporelles)
ou en ingénierie (analyse de vibrations mécaniques).</p>
<h1 id="définitions">Définitions</h1>
<p>Nous allons maintenant définir formellement l’encodage par extraction
de caractéristiques de dispersion.</p>
<h2 id="caractéristiques-de-dispersion">Caractéristiques de
Dispersion</h2>
<p>Considérons un signal <span class="math inline">\(x(t)\)</span>, où
<span class="math inline">\(t\)</span> représente le temps. Nous
cherchons à capturer les variations de ce signal autour d’une valeur
moyenne.</p>
<div class="definition">
<p>Soit <span class="math inline">\(x(t)\)</span> un signal défini sur
un intervalle <span class="math inline">\([a, b]\)</span>. La
caractéristique de dispersion <span class="math inline">\(D\)</span> est
définie comme la variance du signal autour de sa moyenne :</p>
<p><span class="math display">\[D = \frac{1}{b - a} \int_{a}^{b} (x(t) -
\mu)^2 \, dt\]</span></p>
<p>où <span class="math inline">\(\mu\)</span> est la moyenne du signal
:</p>
<p><span class="math display">\[\mu = \frac{1}{b - a} \int_{a}^{b} x(t)
\, dt\]</span></p>
</div>
<h2 id="encodage-par-extraction-de-caractéristiques">Encodage par
Extraction de Caractéristiques</h2>
<p>L’encodage consiste à transformer le signal original en un vecteur de
caractéristiques de dispersion.</p>
<div class="definition">
<p>Soit <span class="math inline">\(x(t)\)</span> un signal défini sur
un intervalle <span class="math inline">\([a, b]\)</span>. L’encodage
par extraction de caractéristiques de dispersion est un vecteur <span
class="math inline">\(E\)</span> défini par :</p>
<p><span class="math display">\[E = [D_1, D_2, \ldots, D_n]\]</span></p>
<p>où <span class="math inline">\(D_i\)</span> est la caractéristique de
dispersion du signal sur le sous-intervalle <span
class="math inline">\([a_i, b_i]\)</span>, avec <span
class="math inline">\(a_1 = a\)</span>, <span class="math inline">\(b_n
= b\)</span> et <span class="math inline">\(b_i = a_{i+1}\)</span>.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Nous allons maintenant énoncer un théorème important concernant
l’encodage par extraction de caractéristiques de dispersion.</p>
<h2 id="stabilité-de-lencodage">Stabilité de l’Encodage</h2>
<div class="theorem">
<p>Soit <span class="math inline">\(x(t)\)</span> et <span
class="math inline">\(y(t)\)</span> deux signaux définis sur un
intervalle <span class="math inline">\([a, b]\)</span>. Si pour tout
<span class="math inline">\(t \in [a, b]\)</span>, on a :</p>
<p><span class="math display">\[|x(t) - y(t)| \leq \epsilon\]</span></p>
<p>alors les encodages correspondants <span
class="math inline">\(E_x\)</span> et <span
class="math inline">\(E_y\)</span> satisfont :</p>
<p><span class="math display">\[\|E_x - E_y\| \leq C
\epsilon\]</span></p>
<p>où <span class="math inline">\(C\)</span> est une constante dépendant
de l’intervalle <span class="math inline">\([a, b]\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Nous allons maintenant prouver le théorème de stabilité de
l’encodage.</p>
<h2 id="preuve-du-théorème-de-stabilité">Preuve du Théorème de
Stabilité</h2>
<div class="proof">
<p><em>Proof.</em> Considérons deux signaux <span
class="math inline">\(x(t)\)</span> et <span
class="math inline">\(y(t)\)</span> définis sur un intervalle <span
class="math inline">\([a, b]\)</span>. Nous avons :</p>
<p><span class="math display">\[|x(t) - y(t)| \leq \epsilon\]</span></p>
<p>Pour chaque sous-intervalle <span class="math inline">\([a_i,
b_i]\)</span>, la différence entre les caractéristiques de dispersion
correspondantes est :</p>
<p><span class="math display">\[|D_{x,i} - D_{y,i}| \leq \frac{1}{b_i -
a_i} \int_{a_i}^{b_i} |(x(t) - \mu_x) - (y(t) - \mu_y)|^2 \,
dt\]</span></p>
<p>où <span class="math inline">\(\mu_x\)</span> et <span
class="math inline">\(\mu_y\)</span> sont les moyennes des signaux <span
class="math inline">\(x(t)\)</span> et <span
class="math inline">\(y(t)\)</span> sur le sous-intervalle <span
class="math inline">\([a_i, b_i]\)</span>.</p>
<p>En utilisant l’inégalité triangulaire et le fait que <span
class="math inline">\(|\mu_x - \mu_y| \leq \epsilon\)</span>, nous
obtenons :</p>
<p><span class="math display">\[|D_{x,i} - D_{y,i}| \leq 2 \epsilon^2 +
4 \epsilon |\mu_x - \mu_y|\]</span></p>
<p>En sommant sur tous les sous-intervalles, nous obtenons :</p>
<p><span class="math display">\[\|E_x - E_y\| \leq 2n\epsilon^2 +
4\epsilon \sum_{i=1}^n |\mu_x - \mu_y|\]</span></p>
<p>où <span class="math inline">\(n\)</span> est le nombre de
sous-intervalles. En utilisant à nouveau l’inégalité <span
class="math inline">\(|\mu_x - \mu_y| \leq \epsilon\)</span>, nous avons
:</p>
<p><span class="math display">\[\sum_{i=1}^n |\mu_x - \mu_y| \leq
n\epsilon\]</span></p>
<p>Ainsi, nous obtenons finalement :</p>
<p><span class="math display">\[\|E_x - E_y\| \leq 2n\epsilon^2 +
4n\epsilon^2 = C\epsilon\]</span></p>
<p>où <span class="math inline">\(C = 6n\)</span> est une constante
dépendant du nombre de sous-intervalles. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous allons maintenant énoncer quelques propriétés importantes de
l’encodage par extraction de caractéristiques de dispersion.</p>
<h2 id="propriétés">Propriétés</h2>
<ol>
<li><p>L’encodage est invariant par translation. C’est-à-dire que si
<span class="math inline">\(x(t)\)</span> et <span
class="math inline">\(y(t) = x(t + c)\)</span> pour une constante <span
class="math inline">\(c\)</span>, alors <span class="math inline">\(E_x
= E_y\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> La traduction ne change pas la variance du signal
autour de sa moyenne, donc les caractéristiques de dispersion restent
inchangées. ◻</p>
</div></li>
<li><p>L’encodage est invariant par scaling. C’est-à-dire que si <span
class="math inline">\(x(t)\)</span> et <span class="math inline">\(y(t)
= a x(b t)\)</span> pour des constantes <span class="math inline">\(a,
b\)</span>, alors <span class="math inline">\(E_x = E_y\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Le scaling affecte la moyenne et la variance du
signal, mais les caractéristiques de dispersion relatives restent
inchangées. ◻</p>
</div></li>
<li><p>L’encodage est stable par rapport aux perturbations petites. Cela
est une conséquence directe du théorème de stabilité.</p></li>
</ol>
<h2 id="corollaires">Corollaires</h2>
<div class="corollary">
<p>Si une suite de signaux <span class="math inline">\(x_n(t)\)</span>
converge uniformément vers un signal <span
class="math inline">\(x(t)\)</span>, alors les encodages correspondants
<span class="math inline">\(E_{x_n}\)</span> convergent vers l’encodage
<span class="math inline">\(E_x\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Cela découle directement du théorème de stabilité. En
effet, pour tout <span class="math inline">\(\epsilon &gt; 0\)</span>,
il existe un <span class="math inline">\(N\)</span> tel que pour tout
<span class="math inline">\(n \geq N\)</span>, on a :</p>
<p><span class="math display">\[|x_n(t) - x(t)| \leq
\epsilon\]</span></p>
<p>pour tout <span class="math inline">\(t \in [a, b]\)</span>. Par le
théorème de stabilité, nous avons :</p>
<p><span class="math display">\[\|E_{x_n} - E_x\| \leq C
\epsilon\]</span></p>
<p>pour tout <span class="math inline">\(n \geq N\)</span>. Cela montre
que <span class="math inline">\(E_{x_n}\)</span> converge vers <span
class="math inline">\(E_x\)</span>. ◻</p>
</div>
</body>
</html>
{% include "footer.html" %}

