{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Encodage Moyen : Une Exploration Mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Encodage Moyen : Une Exploration Mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’encodage moyen, ou encodage de Huffman, est une méthode d’encodage
de données qui vise à minimiser la longueur moyenne des messages
transmis. Cette technique, développée par David A. Huffman en 1952, est
fondée sur la théorie de l’information et trouve des applications dans
divers domaines tels que la compression de données, les
télécommunications et le traitement du signal.</p>
<p>L’encodage moyen émerge comme une réponse à la nécessité de
transmettre des informations de manière efficace, en réduisant au
maximum la redondance. Il est indispensable dans les systèmes où la
bande passante est limitée et où l’efficacité de la transmission est
cruciale.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’encodage moyen, il est essentiel de définir
quelques concepts clés.</p>
<h2 class="unnumbered" id="alphabet-et-fréquences">Alphabet et
Fréquences</h2>
<p>Considérons un alphabet <span class="math inline">\(\Sigma = \{a_1,
a_2, \ldots, a_n\}\)</span> où chaque symbole <span
class="math inline">\(a_i\)</span> apparaît avec une fréquence <span
class="math inline">\(f_i\)</span>. L’objectif est d’assigner à chaque
symbole un code binaire de longueur minimale, en tenant compte des
fréquences d’apparition.</p>
<h2 class="unnumbered" id="arbre-de-huffman">Arbre de Huffman</h2>
<p>Un arbre de Huffman est un arbre binaire où chaque feuille représente
un symbole de l’alphabet, et la longueur du chemin depuis la racine
jusqu’à une feuille représente la longueur du code pour ce symbole.</p>
<p>Formellement, un arbre de Huffman <span
class="math inline">\(T\)</span> est défini comme suit : <span
class="math display">\[T = (V, E)\]</span> où <span
class="math inline">\(V\)</span> est l’ensemble des nœuds et <span
class="math inline">\(E\)</span> est l’ensemble des arêtes. Chaque nœud
interne a exactement deux enfants, et chaque feuille est associée à un
symbole de l’alphabet.</p>
<h2 class="unnumbered" id="code-de-huffman">Code de Huffman</h2>
<p>Un code de Huffman est une fonction <span class="math inline">\(C:
\Sigma \rightarrow \{0,1\}^*\)</span> qui assigne à chaque symbole un
code binaire unique. La longueur du code pour un symbole <span
class="math inline">\(a_i\)</span> est donnée par la profondeur de la
feuille correspondante dans l’arbre de Huffman.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<h2 class="unnumbered" id="théorème-de-huffman">Théorème de Huffman</h2>
<p>Le théorème fondamental de l’encodage moyen stipule que l’arbre de
Huffman minimise la longueur moyenne des messages transmis.</p>
<p>Formellement, soit <span class="math inline">\(L\)</span> la longueur
moyenne des messages : <span class="math display">\[L = \sum_{i=1}^n f_i
\cdot |C(a_i)|\]</span> où <span class="math inline">\(|C(a_i)|\)</span>
est la longueur du code pour le symbole <span
class="math inline">\(a_i\)</span>.</p>
<p>Le théorème de Huffman affirme que : <span
class="math display">\[L_{\text{Huffman}} \leq L_{\text{autre}}\]</span>
pour tout autre code binaire sans préfixe.</p>
<h2 class="unnumbered" id="preuve-du-théorème-de-huffman">Preuve du
Théorème de Huffman</h2>
<p>Pour prouver ce théorème, nous devons montrer que l’arbre de Huffman
minimise la longueur moyenne des messages.</p>
<p>Considérons deux symboles <span class="math inline">\(a_i\)</span> et
<span class="math inline">\(a_j\)</span> avec des fréquences <span
class="math inline">\(f_i\)</span> et <span
class="math inline">\(f_j\)</span> respectivement. Si nous fusionnons
ces deux symboles en un seul nœud interne, la longueur moyenne des
messages sera minimisée.</p>
<p>En effet, fusionner les deux symboles les moins fréquents à chaque
étape garantit que la somme des fréquences est minimisée, ce qui conduit
à une longueur moyenne minimale.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<h2 class="unnumbered"
id="propriété-1-unicité-du-code-de-huffman">Propriété 1 : Unicité du
Code de Huffman</h2>
<p>Le code de Huffman est unique pour un ensemble donné de
fréquences.</p>
<h2 class="unnumbered" id="preuve-de-la-propriété-1">Preuve de la
Propriété 1</h2>
<p>Supposons qu’il existe deux codes de Huffman différents pour le même
ensemble de fréquences. Cela impliquerait que l’arbre de Huffman n’est
pas unique, ce qui contredit la construction de l’arbre.</p>
<h2 class="unnumbered"
id="propriété-2-efficacité-du-code-de-huffman">Propriété 2 : Efficacité
du Code de Huffman</h2>
<p>Le code de Huffman est optimal en termes de longueur moyenne des
messages.</p>
<h2 class="unnumbered" id="preuve-de-la-propriété-2">Preuve de la
Propriété 2</h2>
<p>Cette propriété découle directement du théorème de Huffman, qui
garantit que la longueur moyenne des messages est minimisée.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’encodage moyen, ou encodage de Huffman, est une méthode puissante
pour minimiser la longueur moyenne des messages transmis. Grâce à son
arbre binaire et à ses propriétés optimales, il trouve des applications
dans de nombreux domaines où l’efficacité de la transmission est
cruciale.</p>
<p>En conclusion, l’encodage moyen reste un outil fondamental en théorie
de l’information et continue d’inspirer des recherches dans le domaine
de la compression de données.</p>
</body>
</html>
{% include "footer.html" %}

