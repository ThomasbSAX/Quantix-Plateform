{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Divergence de Le Cam-Yang : Une Mesure de Distance en Statistique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Divergence de Le Cam-Yang : Une Mesure de Distance en
Statistique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La divergence de Le Cam-Yang, introduite par Lucien Le Cam et
Chi-Andreas Yang, est une mesure de distance entre deux lois de
probabilité qui a trouvé des applications importantes en statistique
asymptotique et en théorie de l’estimation. Cette divergence émerge
comme une généralisation des notions classiques de distance telles que
la divergence de Kullback-Leibler, permettant ainsi une analyse plus
fine des propriétés asymptotiques des estimateurs.</p>
<p>L’intérêt principal de la divergence de Le Cam-Yang réside dans sa
capacité à capturer des aspects locaux et globaux des différences entre
lois de probabilité. Elle est particulièrement utile dans le cadre de
l’étude des bornes inférieures de risque, où elle permet de quantifier
la difficulté intrinsèque d’un problème d’estimation.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la divergence de Le Cam-Yang, considérons deux lois
de probabilité <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> sur un espace mesurable <span
class="math inline">\((\mathcal{X}, \mathcal{A})\)</span>. Nous
cherchons une mesure de distance qui capture à la fois les différences
locales et globales entre ces deux lois.</p>
<p>La divergence de Le Cam-Yang est définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux lois de probabilité sur un espace
mesurable <span class="math inline">\((\mathcal{X},
\mathcal{A})\)</span>. La divergence de Le Cam-Yang entre <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> est définie par : <span
class="math display">\[D_{LY}(P, Q) = \sup_{\substack{f : \mathcal{X}
\rightarrow \mathbb{R} \\ \|f\|_2 \leq 1}} \left( \int f \, dP - \int f
\, dQ \right)\]</span> où <span class="math inline">\(\|f\|_2\)</span>
désigne la norme <span class="math inline">\(L^2\)</span> de <span
class="math inline">\(f\)</span> par rapport à une mesure de référence
<span class="math inline">\(\mu\)</span>.</p>
</div>
<p>Une autre formulation équivalente est : <span
class="math display">\[D_{LY}(P, Q) = \sup_{\substack{f : \mathcal{X}
\rightarrow \mathbb{R} \\ \|f\|_2 \leq 1}} \left( \int f \, dP - \int f
\, dQ \right) = \sqrt{2 \cdot D_{KL}(P, Q)}\]</span> où <span
class="math inline">\(D_{KL}\)</span> désigne la divergence de
Kullback-Leibler.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la divergence de Le Cam-Yang est le
suivant :</p>
<div class="theoreme">
<p>Soient <span class="math inline">\(P_n\)</span> et <span
class="math inline">\(Q_n\)</span> deux suites de lois de probabilité
sur un espace mesurable <span class="math inline">\((\mathcal{X},
\mathcal{A})\)</span>. Si la divergence de Le Cam-Yang entre <span
class="math inline">\(P_n\)</span> et <span
class="math inline">\(Q_n\)</span> tend vers zéro lorsque <span
class="math inline">\(n\)</span> tend vers l’infini, alors les suites
<span class="math inline">\(P_n\)</span> et <span
class="math inline">\(Q_n\)</span> sont asymptotiquement équivalentes au
sens de la convergence faible.</p>
</div>
<p>La démonstration de ce théorème repose sur des résultats classiques
en théorie de la mesure et de l’intégration, ainsi que sur des
propriétés de la divergence de Kullback-Leibler.</p>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer le théorème précédent, nous procédons comme suit :</p>
<div class="preuve">
<p>Supposons que <span class="math inline">\(D_{LY}(P_n, Q_n)
\rightarrow 0\)</span> lorsque <span class="math inline">\(n \rightarrow
\infty\)</span>. Nous devons montrer que pour toute fonction bornée et
continue <span class="math inline">\(f : \mathcal{X} \rightarrow
\mathbb{R}\)</span>, nous avons : <span class="math display">\[\int f \,
dP_n - \int f \, dQ_n \rightarrow 0.\]</span></p>
<p>Considérons une fonction <span class="math inline">\(f\)</span>
bornée et continue. Par densité, nous pouvons approcher <span
class="math inline">\(f\)</span> par une suite de fonctions <span
class="math inline">\(f_k\)</span> dans <span
class="math inline">\(L^2(\mu)\)</span>, où <span
class="math inline">\(\mu\)</span> est une mesure de référence. Nous
avons alors : <span class="math display">\[\int f_k \, dP_n - \int f_k
\, dQ_n \leq D_{LY}(P_n, Q_n) \|f_k\|_2.\]</span></p>
<p>En faisant tendre <span class="math inline">\(k\)</span> vers
l’infini, nous obtenons : <span class="math display">\[\int f \, dP_n -
\int f \, dQ_n \leq \liminf_{k \rightarrow \infty} D_{LY}(P_n, Q_n)
\|f_k\|_2.\]</span></p>
<p>Puisque <span class="math inline">\(D_{LY}(P_n, Q_n) \rightarrow
0\)</span>, il s’ensuit que : <span class="math display">\[\int f \,
dP_n - \int f \, dQ_n \rightarrow 0.\]</span></p>
<p>Ainsi, les suites <span class="math inline">\(P_n\)</span> et <span
class="math inline">\(Q_n\)</span> convergent faiblement l’une vers
l’autre.</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
divergence de Le Cam-Yang :</p>
<ol>
<li><p>La divergence de Le Cam-Yang est toujours non négative et
symétrique, c’est-à-dire : <span class="math display">\[D_{LY}(P, Q)
\geq 0 \quad \text{et} \quad D_{LY}(P, Q) = D_{LY}(Q,
P).\]</span></p></li>
<li><p>La divergence de Le Cam-Yang est invariante par transformation
mesurable. Si <span class="math inline">\(T : \mathcal{X} \rightarrow
\mathcal{Y}\)</span> est une transformation mesurable, alors : <span
class="math display">\[D_{LY}(P \circ T^{-1}, Q \circ T^{-1}) =
D_{LY}(P, Q).\]</span></p></li>
<li><p>La divergence de Le Cam-Yang satisfait une inégalité triangulaire
: <span class="math display">\[D_{LY}(P, R) \leq D_{LY}(P, Q) +
D_{LY}(Q, R).\]</span></p></li>
</ol>
<p>Chacune de ces propriétés peut être démontrée en utilisant des
techniques standards en théorie de la mesure et de l’intégration.</p>
</body>
</html>
{% include "footer.html" %}

