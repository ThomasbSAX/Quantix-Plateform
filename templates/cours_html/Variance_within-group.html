{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance within-group: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance within-group: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>The concept of variance within-group emerges from the necessity to
understand the dispersion of data points around their respective group
means. In statistical analysis, particularly in ANOVA (Analysis of
Variance), this measure plays a pivotal role in determining the
variability within each group. The variance within-group is
indispensable for assessing the homogeneity of variances across groups,
which is a fundamental assumption in many statistical tests.</p>
<p>The historical development of this concept can be traced back to the
early 20th century with the advent of ANOVA by Sir Ronald A. Fisher. The
variance within-group provides a quantitative measure of how much the
data points in each group deviate from their group mean, thereby
offering insights into the internal consistency of the groups.</p>
<h1 id="definitions">Definitions</h1>
<p>To understand the variance within-group, let us first consider a
dataset divided into <span class="math inline">\(k\)</span> groups. For
each group <span class="math inline">\(i\)</span>, we have <span
class="math inline">\(n_i\)</span> observations denoted by <span
class="math inline">\(X_{i1}, X_{i2}, \ldots, X_{in_i}\)</span>. The
mean of the <span class="math inline">\(i\)</span>-th group is given by:
<span class="math display">\[\bar{X}_i = \frac{1}{n_i} \sum_{j=1}^{n_i}
X_{ij}\]</span></p>
<p>The variance within-group for the <span
class="math inline">\(i\)</span>-th group is a measure of the spread of
the observations around this mean. Intuitively, we want to capture how
much each observation <span class="math inline">\(X_{ij}\)</span>
deviates from the group mean <span
class="math inline">\(\bar{X}_i\)</span>.</p>
<p>Formally, the variance within-group for the <span
class="math inline">\(i\)</span>-th group is defined as: <span
class="math display">\[\sigma_i^2 = \frac{1}{n_i} \sum_{j=1}^{n_i}
(X_{ij} - \bar{X}_i)^2\]</span></p>
<p>Alternatively, using the sum of squares: <span
class="math display">\[\sigma_i^2 = \frac{1}{n_i} \sum_{j=1}^{n_i}
X_{ij}^2 - \bar{X}_i^2\]</span></p>
<p>For the entire dataset, the total variance within-group can be
expressed as: <span class="math display">\[\sigma_w^2 = \frac{1}{N}
\sum_{i=1}^k n_i \sigma_i^2\]</span> where <span class="math inline">\(N
= \sum_{i=1}^k n_i\)</span> is the total number of observations.</p>
<h1 id="theorems">Theorems</h1>
<p>One of the fundamental theorems related to variance within-group is
the Law of Total Variance, which decomposes the total variance into
within-group and between-group components. Let us first understand the
intuition behind this theorem.</p>
<p>Suppose we have a dataset divided into <span
class="math inline">\(k\)</span> groups. The total variance of the
entire dataset can be thought of as the sum of two components: the
variance within each group and the variance between the groups. The Law
of Total Variance formalizes this intuition.</p>
<p>Formally, the Law of Total Variance states that: <span
class="math display">\[\sigma^2 = \sigma_w^2 + \sigma_b^2\]</span> where
<span class="math inline">\(\sigma^2\)</span> is the total variance,
<span class="math inline">\(\sigma_w^2\)</span> is the within-group
variance, and <span class="math inline">\(\sigma_b^2\)</span> is the
between-group variance.</p>
<p>The between-group variance <span
class="math inline">\(\sigma_b^2\)</span> can be defined as: <span
class="math display">\[\sigma_b^2 = \frac{1}{k} \sum_{i=1}^k (\bar{X}_i
- \bar{X})^2\]</span> where <span class="math inline">\(\bar{X}\)</span>
is the overall mean of the dataset.</p>
<h1 id="proofs">Proofs</h1>
<p>To prove the Law of Total Variance, we start by expressing the total
variance <span class="math inline">\(\sigma^2\)</span> as: <span
class="math display">\[\sigma^2 = \frac{1}{N} \sum_{i=1}^k
\sum_{j=1}^{n_i} (X_{ij} - \bar{X})^2\]</span></p>
<p>We can decompose <span class="math inline">\(X_{ij} -
\bar{X}\)</span> as: <span class="math display">\[X_{ij} - \bar{X} =
(X_{ij} - \bar{X}_i) + (\bar{X}_i - \bar{X})\]</span></p>
<p>Squaring both sides, we get: <span class="math display">\[(X_{ij} -
\bar{X})^2 = (X_{ij} - \bar{X}_i)^2 + 2(X_{ij} - \bar{X}_i)(\bar{X}_i -
\bar{X}) + (\bar{X}_i - \bar{X})^2\]</span></p>
<p>Taking the sum over all observations, the cross-term <span
class="math inline">\(2(X_{ij} - \bar{X}_i)(\bar{X}_i -
\bar{X})\)</span> vanishes because: <span
class="math display">\[\sum_{j=1}^{n_i} (X_{ij} - \bar{X}_i) =
0\]</span></p>
<p>Thus, we have: <span class="math display">\[\sigma^2 = \frac{1}{N}
\sum_{i=1}^k \sum_{j=1}^{n_i} (X_{ij} - \bar{X}_i)^2 + \frac{1}{N}
\sum_{i=1}^k n_i (\bar{X}_i - \bar{X})^2\]</span></p>
<p>The first term on the right-hand side is the within-group variance
<span class="math inline">\(\sigma_w^2\)</span>, and the second term is
the between-group variance <span
class="math inline">\(\sigma_b^2\)</span>. Therefore, we have proven
that: <span class="math display">\[\sigma^2 = \sigma_w^2 +
\sigma_b^2\]</span></p>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>The variance within-group possesses several important properties and
corollaries:</p>
<p>(i) **Non-Negativity**: The variance within-group is always
non-negative, i.e., <span class="math inline">\(\sigma_i^2 \geq
0\)</span> for all <span class="math inline">\(i\)</span>. This follows
from the fact that the sum of squared deviations is always
non-negative.</p>
<p>(ii) **Invariance under Linear Transformations**: The variance
within-group is invariant under linear transformations of the data.
Specifically, if we transform each observation <span
class="math inline">\(X_{ij}\)</span> by a linear function <span
class="math inline">\(Y_{ij} = aX_{ij} + b\)</span>, the variance
within-group remains unchanged up to a scaling factor <span
class="math inline">\(a^2\)</span>.</p>
<p>(iii) **Homogeneity of Variances**: The assumption of homogeneity of
variances, i.e., <span class="math inline">\(\sigma_i^2 =
\sigma_j^2\)</span> for all <span class="math inline">\(i, j\)</span>,
is crucial in many statistical tests such as ANOVA. This assumption
ensures that the groups are comparable in terms of their internal
variability.</p>
<p>(iv) **Relationship with Total Variance**: As established by the Law
of Total Variance, the total variance is the sum of the within-group and
between-group variances. This relationship is fundamental in
understanding the sources of variability in a dataset.</p>
<p>In conclusion, the variance within-group is a cornerstone concept in
statistical analysis, providing deep insights into the internal
consistency and variability of grouped data. Its theoretical foundations
and practical applications make it an indispensable tool in the arsenal
of any statistician or data analyst.</p>
</body>
</html>
{% include "footer.html" %}

