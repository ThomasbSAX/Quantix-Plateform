{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’inégalité de convexité : une exploration mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’inégalité de convexité : une exploration
mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de convexité, aussi connue sous le nom d’inégalité de
Jensen, est un outil fondamental en analyse mathématique et en théorie
des probabilités. Elle émerge naturellement dans le contexte de l’étude
des fonctions convexes, qui sont omniprésentes en mathématiques
appliquées. L’importance de cette inégalité réside dans sa capacité à
fournir des bornes sur les valeurs attendues de fonctions convexes, ce
qui est crucial dans l’analyse des risques en finance, l’optimisation et
bien d’autres domaines.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant de formuler l’inégalité de convexité, il est essentiel de
rappeler la définition d’une fonction convexe. Considérons un intervalle
<span class="math inline">\(I \subseteq \mathbb{R}\)</span> et une
fonction <span class="math inline">\(f: I \rightarrow
\mathbb{R}\)</span>.</p>
<div class="definition">
<p>On dit que <span class="math inline">\(f\)</span> est convexe sur
<span class="math inline">\(I\)</span> si pour tout <span
class="math inline">\(x, y \in I\)</span> et pour tout <span
class="math inline">\(\lambda \in [0, 1]\)</span>, on a : <span
class="math display">\[f(\lambda x + (1 - \lambda) y) \leq \lambda f(x)
+ (1 - \lambda) f(y).\]</span></p>
</div>
<p>Cette définition peut être reformulée en termes de dérivées si <span
class="math inline">\(f\)</span> est deux fois différentiable : <span
class="math display">\[f&#39;&#39;(x) \geq 0 \quad \forall x \in
I.\]</span></p>
<h1 class="unnumbered" id="linégalité-de-jensen">L’inégalité de
Jensen</h1>
<p>L’inégalité de Jensen est une généralisation de la définition de
convexité pour les fonctions à valeurs réelles et les probabilités. Elle
est formulée comme suit :</p>
<div class="theorem">
<p>Soit <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> un
espace probabilisé, et soit <span class="math inline">\(X: \Omega
\rightarrow I\)</span> une variable aléatoire. Supposons que <span
class="math inline">\(f: I \rightarrow \mathbb{R}\)</span> soit une
fonction convexe. Alors : <span class="math display">\[\mathbb{E}[f(X)]
\geq f(\mathbb{E}[X]),\]</span> où <span
class="math inline">\(\mathbb{E}\)</span> désigne l’espérance
mathématique.</p>
</div>
<p>Pour comprendre cette inégalité, considérons une fonction convexe
<span class="math inline">\(f\)</span> et une variable aléatoire <span
class="math inline">\(X\)</span>. L’inégalité de Jensen nous dit que
l’espérance de <span class="math inline">\(f(X)\)</span> est supérieure
ou égale à la valeur de <span class="math inline">\(f\)</span> en
l’espérance de <span class="math inline">\(X\)</span>.</p>
<h1 class="unnumbered" id="preuve-de-linégalité-de-jensen">Preuve de
l’inégalité de Jensen</h1>
<p>Pour démontrer cette inégalité, nous allons utiliser la définition de
convexité et les propriétés de l’espérance mathématique.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(f\)</span> une
fonction convexe sur un intervalle <span
class="math inline">\(I\)</span>, et soit <span
class="math inline">\(X\)</span> une variable aléatoire à valeurs dans
<span class="math inline">\(I\)</span>. Nous voulons montrer que : <span
class="math display">\[\mathbb{E}[f(X)] \geq
f(\mathbb{E}[X]).\]</span></p>
<p>Commençons par considérer le cas discret où <span
class="math inline">\(X\)</span> prend un nombre fini de valeurs.
Supposons que <span class="math inline">\(X\)</span> prenne les valeurs
<span class="math inline">\(x_1, x_2, \ldots, x_n\)</span> avec des
probabilités respectives <span class="math inline">\(p_1, p_2, \ldots,
p_n\)</span>.</p>
<p>Par la définition de convexité, pour tout <span
class="math inline">\(i = 1, 2, \ldots, n\)</span>, nous avons : <span
class="math display">\[f\left(\sum_{j=1}^n p_j x_j\right) \leq
\sum_{j=1}^n p_j f(x_j).\]</span></p>
<p>En prenant l’espérance de <span class="math inline">\(f(X)\)</span>,
nous obtenons : <span class="math display">\[\mathbb{E}[f(X)] =
\sum_{i=1}^n p_i f(x_i).\]</span></p>
<p>D’autre part, <span class="math inline">\(\mathbb{E}[X] =
\sum_{i=1}^n p_i x_i\)</span>. En utilisant la convexité de <span
class="math inline">\(f\)</span>, nous avons : <span
class="math display">\[f(\mathbb{E}[X]) = f\left(\sum_{i=1}^n p_i
x_i\right) \leq \sum_{i=1}^n p_i f(x_i) = \mathbb{E}[f(X)].\]</span></p>
<p>Ainsi, nous avons montré que : <span
class="math display">\[\mathbb{E}[f(X)] \geq
f(\mathbb{E}[X]).\]</span></p>
<p>Pour le cas général où <span class="math inline">\(X\)</span> peut
prendre une infinité de valeurs, nous pouvons utiliser un argument de
densité et d’approximation pour étendre le résultat au cas
continu. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Jensen a plusieurs propriétés intéressantes et
corollaires importants.</p>
<div class="corollary">
<p>Si <span class="math inline">\(f\)</span> est une fonction concave,
alors l’inégalité de Jensen s’inverse : <span
class="math display">\[\mathbb{E}[f(X)] \leq
f(\mathbb{E}[X]).\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Si <span class="math inline">\(f\)</span> est
concave, alors <span class="math inline">\(-f\)</span> est convexe. En
appliquant l’inégalité de Jensen à <span
class="math inline">\(-f\)</span>, nous obtenons : <span
class="math display">\[\mathbb{E}[-f(X)] \geq
-f(\mathbb{E}[X]).\]</span></p>
<p>En multipliant par <span class="math inline">\(-1\)</span> (et en
inversant l’inégalité), nous avons : <span
class="math display">\[\mathbb{E}[f(X)] \leq
f(\mathbb{E}[X]).\]</span> ◻</p>
</div>
<div class="corollary">
<p>Soit <span class="math inline">\(p_1, p_2, \ldots, p_n\)</span> des
probabilités telles que <span class="math inline">\(\sum_{i=1}^n p_i =
1\)</span>, et soit <span class="math inline">\(x_1, x_2, \ldots,
x_n\)</span> des nombres réels. Si <span
class="math inline">\(f\)</span> est une fonction convexe, alors : <span
class="math display">\[\sum_{i=1}^n p_i f(x_i) \geq f\left(\sum_{i=1}^n
p_i x_i\right).\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Ce corollaire est une reformulation directe de
l’inégalité de Jensen pour le cas discret, comme démontré dans la preuve
précédente. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’inégalité de convexité, ou inégalité de Jensen, est un résultat
fondamental en analyse et en théorie des probabilités. Elle trouve des
applications dans de nombreux domaines, notamment en finance, en
optimisation et en apprentissage automatique. Sa démonstration repose
sur la définition de convexité et les propriétés de l’espérance
mathématique, ce qui en fait un outil puissant pour établir des bornes
et des estimations.</p>
</body>
</html>
{% include "footer.html" %}

