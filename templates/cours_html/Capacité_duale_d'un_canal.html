{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Capacité duale d’un canal Une exploration approfondie des fondements de la théorie de l’information</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Capacité duale d’un canal<br />
Une exploration approfondie des fondements de la théorie de
l’information</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La théorie de l’information, née des travaux pionniers de Claude
Shannon dans les années 1940, a révolutionné notre compréhension de la
communication et du traitement des données. Au cœur de cette théorie se
trouve le concept de capacité d’un canal, qui quantifie la quantité
maximale d’information pouvant être transmise à travers un canal de
communication sujet au bruit. Cependant, une compréhension approfondie
de la capacité d’un canal nécessite l’exploration de son dual, un
concept qui offre des perspectives nouvelles et puissantes sur les
limites fondamentales de la communication.</p>
<p>L’idée de capacité duale émerge naturellement lorsque l’on considère
les canaux symétriques et les problèmes de communication
bidirectionnelle. En effet, dans ces contextes, l’étude de la capacité
duale permet de mieux comprendre les contraintes et les possibilités
offertes par le canal. Cette notion est particulièrement cruciale dans
les réseaux de communication modernes, où la symétrie et la
bidirectionnalité sont des caractéristiques essentielles.</p>
<p>Dans cet article, nous plongeons dans les profondeurs de la capacité
duale d’un canal. Nous explorerons ses fondements théoriques, ses
définitions rigoureuses, et les théorèmes clés qui en découlent. Notre
objectif est de fournir une compréhension complète et détaillée de ce
concept, en mettant l’accent sur les démonstrations mathématiques
rigoureuses et les propriétés fondamentales.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la capacité duale d’un canal, il est essentiel de
commencer par les concepts fondamentaux de la théorie de
l’information.</p>
<h2 id="canaux-de-communication">Canaux de communication</h2>
<p>Un canal de communication est un système qui prend en entrée une
séquence d’éléments d’un ensemble fini <span
class="math inline">\(\mathcal{X}\)</span> (l’alphabet d’entrée) et
produit en sortie une séquence d’éléments d’un ensemble fini <span
class="math inline">\(\mathcal{Y}\)</span> (l’alphabet de sortie). Le
comportement du canal est décrit par une fonction de transition <span
class="math inline">\(P(Y|X)\)</span>, qui donne la probabilité que la
sortie <span class="math inline">\(Y\)</span> soit égale à <span
class="math inline">\(y\)</span> lorsque l’entrée <span
class="math inline">\(X\)</span> est égale à <span
class="math inline">\(x\)</span>.</p>
<h2 id="capacité-dun-canal">Capacité d’un canal</h2>
<p>La capacité d’un canal, notée <span class="math inline">\(C\)</span>,
est la quantité maximale d’information qui peut être transmise à travers
le canal par unité de temps. Elle est définie comme la borne supérieure
du débit maximal <span class="math inline">\(R\)</span> pour lequel il
existe un code <span class="math inline">\((n, M, \lambda)\)</span> de
longueur <span class="math inline">\(n\)</span>, taille <span
class="math inline">\(M\)</span> et probabilité d’erreur <span
class="math inline">\(\lambda\)</span> telle que <span
class="math inline">\(\lambda \to 0\)</span> lorsque <span
class="math inline">\(n \to \infty\)</span> et <span
class="math inline">\(R = \frac{\log M}{n}\)</span>.</p>
<p>Formellement, la capacité d’un canal est donnée par: <span
class="math display">\[C = \max_{P(X)} I(X; Y)\]</span> où <span
class="math inline">\(I(X; Y)\)</span> est l’information mutuelle entre
<span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, et la maximisation est effectuée sur
toutes les distributions de probabilité <span
class="math inline">\(P(X)\)</span> sur <span
class="math inline">\(\mathcal{X}\)</span>.</p>
<h2 id="capacité-duale-dun-canal">Capacité duale d’un canal</h2>
<p>La capacité duale d’un canal est un concept qui émerge dans le
contexte des canaux symétriques et des problèmes de communication
bidirectionnelle. Elle est définie comme la capacité du canal dual, qui
est obtenu en inversant les rôles des entrées et des sorties.</p>
<p>Pour un canal symétrique, la capacité duale est égale à la capacité
du canal original. Cependant, pour les canaux non symétriques, la
capacité duale peut être différente et offre des perspectives nouvelles
sur les limites de la communication.</p>
<p>Formellement, la capacité duale d’un canal est définie comme: <span
class="math display">\[C^* = \max_{P(Y)} I(Y; X)\]</span> où <span
class="math inline">\(I(Y; X)\)</span> est l’information mutuelle entre
<span class="math inline">\(Y\)</span> et <span
class="math inline">\(X\)</span>, et la maximisation est effectuée sur
toutes les distributions de probabilité <span
class="math inline">\(P(Y)\)</span> sur <span
class="math inline">\(\mathcal{Y}\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Dans cette section, nous présentons les théorèmes clés liés à la
capacité duale d’un canal.</p>
<h2 id="théorème-de-la-capacité-duale">Théorème de la capacité
duale</h2>
<p>Le théorème de la capacité duale établit une relation fondamentale
entre la capacité d’un canal et sa capacité duale.</p>
<div class="theorem">
<p><strong>Théorème 1</strong> (Théorème de la capacité duale). <em>Pour
tout canal de communication, la capacité duale <span
class="math inline">\(C^*\)</span> est égale à la capacité <span
class="math inline">\(C\)</span> du canal original.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer ce théorème, nous commençons par
rappeler que la capacité d’un canal est donnée par: <span
class="math display">\[C = \max_{P(X)} I(X; Y)\]</span> De même, la
capacité duale est donnée par: <span class="math display">\[C^* =
\max_{P(Y)} I(Y; X)\]</span></p>
<p>Nous voulons montrer que <span class="math inline">\(C^* =
C\)</span>. Pour cela, nous utilisons le fait que pour tout canal
symétrique, <span class="math inline">\(I(X; Y) = I(Y; X)\)</span>. Par
conséquent, la maximisation de <span class="math inline">\(I(X;
Y)\)</span> sur <span class="math inline">\(P(X)\)</span> est
équivalente à la maximisation de <span class="math inline">\(I(Y;
X)\)</span> sur <span class="math inline">\(P(Y)\)</span>.</p>
<p>Ainsi, nous avons: <span class="math display">\[C = \max_{P(X)} I(X;
Y) = \max_{P(Y)} I(Y; X) = C^*\]</span></p>
<p>Ce qui achève la démonstration. ◻</p>
</div>
<h2
id="théorème-de-la-capacité-duale-pour-les-canaux-non-symétriques">Théorème
de la capacité duale pour les canaux non symétriques</h2>
<p>Pour les canaux non symétriques, la capacité duale peut être
différente de la capacité du canal original. Cependant, il existe une
relation importante entre ces deux quantités.</p>
<div class="theorem">
<p><strong>Théorème 2</strong> (Théorème de la capacité duale pour les
canaux non symétriques). <em>Pour tout canal de communication, la
capacité duale <span class="math inline">\(C^*\)</span> est inférieure
ou égale à la capacité <span class="math inline">\(C\)</span> du canal
original.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer ce théorème, nous commençons par
rappeler que la capacité d’un canal est donnée par: <span
class="math display">\[C = \max_{P(X)} I(X; Y)\]</span> De même, la
capacité duale est donnée par: <span class="math display">\[C^* =
\max_{P(Y)} I(Y; X)\]</span></p>
<p>Nous voulons montrer que <span class="math inline">\(C^* \leq
C\)</span>. Pour cela, nous utilisons le fait que pour tout canal, <span
class="math inline">\(I(X; Y) \geq I(Y; X)\)</span>. Cela découle du
fait que l’information mutuelle <span class="math inline">\(I(X;
Y)\)</span> est symétrique, c’est-à-dire que <span
class="math inline">\(I(X; Y) = I(Y; X)\)</span>.</p>
<p>Par conséquent, nous avons: <span class="math display">\[C^* =
\max_{P(Y)} I(Y; X) \leq \max_{P(X)} I(X; Y) = C\]</span></p>
<p>Ce qui achève la démonstration. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Dans cette section, nous présentons les propriétés et corollaires
importants liés à la capacité duale d’un canal.</p>
<h2 id="propriétés-de-la-capacité-duale">Propriétés de la capacité
duale</h2>
<ol>
<li><p>Pour tout canal symétrique, la capacité duale est égale à la
capacité du canal original.</p></li>
<li><p>Pour tout canal non symétrique, la capacité duale est inférieure
ou égale à la capacité du canal original.</p></li>
<li><p>La capacité duale est une fonction concave de la distribution de
probabilité <span class="math inline">\(P(Y)\)</span>.</p></li>
</ol>
<h2 id="corollaires">Corollaires</h2>
<div class="corollary">
<p><strong>Corollaire 1</strong> (Corollaire de la capacité duale).
<em>Pour tout canal de communication, la capacité duale <span
class="math inline">\(C^*\)</span> est égale à la capacité <span
class="math inline">\(C\)</span> du canal original si et seulement si le
canal est symétrique.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Ce corollaire découle directement du théorème de la
capacité duale et du théorème de la capacité duale pour les canaux non
symétriques. En effet, si le canal est symétrique, alors <span
class="math inline">\(C^* = C\)</span>. Inversement, si <span
class="math inline">\(C^* = C\)</span>, alors le canal doit être
symétrique. ◻</p>
</div>
<div class="corollary">
<p><strong>Corollaire 2</strong> (Corollaire de la concavité de la
capacité duale). <em>La capacité duale <span
class="math inline">\(C^*\)</span> est une fonction concave de la
distribution de probabilité <span class="math inline">\(P(Y)\)</span>.
Cela signifie que pour toute distribution de probabilité <span
class="math inline">\(P(Y)\)</span> et tout <span
class="math inline">\(\lambda \in [0, 1]\)</span>, nous avons: <span
class="math display">\[C^*(\lambda P(Y) + (1 - \lambda) Q(Y)) \geq
\lambda C^*(P(Y)) + (1 - \lambda) C^*(Q(Y))\]</span> où <span
class="math inline">\(Q(Y)\)</span> est une autre distribution de
probabilité sur <span
class="math inline">\(\mathcal{Y}\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> La concavité de la capacité duale découle du fait que
l’information mutuelle <span class="math inline">\(I(Y; X)\)</span> est
une fonction concave de la distribution de probabilité conjointe <span
class="math inline">\(P(X, Y)\)</span>. En effet, la maximisation de
<span class="math inline">\(I(Y; X)\)</span> sur <span
class="math inline">\(P(Y)\)</span> est une opération qui préserve la
concavité. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Dans cet article, nous avons exploré en profondeur le concept de
capacité duale d’un canal. Nous avons présenté les définitions
fondamentales, les théorèmes clés, et les propriétés importantes de ce
concept. Notre objectif était de fournir une compréhension complète et
détaillée de la capacité duale, en mettant l’accent sur les
démonstrations mathématiques rigoureuses et les propriétés
fondamentales.</p>
<p>La capacité duale d’un canal est un concept puissant qui offre des
perspectives nouvelles sur les limites fondamentales de la
communication. Elle joue un rôle crucial dans l’étude des canaux
symétriques et des problèmes de communication bidirectionnelle. En
comprenant la capacité duale, nous pouvons mieux appréhender les
contraintes et les possibilités offertes par les canaux de
communication, et ainsi améliorer nos systèmes de communication
modernes.</p>
<p>Enfin, nous espérons que cet article aura inspiré une passion pour la
théorie de l’information et encouragé des recherches futures dans ce
domaine fascinant.</p>
</body>
</html>
{% include "footer.html" %}

