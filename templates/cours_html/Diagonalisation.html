{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Diagonalisation des Matrices: Théorie et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Diagonalisation des Matrices: Théorie et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La diagonalisation des matrices est une technique fondamentale en
algèbre linéaire, permettant de simplifier considérablement l’étude et
la manipulation des matrices. Historiquement, cette notion émerge avec
les travaux de Cauchy sur les équations différentielles linéaires et
ceux de Jordan sur la structure des matrices. La diagonalisation est
indispensable dans l’analyse des systèmes dynamiques, l’optimisation et
la résolution de problèmes d’algèbre linéaire.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour aborder la diagonalisation, commençons par comprendre ce que
nous cherchons à obtenir. Nous voulons transformer une matrice carrée en
une matrice diagonale, c’est-à-dire une matrice dont les éléments hors
de la diagonale principale sont nuls. Cela simplifie grandement les
calculs, notamment pour les puissances de matrices.</p>
<div class="definition">
<p>Une matrice <span class="math inline">\(D \in
M_n(\mathbb{K})\)</span> est dite diagonale s’il existe une base <span
class="math inline">\((e_1, e_2, \dots, e_n)\)</span> de l’espace
vectoriel <span class="math inline">\(\mathbb{K}^n\)</span> telle que
pour tout <span class="math inline">\(i, j \in \{1, 2, \dots,
n\}\)</span>, on a: <span class="math display">\[D_{ij} = \begin{cases}
\lambda_i &amp; \text{si } i = j, \\
0 &amp; \text{sinon.}
\end{cases}\]</span></p>
</div>
<div class="definition">
<p>Une matrice <span class="math inline">\(A \in
M_n(\mathbb{K})\)</span> est dite diagonalisable s’il existe une matrice
inversible <span class="math inline">\(P \in M_n(\mathbb{K})\)</span> et
une matrice diagonale <span class="math inline">\(D \in
M_n(\mathbb{K})\)</span> telles que: <span class="math display">\[A = P
D P^{-1}.\]</span></p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Pour diagonaliser une matrice, nous devons comprendre les conditions
nécessaires et suffisantes. Le théorème suivant est central en
diagonalisation.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(A \in M_n(\mathbb{K})\)</span>. La
matrice <span class="math inline">\(A\)</span> est diagonalisable si et
seulement s’il existe une base de <span
class="math inline">\(\mathbb{K}^n\)</span> constituée de vecteurs
propres de <span class="math inline">\(A\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Supposons que <span class="math inline">\(A\)</span>
soit diagonalisable. Alors, il existe une matrice inversible <span
class="math inline">\(P\)</span> et une matrice diagonale <span
class="math inline">\(D\)</span> telles que <span
class="math inline">\(A = P D P^{-1}\)</span>. Les colonnes de <span
class="math inline">\(P\)</span> sont des vecteurs propres de <span
class="math inline">\(A\)</span>, et les éléments diagonaux de <span
class="math inline">\(D\)</span> sont les valeurs propres
correspondantes.</p>
<p>Réciproquement, supposons qu’il existe une base <span
class="math inline">\((v_1, v_2, \dots, v_n)\)</span> de <span
class="math inline">\(\mathbb{K}^n\)</span> constituée de vecteurs
propres de <span class="math inline">\(A\)</span>. Alors, il existe des
scalaires <span class="math inline">\(\lambda_1, \lambda_2, \dots,
\lambda_n\)</span> tels que pour tout <span class="math inline">\(i \in
\{1, 2, \dots, n\}\)</span>, on a: <span class="math display">\[A v_i =
\lambda_i v_i.\]</span> Considérons la matrice <span
class="math inline">\(P\)</span> dont les colonnes sont les vecteurs
<span class="math inline">\(v_1, v_2, \dots, v_n\)</span>, et la matrice
diagonale <span class="math inline">\(D\)</span> avec les éléments
diagonaux <span class="math inline">\(\lambda_1, \lambda_2, \dots,
\lambda_n\)</span>. Alors, on a: <span class="math display">\[A P = P
D.\]</span> Puisque <span class="math inline">\(P\)</span> est
inversible, on peut multiplier à gauche par <span
class="math inline">\(P^{-1}\)</span> pour obtenir: <span
class="math display">\[P^{-1} A P = D.\]</span> Ainsi, <span
class="math inline">\(A\)</span> est diagonalisable. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La diagonalisation possède plusieurs propriétés intéressantes, que
nous allons explorer.</p>
<div class="proposition">
<p>Soit <span class="math inline">\(A \in M_n(\mathbb{K})\)</span> une
matrice diagonalisable. Alors, pour tout entier naturel <span
class="math inline">\(k\)</span>, la matrice <span
class="math inline">\(A^k\)</span> est donnée par: <span
class="math display">\[A^k = P D^k P^{-1},\]</span> où <span
class="math inline">\(D\)</span> est la matrice diagonale associée à
<span class="math inline">\(A\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Puisque <span class="math inline">\(A = P D
P^{-1}\)</span>, on a: <span class="math display">\[A^k = (P D P^{-1})^k
= P D^k P^{-1}.\]</span> ◻</p>
</div>
<div class="corollaire">
<p>Soit <span class="math inline">\(A \in M_n(\mathbb{K})\)</span> une
matrice diagonalisable. Alors, la trace de <span
class="math inline">\(A\)</span> est égale à la somme de ses valeurs
propres.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(D\)</span> la
matrice diagonale associée à <span class="math inline">\(A\)</span>. La
trace de <span class="math inline">\(A\)</span> est donnée par: <span
class="math display">\[\text{tr}(A) = \text{tr}(P D P^{-1}) =
\text{tr}(D).\]</span> Puisque <span class="math inline">\(D\)</span>
est diagonale, sa trace est la somme de ses éléments diagonaux, qui sont
les valeurs propres de <span class="math inline">\(A\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La diagonalisation des matrices est une technique puissante et
élégante, permettant de simplifier l’étude des matrices et d’optimiser
les calculs. Les théorèmes et propriétés présentés dans cet article
montrent l’importance de cette notion en algèbre linéaire et ses
applications potentielles dans divers domaines des mathématiques et des
sciences.</p>
</body>
</html>
{% include "footer.html" %}

