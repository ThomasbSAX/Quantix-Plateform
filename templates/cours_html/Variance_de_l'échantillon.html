{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance de l’échantillon : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance de l’échantillon : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La variance de l’échantillon est une notion fondamentale en
statistique descriptive et inférentielle. Elle quantifie la dispersion
des données autour de leur moyenne, offrant ainsi une mesure essentielle
de l’hétérogénéité d’un ensemble de données. Historiquement, la variance
a été introduite par Karl Pearson en 1893, marquant une avancée majeure
dans la compréhension des distributions de probabilité et des
échantillons statistiques. Son importance réside dans sa capacité à
fournir une estimation fiable de la variance d’une population, même
lorsque celle-ci est inconnue ou inaccessible.</p>
<p>La variance de l’échantillon est indispensable dans divers domaines,
notamment en économie pour évaluer les risques financiers, en biologie
pour analyser la variabilité génétique, et en ingénierie pour contrôler
la qualité des produits. Elle permet également de construire des
intervalles de confiance et de tester des hypothèses, rendant son étude
cruciale pour toute analyse statistique rigoureuse.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la variance de l’échantillon, commençons par comprendre
ce que nous cherchons à mesurer. Imaginons un ensemble de données
représentant les notes d’un examen. Nous voulons quantifier à quel point
ces notes varient autour de la moyenne. La variance est précisément
cette mesure de dispersion.</p>
<p>Formellement, soit <span class="math inline">\(X\)</span> une
variable aléatoire représentant un échantillon de taille <span
class="math inline">\(n\)</span>, avec <span class="math inline">\(X_1,
X_2, \ldots, X_n\)</span> les observations. La moyenne de l’échantillon
est définie par :</p>
<p><span class="math display">\[\bar{X} = \frac{1}{n} \sum_{i=1}^{n}
X_i\]</span></p>
<p>La variance de l’échantillon, notée <span
class="math inline">\(S^2\)</span>, est alors donnée par :</p>
<p><span class="math display">\[S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i
- \bar{X})^2\]</span></p>
<p>Cette formule utilise un facteur de correction <span
class="math inline">\(n-1\)</span> pour obtenir une estimation non
biaisée de la variance de la population. En effet, en utilisant <span
class="math inline">\(n\)</span> au lieu de <span
class="math inline">\(n-1\)</span>, l’estimation serait sous-évaluée en
moyenne.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème central lié à la variance de l’échantillon est le
théorème de la limite centrale, qui stipule que la distribution des
moyennes d’échantillons tend vers une distribution normale lorsque la
taille de l’échantillon augmente. Ce théorème est crucial pour
comprendre le comportement des estimateurs et justifie l’utilisation de
la variance échantillonnale comme mesure fiable de la dispersion.</p>
<p>Formellement, soit <span class="math inline">\(X_1, X_2, \ldots,
X_n\)</span> des variables aléatoires indépendantes et identiquement
distribuées (i.i.d.) avec une espérance <span
class="math inline">\(\mu\)</span> et une variance <span
class="math inline">\(\sigma^2\)</span>. La moyenne échantillonnale
<span class="math inline">\(\bar{X}\)</span> suit une distribution
normale asymptotiquement :</p>
<p><span class="math display">\[\bar{X} \sim \mathcal{N}\left(\mu,
\frac{\sigma^2}{n}\right)\]</span></p>
<p>Ce théorème montre que la variance de l’échantillon est un outil
puissant pour inférer des propriétés de la population à partir d’un
échantillon.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver que <span class="math inline">\(S^2\)</span> est une
estimation non biaisée de la variance de la population, nous devons
montrer que <span class="math inline">\(\mathbb{E}[S^2] =
\sigma^2\)</span>. Commençons par exprimer <span
class="math inline">\(S^2\)</span> en fonction des observations :</p>
<p><span class="math display">\[S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i
- \bar{X})^2\]</span></p>
<p>En développant le carré, nous obtenons :</p>
<p><span class="math display">\[(X_i - \bar{X})^2 = X_i^2 - 2X_i\bar{X}
+ \bar{X}^2\]</span></p>
<p>En prenant l’espérance de chaque terme, nous avons :</p>
<p><span class="math display">\[\mathbb{E}[(X_i - \bar{X})^2] =
\mathbb{E}[X_i^2] - 2\mathbb{E}[X_i\bar{X}] +
\mathbb{E}[\bar{X}^2]\]</span></p>
<p>En utilisant les propriétés de l’espérance, nous savons que :</p>
<p><span class="math display">\[\mathbb{E}[X_i^2] = \sigma^2 +
\mu^2\]</span></p>
<p><span class="math display">\[\mathbb{E}[X_i\bar{X}] = \frac{1}{n}
\mathbb{E}[X_i^2] + \left(1 - \frac{1}{n}\right) \mathbb{E}[X_i]\mu =
\frac{\sigma^2 + \mu^2}{n} + \left(1 -
\frac{1}{n}\right)\mu^2\]</span></p>
<p><span class="math display">\[\mathbb{E}[\bar{X}^2] =
\text{Var}(\bar{X}) + \mathbb{E}[\bar{X}]^2 = \frac{\sigma^2}{n} +
\mu^2\]</span></p>
<p>En substituant ces expressions dans l’espérance de <span
class="math inline">\((X_i - \bar{X})^2\)</span>, nous obtenons :</p>
<p><span class="math display">\[\mathbb{E}[(X_i - \bar{X})^2] =
(\sigma^2 + \mu^2) - 2\left(\frac{\sigma^2 + \mu^2}{n} + \left(1 -
\frac{1}{n}\right)\mu^2\right) + \left(\frac{\sigma^2}{n} +
\mu^2\right)\]</span></p>
<p>En simplifiant, nous trouvons :</p>
<p><span class="math display">\[\mathbb{E}[(X_i - \bar{X})^2] =
\sigma^2\]</span></p>
<p>Ainsi, en multipliant par <span
class="math inline">\(\frac{1}{n-1}\)</span> et en sommant sur tous les
<span class="math inline">\(i\)</span>, nous obtenons :</p>
<p><span class="math display">\[\mathbb{E}[S^2] = \sigma^2\]</span></p>
<p>Ce qui prouve que <span class="math inline">\(S^2\)</span> est une
estimation non biaisée de la variance de la population.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La variance de l’échantillon possède plusieurs propriétés importantes
:</p>
<ol>
<li><p>**Invariance par translation** : La variance est invariante par
ajout d’une constante. Si <span class="math inline">\(Y_i = X_i +
c\)</span> pour une constante <span class="math inline">\(c\)</span>,
alors :</p>
<p><span class="math display">\[S_Y^2 = S_X^2\]</span></p></li>
<li><p>**Variation par échelle** : La variance est sensible à l’échelle.
Si <span class="math inline">\(Y_i = aX_i\)</span> pour une constante
<span class="math inline">\(a\)</span>, alors :</p>
<p><span class="math display">\[S_Y^2 = a^2 S_X^2\]</span></p></li>
<li><p>**Relation avec la covariance** : La variance est un cas
particulier de la covariance. Pour deux variables aléatoires <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, la covariance est définie par :</p>
<p><span class="math display">\[\text{Cov}(X, Y) = \mathbb{E}[(X -
\mu_X)(Y - \mu_Y)]\]</span></p>
<p>Si <span class="math inline">\(X = Y\)</span>, alors <span
class="math inline">\(\text{Cov}(X, X) =
\text{Var}(X)\)</span>.</p></li>
</ol>
<p>Ces propriétés montrent que la variance de l’échantillon est un outil
robuste et flexible pour analyser les données.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La variance de l’échantillon est une notion centrale en statistique,
offrant une mesure fiable de la dispersion des données. Son étude permet
de comprendre les propriétés fondamentales des distributions et
d’inférer des caractéristiques de la population à partir d’un
échantillon. Les théorèmes et propriétés associés à la variance
enrichissent notre compréhension des phénomènes aléatoires et ouvrent la
voie à des applications pratiques dans divers domaines.</p>
</body>
</html>
{% include "footer.html" %}

