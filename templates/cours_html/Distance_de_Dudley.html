{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Dudley</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Dudley</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Dudley émerge dans le cadre de l’analyse fonctionnelle
et des probabilités, particulièrement dans l’étude des processus
stochastiques. Introduite par Richard Dudley en 1967, cette notion est
cruciale pour comprendre les propriétés de régularité des fonctions
aléatoires et pour établir des inégalités de concentration. Elle trouve
ses applications dans divers domaines, notamment en théorie des
processus empiriques, en apprentissage statistique et en analyse de
données fonctionnelles.</p>
<p>L’intérêt pour la distance de Dudley réside dans sa capacité à
mesurer la complexité d’un ensemble de fonctions, ce qui permet de
contrôler les fluctuations des processus stochastiques. Cette mesure est
indispensable pour déduire des bornes sur les écarts entre les processus
empiriques et leurs espérances, un problème central en théorie de
l’estimation.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la distance de Dudley, considérons un espace métrique
<span class="math inline">\((T, d)\)</span> et un ensemble <span
class="math inline">\(\mathcal{F}\)</span> de fonctions bornées sur
<span class="math inline">\(T\)</span>. Nous cherchons à mesurer la
complexité de <span class="math inline">\(\mathcal{F}\)</span> en termes
de la distance <span class="math inline">\(d\)</span>. Intuitivement,
plus <span class="math inline">\(\mathcal{F}\)</span> est complexe, plus
les fonctions de <span class="math inline">\(\mathcal{F}\)</span>
varient rapidement sur <span class="math inline">\(T\)</span>, ce qui
rend difficile le contrôle des fluctuations.</p>
<div class="definition">
<p>Soit <span class="math inline">\((T, d)\)</span> un espace métrique
et <span class="math inline">\(\mathcal{F}\)</span> un ensemble de
fonctions bornées sur <span class="math inline">\(T\)</span>. La
distance de Dudley de <span class="math inline">\(\mathcal{F}\)</span>
est définie par : <span class="math display">\[\Delta(\mathcal{F}, d) =
\sup_{\delta &gt; 0} \left( \delta \int_{0}^{\infty} \sqrt{\log
N(\mathcal{F}, d, \delta \epsilon)} \, d\epsilon \right),\]</span> où
<span class="math inline">\(N(\mathcal{F}, d, \delta)\)</span> est le
nombre minimal de boules de rayon <span
class="math inline">\(\delta\)</span> nécessaires pour couvrir <span
class="math inline">\(\mathcal{F}\)</span> dans la métrique <span
class="math inline">\(d\)</span>.</p>
</div>
<p>Une autre formulation équivalente est : <span
class="math display">\[\Delta(\mathcal{F}, d) = \sup_{\delta &gt; 0}
\left( \delta \int_{0}^{\infty} \sqrt{\log N(\mathcal{F}, d, \delta t)}
\, dt \right).\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un résultat fondamental lié à la distance de Dudley est l’inégalité
de concentration de Dudley, qui fournit une borne supérieure sur les
écarts entre un processus empirique et son espérance.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((T, d)\)</span> un espace métrique
compact et <span class="math inline">\(\mathcal{F}\)</span> un ensemble
de fonctions bornées sur <span class="math inline">\(T\)</span>.
Supposons que les fonctions de <span
class="math inline">\(\mathcal{F}\)</span> soient centrées, i.e., <span
class="math inline">\(\mathbb{E}[f(t)] = 0\)</span> pour tout <span
class="math inline">\(t \in T\)</span>. Alors, pour tout <span
class="math inline">\(\epsilon &gt; 0\)</span>, on a : <span
class="math display">\[\mathbb{P}\left( \sup_{f \in \mathcal{F}} f(t) -
\mathbb{E}[f(t)] \geq \epsilon \right) \leq 2 \exp\left(
-\frac{\epsilon^2}{8 \Delta(\mathcal{F}, d)^2} \right).\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour démontrer l’inégalité de concentration de Dudley, nous utilisons
des techniques d’entropie et des inégalités de concentration pour les
processus empiriques. La preuve repose sur le lemme de Talagrand et
l’inégalité de Bernstein.</p>
<div class="proof">
<p><em>Proof.</em> Considérons un processus empirique <span
class="math inline">\(X_t\)</span> défini par <span
class="math inline">\(X_t = \sum_{i=1}^n f_i(t) \xi_i\)</span>, où <span
class="math inline">\(\xi_i\)</span> sont des variables aléatoires
indépendantes de loi Rademacher. Nous voulons contrôler la déviation de
<span class="math inline">\(X_t\)</span> autour de son espérance.</p>
<p>Par le lemme de Talagrand, nous avons : <span
class="math display">\[\mathbb{P}\left( \sup_{f \in \mathcal{F}} |X_t -
\mathbb{E}[X_t]| \geq \epsilon \right) \leq 2 \exp\left(
-\frac{\epsilon^2}{8 \sigma^2} \right),\]</span> où <span
class="math inline">\(\sigma^2\)</span> est la variance du processus
<span class="math inline">\(X_t\)</span>.</p>
<p>En utilisant l’inégalité de Bernstein et les propriétés de
l’entropie, nous pouvons montrer que <span
class="math inline">\(\sigma^2 \leq \Delta(\mathcal{F}, d)^2\)</span>.
Ainsi, nous obtenons l’inégalité de concentration souhaitée. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons quelques propriétés importantes de la distance de
Dudley.</p>
<ol>
<li><p><strong>Invariance par translation</strong> : La distance de
Dudley est invariante par translation des fonctions. Si <span
class="math inline">\(\mathcal{F}\)</span> est translaté par une
fonction bornée <span class="math inline">\(g\)</span>, alors <span
class="math inline">\(\Delta(\mathcal{F} + g, d) = \Delta(\mathcal{F},
d)\)</span>.</p></li>
<li><p><strong>Inégalité triangulaire</strong> : Pour deux ensembles de
fonctions <span class="math inline">\(\mathcal{F}_1\)</span> et <span
class="math inline">\(\mathcal{F}_2\)</span>, on a : <span
class="math display">\[\Delta(\mathcal{F}_1 + \mathcal{F}_2, d) \leq
\Delta(\mathcal{F}_1, d) + \Delta(\mathcal{F}_2, d).\]</span></p></li>
<li><p><strong>Contrôle de la complexité</strong> : La distance de
Dudley fournit un moyen de contrôler la complexité d’un ensemble de
fonctions. Plus <span class="math inline">\(\Delta(\mathcal{F},
d)\)</span> est petit, plus l’ensemble <span
class="math inline">\(\mathcal{F}\)</span> est simple.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La distance de Dudley est un outil puissant pour l’analyse des
processus stochastiques et la théorie de l’estimation. Ses applications
vont au-delà des mathématiques pures, touchant des domaines tels que
l’apprentissage statistique et l’analyse de données. La compréhension de
cette notion permet de mieux appréhender les fluctuations des fonctions
aléatoires et de déduire des bornes précises sur leurs écarts.</p>
</body>
</html>
{% include "footer.html" %}

