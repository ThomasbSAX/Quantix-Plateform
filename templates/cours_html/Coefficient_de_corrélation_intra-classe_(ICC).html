{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Le Coefficient de Corrélation Intra-Classes (ICC)</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Le Coefficient de Corrélation Intra-Classes (ICC)</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>Le coefficient de corrélation intra-classe (ICC) est une mesure
statistique fondamentale dans l’analyse des données hiérarchiques ou
groupées. Il émerge comme un outil indispensable pour quantifier la
similarité des mesures au sein de groupes ou de classes, par opposition
à la variabilité entre ces groupes. Historiquement, l’ICC a été
développé pour répondre à des besoins en psychométrie et en
biostatistiques, où l’évaluation de la fiabilité des mesures répétées ou
des évaluations inter-juges est cruciale. L’ICC permet de déterminer
dans quelle mesure les observations au sein d’un même groupe sont plus
proches les unes des autres que celles de groupes différents, ce qui est
essentiel pour valider la cohérence interne des données et la robustesse
des conclusions tirées de ces analyses.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir l’ICC, commençons par comprendre ce que nous cherchons à
mesurer. Supposons que nous avons un ensemble de données structurées en
groupes, où chaque groupe contient plusieurs observations. Nous voulons
quantifier la proportion de la variance totale des données qui est due
aux différences entre les groupes plutôt qu’aux variations au sein des
groupes. En d’autres termes, nous cherchons une mesure qui reflète à
quel point les observations dans un même groupe sont similaires.</p>
<p>Formellement, soit <span class="math inline">\(Y_{ij}\)</span> la
mesure de l’observation <span class="math inline">\(j\)</span> dans le
groupe <span class="math inline">\(i\)</span>, où <span
class="math inline">\(i = 1, \ldots, n\)</span> et <span
class="math inline">\(j = 1, \ldots, k_i\)</span>. Nous définissons les
composantes de variance comme suit :</p>
<ul>
<li><p>La variance entre les groupes : <span
class="math inline">\(\sigma^2_b = \frac{1}{n-1} \sum_{i=1}^n (\bar{Y}_i
- \bar{Y})^2\)</span></p></li>
<li><p>La variance au sein des groupes : <span
class="math inline">\(\sigma^2_w = \frac{1}{N-n} \sum_{i=1}^n
\sum_{j=1}^{k_i} (Y_{ij} - \bar{Y}_i)^2\)</span></p></li>
<li><p>La variance totale : <span class="math inline">\(\sigma^2_t =
\frac{1}{N-1} \sum_{i=1}^n \sum_{j=1}^{k_i} (Y_{ij} -
\bar{Y})^2\)</span></p></li>
</ul>
<p>où <span class="math inline">\(N = \sum_{i=1}^n k_i\)</span> est le
nombre total d’observations, <span
class="math inline">\(\bar{Y}_i\)</span> est la moyenne du groupe <span
class="math inline">\(i\)</span>, et <span
class="math inline">\(\bar{Y}\)</span> est la moyenne globale.</p>
<p>Le coefficient de corrélation intra-classe (ICC) est alors défini
comme :</p>
<p><span class="math display">\[\text{ICC} =
\frac{\sigma^2_b}{\sigma^2_b + \sigma^2_w}\]</span></p>
<p>Cette formule capture la proportion de la variance totale qui est
attribuable aux différences entre les groupes.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à l’ICC est le théorème de la
décomposition de la variance, qui stipule que la variance totale peut
être décomposée en une somme des variances entre les groupes et au sein
des groupes. Formellement, nous avons :</p>
<p><span class="math display">\[\sigma^2_t = \sigma^2_b +
\sigma^2_w\]</span></p>
<p>Ce théorème est crucial pour comprendre la structure des données
hiérarchiques et pour interpréter correctement l’ICC. Il permet de
séparer les sources de variabilité et de quantifier leur contribution
relative à la variance totale.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de la décomposition de la variance, nous
commençons par exprimer la variance totale en termes des moyennes des
groupes et de la moyenne globale :</p>
<p><span class="math display">\[\sigma^2_t = \frac{1}{N-1} \sum_{i=1}^n
\sum_{j=1}^{k_i} (Y_{ij} - \bar{Y})^2\]</span></p>
<p>Nous pouvons décomposer cette expression en utilisant l’identité
suivante :</p>
<p><span class="math display">\[(Y_{ij} - \bar{Y})^2 = (Y_{ij} -
\bar{Y}_i + \bar{Y}_i - \bar{Y})^2 = (Y_{ij} - \bar{Y}_i)^2 + 2(Y_{ij} -
\bar{Y}_i)(\bar{Y}_i - \bar{Y}) + (\bar{Y}_i - \bar{Y})^2\]</span></p>
<p>En prenant la somme sur toutes les observations, nous obtenons :</p>
<p><span class="math display">\[\sum_{i=1}^n \sum_{j=1}^{k_i} (Y_{ij} -
\bar{Y})^2 = \sum_{i=1}^n \sum_{j=1}^{k_i} (Y_{ij} - \bar{Y}_i)^2 + 2
\sum_{i=1}^n \sum_{j=1}^{k_i} (Y_{ij} - \bar{Y}_i)(\bar{Y}_i - \bar{Y})
+ \sum_{i=1}^n k_i (\bar{Y}_i - \bar{Y})^2\]</span></p>
<p>Le terme croisé <span class="math inline">\(2 \sum_{i=1}^n
\sum_{j=1}^{k_i} (Y_{ij} - \bar{Y}_i)(\bar{Y}_i - \bar{Y})\)</span> est
égal à zéro car <span class="math inline">\(\sum_{j=1}^{k_i} (Y_{ij} -
\bar{Y}_i) = 0\)</span>. Il reste donc :</p>
<p><span class="math display">\[\sum_{i=1}^n \sum_{j=1}^{k_i} (Y_{ij} -
\bar{Y})^2 = \sum_{i=1}^n \sum_{j=1}^{k_i} (Y_{ij} - \bar{Y}_i)^2 +
\sum_{i=1}^n k_i (\bar{Y}_i - \bar{Y})^2\]</span></p>
<p>En divisant par <span class="math inline">\(N-1\)</span> et en
utilisant les définitions des variances entre et au sein des groupes,
nous obtenons :</p>
<p><span class="math display">\[\sigma^2_t = \frac{N-n}{N-1} \sigma^2_w
+ \frac{n-1}{N-1} \sigma^2_b\]</span></p>
<p>Pour des grands <span class="math inline">\(N\)</span>, cette
expression se simplifie en :</p>
<p><span class="math display">\[\sigma^2_t = \sigma^2_b +
\sigma^2_w\]</span></p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’ICC possède plusieurs propriétés importantes :</p>
<ul>
<li><p>L’ICC est une mesure de la fiabilité des mesures répétées. Plus
l’ICC est proche de 1, plus les observations au sein d’un même groupe
sont similaires.</p></li>
<li><p>L’ICC peut être utilisé pour évaluer la cohérence interne des
données. Un ICC élevé indique une forte cohérence.</p></li>
<li><p>L’ICC est sensible à la taille des groupes. Des groupes de
tailles différentes peuvent affecter la valeur de l’ICC.</p></li>
</ul>
<p>Pour prouver ces propriétés, nous pouvons utiliser les définitions et
le théorème de la décomposition de la variance. Par exemple, pour
montrer que l’ICC est une mesure de fiabilité, nous pouvons considérer
le cas où toutes les observations dans un groupe sont identiques. Dans
ce cas, <span class="math inline">\(\sigma^2_w = 0\)</span> et l’ICC est
égal à 1, indiquant une fiabilité parfaite.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le coefficient de corrélation intra-classe (ICC) est un outil
puissant pour l’analyse des données hiérarchiques. Il permet de
quantifier la similarité des observations au sein de groupes et de
valider la cohérence interne des données. En comprenant les définitions,
les théorèmes et les propriétés de l’ICC, nous pouvons mieux interpréter
les résultats des analyses statistiques et tirer des conclusions plus
robustes.</p>
</body>
</html>
{% include "footer.html" %}

