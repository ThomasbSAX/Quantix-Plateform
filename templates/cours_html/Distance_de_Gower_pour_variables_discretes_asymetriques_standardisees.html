{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Gower pour variables discrètes asymétriques standardisées</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Gower pour variables discrètes
asymétriques standardisées</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Gower est une mesure de dissimilarité particulièrement
adaptée aux données mixtes, c’est-à-dire des ensembles de variables où
certaines sont quantitatives et d’autres qualitatives. Son origine
remonte aux travaux de Gower en 1971, où il a cherché à généraliser les
distances euclidiennes pour prendre en compte la nature heterogeneous
des données. Cette notion est indispensable dans les domaines où les
données sont complexes et ne peuvent pas être traitées par des méthodes
classiques de distance, comme en biologie, en sociologie ou en
économie.</p>
<p>L’émergence de la distance de Gower répond à un besoin crucial :
mesurer la dissimilarité entre des objets décrits par des variables de
types différents. Par exemple, dans une étude médicale, on pourrait
vouloir comparer des patients en fonction de leur âge (variable
quantitative), de leur sexe (variable qualitative binaire) et de leur
groupe sanguin (variable qualitative nominale). La distance de Gower
permet de combiner ces informations de manière cohérente et
significative.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la distance de Gower, nous devons d’abord comprendre ce
que nous cherchons à mesurer. Imaginons deux objets décrits par un
ensemble de variables. Nous voulons quantifier à quel point ces deux
objets diffèrent, en tenant compte du type de chaque variable. Pour une
variable quantitative, la différence est simplement la distance absolue
entre les valeurs. Pour une variable qualitative, nous devons définir
une mesure de dissimilarité appropriée.</p>
<p>Supposons que nous ayons un ensemble de variables <span
class="math inline">\(V = \{v_1, v_2, \dots, v_p\}\)</span>, où
certaines variables sont quantitatives et d’autres qualitatives. Pour
chaque variable quantitative <span class="math inline">\(v_k\)</span>,
nous standardisons les valeurs pour qu’elles soient comparables. Pour
une variable qualitative <span class="math inline">\(v_k\)</span>, nous
définissons une matrice de dissimilarité <span
class="math inline">\(\Delta^{(k)}\)</span> où chaque entrée <span
class="math inline">\(\Delta^{(k)}_{ij}\)</span> représente la
dissimilarité entre les catégories <span
class="math inline">\(i\)</span> et <span
class="math inline">\(j\)</span>.</p>
<p>La distance de Gower entre deux objets <span
class="math inline">\(x\)</span> et <span
class="math inline">\(y\)</span> est alors définie comme la moyenne des
dissimilarités sur toutes les variables, pondérée par l’importance de
chaque variable. Formellement, nous avons :</p>
<p><span class="math display">\[d_G(x, y) = \frac{\sum_{k=1}^p w_k
d_k(x_k, y_k)}{\sum_{k=1}^p w_k}\]</span></p>
<p>où <span class="math inline">\(w_k\)</span> est le poids de la
variable <span class="math inline">\(v_k\)</span>, et <span
class="math inline">\(d_k(x_k, y_k)\)</span> est la dissimilarité entre
les valeurs <span class="math inline">\(x_k\)</span> et <span
class="math inline">\(y_k\)</span> pour la variable <span
class="math inline">\(v_k\)</span>.</p>
<p>Pour une variable quantitative standardisée <span
class="math inline">\(v_k\)</span>, la dissimilarité est définie par
:</p>
<p><span class="math display">\[d_k(x_k, y_k) = |x_k - y_k|\]</span></p>
<p>Pour une variable qualitative <span
class="math inline">\(v_k\)</span>, la dissimilarité est définie par
:</p>
<p><span class="math display">\[d_k(x_k, y_k) = \Delta^{(k)}_{x_k
y_k}\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème important lié à la distance de Gower est le théorème de
la métrique, qui garantit que la distance de Gower satisfait les
propriétés d’une métrique sous certaines conditions. Ce théorème est
crucial pour assurer que la distance de Gower peut être utilisée dans
des algorithmes qui nécessitent une métrique, comme les méthodes de
clustering.</p>
<p>Supposons que nous avons un ensemble de variables <span
class="math inline">\(V = \{v_1, v_2, \dots, v_p\}\)</span> avec des
poids <span class="math inline">\(w_k &gt; 0\)</span> pour chaque
variable <span class="math inline">\(v_k\)</span>. Supposons également
que pour chaque variable qualitative <span
class="math inline">\(v_k\)</span>, la matrice de dissimilarité <span
class="math inline">\(\Delta^{(k)}\)</span> satisfait les propriétés
d’une métrique : non-négativité, identité des indiscernables, symétrie
et inégalité triangulaire.</p>
<p>Alors, la distance de Gower <span class="math inline">\(d_G\)</span>
définie par :</p>
<p><span class="math display">\[d_G(x, y) = \frac{\sum_{k=1}^p w_k
d_k(x_k, y_k)}{\sum_{k=1}^p w_k}\]</span></p>
<p>satisfait également les propriétés d’une métrique.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver que la distance de Gower satisfait les propriétés d’une
métrique, nous devons vérifier chacune des quatre propriétés :
non-négativité, identité des indiscernables, symétrie et inégalité
triangulaire.</p>
<div class="proof">
<p><em>Proof.</em> 1. <strong>Non-négativité</strong> : Pour tout <span
class="math inline">\(x, y\)</span>, nous avons :</p>
<p><span class="math display">\[d_G(x, y) = \frac{\sum_{k=1}^p w_k
d_k(x_k, y_k)}{\sum_{k=1}^p w_k} \geq 0\]</span></p>
<p>car <span class="math inline">\(d_k(x_k, y_k) \geq 0\)</span> pour
tout <span class="math inline">\(k\)</span>.</p>
<p>2. <strong>Identité des indiscernables</strong> : Pour tout <span
class="math inline">\(x\)</span>, nous avons :</p>
<p><span class="math display">\[d_G(x, x) = \frac{\sum_{k=1}^p w_k
d_k(x_k, x_k)}{\sum_{k=1}^p w_k} = 0\]</span></p>
<p>car <span class="math inline">\(d_k(x_k, x_k) = 0\)</span> pour tout
<span class="math inline">\(k\)</span>.</p>
<p>3. <strong>Symétrie</strong> : Pour tout <span
class="math inline">\(x, y\)</span>, nous avons :</p>
<p><span class="math display">\[d_G(x, y) = \frac{\sum_{k=1}^p w_k
d_k(x_k, y_k)}{\sum_{k=1}^p w_k} = \frac{\sum_{k=1}^p w_k d_k(y_k,
x_k)}{\sum_{k=1}^p w_k} = d_G(y, x)\]</span></p>
<p>car <span class="math inline">\(d_k(x_k, y_k) = d_k(y_k,
x_k)\)</span> pour tout <span class="math inline">\(k\)</span>.</p>
<p>4. <strong>Inégalité triangulaire</strong> : Pour tout <span
class="math inline">\(x, y, z\)</span>, nous avons :</p>
<p><span class="math display">\[d_G(x, y) + d_G(y, z) =
\frac{\sum_{k=1}^p w_k (d_k(x_k, y_k) + d_k(y_k, z_k))}{\sum_{k=1}^p
w_k}\]</span></p>
<p>Nous devons montrer que :</p>
<p><span class="math display">\[d_k(x_k, y_k) + d_k(y_k, z_k) \geq
d_k(x_k, z_k)\]</span></p>
<p>pour tout <span class="math inline">\(k\)</span>. Pour les variables
quantitatives, cela découle de l’inégalité triangulaire pour la distance
absolue. Pour les variables qualitatives, cela découle de l’inégalité
triangulaire pour la matrice de dissimilarité <span
class="math inline">\(\Delta^{(k)}\)</span>.</p>
<p>Par conséquent, nous avons :</p>
<p><span class="math display">\[d_G(x, y) + d_G(y, z) \geq d_G(x,
z)\]</span></p>
<p>Ce qui achève la preuve. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
distance de Gower.</p>
<ol>
<li><p><strong>Invariance par translation</strong> : La distance de
Gower est invariante par translation des variables quantitatives. Cela
signifie que si nous ajoutons une constante à toutes les valeurs d’une
variable quantitative, la distance de Gower reste inchangée.</p>
<div class="proof">
<p><em>Proof.</em> Supposons que nous ajoutons une constante <span
class="math inline">\(c\)</span> à toutes les valeurs de la variable
quantitative <span class="math inline">\(v_k\)</span>. Alors, pour tout
<span class="math inline">\(x, y\)</span>, nous avons :</p>
<p><span class="math display">\[d_k(x_k + c, y_k + c) = |(x_k + c) -
(y_k + c)| = |x_k - y_k| = d_k(x_k, y_k)\]</span></p>
<p>Par conséquent, la distance de Gower reste inchangée. ◻</p>
</div></li>
<li><p><strong>Invariance par échelle</strong> : La distance de Gower
est invariante par multiplication des variables quantitatives par une
constante positive. Cela signifie que si nous multiplions toutes les
valeurs d’une variable quantitative par une constante positive, la
distance de Gower reste inchangée.</p>
<div class="proof">
<p><em>Proof.</em> Supposons que nous multiplions toutes les valeurs de
la variable quantitative <span class="math inline">\(v_k\)</span> par
une constante positive <span class="math inline">\(a\)</span>. Alors,
pour tout <span class="math inline">\(x, y\)</span>, nous avons :</p>
<p><span class="math display">\[d_k(a x_k, a y_k) = |a x_k - a y_k| = a
|x_k - y_k| = a d_k(x_k, y_k)\]</span></p>
<p>Cependant, la standardisation des variables quantitatives garantit
que cette multiplication n’affecte pas la distance de Gower. ◻</p>
</div></li>
<li><p><strong>Sensibilité aux poids</strong> : La distance de Gower est
sensible aux poids des variables. Cela signifie que la modification des
poids des variables peut affecter la distance de Gower.</p>
<div class="proof">
<p><em>Proof.</em> Supposons que nous changeons le poids <span
class="math inline">\(w_k\)</span> de la variable <span
class="math inline">\(v_k\)</span> en <span
class="math inline">\(w&#39;_k\)</span>. Alors, pour tout <span
class="math inline">\(x, y\)</span>, nous avons :</p>
<p><span class="math display">\[d_G(x, y) = \frac{\sum_{k=1}^p w&#39;_k
d_k(x_k, y_k)}{\sum_{k=1}^p w&#39;_k}\]</span></p>
<p>qui peut être différent de la distance de Gower originale. ◻</p>
</div></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La distance de Gower est une mesure de dissimilarité puissante et
flexible, particulièrement adaptée aux données mixtes. Son utilisation
permet de combiner des variables de types différents de manière
cohérente et significative. Les propriétés et théorèmes associés à la
distance de Gower en font un outil précieux pour l’analyse des données
complexes.</p>
</body>
</html>
{% include "footer.html" %}

