{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Earth Mover’s Distance : Une Métrique pour les Distributions</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Earth Mover’s Distance : Une Métrique pour les
Distributions</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’Earth Mover’s Distance (EMD), également connue sous le nom de
Wassestein distance, est une métrique fondamentale en théorie des
probabilités et en analyse des données. Son origine remonte aux travaux
de Leonid Kantorovich dans les années 1940, où il a introduit cette
notion pour résoudre des problèmes de transport optimal. L’EMD mesure la
distance entre deux distributions de probabilités en termes du coût
minimal nécessaire pour transformer une distribution en une autre.</p>
<p>Cette métrique est indispensable dans de nombreux domaines, notamment
en vision par ordinateur, en traitement du signal et en apprentissage
automatique. Elle permet de comparer des formes, des textures et des
distributions de manière robuste et intuitive.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre l’EMD, commençons par définir ce que nous cherchons à
mesurer. Supposons que nous ayons deux distributions de probabilités
discrètes sur un espace métrique <span class="math inline">\((X,
d)\)</span>. Nous voulons mesurer la quantité de travail nécessaire pour
transformer une distribution en une autre.</p>
<p>Formellement, soit <span class="math inline">\(P = \{(x_1, p_1),
\ldots, (x_n, p_n)\}\)</span> et <span class="math inline">\(Q = \{(y_1,
q_1), \ldots, (y_m, q_m)\}\)</span> deux distributions de probabilités
discrètes, où <span class="math inline">\(x_i, y_j \in X\)</span> et
<span class="math inline">\(p_i, q_j \geq 0\)</span> avec <span
class="math inline">\(\sum_{i=1}^n p_i = \sum_{j=1}^m q_j =
1\)</span>.</p>
<p>Nous cherchons à trouver un couplage entre <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span>, c’est-à-dire une matrice <span
class="math inline">\(F \in \mathbb{R}^{n \times m}\)</span> telle que
<span class="math inline">\(\sum_{j=1}^m F_{ij} = p_i\)</span> pour tout
<span class="math inline">\(i\)</span> et <span
class="math inline">\(\sum_{i=1}^n F_{ij} = q_j\)</span> pour tout <span
class="math inline">\(j\)</span>.</p>
<p>L’EMD est alors définie comme le coût minimal de ce transport :</p>
<div class="definition">
<p>L’Earth Mover’s Distance entre <span class="math inline">\(P\)</span>
et <span class="math inline">\(Q\)</span> est donnée par : <span
class="math display">\[\text{EMD}(P, Q) = \min_F \sum_{i=1}^n
\sum_{j=1}^m F_{ij} d(x_i, y_j)\]</span> où la minimisation est prise
sur toutes les matrices de couplage <span
class="math inline">\(F\)</span> entre <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span>.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à l’EMD est le théorème de
Kantorovich-Rubinstein, qui donne une formulation duale de l’EMD.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilités sur
un espace métrique <span class="math inline">\((X, d)\)</span>. Alors :
<span class="math display">\[\text{EMD}(P, Q) = \sup_{f \in
\text{Lip}_1(X)} \left( \int_X f dP - \int_X f dQ \right)\]</span> où
<span class="math inline">\(\text{Lip}_1(X)\)</span> est l’ensemble des
fonctions <span class="math inline">\(f: X \to \mathbb{R}\)</span>
Lipschitziennes de constante <span class="math inline">\(\leq
1\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Kantorovich-Rubinstein, nous utilisons la
théorie du transport optimal. La preuve repose sur le fait que toute
fonction Lipschitzienne de constante 1 est une contrainte linéaire dans
le problème dual.</p>
<div class="proof">
<p><em>Proof.</em> Considérons le problème de minimisation : <span
class="math display">\[\min_F \sum_{i=1}^n \sum_{j=1}^m F_{ij} d(x_i,
y_j)\]</span> avec les contraintes <span
class="math inline">\(\sum_{j=1}^m F_{ij} = p_i\)</span> et <span
class="math inline">\(\sum_{i=1}^n F_{ij} = q_j\)</span>.</p>
<p>Le problème dual est : <span class="math display">\[\max_{f, g}
\sum_{i=1}^n p_i f(x_i) - \sum_{j=1}^m q_j g(y_j)\]</span> sous les
contraintes <span class="math inline">\(f(x_i) - g(y_j) \leq d(x_i,
y_j)\)</span> pour tous <span class="math inline">\(i, j\)</span>.</p>
<p>Par dualité, nous savons que la valeur optimale du problème primal
est égale à la valeur optimale du problème dual. En choisissant <span
class="math inline">\(f\)</span> et <span
class="math inline">\(g\)</span> comme des fonctions Lipschitziennes de
constante 1, nous obtenons la formulation duale du théorème. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’EMD possède plusieurs propriétés intéressantes :</p>
<ol>
<li><p><strong>Métricité</strong> : L’EMD est une métrique sur l’espace
des distributions de probabilités. Cela signifie qu’elle satisfait les
propriétés de non-négativité, de symétrie et d’inégalité
triangulaire.</p></li>
<li><p><strong>Invariance par translation</strong> : L’EMD est
invariante par translation. Si nous translatons toutes les masses de
<span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> par le même vecteur, l’EMD reste
inchangée.</p></li>
<li><p><strong>Continuité</strong> : L’EMD est continue par rapport à la
convergence faible des distributions de probabilités.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’Earth Mover’s Distance est une métrique puissante et flexible pour
comparer des distributions de probabilités. Ses applications sont vastes
et variées, allant de la vision par ordinateur à l’apprentissage
automatique. En comprenant les définitions, théorèmes et propriétés de
l’EMD, nous pouvons mieux apprécier son importance et son utilité dans
divers domaines.</p>
</body>
</html>
{% include "footer.html" %}

