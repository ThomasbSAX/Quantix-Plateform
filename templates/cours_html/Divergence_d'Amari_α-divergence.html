{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Divergence d’Amari \alpha-divergence</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Divergence d’Amari <span
class="math inline">\(\alpha\)</span>-divergence</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La divergence d’Amari, également connue sous le nom de <span
class="math inline">\(\alpha\)</span>-divergence, est une mesure de
divergence entre deux distributions de probabilité. Cette notion émerge
dans le cadre de l’analyse des informations et de la théorie des
statistiques, où elle trouve des applications notamment dans les
méthodes d’estimation non paramétriques et l’apprentissage automatique.
La <span class="math inline">\(\alpha\)</span>-divergence généralise
plusieurs mesures de divergence bien connues, telles que la divergence
de Kullback-Leibler et la divergence de Hellinger. Son étude est
indispensable pour comprendre les propriétés fondamentales des mesures
de divergence et leurs applications pratiques.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir la divergence d’Amari <span
class="math inline">\(\alpha\)</span>-divergence, commençons par
considérer deux distributions de probabilité <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> sur un espace mesurable <span
class="math inline">\((\Omega, \mathcal{F})\)</span>. Nous cherchons une
mesure qui quantifie la différence entre ces deux distributions.
Intuitivement, cette mesure doit être symétrique et dépendre d’un
paramètre <span class="math inline">\(\alpha\)</span> qui contrôle la
sensibilité de la divergence aux différences locales entre <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span>.</p>
<p>La divergence d’Amari <span
class="math inline">\(\alpha\)</span>-divergence est formellement
définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilité sur
un espace mesurable <span class="math inline">\((\Omega,
\mathcal{F})\)</span>. La divergence d’Amari <span
class="math inline">\(\alpha\)</span>-divergence est définie par : <span
class="math display">\[D_{\alpha}(P \| Q) = \frac{1}{\alpha(1-\alpha)}
\left( 1 - \int_{\Omega} \left( \frac{dP}{dQ} \right)^{\alpha} dQ
\right),\]</span> où <span class="math inline">\(\frac{dP}{dQ}\)</span>
est la densité de <span class="math inline">\(P\)</span> par rapport à
<span class="math inline">\(Q\)</span>, et <span
class="math inline">\(\alpha \in \mathbb{R} \setminus \{0,
1\}\)</span>.</p>
</div>
<p>Une autre formulation équivalente est : <span
class="math display">\[D_{\alpha}(P \| Q) = \frac{1}{\alpha(1-\alpha)}
\left( 1 - \mathbb{E}_{Q} \left[ \left( \frac{dP}{dQ} \right)^{\alpha}
\right] \right),\]</span> où <span
class="math inline">\(\mathbb{E}_{Q}\)</span> désigne l’espérance par
rapport à la distribution <span class="math inline">\(Q\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la divergence d’Amari <span
class="math inline">\(\alpha\)</span>-divergence est le suivant :</p>
<div class="theorem">
<p>Pour tout <span class="math inline">\(\alpha \in (0, 1) \cup (1,
\infty)\)</span>, la divergence d’Amari <span
class="math inline">\(D_{\alpha}(P \| Q)\)</span> est convexe en <span
class="math inline">\(P\)</span> pour <span
class="math inline">\(Q\)</span> fixé.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, nous utilisons le
fait que la fonction <span class="math inline">\(f(x) =
x^{\alpha}\)</span> est convexe pour <span class="math inline">\(\alpha
\in (0, 1) \cup (1, \infty)\)</span>. Par conséquent, l’espérance <span
class="math inline">\(\mathbb{E}_{Q} \left[ \left( \frac{dP}{dQ}
\right)^{\alpha} \right]\)</span> est également convexe en <span
class="math inline">\(P\)</span> pour <span
class="math inline">\(Q\)</span> fixé. La divergence d’Amari étant une
transformation linéaire de cette espérance, elle hérite de la propriété
de convexité. ◻</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Considérons maintenant une preuve détaillée de la propriété de
convexité. Soient <span class="math inline">\(P_1\)</span> et <span
class="math inline">\(P_2\)</span> deux distributions de probabilité, et
<span class="math inline">\(\lambda \in [0, 1]\)</span>. Nous voulons
montrer que : <span class="math display">\[D_{\alpha}(\lambda P_1 + (1 -
\lambda) P_2 \| Q) \leq \lambda D_{\alpha}(P_1 \| Q) + (1 - \lambda)
D_{\alpha}(P_2 \| Q).\]</span></p>
<p>Commençons par développer le terme de gauche : <span
class="math display">\[D_{\alpha}(\lambda P_1 + (1 - \lambda) P_2 \| Q)
= \frac{1}{\alpha(1-\alpha)} \left( 1 - \mathbb{E}_{Q} \left[ \left(
\frac{d(\lambda P_1 + (1 - \lambda) P_2)}{dQ} \right)^{\alpha} \right]
\right).\]</span></p>
<p>En utilisant la linéarité de l’espérance, nous obtenons : <span
class="math display">\[\mathbb{E}_{Q} \left[ \left( \frac{d(\lambda P_1
+ (1 - \lambda) P_2)}{dQ} \right)^{\alpha} \right] = \mathbb{E}_{Q}
\left[ \left( \lambda \frac{dP_1}{dQ} + (1 - \lambda) \frac{dP_2}{dQ}
\right)^{\alpha} \right].\]</span></p>
<p>Par la convexité de la fonction <span class="math inline">\(f(x) =
x^{\alpha}\)</span>, nous avons : <span
class="math display">\[\mathbb{E}_{Q} \left[ \left( \lambda
\frac{dP_1}{dQ} + (1 - \lambda) \frac{dP_2}{dQ} \right)^{\alpha} \right]
\leq \lambda \mathbb{E}_{Q} \left[ \left( \frac{dP_1}{dQ}
\right)^{\alpha} \right] + (1 - \lambda) \mathbb{E}_{Q} \left[ \left(
\frac{dP_2}{dQ} \right)^{\alpha} \right].\]</span></p>
<p>En substituant cette inégalité dans l’expression précédente, nous
obtenons : <span class="math display">\[D_{\alpha}(\lambda P_1 + (1 -
\lambda) P_2 \| Q) \geq \frac{1}{\alpha(1-\alpha)} \left( 1 - \lambda
\mathbb{E}_{Q} \left[ \left( \frac{dP_1}{dQ} \right)^{\alpha} \right] -
(1 - \lambda) \mathbb{E}_{Q} \left[ \left( \frac{dP_2}{dQ}
\right)^{\alpha} \right] \right).\]</span></p>
<p>En réarrangeant les termes, nous obtenons finalement : <span
class="math display">\[D_{\alpha}(\lambda P_1 + (1 - \lambda) P_2 \| Q)
\leq \lambda D_{\alpha}(P_1 \| Q) + (1 - \lambda) D_{\alpha}(P_2 \|
Q),\]</span> ce qui prouve la convexité de la divergence d’Amari.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
divergence d’Amari <span
class="math inline">\(\alpha\)</span>-divergence :</p>
<ul>
<li><p><strong>Continuité</strong> : Pour <span
class="math inline">\(\alpha \in (0, 1) \cup (1, \infty)\)</span>, la
divergence d’Amari <span class="math inline">\(D_{\alpha}(P \|
Q)\)</span> est continue en <span class="math inline">\(P\)</span> pour
<span class="math inline">\(Q\)</span> fixé.</p></li>
<li><p><strong>Symétrie</strong> : Pour <span
class="math inline">\(\alpha = 1/2\)</span>, la divergence d’Amari
devient symétrique, c’est-à-dire que <span
class="math inline">\(D_{1/2}(P \| Q) = D_{1/2}(Q \|
P)\)</span>.</p></li>
<li><p><strong>Limites</strong> : En prenant la limite lorsque <span
class="math inline">\(\alpha\)</span> tend vers 0, nous obtenons la
divergence de Kullback-Leibler : <span
class="math display">\[\lim_{\alpha \to 0} D_{\alpha}(P \| Q) = D_{KL}(P
\| Q).\]</span> De même, en prenant la limite lorsque <span
class="math inline">\(\alpha\)</span> tend vers 1, nous obtenons
également la divergence de Kullback-Leibler : <span
class="math display">\[\lim_{\alpha \to 1} D_{\alpha}(P \| Q) = D_{KL}(Q
\| P).\]</span></p></li>
</ul>
<p>Pour chaque propriété, des preuves détaillées peuvent être fournies
en utilisant les définitions et les théorèmes précédents. Par exemple,
la symétrie pour <span class="math inline">\(\alpha = 1/2\)</span> peut
être démontrée en montrant que : <span class="math display">\[D_{1/2}(P
\| Q) = \frac{4}{1} \left( 1 - \mathbb{E}_{Q} \left[
\sqrt{\frac{dP}{dQ}} \right] \right) = D_{1/2}(Q \| P).\]</span></p>
</body>
</html>
{% include "footer.html" %}

