{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Fonction fortement convexe</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Fonction fortement convexe</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les fonctions fortement convexes jouent un rôle central en analyse
convexe, optimisation et théorie des équations différentielles.
Introduites pour la première fois par Moreau en 1962, ces fonctions
généralisent les notions classiques de convexité et de strict convexité.
Elles permettent de modéliser des phénomènes où une certaine régularité
est requise, comme dans les problèmes d’optimisation où l’on cherche à
éviter les minimums locaux indésirables.</p>
<p>L’importance des fonctions fortement convexes réside dans leur
capacité à garantir l’existence et l’unicité des solutions aux problèmes
d’optimisation, ainsi que dans leur stabilité numérique. Elles sont
également utilisées en machine learning pour assurer la convergence
rapide des algorithmes d’optimisation.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre ce qu’est une fonction fortement convexe, considérons
d’abord une fonction convexe. Une fonction <span class="math inline">\(f
: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> est convexe si pour tout
<span class="math inline">\(x, y \in \mathbb{R}^n\)</span> et tout <span
class="math inline">\(\lambda \in [0,1]\)</span>, on a : <span
class="math display">\[f(\lambda x + (1-\lambda) y) \leq \lambda f(x) +
(1-\lambda) f(y).\]</span></p>
<p>Une fonction fortement convexe est une généralisation de cette
notion. Intuitivement, une fonction fortement convexe est une fonction
convexe qui "courbe vers le haut" suffisamment pour éviter les plateaux
et garantir l’unicité des minimums.</p>
<div class="definition">
<p>Soit <span class="math inline">\(f : \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction différentiable. On dit que <span
class="math inline">\(f\)</span> est fortement convexe avec paramètre
<span class="math inline">\(m &gt; 0\)</span> si pour tout <span
class="math inline">\(x, y \in \mathbb{R}^n\)</span>, on a : <span
class="math display">\[f(y) \geq f(x) + \langle \nabla f(x), y - x
\rangle + \frac{m}{2} \|y - x\|^2.\]</span> Equivalemment, on peut dire
que <span class="math inline">\(f\)</span> est fortement convexe si sa
dérivée seconde est uniformément positive, c’est-à-dire : <span
class="math display">\[\langle \nabla^2 f(x) (y - x), y - x \rangle \geq
m \|y - x\|^2, \quad \forall x, y \in \mathbb{R}^n.\]</span></p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un résultat fondamental concernant les fonctions fortement convexes
est le théorème suivant, qui garantit l’existence et l’unicité du
minimum global.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(f : \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction fortement convexe avec paramètre <span
class="math inline">\(m &gt; 0\)</span>. Alors, <span
class="math inline">\(f\)</span> admet un unique minimum global.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(x^*\)</span> un
point critique de <span class="math inline">\(f\)</span>, c’est-à-dire
que <span class="math inline">\(\nabla f(x^*) = 0\)</span>. Alors, pour
tout <span class="math inline">\(y \in \mathbb{R}^n\)</span>, on a :
<span class="math display">\[f(y) \geq f(x^*) + \frac{m}{2} \|y -
x^*\|^2.\]</span> Cela montre que <span class="math inline">\(f\)</span>
atteint son minimum en <span class="math inline">\(x^*\)</span>. De
plus, si <span class="math inline">\(y^*\)</span> est un autre point
critique, alors : <span class="math display">\[f(y^*) \geq f(x^*) +
\frac{m}{2} \|y^* - x^*\|^2,\]</span> et <span
class="math display">\[f(x^*) \geq f(y^*) + \frac{m}{2} \|x^* -
y^*\|^2.\]</span> En additionnant ces deux inégalités, on obtient :
<span class="math display">\[0 \geq m \|x^* - y^*\|^2.\]</span> Puisque
<span class="math inline">\(m &gt; 0\)</span>, cela implique que <span
class="math inline">\(x^* = y^*\)</span>. Donc, le minimum est
unique. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Les fonctions fortement convexes possèdent plusieurs propriétés
intéressantes.</p>
<div class="proposition">
<p>Soit <span class="math inline">\(f : \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction fortement convexe avec paramètre <span
class="math inline">\(m &gt; 0\)</span>. Alors, pour tout <span
class="math inline">\(x, y \in \mathbb{R}^n\)</span>, on a : <span
class="math display">\[f(y) \leq f(x) + \langle \nabla f(x), y - x
\rangle + \frac{L}{2} \|y - x\|^2,\]</span> où <span
class="math inline">\(L\)</span> est la constante de Lipschitz de <span
class="math inline">\(\nabla f\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Cette proposition découle du fait que la dérivée
seconde de <span class="math inline">\(f\)</span> est bornée par <span
class="math inline">\(L\)</span>. En effet, en intégrant l’inégalité :
<span class="math display">\[\langle \nabla^2 f(x) (y - x), y - x
\rangle \leq L \|y - x\|^2,\]</span> on obtient l’inégalité
désirée. ◻</p>
</div>
<div class="corollaire">
<p>Soit <span class="math inline">\(f : \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction fortement convexe avec paramètre <span
class="math inline">\(m &gt; 0\)</span>. Alors, la suite générée par
l’algorithme de gradient descendant converge linéairement vers le
minimum global.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Cette convergence découle des propriétés de
contraction de l’algorithme de gradient descendant lorsque la fonction
est fortement convexe. Plus précisément, on peut montrer que l’erreur
diminue exponentiellement à chaque itération. ◻</p>
</div>
<h1 id="exemples">Exemples</h1>
<p>Pour illustrer la notion de fonction fortement convexe, considérons
quelques exemples.</p>
<div class="exemple">
<p>La fonction <span class="math inline">\(f(x) = \frac{m}{2}
\|x\|^2\)</span>, où <span class="math inline">\(m &gt; 0\)</span>, est
fortement convexe avec paramètre <span class="math inline">\(m\)</span>.
En effet, on a : <span class="math display">\[f(y) = \frac{m}{2} \|y\|^2
= \frac{m}{2} \|x\|^2 + m \langle x, y - x \rangle + \frac{m}{2} \|y -
x\|^2 = f(x) + \langle \nabla f(x), y - x \rangle + \frac{m}{2} \|y -
x\|^2.\]</span></p>
</div>
<div class="exemple">
<p>La fonction <span class="math inline">\(f(x) = e^x\)</span> n’est pas
fortement convexe sur <span class="math inline">\(\mathbb{R}\)</span>.
En effet, sa dérivée seconde est <span
class="math inline">\(f&#39;&#39;(x) = e^x\)</span>, qui n’est pas
bornée inférieurement par une constante positive sur <span
class="math inline">\(\mathbb{R}\)</span>.</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Les fonctions fortement convexes sont des outils puissants en analyse
convexe et optimisation. Elles permettent de garantir l’existence et
l’unicité des solutions aux problèmes d’optimisation, ainsi que la
convergence rapide des algorithmes numériques. Leur étude continue de
susciter un vif intérêt dans la communauté mathématique et
appliquée.</p>
</body>
</html>
{% include "footer.html" %}

