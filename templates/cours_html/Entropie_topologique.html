{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Entropie Topologique : Une Mesure de la Complexité Dynamique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Entropie Topologique : Une Mesure de la Complexité
Dynamique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’entropie topologique, introduite par Adolf Theodor Bouwens en 1970,
est un concept fondamental dans la théorie des systèmes dynamiques. Elle
mesure la complexité d’un système dynamique en quantifiant le taux de
croissance du nombre de pièces distinctes dans lesquelles un espace peut
être divisé sous l’action d’itérations successives de la transformation.
Cette notion émerge comme une réponse à la nécessité de comprendre et de
classifier les systèmes dynamiques en fonction de leur comportement
chaotique ou ordonné.</p>
<p>L’entropie topologique est indispensable dans l’étude des systèmes
dynamiques car elle permet de distinguer entre des comportements simples
et complexes. Par exemple, une rotation sur un cercle a une entropie
nulle, indiquant un comportement périodique simple, tandis qu’une
transformation expansive peut avoir une entropie positive, reflétant un
comportement chaotique.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir l’entropie topologique, commençons par comprendre ce que
nous cherchons à mesurer. Imaginons un espace topologique <span
class="math inline">\(X\)</span> muni d’une métrique <span
class="math inline">\(d\)</span>. Nous voulons quantifier la manière
dont les itérations successives d’une transformation <span
class="math inline">\(f: X \rightarrow X\)</span> divisent l’espace en
pièces distinctes.</p>
<div class="definition">
<p>Soit <span class="math inline">\((X, d)\)</span> un espace métrique
compact et soit <span class="math inline">\(f: X \rightarrow X\)</span>
une transformation continue. Pour un ouvert <span
class="math inline">\(U \subset X\)</span>, définissons l’ensemble des
<span class="math inline">\(n\)</span>-ièmes itérées de <span
class="math inline">\(U\)</span> par <span class="math display">\[f^n(U)
= \{f^n(x) : x \in U\}.\]</span> Un ensemble <span
class="math inline">\(E \subset X\)</span> est dit <span
class="math inline">\((n, \epsilon)\)</span>-séparé par <span
class="math inline">\(U\)</span> si pour tout <span
class="math inline">\(x, y \in E\)</span>, il existe un entier <span
class="math inline">\(k \leq n\)</span> tel que <span
class="math inline">\(d(f^k(x), f^k(y)) &gt; \epsilon\)</span>.</p>
<p>Le nombre maximal de points <span class="math inline">\((n,
\epsilon)\)</span>-séparés par <span class="math inline">\(U\)</span>
est noté <span class="math inline">\(s_n(U, \epsilon)\)</span>.
L’entropie topologique de <span class="math inline">\(f\)</span> est
alors définie par <span class="math display">\[h_{\text{top}}(f) =
\lim_{\epsilon \rightarrow 0} \left( \limsup_{n \rightarrow \infty}
\frac{1}{n} \log s_n(U, \epsilon) \right).\]</span></p>
</div>
<p>Une autre formulation équivalente de l’entropie topologique utilise
les ouverts recouvrants. Soit <span class="math inline">\(\mathcal{U} =
\{U_1, U_2, \ldots, U_k\}\)</span> un recouvrement ouvert de <span
class="math inline">\(X\)</span>. Le <span
class="math inline">\(n\)</span>-ième produit de <span
class="math inline">\(\mathcal{U}\)</span> est défini par <span
class="math display">\[\mathcal{U}^n = \{U_{i_1} \cap f^{-1}(U_{i_2})
\cap \ldots \cap f^{-n+1}(U_{i_n}) : i_1, i_2, \ldots, i_n \in \{1, 2,
\ldots, k\}\}.\]</span> Le nombre minimal d’éléments nécessaires pour
recouvrir <span class="math inline">\(X\)</span> est noté <span
class="math inline">\(N(\mathcal{U}^n)\)</span>. L’entropie topologique
peut alors être définie comme <span
class="math display">\[h_{\text{top}}(f) = \lim_{\epsilon \rightarrow 0}
\left( \liminf_{n \rightarrow \infty} \frac{1}{n} \log N(\mathcal{U}^n)
\right).\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à l’entropie topologique est le théorème
de variational principle, qui relie l’entropie topologique à l’entropie
mesurée.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((X, d)\)</span> un espace métrique
compact et soit <span class="math inline">\(f: X \rightarrow X\)</span>
une transformation continue. Alors, pour toute mesure de probabilité
<span class="math inline">\(\mu\)</span> sur <span
class="math inline">\(X\)</span>, on a <span
class="math display">\[h_{\mu}(f) \leq h_{\text{top}}(f),\]</span> où
<span class="math inline">\(h_{\mu}(f)\)</span> est l’entropie mesurée
de <span class="math inline">\(f\)</span> par rapport à <span
class="math inline">\(\mu\)</span>. De plus, il existe une mesure <span
class="math inline">\(\mu\)</span> telle que <span
class="math display">\[h_{\text{top}}(f) = h_{\mu}(f).\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de variational principle, nous commençons
par définir l’entropie mesurée. Soit <span
class="math inline">\(\mu\)</span> une mesure de probabilité sur <span
class="math inline">\(X\)</span>. Pour un recouvrement ouvert <span
class="math inline">\(\mathcal{U} = \{U_1, U_2, \ldots, U_k\}\)</span>,
définissons la mesure de l’ensemble <span
class="math inline">\(A\)</span> par rapport à <span
class="math inline">\(\mathcal{U}\)</span> comme <span
class="math display">\[\mu(A|\mathcal{U}) = \sum_{i=1}^k \mu(U_i)
\chi_{U_i}(A),\]</span> où <span
class="math inline">\(\chi_{U_i}\)</span> est la fonction
caractéristique de <span class="math inline">\(U_i\)</span>.</p>
<p>L’entropie mesurée de <span class="math inline">\(f\)</span> par
rapport à <span class="math inline">\(\mu\)</span> est définie par <span
class="math display">\[h_{\mu}(f) = \lim_{\epsilon \rightarrow 0} \left(
\liminf_{n \rightarrow \infty} \frac{1}{n} H(\mathcal{U}^n|\mu)
\right),\]</span> où <span
class="math inline">\(H(\mathcal{U}^n|\mu)\)</span> est l’entropie de
Shannon de la partition <span
class="math inline">\(\mathcal{U}^n\)</span> par rapport à <span
class="math inline">\(\mu\)</span>.</p>
<p>Pour prouver l’inégalité <span class="math inline">\(h_{\mu}(f) \leq
h_{\text{top}}(f)\)</span>, nous utilisons le fait que pour tout
recouvrement ouvert <span class="math inline">\(\mathcal{U}\)</span>, on
a <span class="math display">\[H(\mathcal{U}^n|\mu) \leq \log
N(\mathcal{U}^n).\]</span> En prenant la limite inférieure et en
utilisant la définition de l’entropie topologique, nous obtenons
l’inégalité souhaitée.</p>
<p>Pour prouver l’égalité <span class="math inline">\(h_{\text{top}}(f)
= h_{\mu}(f)\)</span>, nous utilisons le fait que pour toute mesure
<span class="math inline">\(\mu\)</span>, il existe un recouvrement
ouvert <span class="math inline">\(\mathcal{U}\)</span> tel que <span
class="math display">\[h_{\mu}(f) = \lim_{n \rightarrow \infty}
\frac{1}{n} H(\mathcal{U}^n|\mu).\]</span> En combinant cette égalité
avec l’inégalité précédente, nous obtenons le résultat désiré.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<ol>
<li><p>L’entropie topologique est invariante par conjugaison.
C’est-à-dire, si <span class="math inline">\(f\)</span> et <span
class="math inline">\(g\)</span> sont des transformations conjuguées,
alors <span class="math inline">\(h_{\text{top}}(f) =
h_{\text{top}}(g)\)</span>.</p></li>
<li><p>Pour une transformation expansive, l’entropie topologique est
égale à la somme des logarithmes des facteurs d’expansion.</p></li>
<li><p>Pour une transformation de Bernoulli, l’entropie topologique est
égale à l’entropie de la mesure de Bernoulli correspondante.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’entropie topologique est un outil puissant pour comprendre la
complexité des systèmes dynamiques. Elle permet de quantifier le
comportement chaotique ou ordonné d’une transformation et de classifier
les systèmes dynamiques en fonction de leur complexité. Les théorèmes et
propriétés associés à l’entropie topologique fournissent des insights
profonds sur la nature des systèmes dynamiques et ouvrent la voie à de
nouvelles découvertes dans ce domaine fascinant.</p>
</body>
</html>
{% include "footer.html" %}

