{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’étude de la Covariance : Une Exploration Mathématique Approfondie</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’étude de la Covariance : Une Exploration
Mathématique Approfondie</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La covariance est un concept fondamental en statistiques et en
probabilités, qui mesure la relation linéaire entre deux variables
aléatoires. Son origine remonte aux travaux pionniers de Francis Galton
sur l’hérédité des caractéristiques physiques, où il observa que les
descendants tendaient à régresser vers la moyenne de la population. Ce
phénomène, connu sous le nom d’effet régression vers la moyenne, a
conduit à l’introduction de la covariance comme outil pour quantifier
cette relation.</p>
<p>La covariance émerge comme une réponse à la nécessité de comprendre
comment deux variables varient ensemble. Elle est indispensable dans
l’analyse des données multivariées, où elle permet de capturer les
corrélations entre différentes caractéristiques. En outre, la covariance
joue un rôle central dans des domaines tels que l’économie, la finance,
et les sciences sociales, où elle est utilisée pour évaluer les risques
et les dépendances entre différents facteurs.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la covariance, considérons deux variables aléatoires
<span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>. Nous cherchons à mesurer comment ces
variables varient ensemble. Intuitivement, si <span
class="math inline">\(X\)</span> augmente lorsque <span
class="math inline">\(Y\)</span> augmente, et vice versa, nous nous
attendons à ce que la covariance soit positive. Inversement, si <span
class="math inline">\(X\)</span> augmente lorsque <span
class="math inline">\(Y\)</span> diminue, la covariance sera
négative.</p>
<p>Formellement, la covariance entre deux variables aléatoires <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> est définie comme suit :</p>
<div class="definition">
<p>La covariance entre deux variables aléatoires <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, notée <span
class="math inline">\(\text{Cov}(X, Y)\)</span>, est donnée par : <span
class="math display">\[\text{Cov}(X, Y) = \mathbb{E}[(X -
\mathbb{E}[X])(Y - \mathbb{E}[Y])]\]</span> où <span
class="math inline">\(\mathbb{E}\)</span> désigne l’espérance
mathématique.</p>
</div>
<p>Une autre formulation équivalente de la covariance est : <span
class="math display">\[\text{Cov}(X, Y) = \mathbb{E}[XY] -
\mathbb{E}[X]\mathbb{E}[Y]\]</span></p>
<p>Cette définition met en évidence que la covariance est une mesure de
la dépendance linéaire entre deux variables. Elle peut être positive,
négative ou nulle, indiquant respectivement une corrélation positive,
négative ou aucune corrélation linéaire.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la covariance est le théorème de la
variance des sommes, qui généralise la notion de variance pour plusieurs
variables.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des
variables aléatoires. La variance de la somme de ces variables est
donnée par : <span class="math display">\[\text{Var}\left(\sum_{i=1}^n
X_i\right) = \sum_{i=1}^n \text{Var}(X_i) + 2 \sum_{1 \leq i &lt; j \leq
n} \text{Cov}(X_i, X_j)\]</span></p>
</div>
<p>La démonstration de ce théorème repose sur l’expansion de la variance
et l’utilisation des propriétés de la covariance. En développant <span
class="math inline">\(\text{Var}\left(\sum_{i=1}^n X_i\right)\)</span>,
nous obtenons : <span
class="math display">\[\text{Var}\left(\sum_{i=1}^n X_i\right) =
\mathbb{E}\left[\left(\sum_{i=1}^n (X_i -
\mathbb{E}[X_i])\right)^2\right]\]</span> En utilisant l’additivité de
l’espérance et les propriétés de la covariance, nous arrivons à la
formulation donnée dans le théorème.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour démontrer que <span class="math inline">\(\text{Cov}(X, Y) =
\mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]\)</span>, commençons par
développer l’expression de la covariance : <span
class="math display">\[\text{Cov}(X, Y) = \mathbb{E}[(X -
\mathbb{E}[X])(Y - \mathbb{E}[Y])]\]</span> En utilisant la linéarité de
l’espérance, nous avons : <span class="math display">\[\mathbb{E}[(X -
\mathbb{E}[X])(Y - \mathbb{E}[Y])] = \mathbb{E}[XY - X\mathbb{E}[Y] -
Y\mathbb{E}[X] + \mathbb{E}[X]\mathbb{E}[Y]]\]</span> En séparant les
termes, nous obtenons : <span class="math display">\[\mathbb{E}[XY] -
\mathbb{E}[X]\mathbb{E}[Y] - \mathbb{E}[Y]\mathbb{E}[X] +
\mathbb{E}[X]\mathbb{E}[Y]\]</span> Les termes <span
class="math inline">\(-\mathbb{E}[X]\mathbb{E}[Y]\)</span> et <span
class="math inline">\(+\mathbb{E}[X]\mathbb{E}[Y]\)</span> se
compensent, laissant : <span class="math display">\[\mathbb{E}[XY] -
\mathbb{E}[X]\mathbb{E}[Y]\]</span> Ainsi, nous avons démontré que :
<span class="math display">\[\text{Cov}(X, Y) = \mathbb{E}[XY] -
\mathbb{E}[X]\mathbb{E}[Y]\]</span></p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La covariance possède plusieurs propriétés importantes qui en font un
outil puissant pour l’analyse des données.</p>
<ul>
<li><p><strong>Invariance par translation</strong> : La covariance est
invariante par translation. Si <span class="math inline">\(a\)</span> et
<span class="math inline">\(b\)</span> sont des constantes, alors :
<span class="math display">\[\text{Cov}(X + a, Y + b) = \text{Cov}(X,
Y)\]</span></p></li>
<li><p><strong>Homogénéité</strong> : La covariance est homogène de
degré 2. Si <span class="math inline">\(c\)</span> et <span
class="math inline">\(d\)</span> sont des constantes, alors : <span
class="math display">\[\text{Cov}(cX, dY) = cd \, \text{Cov}(X,
Y)\]</span></p></li>
<li><p><strong>Symétrie</strong> : La covariance est symétrique. Pour
toute paire de variables aléatoires <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, nous avons : <span
class="math display">\[\text{Cov}(X, Y) = \text{Cov}(Y,
X)\]</span></p></li>
<li><p><strong>Variance</strong> : La variance d’une variable aléatoire
<span class="math inline">\(X\)</span> est un cas particulier de la
covariance : <span class="math display">\[\text{Var}(X) = \text{Cov}(X,
X)\]</span></p></li>
</ul>
<p>Chacune de ces propriétés peut être démontrée en utilisant les
définitions et les théorèmes précédents. Par exemple, pour la propriété
de symétrie, nous avons : <span class="math display">\[\text{Cov}(X, Y)
= \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y] = \mathbb{E}[YX] -
\mathbb{E}[Y]\mathbb{E}[X] = \text{Cov}(Y, X)\]</span></p>
<p>En conclusion, la covariance est un concept essentiel en statistiques
et en probabilités, offrant des insights précieux sur les relations
entre différentes variables. Son étude approfondie permet de mieux
comprendre et d’analyser les données multivariées, ouvrant la voie à des
applications pratiques dans divers domaines.</p>
</body>
</html>
{% include "footer.html" %}

