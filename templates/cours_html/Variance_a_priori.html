{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance a priori : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance a priori : Fondements et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La variance a priori émerge comme un concept fondamental en théorie
des probabilités et en statistique bayésienne. Son origine remonte aux
travaux pionniers de Thomas Bayes au XVIIIe siècle, bien que sa
formalisation moderne soit attribuée à des mathématiciens tels
qu’Abraham de Moivre et Pierre-Simon Laplace. La notion de variance a
priori est indispensable pour quantifier l’incertitude dans les modèles
probabilistes avant l’observation des données. Elle permet de capturer
l’information préalable, ou <em>prior knowledge</em>, et joue un rôle
crucial dans l’estimation des paramètres et la prédiction.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la variance a priori, considérons un paramètre <span
class="math inline">\(\theta\)</span> d’un modèle statistique. Avant de
recueillir des données, nous avons une certaine croyance ou information
sur <span class="math inline">\(\theta\)</span>, représentée par une
distribution de probabilité a priori <span
class="math inline">\(p(\theta)\)</span>. La variance a priori mesure la
dispersion de cette distribution.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\theta\)</span> un paramètre
aléatoire avec une distribution de probabilité a priori <span
class="math inline">\(p(\theta)\)</span>. La variance a priori de <span
class="math inline">\(\theta\)</span> est définie comme : <span
class="math display">\[\text{Var}_{\text{prior}}(\theta) =
\mathbb{E}_{\text{prior}}[(\theta -
\mathbb{E}_{\text{prior}}[\theta])^2]\]</span> où <span
class="math inline">\(\mathbb{E}_{\text{prior}}\)</span> désigne
l’espérance mathématique sous la distribution a priori <span
class="math inline">\(p(\theta)\)</span>.</p>
</div>
<p>De manière équivalente, on peut exprimer la variance a priori en
utilisant les propriétés de l’espérance : <span
class="math display">\[\text{Var}_{\text{prior}}(\theta) =
\mathbb{E}_{\text{prior}}[\theta^2] -
(\mathbb{E}_{\text{prior}}[\theta])^2\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème central en statistique bayésienne est celui de la
variance totale, qui décompose la variance postérieure en termes de
variance a priori et de variance résiduelle.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\theta\)</span> un paramètre avec
une distribution a priori <span class="math inline">\(p(\theta)\)</span>
et soit <span class="math inline">\(y\)</span> des données observées. La
variance postérieure de <span class="math inline">\(\theta\)</span> peut
être décomposée comme suit : <span
class="math display">\[\text{Var}_{\text{post}}(\theta \mid y) =
\mathbb{E}_{y}[\text{Var}_{\text{prior}}(\theta)] +
\text{Var}_y(\mathbb{E}_{\text{prior}}[\theta \mid y])\]</span> où <span
class="math inline">\(\text{Var}_{\text{post}}(\theta \mid y)\)</span>
est la variance postérieure de <span
class="math inline">\(\theta\)</span> conditionnellement aux données
<span class="math inline">\(y\)</span>.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour démontrer le théorème de la variance totale, nous utilisons les
propriétés de l’espérance et de la variance. Commençons par exprimer la
variance postérieure : <span
class="math display">\[\text{Var}_{\text{post}}(\theta \mid y) =
\mathbb{E}_{y}[\mathbb{E}_{\text{prior}}[(\theta -
\mathbb{E}_{\text{post}}[\theta \mid y])^2 \mid y]]\]</span></p>
<p>En développant le carré, nous obtenons : <span
class="math display">\[\text{Var}_{\text{post}}(\theta \mid y) =
\mathbb{E}_{y}[\mathbb{E}_{\text{prior}}[\theta^2 \mid y]] -
(\mathbb{E}_{y}[\mathbb{E}_{\text{prior}}[\theta \mid
y]])^2\]</span></p>
<p>En utilisant la loi des espérances itérées, nous avons : <span
class="math display">\[\mathbb{E}_{y}[\mathbb{E}_{\text{prior}}[\theta^2
\mid y]] = \mathbb{E}_{\text{prior}}[\theta^2]\]</span></p>
<p>De même, pour le deuxième terme : <span
class="math display">\[\mathbb{E}_{y}[\mathbb{E}_{\text{prior}}[\theta
\mid y]] = \mathbb{E}_{\text{prior}}[\theta]\]</span></p>
<p>Ainsi, la variance postérieure peut être écrite comme : <span
class="math display">\[\text{Var}_{\text{post}}(\theta \mid y) =
\mathbb{E}_{\text{prior}}[\theta^2] -
(\mathbb{E}_{\text{prior}}[\theta])^2 =
\text{Var}_{\text{prior}}(\theta)\]</span></p>
<p>Cependant, cette démonstration simplifiée ne tient pas compte de la
dépendance entre <span class="math inline">\(\theta\)</span> et <span
class="math inline">\(y\)</span>. Pour une démonstration plus
rigoureuse, nous devons considérer la variance conditionnelle et
marginale.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<ul>
<li><p>La variance a priori est toujours non négative, c’est-à-dire
<span class="math inline">\(\text{Var}_{\text{prior}}(\theta) \geq
0\)</span>.</p></li>
<li><p>Si <span class="math inline">\(\theta\)</span> est une constante
déterministe, alors <span
class="math inline">\(\text{Var}_{\text{prior}}(\theta) =
0\)</span>.</p></li>
<li><p>Pour une distribution normale a priori <span
class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span>, la variance a
priori est simplement <span
class="math inline">\(\sigma^2\)</span>.</p></li>
</ul>
<p>Pour démontrer la propriété (iii), considérons une distribution
normale a priori : <span class="math display">\[p(\theta) =
\frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(\theta -
\mu)^2}{2\sigma^2}\right)\]</span></p>
<p>L’espérance et la variance de cette distribution sont respectivement
<span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\sigma^2\)</span>. Ainsi, la variance a priori est
: <span class="math display">\[\text{Var}_{\text{prior}}(\theta) =
\sigma^2\]</span></p>
</body>
</html>
{% include "footer.html" %}

