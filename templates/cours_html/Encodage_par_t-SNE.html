{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Encodage par t-SNE : Une Approche Non-Linéaire pour la Visualisation de Données</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Encodage par t-SNE : Une Approche Non-Linéaire pour
la Visualisation de Données</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’analyse des données de haute dimension est une tâche centrale en
science des données, mais la visualisation directe de ces données reste
un défi majeur. Les méthodes classiques de réduction de dimension,
telles que l’Analyse en Composantes Principales (PCA), sont linéaires et
souvent inadaptées pour capturer les structures non-linéaires présentes
dans les données. C’est dans ce contexte que l’Encodage par
t-Distributed Stochastic Neighbor Embedding (t-SNE) émerge comme une
technique puissante pour la visualisation de données complexes.</p>
<p>Le t-SNE, introduit par van der Maaten et Hinton en 2008, est une
méthode non-linéaire qui permet de projeter des données de haute
dimension dans un espace de faible dimension, tout en préservant les
relations locales entre les points. Cette approche est particulièrement
utile pour explorer des ensembles de données complexes, tels que ceux
rencontrés en bioinformatique, en traitement du langage naturel ou en
reconnaissance d’images.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant de définir formellement le t-SNE, il est essentiel de
comprendre les concepts sous-jacents. Le t-SNE vise à modéliser la
distribution des points dans un espace de haute dimension et à la
reproduire dans un espace de faible dimension. Pour ce faire, il utilise
une distribution conditionnelle de probabilités pour capturer les
relations locales entre les points.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X = \{x_1, x_2, \dots,
x_n\}\)</span> un ensemble de points dans un espace de haute dimension.
La distribution des probabilités de voisinage pour chaque point <span
class="math inline">\(x_i\)</span> est définie par : <span
class="math display">\[p_{j|i} = \frac{\exp(-||x_i - x_j||^2 /
2\sigma_i^2)}{\sum_{k \neq i} \exp(-||x_i - x_k||^2 /
2\sigma_i^2)}\]</span> où <span class="math inline">\(\sigma_i\)</span>
est la variance du noyau gaussien centré sur <span
class="math inline">\(x_i\)</span>.</p>
</div>
<p>La distribution conjointe des probabilités de voisinage est alors
définie par : <span class="math display">\[p_{ij} = \frac{p_{j|i} +
p_{i|j}}{2n}\]</span></p>
<div class="definition">
<p>Le t-SNE cherche à minimiser la divergence de Kullback-Leibler entre
la distribution conjointe des probabilités de voisinage dans l’espace de
haute dimension et une distribution similaire dans un espace de faible
dimension.</p>
</div>
<p>Formellement, soit <span class="math inline">\(Y = \{y_1, y_2, \dots,
y_n\}\)</span> un ensemble de points dans un espace de faible dimension.
La distribution conjointe des probabilités de voisinage dans cet espace
est définie par : <span class="math display">\[q_{ij} =
\frac{\exp(-||y_i - y_j||^2)}{\sum_{k \neq l} \exp(-||y_k -
y_l||^2)}\]</span> Le t-SNE minimise alors la fonction de coût suivante
: <span class="math display">\[C = \sum_{i \neq j} p_{ij} \log \left(
\frac{p_{ij}}{q_{ij}} \right)\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Le t-SNE repose sur plusieurs théorèmes et propriétés clés, notamment
ceux concernant la minimisation de la divergence de
Kullback-Leibler.</p>
<div class="theorem">
<p>La minimisation de la divergence de Kullback-Leibler entre les
distributions conjointes <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> est équivalente à la maximisation de
l’information mutuelle entre ces distributions.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La divergence de Kullback-Leibler entre <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> est définie par : <span
class="math display">\[D_{KL}(P || Q) = \sum_{i,j} p_{ij} \log \left(
\frac{p_{ij}}{q_{ij}} \right)\]</span> En utilisant la propriété de
l’information mutuelle, nous avons : <span class="math display">\[I(P;
Q) = \sum_{i,j} p_{ij} \log \left( \frac{p_{ij}}{q_{ij}}
\right)\]</span> Il s’ensuit que : <span class="math display">\[D_{KL}(P
|| Q) = -I(P; Q)\]</span> Ainsi, minimiser <span
class="math inline">\(D_{KL}(P || Q)\)</span> est équivalent à maximiser
<span class="math inline">\(I(P; Q)\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>La preuve de l’efficacité du t-SNE repose sur la minimisation de la
divergence de Kullback-Leibler. Voici une démonstration détaillée :</p>
<div class="proof">
<p><em>Proof.</em> Considérons la fonction de coût <span
class="math inline">\(C\)</span> définie par : <span
class="math display">\[C = \sum_{i \neq j} p_{ij} \log \left(
\frac{p_{ij}}{q_{ij}} \right)\]</span> Nous voulons minimiser cette
fonction par rapport à <span class="math inline">\(Y\)</span>. Pour ce
faire, nous utilisons la méthode du gradient stochastique.</p>
<p>Le gradient de <span class="math inline">\(C\)</span> par rapport à
<span class="math inline">\(y_i\)</span> est donné par : <span
class="math display">\[\frac{\partial C}{\partial y_i} = 4 \sum_{j \neq
i} (p_{ij} - q_{ij}) (y_i - y_j)\]</span> En utilisant cette expression,
nous pouvons mettre à jour les points <span
class="math inline">\(y_i\)</span> de manière itérative pour minimiser
<span class="math inline">\(C\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le t-SNE possède plusieurs propriétés intéressantes qui en font une
méthode puissante pour la visualisation de données.</p>
<ol>
<li><p><strong>Préservation des Relations Locales</strong> : Le t-SNE
est particulièrement efficace pour préserver les relations locales entre
les points, ce qui le rend idéal pour la visualisation de structures
complexes.</p></li>
<li><p><strong>Robustesse aux Bruits</strong> : Le t-SNE est robuste aux
bruits et aux variations dans les données, ce qui le rend adapté à
l’analyse de grands ensembles de données.</p></li>
<li><p><strong>Interprétabilité</strong> : Les projections obtenues par
t-SNE sont souvent plus interprétables que celles obtenues par d’autres
méthodes de réduction de dimension.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’Encodage par t-SNE est une méthode puissante et flexible pour la
visualisation de données de haute dimension. En capturant les relations
locales entre les points et en préservant ces relations dans un espace
de faible dimension, le t-SNE offre une approche non-linéaire pour
explorer des ensembles de données complexes. Bien que cette méthode
présente certaines limitations, telles que la sensibilité aux paramètres
et la difficulté d’interprétation des projections, elle reste un outil
précieux pour les chercheurs en science des données.</p>
</body>
</html>
{% include "footer.html" %}

