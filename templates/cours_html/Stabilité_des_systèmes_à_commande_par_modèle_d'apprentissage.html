{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Stabilité des systèmes à commande par modèle d’apprentissage</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Stabilité des systèmes à commande par modèle
d’apprentissage</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’émergence des systèmes à commande par modèle d’apprentissage (MLC,
pour <em>Machine Learning Control</em>) représente une avancée
significative dans le domaine de l’automatisation et du contrôle des
systèmes dynamiques. Ces systèmes intègrent des techniques
d’apprentissage automatique pour adapter et optimiser les commandes en
temps réel, offrant ainsi une flexibilité et une robustesse accrues face
à des environnements complexes et changeants.</p>
<p>L’origine de cette approche remonte aux années 1980 avec les premiers
travaux sur l’apprentissage par renforcement et les réseaux de neurones
appliqués au contrôle. Cependant, c’est avec l’avènement des big data et
des algorithmes d’apprentissage profond que cette discipline a connu un
essor remarquable. Les systèmes MLC sont désormais indispensables dans
des domaines variés tels que la robotique, l’automobile autonome, et les
systèmes industriels intelligents.</p>
<p>L’objectif principal de cet article est d’explorer la stabilité des
systèmes MLC, un aspect crucial pour garantir leur fiabilité et leur
sécurité. Nous aborderons les définitions fondamentales, les théorèmes
clés, ainsi que les propriétés et corollaires associés à cette
notion.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la stabilité des systèmes MLC, il est essentiel de
définir plusieurs concepts clés.</p>
<h2 id="stabilité-dun-système-dynamique">Stabilité d’un système
dynamique</h2>
<p>Considérons un système dynamique décrit par une équation
différentielle : <span class="math display">\[\dot{x}(t) = f(x(t),
u(t))\]</span> où <span class="math inline">\(x(t) \in
\mathbb{R}^n\)</span> représente l’état du système à l’instant <span
class="math inline">\(t\)</span>, et <span class="math inline">\(u(t)
\in \mathbb{R}^m\)</span> est la commande appliquée.</p>
<p>Nous cherchons à déterminer si le système reste proche d’un état
d’équilibre <span class="math inline">\(x_e\)</span> lorsque les
perturbations sont faibles. Intuitivement, un système est stable si de
petites variations initiales ne conduisent pas à des comportements
imprévisibles ou divergents.</p>
<p>Formellement, nous disons qu’un système est <em>stable au sens de
Lyapunov</em> si pour tout <span class="math inline">\(\epsilon &gt;
0\)</span>, il existe un <span class="math inline">\(\delta(\epsilon)
&gt; 0\)</span> tel que : <span class="math display">\[\forall t \geq 0,
\|x(0) - x_e\| &lt; \delta \implies \|x(t) - x_e\| &lt;
\epsilon\]</span></p>
<h2 id="stabilité-asymptotique">Stabilité asymptotique</h2>
<p>La stabilité au sens de Lyapunov ne garantit pas que le système
converge vers l’état d’équilibre. Pour cela, nous introduisons la notion
de stabilité asymptotique.</p>
<p>Un système est <em>asymptotiquement stable</em> si : <span
class="math display">\[\lim_{t \to \infty} \|x(t) - x_e\| = 0\]</span>
pour toute condition initiale <span class="math inline">\(x(0)\)</span>
suffisamment proche de <span class="math inline">\(x_e\)</span>.</p>
<h2 id="stabilité-des-systèmes-mlc">Stabilité des systèmes MLC</h2>
<p>Dans le contexte des systèmes MLC, la commande <span
class="math inline">\(u(t)\)</span> est générée par un modèle
d’apprentissage automatique. Nous devons donc adapter les définitions
précédentes pour prendre en compte cette particularité.</p>
<p>Considérons un système MLC décrit par : <span
class="math display">\[\dot{x}(t) = f(x(t), u_{\theta}(x(t)))\]</span>
où <span class="math inline">\(\theta\)</span> représente les paramètres
du modèle d’apprentissage.</p>
<p>Le système est stable si, pour une fonction de coût <span
class="math inline">\(J(\theta)\)</span> appropriée, les paramètres
<span class="math inline">\(\theta\)</span> convergent vers un ensemble
stable.</p>
<h1 id="théorèmes">Théorèmes</h1>
<h2 id="théorème-de-lyapunov-pour-les-systèmes-mlc">Théorème de Lyapunov
pour les systèmes MLC</h2>
<p>Un outil fondamental pour analyser la stabilité des systèmes
dynamiques est le théorème de Lyapunov. Nous adaptons ce théorème au
contexte des systèmes MLC.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(V(x) : \mathbb{R}^n \to
\mathbb{R}\)</span> une fonction de Lyapunov positive définie,
c’est-à-dire : <span class="math display">\[V(x) &gt; 0 \quad \forall x
\neq x_e, \quad V(x_e) = 0\]</span> et sa dérivée le long des
trajectoires du système : <span class="math display">\[\dot{V}(x) =
\frac{\partial V}{\partial x} f(x, u_{\theta}(x)) \leq 0\]</span> Alors
le système est stable au sens de Lyapunov.</p>
</div>
<h2
id="démonstration-du-théorème-de-lyapunov-pour-les-systèmes-mlc">Démonstration
du théorème de Lyapunov pour les systèmes MLC</h2>
<p>Pour démontrer ce théorème, nous procédons comme suit :</p>
<p>1. Considérons une boule <span
class="math inline">\(B_{\delta}\)</span> centrée en <span
class="math inline">\(x_e\)</span> de rayon <span
class="math inline">\(\delta\)</span>. 2. Pour tout <span
class="math inline">\(x(0) \in B_{\delta}\)</span>, nous avons <span
class="math inline">\(V(x(0)) &lt; c\)</span> pour une constante <span
class="math inline">\(c &gt; 0\)</span>. 3. Puisque <span
class="math inline">\(V(x(t))\)</span> est décroissante (car <span
class="math inline">\(\dot{V}(x(t)) \leq 0\)</span>), nous avons <span
class="math inline">\(V(x(t)) \leq V(x(0)) &lt; c\)</span> pour tout
<span class="math inline">\(t \geq 0\)</span>. 4. Par la définition de
<span class="math inline">\(V(x)\)</span>, cela implique que <span
class="math inline">\(x(t) \in B_{\epsilon}\)</span> pour un certain
<span class="math inline">\(\epsilon &gt; 0\)</span>.</p>
<p>Ainsi, le système est stable au sens de Lyapunov.</p>
<h2
id="théorème-de-stabilité-asymptotique-pour-les-systèmes-mlc">Théorème
de stabilité asymptotique pour les systèmes MLC</h2>
<p>Pour garantir la stabilité asymptotique, nous avons besoin d’une
condition supplémentaire.</p>
<div class="theorem">
<p>Si <span class="math inline">\(\dot{V}(x) &lt; 0\)</span> pour tout
<span class="math inline">\(x \neq x_e\)</span>, alors le système est
asymptotiquement stable.</p>
</div>
<h2
id="démonstration-du-théorème-de-stabilité-asymptotique-pour-les-systèmes-mlc">Démonstration
du théorème de stabilité asymptotique pour les systèmes MLC</h2>
<p>La démonstration suit les mêmes étapes que précédemment, mais nous
utilisons le fait que <span class="math inline">\(\dot{V}(x) &lt;
0\)</span> pour montrer que <span class="math inline">\(V(x(t)) \to
0\)</span> lorsque <span class="math inline">\(t \to \infty\)</span>.
Par conséquent, <span class="math inline">\(x(t) \to x_e\)</span>.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriété-de-convergence-des-paramètres">Propriété de
convergence des paramètres</h2>
<div class="property">
<p>Les paramètres <span class="math inline">\(\theta\)</span> du modèle
d’apprentissage convergent vers un ensemble stable si la fonction de
coût <span class="math inline">\(J(\theta)\)</span> est convexe et
strictement décroissante.</p>
</div>
<h2
id="démonstration-de-la-propriété-de-convergence-des-paramètres">Démonstration
de la propriété de convergence des paramètres</h2>
<p>1. Considérons une suite <span
class="math inline">\(\theta_k\)</span> générée par un algorithme
d’optimisation. 2. Si <span class="math inline">\(J(\theta)\)</span> est
convexe, alors tout point critique est un minimum global. 3. Si <span
class="math inline">\(J(\theta)\)</span> est strictement décroissante,
alors la suite <span class="math inline">\(\theta_k\)</span> converge
vers un point critique.</p>
<h2 id="corollaire-de-stabilité-globale">Corollaire de stabilité
globale</h2>
<div class="corollary">
<p>Si <span class="math inline">\(V(x)\)</span> est radialeement non
bornée et <span class="math inline">\(\dot{V}(x) &lt; 0\)</span>, alors
le système est globalement asymptotiquement stable.</p>
</div>
<h2 id="démonstration-du-corollaire-de-stabilité-globale">Démonstration
du corollaire de stabilité globale</h2>
<p>1. Puisque <span class="math inline">\(V(x)\)</span> est radialeement
non bornée, toute trajectoire initiale finit par entrer dans une boule
<span class="math inline">\(B_{\delta}\)</span>. 2. En appliquant le
théorème de stabilité asymptotique, nous concluons que <span
class="math inline">\(x(t) \to x_e\)</span>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Dans cet article, nous avons exploré la notion de stabilité des
systèmes à commande par modèle d’apprentissage. Nous avons défini les
concepts clés, présenté les théorèmes fondamentaux, et démontré leurs
propriétés. Ces résultats fournissent une base solide pour l’analyse et
la conception de systèmes MLC stables et robustes.</p>
</body>
</html>
{% include "footer.html" %}

