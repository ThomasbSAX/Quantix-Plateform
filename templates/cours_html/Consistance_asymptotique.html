{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Consistance asymptotique : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Consistance asymptotique : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La notion de consistance asymptotique émerge dans le cadre de
l’inférence statistique, où elle joue un rôle fondamental.
Historiquement, cette idée a été développée pour répondre à la nécessité
de garantir que les estimateurs statistiques convergent vers la vraie
valeur du paramètre sous-jacent lorsque la taille de l’échantillon tend
vers l’infini. Cette propriété est indispensable pour valider la
robustesse des méthodes statistiques, notamment dans les contextes où
les données sont abondantes mais bruitées.</p>
<p>La consistance asymptotique est donc au cœur des préoccupations
méthodologiques en statistique mathématique. Elle permet de justifier
l’utilisation d’estimateurs même lorsque leur comportement exact est
complexe à analyser pour des tailles finies d’échantillons.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la notion de consistance asymptotique, commençons par
comprendre ce que nous cherchons à atteindre. Supposons que nous ayons
un paramètre <span class="math inline">\(\theta\)</span> inconnu que
nous souhaitons estimer à partir d’un échantillon de données. Nous
voulons qu’en augmentant la taille de notre échantillon, notre
estimateur <span class="math inline">\(\hat{\theta}_n\)</span> se
rapproche de plus en plus de la vraie valeur <span
class="math inline">\(\theta\)</span>.</p>
<p>Formellement, nous disons qu’un estimateur <span
class="math inline">\(\hat{\theta}_n\)</span> est
<strong>consistant</strong> si, pour tout <span
class="math inline">\(\epsilon &gt; 0\)</span>, nous avons <span
class="math display">\[\lim_{n \to \infty} P(|\hat{\theta}_n - \theta|
&lt; \epsilon) = 1.\]</span> Cela signifie que la probabilité que
l’estimateur soit proche de <span class="math inline">\(\theta\)</span>
tend vers 1 lorsque <span class="math inline">\(n\)</span> tend vers
l’infini.</p>
<p>Une autre formulation équivalente est la suivante : <span
class="math inline">\(\hat{\theta}_n\)</span> est consistant si <span
class="math display">\[\hat{\theta}_n \xrightarrow{P} \theta,\]</span>
où <span class="math inline">\(\xrightarrow{P}\)</span> désigne la
convergence en probabilité.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème central en statistique est le <strong>théorème de la
limite centrale</strong>, qui joue un rôle clé dans l’étude de la
consistance asymptotique. Ce théorème nous dit que, sous certaines
conditions, la distribution d’un estimateur normalisé converge vers une
loi normale.</p>
<p>Supposons que nous ayons un échantillon <span
class="math inline">\(X_1, X_2, \ldots, X_n\)</span> de variables
aléatoires indépendantes et identiquement distribuées (i.i.d.) avec
espérance <span class="math inline">\(\mu\)</span> et variance <span
class="math inline">\(\sigma^2 &lt; \infty\)</span>. Alors, la moyenne
empirique <span class="math inline">\(\bar{X}_n = \frac{1}{n}
\sum_{i=1}^n X_i\)</span> satisfait <span
class="math display">\[\sqrt{n} (\bar{X}_n - \mu) \xrightarrow{d}
\mathcal{N}(0, \sigma^2),\]</span> où <span
class="math inline">\(\xrightarrow{d}\)</span> désigne la convergence en
loi et <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span> est
la loi normale centrée de variance <span
class="math inline">\(\sigma^2\)</span>.</p>
<p>Ce théorème est crucial car il permet de déduire la consistance
asymptotique de la moyenne empirique. En effet, comme <span
class="math inline">\(\bar{X}_n\)</span> converge en loi vers une
variable aléatoire de moyenne <span class="math inline">\(\mu\)</span>,
il s’ensuit que <span class="math inline">\(\bar{X}_n\)</span> converge
en probabilité vers <span class="math inline">\(\mu\)</span>.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver la consistance asymptotique de la moyenne empirique,
nous allons utiliser le théorème de la limite centrale. Supposons que
<span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> sont des
variables aléatoires i.i.d. avec espérance <span
class="math inline">\(\mu\)</span> et variance <span
class="math inline">\(\sigma^2 &lt; \infty\)</span>.</p>
<p>Par le théorème de la limite centrale, nous avons <span
class="math display">\[\sqrt{n} (\bar{X}_n - \mu) \xrightarrow{d}
\mathcal{N}(0, \sigma^2).\]</span> Cela signifie que pour tout <span
class="math inline">\(\epsilon &gt; 0\)</span>, <span
class="math display">\[P(|\sqrt{n} (\bar{X}_n - \mu)| &lt; \epsilon) \to
P(|Z| &lt; \epsilon),\]</span> où <span class="math inline">\(Z\)</span>
est une variable aléatoire suivant une loi normale centrée réduite.</p>
<p>En particulier, comme <span class="math inline">\(P(|Z| &lt;
\epsilon) &gt; 0\)</span> pour tout <span class="math inline">\(\epsilon
&gt; 0\)</span>, il s’ensuit que <span
class="math display">\[P(|\bar{X}_n - \mu| &lt;
\frac{\epsilon}{\sqrt{n}}) \to 1.\]</span> Par conséquent, nous avons
<span class="math display">\[P(|\bar{X}_n - \mu| &lt; \epsilon) \to
1,\]</span> ce qui montre que <span
class="math inline">\(\bar{X}_n\)</span> est un estimateur consistant de
<span class="math inline">\(\mu\)</span>.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons ci-dessous quelques propriétés importantes de la
consistance asymptotique :</p>
<ol>
<li><p>Si <span class="math inline">\(\hat{\theta}_n\)</span> est un
estimateur consistant de <span class="math inline">\(\theta\)</span>,
alors toute fonction continue <span class="math inline">\(g\)</span>
telle que <span class="math inline">\(g(\hat{\theta}_n)\)</span> est
bien définie pour tout <span class="math inline">\(n\)</span>
suffisamment grand, est un estimateur consistant de <span
class="math inline">\(g(\theta)\)</span>. Cela découle du théorème de la
convergence continue.</p></li>
<li><p>La consistance asymptotique est une propriété faible au sens où
elle ne garantit pas la vitesse de convergence. D’autres notions comme
la convergence en moyenne quadratique ou la convergence presque sûre
peuvent fournir des informations supplémentaires sur le comportement de
l’estimateur.</p></li>
<li><p>La consistance asymptotique est une propriété essentielle pour
l’étude des tests statistiques et des intervalles de confiance, car elle
permet de justifier les approximations asymptotiques utilisées dans ces
contextes.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La consistance asymptotique est une notion fondamentale en
statistique mathématique, permettant de garantir la robustesse des
estimateurs lorsque la taille de l’échantillon tend vers l’infini. À
travers le théorème de la limite centrale et d’autres résultats clés,
nous avons vu comment cette propriété peut être établie et quelles sont
ses implications pratiques. La compréhension approfondie de la
consistance asymptotique est indispensable pour le développement et
l’analyse des méthodes statistiques modernes.</p>
</body>
</html>
{% include "footer.html" %}

