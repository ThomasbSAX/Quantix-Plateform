{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Le noyau sigmoïde : une exploration mathématique et ses applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Le noyau sigmoïde : une exploration mathématique et
ses applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Le noyau sigmoïde, souvent utilisé dans le cadre des machines à
vecteurs de support (SVM), est une fonction de similarité qui permet de
mesurer la proximité entre deux vecteurs dans un espace de dimension
élevée. Son origine remonte aux travaux sur les fonctions d’activation
en réseaux de neurones, où la sigmoïde est utilisée pour introduire une
non-linéarité. Dans le contexte des SVM, le noyau sigmoïde permet de
transformer l’espace d’entrée de manière à ce que les données deviennent
linéairement séparables.</p>
<p>L’intérêt principal du noyau sigmoïde réside dans sa capacité à
capturer des relations non linéaires entre les données, ce qui est
crucial pour de nombreuses applications en apprentissage automatique.
Cependant, son utilisation doit être soigneusement contrôlée, car il
peut conduire à des problèmes de convergence et d’interprétabilité.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre le noyau sigmoïde, commençons par rappeler ce que
nous cherchons à obtenir. Nous voulons une fonction qui mesure la
similarité entre deux vecteurs en tenant compte de leur proximité ainsi
que d’un paramètre de régularisation. Cette fonction doit être
symétrique et positive définie pour garantir que la matrice de Gram
associée soit inversible.</p>
<p>La fonction sigmoïde classique est définie comme suit : <span
class="math display">\[\sigma(x) = \frac{1}{1 + e^{-x}}\]</span></p>
<p>Le noyau sigmoïde est une généralisation de cette fonction, adaptée
pour mesurer la similarité entre deux vecteurs. Formellement, le noyau
sigmoïde est défini par : <span
class="math display">\[K_{\text{sigmoid}}(x, y) = \tanh(\alpha x^T y +
c)\]</span></p>
<p>où <span class="math inline">\(\alpha &gt; 0\)</span> est un
paramètre de régularisation et <span class="math inline">\(c &lt;
0\)</span> est une constante qui contrôle la forme du noyau. En
utilisant des quantificateurs, nous pouvons écrire : <span
class="math display">\[\forall x, y \in \mathbb{R}^n, \exists \alpha
&gt; 0, c &lt; 0 \text{ tels que } K_{\text{sigmoid}}(x, y) =
\tanh(\alpha x^T y + c)\]</span></p>
<p>Une autre formulation équivalente est : <span
class="math display">\[K_{\text{sigmoid}}(x, y) = \frac{e^{\alpha x^T y
+ c} - e^{-\alpha x^T y - c}}{e^{\alpha x^T y + c} + e^{-\alpha x^T y -
c}}\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental concernant le noyau sigmoïde est celui de la
positivité définie. Ce théorème garantit que la matrice de Gram associée
au noyau sigmoïde est positive définie, ce qui est essentiel pour les
algorithmes d’optimisation utilisés dans les SVM.</p>
<p>Pour énoncer ce théorème, commençons par rappeler que nous cherchons
à montrer que pour tout ensemble de vecteurs <span
class="math inline">\(\{x_1, \ldots, x_m\}\)</span>, la matrice <span
class="math inline">\(K\)</span> définie par <span
class="math inline">\(K_{ij} = K_{\text{sigmoid}}(x_i, x_j)\)</span> est
positive définie.</p>
<p>Le théorème de la positivité définie du noyau sigmoïde s’énonce comme
suit :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\alpha &gt; 0\)</span> et <span
class="math inline">\(c &lt; 0\)</span>. Pour tout ensemble de vecteurs
<span class="math inline">\(\{x_1, \ldots, x_m\} \in
\mathbb{R}^n\)</span>, la matrice <span class="math inline">\(K\)</span>
définie par : <span class="math display">\[K_{ij} = \tanh(\alpha x_i^T
x_j + c)\]</span> est positive définie.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous devons montrer que pour tout vecteur
<span class="math inline">\(\alpha \in \mathbb{R}^m\)</span>, nous avons
: <span class="math display">\[\sum_{i,j=1}^m \alpha_i \alpha_j K_{ij}
\geq 0\]</span></p>
<p>En utilisant la définition du noyau sigmoïde, nous pouvons écrire :
<span class="math display">\[\sum_{i,j=1}^m \alpha_i \alpha_j
\tanh(\alpha x_i^T x_j + c) \geq 0\]</span></p>
<p>Pour ce faire, nous utilisons le fait que la fonction <span
class="math inline">\(\tanh\)</span> est une fonction croissante et
bornée. Nous pouvons également utiliser l’inégalité de Cauchy-Schwarz
pour montrer que la somme est non négative.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Le noyau sigmoïde possède plusieurs propriétés intéressantes qui en
font un outil puissant pour l’apprentissage automatique. Voici
quelques-unes de ces propriétés :</p>
<ol>
<li><p><strong>Symétrie</strong> : Le noyau sigmoïde est symétrique,
c’est-à-dire que <span class="math inline">\(K_{\text{sigmoid}}(x, y) =
K_{\text{sigmoid}}(y, x)\)</span>.</p></li>
<li><p><strong>Positivité définie</strong> : Comme nous l’avons vu dans
le théorème précédent, le noyau sigmoïde est positif défini.</p></li>
<li><p><strong>Paramétrisation</strong> : Les paramètres <span
class="math inline">\(\alpha\)</span> et <span
class="math inline">\(c\)</span> permettent de contrôler la forme du
noyau, ce qui est crucial pour l’adaptation aux données.</p></li>
</ol>
<p>Chacune de ces propriétés peut être démontrée rigoureusement en
utilisant des outils mathématiques avancés. Par exemple, la symétrie
découle directement de la définition du noyau sigmoïde, tandis que la
positivité définie nécessite une analyse plus approfondie.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Le noyau sigmoïde est un outil puissant pour l’apprentissage
automatique, notamment dans le cadre des machines à vecteurs de support.
Sa capacité à capturer des relations non linéaires en fait un choix
populaire pour de nombreuses applications. Cependant, son utilisation
doit être soigneusement contrôlée pour éviter les problèmes de
convergence et d’interprétabilité.</p>
<p>En conclusion, le noyau sigmoïde est une fonction de similarité riche
et flexible qui continue de jouer un rôle important dans le domaine de
l’apprentissage automatique.</p>
</body>
</html>
{% include "footer.html" %}

