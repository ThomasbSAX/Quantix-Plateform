{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Accuracy: Une mesure fondamentale en apprentissage automatique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Accuracy: Une mesure fondamentale en apprentissage
automatique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’accuracy, ou taux de bonne classification, est une métrique
essentielle dans le domaine de l’apprentissage automatique. Elle mesure
la proportion de prédictions correctes effectuées par un modèle parmi
l’ensemble des prédictions totales. L’émergence de cette notion est
intimement liée au développement des algorithmes de classification, où
la capacité à évaluer la performance d’un modèle est cruciale.</p>
<p>L’accuracy est indispensable dans de nombreux cadres, notamment en
médecine pour le diagnostic automatique, en finance pour la détection de
fraudes, et dans les systèmes de recommandation. Elle permet de comparer
différents modèles et de choisir celui qui performe le mieux sur un
ensemble de données donné.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir l’accuracy, commençons par comprendre ce que nous
cherchons à mesurer. Imaginons un modèle de classification binaire qui
prédit si un email est un spam (1) ou non (0). Nous voulons savoir
quelle proportion de ces prédictions est correcte.</p>
<p>Formellement, soit <span class="math inline">\(y_i\)</span> la vraie
classe de l’échantillon <span class="math inline">\(i\)</span> et <span
class="math inline">\(\hat{y}_i\)</span> la classe prédite par le
modèle. L’accuracy est définie comme suit :</p>
<div class="definition">
<p>L’accuracy <span class="math inline">\(A\)</span> d’un modèle de
classification sur un ensemble de <span class="math inline">\(N\)</span>
échantillons est donnée par : <span class="math display">\[A =
\frac{1}{N} \sum_{i=1}^{N} \mathbb{I}(y_i = \hat{y}_i)\]</span> où <span
class="math inline">\(\mathbb{I}\)</span> est la fonction indicatrice
qui vaut 1 si la condition est vraie et 0 sinon.</p>
</div>
<p>Une autre manière de formuler cette définition est : <span
class="math display">\[A = \frac{\text{Nombre de prédictions
correctes}}{\text{Nombre total de prédictions}}\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème important lié à l’accuracy est celui de la loi des grands
nombres, qui garantit que l’accuracy estimée sur un échantillon tend
vers l’accuracy réelle lorsque la taille de l’échantillon augmente.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(A_n\)</span> l’accuracy estimée sur
un échantillon de taille <span class="math inline">\(n\)</span>. Alors,
pour tout <span class="math inline">\(\epsilon &gt; 0\)</span>, <span
class="math display">\[\lim_{n \to \infty} P\left( |A_n - A| \geq
\epsilon \right) = 0\]</span> où <span class="math inline">\(A\)</span>
est l’accuracy réelle.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de la loi des grands nombres pour
l’accuracy, nous pouvons utiliser les propriétés de la fonction
indicatrice et la loi des grands nombres classique.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(X_i = \mathbb{I}(y_i
= \hat{y}_i)\)</span>. Chaque <span class="math inline">\(X_i\)</span>
est une variable aléatoire de Bernoulli avec une probabilité de succès
<span class="math inline">\(p = A\)</span>. L’accuracy estimée est alors
la moyenne empirique des <span class="math inline">\(X_i\)</span> :
<span class="math display">\[A_n = \frac{1}{n} \sum_{i=1}^{n}
X_i\]</span> Par la loi des grands nombres, nous avons : <span
class="math display">\[\lim_{n \to \infty} A_n = p = A \quad
\text{presque sûrement}\]</span> Cela implique que pour tout <span
class="math inline">\(\epsilon &gt; 0\)</span>, <span
class="math display">\[\lim_{n \to \infty} P\left( |A_n - A| \geq
\epsilon \right) = 0\]</span> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’accuracy possède plusieurs propriétés intéressantes :</p>
<ol>
<li><p>L’accuracy est bornée entre 0 et 1 : <span
class="math display">\[0 \leq A \leq 1\]</span></p></li>
<li><p>L’accuracy est invariante par permutation des échantillons. Cela
signifie que l’ordre des échantillons n’affecte pas la valeur de
l’accuracy.</p></li>
<li><p>L’accuracy peut être exprimée en termes de la matrice de
confusion. Soit <span class="math inline">\(TP\)</span> le nombre de
vrais positifs, <span class="math inline">\(TN\)</span> le nombre de
vrais négatifs, <span class="math inline">\(FP\)</span> le nombre de
faux positifs et <span class="math inline">\(FN\)</span> le nombre de
faux négatifs. Alors, <span class="math display">\[A = \frac{TP + TN}{TP
+ TN + FP + FN}\]</span></p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’accuracy est une métrique fondamentale en apprentissage
automatique, permettant d’évaluer la performance des modèles de
classification. Sa simplicité et son interprétation intuitive en font un
outil indispensable dans de nombreux domaines applicatifs.</p>
</body>
</html>
{% include "footer.html" %}

