{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Encodage par Extraction de Caractéristiques de Pooling</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Encodage par Extraction de Caractéristiques de
Pooling</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’encodage par extraction de caractéristiques de pooling est une
technique fondamentale en apprentissage automatique et en traitement du
signal. Cette méthode émerge comme une réponse à la nécessité de réduire
la dimension des données tout en préservant leur structure intrinsèque.
Historiquement, cette approche trouve ses racines dans les travaux sur
le traitement des images et la reconnaissance de motifs. Le pooling,
souvent utilisé en conjonction avec les réseaux de neurones convolutifs,
permet de condenser l’information tout en réduisant la sensibilité aux
variations locales.</p>
<p>L’importance de cette technique réside dans sa capacité à extraire
des caractéristiques robustes et invariantes. En effet, le pooling
permet de rendre les représentations plus résistantes aux déformations
et aux translations, ce qui est crucial pour des tâches telles que la
classification d’images ou la reconnaissance de la parole. De plus,
cette méthode est indispensable dans les architectures profondes où la
réduction de la dimension des données est nécessaire pour éviter le
surapprentissage et améliorer l’efficacité computationnelle.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre l’encodage par extraction de caractéristiques de
pooling, il est essentiel de définir les concepts clés. Supposons que
nous ayons un ensemble de données d’entrée <span
class="math inline">\(X\)</span> de dimension <span
class="math inline">\(n\)</span>. Notre objectif est de transformer ces
données en une représentation plus compacte tout en préservant les
informations pertinentes.</p>
<div class="definition">
<p>Le pooling est une opération qui réduit la dimension d’un ensemble de
données en agrégeant les informations locales. Formellement, pour une
fonction <span class="math inline">\(f: \mathbb{R}^n \rightarrow
\mathbb{R}^m\)</span> avec <span class="math inline">\(m &lt;
n\)</span>, le pooling peut être défini comme suit : <span
class="math display">\[y_i = f(x_{i_1}, x_{i_2}, \ldots, x_{i_k}) \quad
\text{pour} \quad i = 1, \ldots, m\]</span> où <span
class="math inline">\(x_{i_1}, x_{i_2}, \ldots, x_{i_k}\)</span> sont
les éléments d’entrée et <span class="math inline">\(y_i\)</span> est la
sortie après pooling.</p>
</div>
<p>Il existe plusieurs types de pooling, notamment le max-pooling et
l’average-pooling. Le max-pooling sélectionne la valeur maximale dans
une région locale, tandis que l’average-pooling calcule la moyenne des
valeurs dans cette région.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à l’encodage par extraction de
caractéristiques de pooling est le théorème de la réduction de
dimension. Ce théorème établit que le pooling peut réduire la dimension
des données tout en préservant certaines propriétés importantes.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> un ensemble de données de
dimension <span class="math inline">\(n\)</span> et <span
class="math inline">\(f\)</span> une fonction de pooling. Si <span
class="math inline">\(f\)</span> est une fonction Lipschitzienne avec
une constante <span class="math inline">\(L\)</span>, alors il existe
une constante <span class="math inline">\(C\)</span> telle que : <span
class="math display">\[\|f(X) - f(Y)\| \leq C \|X - Y\|\]</span> pour
tout <span class="math inline">\(X, Y\)</span> dans l’espace des
données.</p>
</div>
<p>La démonstration de ce théorème repose sur les propriétés de la
fonction de pooling et les inégalités de Lipschitz. En particulier, on
peut utiliser le lemme de la contraction pour montrer que la distance
entre les représentations après pooling est bornée par la distance entre
les données d’origine.</p>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer le théorème de la réduction de dimension, nous
commençons par rappeler que <span class="math inline">\(f\)</span> est
une fonction Lipschitzienne. Cela signifie qu’il existe une constante
<span class="math inline">\(L\)</span> telle que : <span
class="math display">\[\|f(X) - f(Y)\| \leq L \|X - Y\|\]</span> pour
tout <span class="math inline">\(X, Y\)</span> dans l’espace des
données. En utilisant cette propriété, nous pouvons écrire : <span
class="math display">\[\|f(X) - f(Y)\| \leq L \|X - Y\|\]</span> En
choisissant <span class="math inline">\(C = L\)</span>, nous obtenons la
conclusion du théorème.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>L’encodage par extraction de caractéristiques de pooling possède
plusieurs propriétés importantes. Nous en listons quelques-unes
ci-dessous :</p>
<ol>
<li><p><strong>Invariance aux translations</strong> : Le pooling rend
les représentations plus résistantes aux translations locales. Cela
signifie que de petites variations dans la position des caractéristiques
n’affectent pas significativement la sortie après pooling.</p></li>
<li><p><strong>Réduction de la dimension</strong> : Le pooling permet de
réduire la dimension des données, ce qui est crucial pour éviter le
surapprentissage et améliorer l’efficacité computationnelle.</p></li>
<li><p><strong>Robustesse aux déformations</strong> : Les
représentations obtenues après pooling sont plus robustes aux
déformations locales, ce qui est essentiel pour des tâches telles que la
reconnaissance de motifs.</p></li>
</ol>
<p>Pour chaque propriété, nous pouvons fournir une preuve détaillée en
utilisant les concepts et théorèmes introduits précédemment. Par
exemple, pour la propriété d’invariance aux translations, nous pouvons
utiliser le théorème de la réduction de dimension pour montrer que les
petites variations dans la position des caractéristiques n’affectent pas
significativement la sortie après pooling.</p>
</body>
</html>
{% include "footer.html" %}

