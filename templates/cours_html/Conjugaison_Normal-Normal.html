{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Conjugaison Normal-Normal : Une Exploration Mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Conjugaison Normal-Normal : Une Exploration
Mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La conjugaison Normal-Normal, souvent désignée par l’acronyme NNJ
(Normal-Normal Joint), émerge comme un concept fondamental dans
l’analyse des distributions conjuguées en statistique bayésienne. Son
importance réside dans sa capacité à modéliser des situations où les
données sont supposées suivre une distribution normale, tout en
intégrant une incertitude sur la moyenne et la variance de cette
distribution. Ce cadre est particulièrement utile dans les modèles
hiérarchiques, où l’on souhaite capturer la variabilité à différents
niveaux.</p>
<p>L’origine de cette notion remonte aux travaux pionniers sur les
distributions conjuguées, initiés par Raiffa et Schlaifer dans les
années 1960. La conjugaison Normal-Normal offre une solution élégante
pour traiter des problèmes où les paramètres sont eux-mêmes distribués
de manière normale. Cette approche permet non seulement de simplifier
les calculs, mais aussi d’offrir des interprétations intuitives des
résultats.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la conjugaison Normal-Normal, il est essentiel de
définir les éléments clés qui la composent. Considérons un modèle où
nous observons des données <span class="math inline">\(y_1, y_2, \ldots,
y_n\)</span> supposées être des réalisations indépendantes d’une
variable aléatoire normale <span class="math inline">\(Y\)</span> de
moyenne <span class="math inline">\(\mu\)</span> et de variance <span
class="math inline">\(\sigma^2\)</span>.</p>
<p>Nous cherchons à modéliser notre incertitude sur les paramètres <span
class="math inline">\(\mu\)</span> et <span
class="math inline">\(\sigma^2\)</span>. Pour ce faire, nous
introduisons une distribution a priori sur ces paramètres. Supposons que
<span class="math inline">\(\mu\)</span> suit une distribution normale
de moyenne <span class="math inline">\(m_0\)</span> et de variance <span
class="math inline">\(v_0\)</span>, et que <span
class="math inline">\(\sigma^2\)</span> suit une distribution
inverse-gamma de paramètres <span class="math inline">\(a_0\)</span> et
<span class="math inline">\(b_0\)</span>.</p>
<p>La conjugaison Normal-Normal consiste alors à déterminer la
distribution a posteriori des paramètres <span
class="math inline">\(\mu\)</span> et <span
class="math inline">\(\sigma^2\)</span> après avoir observé les données.
Formellement, nous avons :</p>
<div class="definition">
<p>Soit <span class="math inline">\(Y \sim \mathcal{N}(\mu,
\sigma^2)\)</span>, où <span class="math inline">\(\mu \sim
\mathcal{N}(m_0, v_0)\)</span> et <span class="math inline">\(\sigma^2
\sim \text{Inv-Gamma}(a_0, b_0)\)</span>. La distribution a posteriori
de <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\sigma^2\)</span> est donnée par : <span
class="math display">\[p(\mu, \sigma^2 | y_1, \ldots, y_n) \propto
p(y_1, \ldots, y_n | \mu, \sigma^2) p(\mu) p(\sigma^2).\]</span></p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème central dans l’étude de la conjugaison Normal-Normal est
celui qui caractérise la distribution a posteriori des paramètres. Ce
théorème permet de déterminer explicitement les nouveaux hyperparamètres
de la distribution a posteriori en fonction des données observées.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(Y \sim \mathcal{N}(\mu,
\sigma^2)\)</span>, avec <span class="math inline">\(\mu \sim
\mathcal{N}(m_0, v_0)\)</span> et <span class="math inline">\(\sigma^2
\sim \text{Inv-Gamma}(a_0, b_0)\)</span>. La distribution a posteriori
de <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\sigma^2\)</span> est donnée par : <span
class="math display">\[\mu | y_1, \ldots, y_n, \sigma^2 \sim
\mathcal{N}(m_n, v_n),\]</span> <span class="math display">\[\sigma^2 |
y_1, \ldots, y_n \sim \text{Inv-Gamma}(a_n, b_n),\]</span> où les
nouveaux hyperparamètres sont définis par : <span
class="math display">\[m_n = \frac{v_0 m_0 + n \bar{y} / \sigma^2}{v_0 /
\sigma^2 + n},\]</span> <span class="math display">\[v_n =
\frac{1}{v_0^{-1} + n / \sigma^2},\]</span> <span
class="math display">\[a_n = a_0 + n/2,\]</span> <span
class="math display">\[b_n = b_0 + \frac{1}{2} \left( \sum_{i=1}^n (y_i
- \bar{y})^2 + \frac{n v_0 (\bar{y} - m_0)^2}{v_0 + n \sigma^2}
\right).\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>La preuve de ce théorème repose sur l’application des règles de Bayes
et les propriétés des distributions normales et inverse-gamma. Nous
commençons par exprimer la distribution a posteriori en utilisant la
règle de Bayes :</p>
<p><span class="math display">\[p(\mu, \sigma^2 | y_1, \ldots, y_n) =
\frac{p(y_1, \ldots, y_n | \mu, \sigma^2) p(\mu) p(\sigma^2)}{p(y_1,
\ldots, y_n)}.\]</span></p>
<p>Ensuite, nous utilisons le fait que les données sont indépendantes et
identiquement distribuées selon une loi normale :</p>
<p><span class="math display">\[p(y_1, \ldots, y_n | \mu, \sigma^2) =
\prod_{i=1}^n \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(y_i -
\mu)^2}{2 \sigma^2} \right).\]</span></p>
<p>Nous intégrons ensuite cette expression avec la distribution a priori
de <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\sigma^2\)</span>. Après des calculs détaillés,
nous obtenons les expressions pour les nouveaux hyperparamètres <span
class="math inline">\(m_n\)</span>, <span
class="math inline">\(v_n\)</span>, <span
class="math inline">\(a_n\)</span> et <span
class="math inline">\(b_n\)</span>.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La conjugaison Normal-Normal possède plusieurs propriétés
intéressantes qui en font un outil puissant pour l’analyse
bayésienne.</p>
<ul>
<li><p>La distribution a posteriori de <span
class="math inline">\(\mu\)</span> reste normale, ce qui simplifie les
calculs et permet des interprétations intuitives.</p></li>
<li><p>La distribution a posteriori de <span
class="math inline">\(\sigma^2\)</span> reste inverse-gamma, ce qui
permet de maintenir la structure hiérarchique du modèle.</p></li>
<li><p>Les hyperparamètres a posteriori dépendent des données observées,
ce qui permet d’incorporer l’information contenue dans les
données.</p></li>
</ul>
<p>Ces propriétés font de la conjugaison Normal-Normal un cadre flexible
et puissant pour l’analyse statistique bayésienne.</p>
</body>
</html>
{% include "footer.html" %}

