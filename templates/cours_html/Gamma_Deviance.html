{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Gamma Deviance: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Gamma Deviance: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>The concept of Gamma Deviance emerges from the need to understand and
model the variability in data that follows a gamma distribution. This
distribution is widely used in various fields such as finance,
engineering, and biology to model waiting times and other continuous
positive random variables. The deviance is a measure of the goodness of
fit of a statistical model, and in the context of gamma distributions,
it provides insights into the dispersion and shape of the data.</p>
<p>Gamma Deviance is indispensable in statistical modeling, particularly
in generalized linear models (GLMs), where it helps in assessing the fit
of the model to the data. It is also crucial in understanding the
behavior of gamma-distributed data under different conditions and
transformations.</p>
<h1 id="définitions">Définitions</h1>
<p>Before formally defining Gamma Deviance, let us consider the scenario
where we have a set of data points that are modeled by a gamma
distribution. The gamma distribution is characterized by two parameters:
the shape parameter <span class="math inline">\(k\)</span> and the scale
parameter <span class="math inline">\(\theta\)</span>. The probability
density function (PDF) of a gamma-distributed random variable <span
class="math inline">\(X\)</span> is given by:</p>
<p><span class="math display">\[f(x; k, \theta) = \frac{x^{k-1}
e^{-x/\theta}}{\theta^k \Gamma(k)}\]</span></p>
<p>where <span class="math inline">\(\Gamma(k)\)</span> is the gamma
function. The deviance measures how well this model fits the observed
data.</p>
<h4 id="definition">Definition:</h4>
<p>Let <span class="math inline">\(Y_1, Y_2, \ldots, Y_n\)</span> be
independent observations from a gamma distribution with shape parameter
<span class="math inline">\(k\)</span> and scale parameter <span
class="math inline">\(\theta\)</span>. The Gamma Deviance <span
class="math inline">\(D\)</span> is defined as:</p>
<p><span class="math display">\[D = -2 \left( \sum_{i=1}^n \log f(Y_i;
\hat{k}, \hat{\theta}) - \sum_{i=1}^n \log f(Y_i; k^*, \theta^*)
\right)\]</span></p>
<p>where <span class="math inline">\((\hat{k}, \hat{\theta})\)</span>
are the maximum likelihood estimates of the parameters, and <span
class="math inline">\((k^*, \theta^*)\)</span> are the saturated model
estimates.</p>
<p>Alternatively, the Gamma Deviance can be expressed in terms of the
observed and expected values:</p>
<p><span class="math display">\[D = 2 \sum_{i=1}^n \left(
\frac{Y_i}{\hat{\theta}} - \hat{k}
\log\left(\frac{Y_i}{\hat{\theta}}\right) + \hat{k} - Y_i / \theta^* +
k^* \log(Y_i / \theta^*) - k^* \right)\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<h4 id="theorem-wilks-theorem">Theorem (Wilks’ Theorem):</h4>
<p>Under regularity conditions, the deviance <span
class="math inline">\(D\)</span> follows a chi-squared distribution with
degrees of freedom equal to the difference in the number of parameters
between the saturated model and the fitted model.</p>
<p><span class="math display">\[D \sim \chi^2_{p - q}\]</span></p>
<p>where <span class="math inline">\(p\)</span> is the number of
parameters in the saturated model and <span
class="math inline">\(q\)</span> is the number of parameters in the
fitted model.</p>
<h4 id="proof">Proof:</h4>
<p>The proof of Wilks’ Theorem relies on the properties of maximum
likelihood estimators and the asymptotic normality of these estimators.
The deviance can be shown to be a quadratic form in the differences
between the observed and expected values, which under certain
conditions, follows a chi-squared distribution.</p>
<h1 id="preuves">Preuves</h1>
<p>To understand the proof of Wilks’ Theorem, let us consider the
likelihood function <span class="math inline">\(L(k, \theta)\)</span>
for the gamma distribution. The log-likelihood function is given by:</p>
<p><span class="math display">\[\ell(k, \theta) = \sum_{i=1}^n \left( (k
- 1) \log Y_i - \frac{Y_i}{\theta} - k \log \theta - \log \Gamma(k)
\right)\]</span></p>
<p>The maximum likelihood estimates <span
class="math inline">\((\hat{k}, \hat{\theta})\)</span> are obtained by
maximizing this function. The deviance <span
class="math inline">\(D\)</span> can be expressed as:</p>
<p><span class="math display">\[D = -2 \left( \ell(\hat{k},
\hat{\theta}) - \ell(k^*, \theta^*) \right)\]</span></p>
<p>Using a second-order Taylor expansion around the maximum likelihood
estimates, we can show that <span class="math inline">\(D\)</span> is
approximately a quadratic form in the differences between the observed
and expected values. Under regularity conditions, this quadratic form
follows a chi-squared distribution.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h4 id="i-property">(i) Property:</h4>
<p>The Gamma Deviance is always non-negative.</p>
<p><span class="math display">\[D \geq 0\]</span></p>
<h4 id="proof-1">Proof:</h4>
<p>This property follows from the fact that the deviance is defined in
terms of a log-likelihood ratio, and the logarithm of a probability is
always less than or equal to zero.</p>
<h4 id="ii-property">(ii) Property:</h4>
<p>The Gamma Deviance is invariant under reparameterization of the
model.</p>
<h4 id="proof-2">Proof:</h4>
<p>This property can be shown by considering different parameterizations
of the gamma distribution and showing that the deviance remains
unchanged.</p>
<h4 id="iii-corollary">(iii) Corollary:</h4>
<p>For a saturated model, the Gamma Deviance is zero.</p>
<p><span class="math display">\[D = 0\]</span></p>
<h4 id="proof-3">Proof:</h4>
<p>In a saturated model, the fitted parameters <span
class="math inline">\((\hat{k}, \hat{\theta})\)</span> are equal to the
saturated model parameters <span class="math inline">\((k^*,
\theta^*)\)</span>, so the deviance is zero.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Gamma Deviance is a powerful tool in statistical modeling,
particularly for data that follows a gamma distribution. It provides a
measure of the goodness of fit and helps in assessing the adequacy of
the model. The properties and theorems associated with Gamma Deviance
are crucial in understanding its behavior and applications.</p>
</body>
</html>
{% include "footer.html" %}

