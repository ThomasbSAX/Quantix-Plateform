{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Wasserstein-2 : Théorie et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Wasserstein-2 : Théorie et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Wasserstein, également connue sous le nom de distance
de Kantorovich-Rubinstein, est une notion centrale en théorie des
probabilités et en analyse optimale de transport. Elle trouve ses
racines dans les travaux de Leonid Kantorovich dans les années 1940, qui
a introduit cette notion pour résoudre des problèmes d’optimisation en
économie. Plus tard, les travaux de Vladimir Rubinstein et autres
chercheurs ont approfondi cette théorie.</p>
<p>La distance de Wasserstein-2, en particulier, est d’une importance
capitale dans divers domaines tels que la théorie des probabilités,
l’apprentissage automatique, et même en physique statistique. Elle
permet de mesurer la distance entre deux distributions de probabilité en
tenant compte des coûts de transport d’une distribution à une autre.
Cette notion est indispensable pour comprendre les phénomènes de
convergence en probabilité, les algorithmes d’optimisation, et les
modèles de diffusion.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la distance de Wasserstein-2, commençons par
comprendre ce que nous cherchons à mesurer. Imaginons deux distributions
de probabilité sur un espace métrique <span class="math inline">\((X,
d)\)</span>. Nous voulons quantifier la différence entre ces deux
distributions en tenant compte de la "distance" minimale nécessaire pour
transformer une distribution en l’autre.</p>
<p>Formellement, soit <span class="math inline">\((X, d)\)</span> un
espace métrique et <span class="math inline">\(\mathcal{P}(X)\)</span>
l’ensemble des mesures de probabilité sur <span
class="math inline">\(X\)</span>. La distance de Wasserstein-2 entre
deux mesures <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> est définie comme suit :</p>
<div class="definition">
<p>La distance de Wasserstein-2 entre deux mesures <span
class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> est donnée par : <span
class="math display">\[W_2(\mu, \nu) = \left( \inf_{\gamma \in
\Gamma(\mu, \nu)} \int_{X \times X} d(x, y)^2 \, d\gamma(x, y)
\right)^{1/2}\]</span> où <span class="math inline">\(\Gamma(\mu,
\nu)\)</span> est l’ensemble des mesures de couplage entre <span
class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span>, c’est-à-dire les mesures <span
class="math inline">\(\gamma\)</span> sur <span class="math inline">\(X
\times X\)</span> telles que pour tout borélien <span
class="math inline">\(A \subset X\)</span>, <span
class="math inline">\(\gamma(A \times X) = \mu(A)\)</span> et <span
class="math inline">\(\gamma(X \times A) = \nu(A)\)</span>.</p>
</div>
<p>Une autre manière de formuler cette définition est la suivante :</p>
<div class="definition">
<p>Soient <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> deux mesures de probabilité sur un
espace métrique <span class="math inline">\((X, d)\)</span>. La distance
de Wasserstein-2 est définie par : <span class="math display">\[W_2(\mu,
\nu) = \inf_{\gamma \in \Gamma(\mu, \nu)} \left( \int_{X \times X} d(x,
y)^2 \, d\gamma(x, y) \right)^{1/2}\]</span></p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la distance de Wasserstein-2 est le
théorème de Kantorovich-Rubinstein, qui établit une dualité entre la
distance de Wasserstein et les fonctions Lipschitz.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(\mu\)</span> et <span
class="math inline">\(\nu\)</span> deux mesures de probabilité sur un
espace métrique <span class="math inline">\((X, d)\)</span>. Alors,
<span class="math display">\[W_2(\mu, \nu) = \sup_{f \in
\text{Lip}_1(X)} \left| \int_X f \, d\mu - \int_X f \, d\nu
\right|\]</span> où <span class="math inline">\(\text{Lip}_1(X)\)</span>
est l’ensemble des fonctions <span class="math inline">\(f: X \to
\mathbb{R}\)</span> Lipschitz avec une constante de Lipschitz inférieure
ou égale à 1.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Kantorovich-Rubinstein, nous commençons
par rappeler quelques propriétés fondamentales des mesures de couplage
et des fonctions Lipschitz.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\gamma \in
\Gamma(\mu, \nu)\)</span>. Pour toute fonction <span
class="math inline">\(f: X \to \mathbb{R}\)</span> Lipschitz avec une
constante de Lipschitz <span class="math inline">\(L\)</span>, nous
avons : <span class="math display">\[\left| \int_{X \times X} f(x) -
f(y) \, d\gamma(x, y) \right| \leq L \int_{X \times X} d(x, y) \,
d\gamma(x, y)\]</span> En prenant la supremum sur toutes les fonctions
<span class="math inline">\(f\)</span> Lipschitz avec <span
class="math inline">\(L=1\)</span>, nous obtenons : <span
class="math display">\[\sup_{f \in \text{Lip}_1(X)} \left| \int_X f \,
d\mu - \int_X f \, d\nu \right| \leq W_2(\mu, \nu)\]</span>
Réciproquement, pour toute <span class="math inline">\(\epsilon &gt;
0\)</span>, il existe une fonction <span
class="math inline">\(f_\epsilon\)</span> Lipschitz telle que : <span
class="math display">\[W_2(\mu, \nu) \leq \left| \int_X f_\epsilon \,
d\mu - \int_X f_\epsilon \, d\nu \right| + \epsilon\]</span> En faisant
tendre <span class="math inline">\(\epsilon\)</span> vers 0, nous
obtenons l’égalité souhaitée. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La distance de Wasserstein-2 possède plusieurs propriétés
intéressantes. En voici quelques-unes :</p>
<ol>
<li><p>**Inégalité triangulaire** : Pour toutes mesures <span
class="math inline">\(\mu, \nu, \rho\)</span> sur <span
class="math inline">\(X\)</span>, <span class="math display">\[W_2(\mu,
\nu) \leq W_2(\mu, \rho) + W_2(\rho, \nu)\]</span></p></li>
<li><p>**Continuité** : La distance de Wasserstein-2 est continue par
rapport à la convergence faible des mesures. C’est-à-dire, si <span
class="math inline">\(\mu_n \to \mu\)</span> et <span
class="math inline">\(\nu_n \to \nu\)</span> faiblement, alors <span
class="math inline">\(W_2(\mu_n, \nu_n) \to W_2(\mu,
\nu)\)</span>.</p></li>
<li><p>**Inégalité de Talagrand** : Pour toute mesure <span
class="math inline">\(\mu\)</span> sur un espace de Hilbert <span
class="math inline">\(H\)</span>, si <span class="math inline">\(\nu =
\mathcal{N}(0, I)\)</span> est la loi normale standard, alors <span
class="math display">\[W_2(\mu, \nu) \leq \sqrt{2 \log \left(
\frac{\det(\Sigma)^{1/2}}{\prod_{i=1}^n \lambda_i} \right)}\]</span> où
<span class="math inline">\(\Sigma\)</span> est la matrice de covariance
de <span class="math inline">\(\mu\)</span>.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La distance de Wasserstein-2 est un outil puissant et polyvalent en
théorie des probabilités et en analyse optimale de transport. Ses
applications vont de la convergence en probabilité à l’apprentissage
automatique, en passant par la physique statistique. Les propriétés et
théorèmes associés à cette distance continuent de fasciner les
chercheurs et d’ouvrir de nouvelles perspectives dans divers domaines
scientifiques.</p>
</body>
</html>
{% include "footer.html" %}

