{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Direct Sum Kernel: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Direct Sum Kernel: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-and-motivations">Introduction
and Motivations</h1>
<p>The concept of the direct sum kernel emerges from the intersection of
linear algebra and functional analysis, providing a powerful tool for
understanding and manipulating vector spaces. Historically, the direct
sum decomposition has been fundamental in simplifying complex structures
into manageable components. The kernel of a linear operator, on the
other hand, encapsulates the null space where the operator’s action
vanishes. Combining these two notions leads to the direct sum kernel,
which is indispensable in various fields such as differential equations,
control theory, and quantum mechanics.</p>
<h1 class="unnumbered" id="definitions">Definitions</h1>
<p>To understand the direct sum kernel, let’s first consider a linear
operator <span class="math inline">\(T: V \to W\)</span> between vector
spaces <span class="math inline">\(V\)</span> and <span
class="math inline">\(W\)</span>. The kernel of <span
class="math inline">\(T\)</span>, denoted <span
class="math inline">\(\ker(T)\)</span>, is the set of all vectors in
<span class="math inline">\(V\)</span> that are mapped to the zero
vector in <span class="math inline">\(W\)</span>. Formally, we have:</p>
<p><span class="math display">\[\ker(T) = \{ v \in V \mid T(v) = 0_W
\}\]</span></p>
<p>Now, suppose <span class="math inline">\(V\)</span> can be decomposed
into a direct sum of two subspaces <span
class="math inline">\(U\)</span> and <span
class="math inline">\(W\)</span>. This means that every vector in <span
class="math inline">\(V\)</span> can be uniquely expressed as a sum of
vectors from <span class="math inline">\(U\)</span> and <span
class="math inline">\(W\)</span>. Mathematically, this is written
as:</p>
<p><span class="math display">\[V = U \oplus W\]</span></p>
<p>The direct sum kernel extends this idea to the context of linear
operators. Specifically, if <span class="math inline">\(T\)</span> can
be decomposed into operators <span class="math inline">\(T_1: U \to
V\)</span> and <span class="math inline">\(T_2: W \to V\)</span>, such
that:</p>
<p><span class="math display">\[T(v) = T_1(u) + T_2(w) \quad \text{for
all} \quad v = u + w \in V\]</span></p>
<p>then the direct sum kernel <span
class="math inline">\(\ker(T)\)</span> can be expressed as:</p>
<p><span class="math display">\[\ker(T) = \ker(T_1) \oplus
\ker(T_2)\]</span></p>
<p>This decomposition allows us to analyze the kernel of <span
class="math inline">\(T\)</span> by studying the kernels of its
constituent operators <span class="math inline">\(T_1\)</span> and <span
class="math inline">\(T_2\)</span>.</p>
<h1 class="unnumbered" id="theorems">Theorems</h1>
<p>One of the fundamental theorems related to the direct sum kernel is
the following:</p>
<p><strong>Theorem (Direct Sum Kernel Theorem):</strong> Let <span
class="math inline">\(V\)</span> be a vector space that can be
decomposed into the direct sum of two subspaces <span
class="math inline">\(U\)</span> and <span
class="math inline">\(W\)</span>, i.e., <span class="math inline">\(V =
U \oplus W\)</span>. Let <span class="math inline">\(T: V \to V\)</span>
be a linear operator that can be decomposed into operators <span
class="math inline">\(T_1: U \to V\)</span> and <span
class="math inline">\(T_2: W \to V\)</span>, such that:</p>
<p><span class="math display">\[T(v) = T_1(u) + T_2(w) \quad \text{for
all} \quad v = u + w \in V\]</span></p>
<p>Then the kernel of <span class="math inline">\(T\)</span> can be
expressed as the direct sum of the kernels of <span
class="math inline">\(T_1\)</span> and <span
class="math inline">\(T_2\)</span>:</p>
<p><span class="math display">\[\ker(T) = \ker(T_1) \oplus
\ker(T_2)\]</span></p>
<p><strong>Proof:</strong> To prove this theorem, we need to show two
things: first, that <span class="math inline">\(\ker(T_1) \oplus
\ker(T_2) \subseteq \ker(T)\)</span>, and second, that <span
class="math inline">\(\ker(T) \subseteq \ker(T_1) \oplus
\ker(T_2)\)</span>.</p>
<ol>
<li><p>Let <span class="math inline">\(v \in \ker(T_1) \oplus
\ker(T_2)\)</span>. Then there exist <span class="math inline">\(u \in
\ker(T_1)\)</span> and <span class="math inline">\(w \in
\ker(T_2)\)</span> such that <span class="math inline">\(v = u +
w\)</span>. By definition of the kernel, we have:</p>
<p><span class="math display">\[T_1(u) = 0_V \quad \text{and} \quad
T_2(w) = 0_V\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[T(v) = T_1(u) + T_2(w) = 0_V + 0_V =
0_V\]</span></p>
<p>Hence, <span class="math inline">\(v \in \ker(T)\)</span>, which
shows that <span class="math inline">\(\ker(T_1) \oplus \ker(T_2)
\subseteq \ker(T)\)</span>.</p></li>
<li><p>Conversely, let <span class="math inline">\(v \in
\ker(T)\)</span>. Since <span class="math inline">\(V = U \oplus
W\)</span>, we can write <span class="math inline">\(v\)</span> uniquely
as <span class="math inline">\(v = u + w\)</span> for some <span
class="math inline">\(u \in U\)</span> and <span class="math inline">\(w
\in W\)</span>. Then,</p>
<p><span class="math display">\[T(v) = T_1(u) + T_2(w) =
0_V\]</span></p>
<p>This implies that <span class="math inline">\(T_1(u) =
-T_2(w)\)</span>. However, since <span class="math inline">\(U\)</span>
and <span class="math inline">\(W\)</span> are subspaces of <span
class="math inline">\(V\)</span>, and <span
class="math inline">\(T_1\)</span> maps <span
class="math inline">\(U\)</span> to <span
class="math inline">\(V\)</span> while <span
class="math inline">\(T_2\)</span> maps <span
class="math inline">\(W\)</span> to <span
class="math inline">\(V\)</span>, the only way this equality holds is if
both <span class="math inline">\(T_1(u) = 0_V\)</span> and <span
class="math inline">\(T_2(w) = 0_V\)</span>. Therefore, <span
class="math inline">\(u \in \ker(T_1)\)</span> and <span
class="math inline">\(w \in \ker(T_2)\)</span>, which means that <span
class="math inline">\(v = u + w \in \ker(T_1) \oplus \ker(T_2)\)</span>.
This shows that <span class="math inline">\(\ker(T) \subseteq \ker(T_1)
\oplus \ker(T_2)\)</span>.</p></li>
</ol>
<p>Since both inclusions hold, we conclude that <span
class="math inline">\(\ker(T) = \ker(T_1) \oplus \ker(T_2)\)</span>.</p>
<h1 class="unnumbered" id="properties-and-corollaries">Properties and
Corollaries</h1>
<p>The direct sum kernel theorem has several important properties and
corollaries:</p>
<ol>
<li><p><strong>Dimension Property:</strong> The dimension of the kernel
of <span class="math inline">\(T\)</span> is equal to the sum of the
dimensions of the kernels of <span class="math inline">\(T_1\)</span>
and <span class="math inline">\(T_2\)</span>:</p>
<p><span class="math display">\[\dim(\ker(T)) = \dim(\ker(T_1)) +
\dim(\ker(T_2))\]</span></p>
<p>This follows directly from the fact that <span
class="math inline">\(\ker(T) = \ker(T_1) \oplus
\ker(T_2)\)</span>.</p></li>
<li><p><strong>Image Property:</strong> The image of <span
class="math inline">\(T\)</span> is related to the images of <span
class="math inline">\(T_1\)</span> and <span
class="math inline">\(T_2\)</span>. Specifically, if <span
class="math inline">\(T_1\)</span> and <span
class="math inline">\(T_2\)</span> are injective (i.e., their kernels
are trivial), then the image of <span class="math inline">\(T\)</span>
is equal to the sum of the images of <span
class="math inline">\(T_1\)</span> and <span
class="math inline">\(T_2\)</span>:</p>
<p><span class="math display">\[\text{Im}(T) = \text{Im}(T_1) +
\text{Im}(T_2)\]</span></p>
<p>This property is useful in understanding the range of the operator
<span class="math inline">\(T\)</span>.</p></li>
<li><p><strong>Decomposition Property:</strong> If <span
class="math inline">\(V\)</span> can be decomposed into a direct sum of
more than two subspaces, say <span class="math inline">\(V = U_1 \oplus
U_2 \oplus \cdots \oplus U_n\)</span>, then the kernel of <span
class="math inline">\(T\)</span> can be expressed as the direct sum of
the kernels of its constituent operators:</p>
<p><span class="math display">\[\ker(T) = \ker(T_1) \oplus \ker(T_2)
\oplus \cdots \oplus \ker(T_n)\]</span></p>
<p>This generalization extends the direct sum kernel theorem to
higher-dimensional decompositions.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>The concept of the direct sum kernel provides a powerful framework
for analyzing linear operators and their null spaces. By decomposing
vector spaces into direct sums of subspaces, we can simplify the study
of complex operators and gain deeper insights into their properties. The
direct sum kernel theorem, along with its properties and corollaries,
offers a robust tool for researchers in various fields to tackle
intricate problems with elegance and precision.</p>
</body>
</html>
{% include "footer.html" %}

