{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’Entropie de Permutation : Une Mesure de Complexité des Systèmes Dynamiques</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’Entropie de Permutation : Une Mesure de Complexité
des Systèmes Dynamiques</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’étude des systèmes dynamiques a toujours été un champ fertile pour
les mathématiciens, cherchant à comprendre le comportement des systèmes
évoluant dans le temps. Parmi les outils développés pour analyser ces
systèmes, l’entropie de permutation se distingue par sa capacité à
capturer la complexité des dynamiques temporelles. Introduite
initialement pour les systèmes continus, cette notion a trouvé des
applications dans divers domaines, allant de la physique théorique à
l’analyse des séries temporelles financières.</p>
<p>L’entropie de permutation émerge comme une réponse aux limites des
mesures traditionnelles d’entropie, telles que l’entropie de Shannon ou
l’entropie de Kolmogorov-Sinai. Elle permet d’analyser des systèmes pour
lesquels les données sont disponibles sous forme de séries temporelles
discrètes, offrant ainsi une approche plus accessible et pratique. Son
importance réside dans sa capacité à détecter des changements subtils
dans la structure des séries temporelles, rendant possible
l’identification de transitions de phase ou de bifurcations dans les
systèmes dynamiques.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire l’entropie de permutation, commençons par comprendre
ce que nous cherchons à mesurer. Imaginons une série temporelle discrète
<span class="math inline">\((x_1, x_2, \ldots, x_n)\)</span>. Nous
voulons capturer la manière dont les valeurs de cette série évoluent
dans le temps, en particulier comment les séquences de valeurs se
comparent entre elles. L’idée est de transformer cette série en une
séquence de motifs ordinaires, ou <em>patterns</em>, et d’analyser la
distribution de ces motifs.</p>
<p>Formellement, pour une série temporelle <span
class="math inline">\((x_1, x_2, \ldots, x_n)\)</span>, un motif de
longueur <span class="math inline">\(m\)</span> est une séquence de
<span class="math inline">\(m\)</span> valeurs consécutives. Pour chaque
motif, nous considérons l’ordre relatif des valeurs dans le motif. Par
exemple, pour <span class="math inline">\(m = 3\)</span>, le motif <span
class="math inline">\((x_i, x_{i+1}, x_{i+2})\)</span> peut être ordonné
de <span class="math inline">\(6\)</span> manières différentes,
correspondant aux <span class="math inline">\(3! = 6\)</span>
permutations possibles de trois éléments.</p>
<p>L’entropie de permutation est alors définie comme une mesure de
l’incertitude ou de la complexité de ces motifs. Plus précisément, nous
définissons une partition de l’espace des phases en sous-ensembles
correspondant à chaque permutation possible, et nous calculons
l’entropie de Shannon de cette partition.</p>
<div class="definition">
<p>Soit <span class="math inline">\((x_1, x_2, \ldots, x_n)\)</span> une
série temporelle discrète. Pour un entier <span class="math inline">\(m
\geq 2\)</span>, nous définissons les motifs de longueur <span
class="math inline">\(m\)</span> comme suit : <span
class="math display">\[\text{Pour tout } i \text{ tel que } 1 \leq i
\leq n - m + 1, \text{ le motif est } (x_i, x_{i+1}, \ldots,
x_{i+m-1}).\]</span> Pour chaque motif, nous considérons la permutation
<span class="math inline">\(\pi_i\)</span> qui ordonne les éléments du
motif dans l’ordre croissant. Nous définissons alors la fréquence
relative <span class="math inline">\(p_\pi\)</span> de chaque
permutation <span class="math inline">\(\pi\)</span> comme : <span
class="math display">\[p_\pi = \frac{\text{Nombre de motifs
correspondant à } \pi}{\text{Nombre total de motifs}}.\]</span>
L’entropie de permutation <span class="math inline">\(H(m)\)</span> est
alors donnée par : <span class="math display">\[H(m) = -\sum_{\pi} p_\pi
\log_2 p_\pi,\]</span> où la somme est prise sur toutes les permutations
<span class="math inline">\(\pi\)</span> de longueur <span
class="math inline">\(m\)</span>.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un des résultats fondamentaux concernant l’entropie de permutation
est son lien avec l’entropie topologique d’un système dynamique. Plus
précisément, pour un système dynamique continu, l’entropie de
permutation peut être utilisée pour estimer l’entropie topologique.</p>
<div class="theoreme">
<p>Soit <span class="math inline">\(f : X \to X\)</span> un système
dynamique continu. Supposons que l’entropie topologique <span
class="math inline">\(h_{\text{top}}(f)\)</span> de <span
class="math inline">\(f\)</span> est finie. Alors, pour toute série
temporelle discrète <span class="math inline">\((x_1, x_2, \ldots,
x_n)\)</span> générée par <span class="math inline">\(f\)</span>,
l’entropie de permutation <span class="math inline">\(H(m)\)</span>
satisfait : <span class="math display">\[\lim_{m \to \infty} H(m) =
h_{\text{top}}(f).\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème précédent, nous avons besoin de plusieurs
étapes intermédiaires. Commençons par rappeler que l’entropie
topologique est une mesure de la complexité d’un système dynamique,
capturant le taux auquel les orbites du système se séparent.</p>
<div class="proof">
<p><em>Proof.</em> Considérons un système dynamique <span
class="math inline">\(f : X \to X\)</span> avec une entropie topologique
finie <span class="math inline">\(h_{\text{top}}(f)\)</span>. Nous
voulons montrer que l’entropie de permutation <span
class="math inline">\(H(m)\)</span> converge vers <span
class="math inline">\(h_{\text{top}}(f)\)</span> lorsque <span
class="math inline">\(m \to \infty\)</span>.</p>
<p>Pour cela, nous utilisons le fait que l’entropie de permutation peut
être vue comme une approximation discrète de l’entropie topologique.
Plus précisément, pour chaque motif de longueur <span
class="math inline">\(m\)</span>, nous pouvons associer une partition de
l’espace des phases en sous-ensembles correspondant aux différentes
permutations possibles.</p>
<p>En appliquant le théorème de l’entropie topologique, nous savons que
pour toute partition <span class="math inline">\(\alpha\)</span> de
<span class="math inline">\(X\)</span>, l’entropie de la partition <span
class="math inline">\(h(f, \alpha)\)</span> est inférieure ou égale à
l’entropie topologique <span
class="math inline">\(h_{\text{top}}(f)\)</span>. De plus, en prenant la
limite lorsque la taille des éléments de la partition tend vers zéro,
l’entropie de la partition converge vers <span
class="math inline">\(h_{\text{top}}(f)\)</span>.</p>
<p>En choisissant une partition basée sur les motifs de longueur <span
class="math inline">\(m\)</span>, nous pouvons montrer que l’entropie de
permutation <span class="math inline">\(H(m)\)</span> est une
approximation discrète de <span class="math inline">\(h(f,
\alpha)\)</span>. En prenant la limite lorsque <span
class="math inline">\(m \to \infty\)</span>, nous obtenons que <span
class="math inline">\(H(m)\)</span> converge vers <span
class="math inline">\(h_{\text{top}}(f)\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’entropie de permutation possède plusieurs propriétés intéressantes
qui en font un outil puissant pour l’analyse des systèmes dynamiques.
Nous en listons quelques-unes ci-dessous :</p>
<ol>
<li><p><strong>Invariance par Transformation Affine</strong> :
L’entropie de permutation est invariante par transformation affine des
données. Plus précisément, si nous appliquons une transformation affine
<span class="math inline">\(y_i = a x_i + b\)</span> à la série
temporelle, l’entropie de permutation reste inchangée.</p></li>
<li><p><strong>Stabilité</strong> : L’entropie de permutation est stable
sous petites perturbations des données. Cela signifie que de petites
variations dans les valeurs de la série temporelle n’affectent pas
significativement l’entropie de permutation.</p></li>
<li><p><strong>Lien avec l’Entropie de Shannon</strong> : Pour des
systèmes dynamiques continus, l’entropie de permutation peut être vue
comme une approximation discrète de l’entropie de Shannon. Plus
précisément, en prenant la limite lorsque la taille des motifs tend vers
zéro, l’entropie de permutation converge vers l’entropie de
Shannon.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’entropie de permutation est un outil puissant pour l’analyse des
systèmes dynamiques, offrant une mesure de la complexité des séries
temporelles discrètes. Son lien avec l’entropie topologique en fait un
outil précieux pour comprendre le comportement des systèmes dynamiques
continus. Les propriétés de stabilité et d’invariance par transformation
affine en font un outil robuste et pratique pour l’analyse des données
réelles.</p>
<p>Future recherches pourraient explorer des extensions de l’entropie de
permutation à des systèmes dynamiques plus complexes, tels que les
systèmes stochastiques ou les réseaux de neurones. De plus, des
applications dans des domaines tels que la finance, la biologie et
l’ingénierie pourraient être développées pour exploiter pleinement le
potentiel de cette mesure.</p>
</body>
</html>
{% include "footer.html" %}

