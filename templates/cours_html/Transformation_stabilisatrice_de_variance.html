{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Transformation stabilisatrice de variance</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Transformation stabilisatrice de variance</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les transformations stabilisatrices de variance sont des outils
fondamentaux en statistique, particulièrement dans l’analyse de
régression et la modélisation des données. Elles émergent d’un besoin
crucial : stabiliser la variance des résidus pour satisfaire les
hypothèses des modèles statistiques classiques. Historiquement, ces
transformations ont été introduites pour résoudre les problèmes de
non-normalité et d’hétéroscédasticité dans les données.</p>
<p>En effet, lorsque la variance des résidus n’est pas constante
(hétéroscédasticité), les estimations des paramètres du modèle peuvent
être biaisées et inefficaces. Les transformations stabilisatrices de
variance permettent de transformer les données pour rendre la variance
des résidus constante, améliorant ainsi la validité et l’efficacité des
modèles statistiques.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre les transformations stabilisatrices de variance,
commençons par définir ce que nous cherchons à obtenir. Supposons que
nous ayons un modèle de régression où les résidus présentent une
variance non constante. Notre objectif est de transformer ces résidus
pour que leur variance devienne constante.</p>
<p>Formellement, soit <span class="math inline">\(Y\)</span> une
variable aléatoire avec une variance non constante. Nous cherchons une
fonction de transformation <span class="math inline">\(g\)</span> telle
que la variance de <span class="math inline">\(g(Y)\)</span> soit
constante.</p>
<div class="definition">
<p>Soit <span class="math inline">\(Y\)</span> une variable aléatoire
avec une fonction de variance <span class="math inline">\(V(Y) =
\sigma^2(Y)\)</span>. Une transformation stabilisatrice de variance est
une fonction <span class="math inline">\(g: \mathbb{R} \rightarrow
\mathbb{R}\)</span> telle que : <span class="math display">\[\forall
y_1, y_2 \in \mathbb{R}, \quad V(g(y_1)) = V(g(y_2))\]</span></p>
</div>
<p>Une autre manière de formuler cette définition est la suivante :
<span class="math display">\[\exists c \in \mathbb{R} \text{ tel que }
V(g(Y)) = c\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental dans le domaine des transformations
stabilisatrices de variance est le théorème de Box-Cox. Ce théorème
fournit une méthode pour trouver la transformation optimale qui
stabilise la variance des résidus.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(Y\)</span> une variable aléatoire
positive. La transformation de Box-Cox est définie par : <span
class="math display">\[g(Y, \lambda) = \begin{cases}
\frac{Y^\lambda - 1}{\lambda} &amp; \text{si } \lambda \neq 0 \\
\log(Y) &amp; \text{si } \lambda = 0
\end{cases}\]</span> où <span class="math inline">\(\lambda\)</span> est
un paramètre à estimer. La transformation de Box-Cox stabilise la
variance des résidus si <span class="math inline">\(\lambda\)</span> est
choisi de manière appropriée.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Box-Cox, nous devons montrer que la
transformation <span class="math inline">\(g(Y, \lambda)\)</span>
stabilise effectivement la variance des résidus. Commençons par rappeler
que nous cherchons à minimiser la variance des résidus transformés.</p>
<p>Soit <span class="math inline">\(Y\)</span> une variable aléatoire
positive. La transformation de Box-Cox est définie comme suit : <span
class="math display">\[g(Y, \lambda) = \begin{cases}
\frac{Y^\lambda - 1}{\lambda} &amp; \text{si } \lambda \neq 0 \\
\log(Y) &amp; \text{si } \lambda = 0
\end{cases}\]</span></p>
<p>Nous devons montrer que pour un certain <span
class="math inline">\(\lambda\)</span>, la variance de <span
class="math inline">\(g(Y, \lambda)\)</span> est constante. Pour ce
faire, nous utilisons le fait que la variance d’une transformation non
linéaire peut être approximée par une série de Taylor.</p>
<p>En développant <span class="math inline">\(g(Y, \lambda)\)</span>
autour du point <span class="math inline">\(\mu_Y\)</span>, nous
obtenons : <span class="math display">\[g(Y, \lambda) \approx g(\mu_Y,
\lambda) + g&#39;(\mu_Y, \lambda)(Y - \mu_Y)\]</span></p>
<p>La variance de <span class="math inline">\(g(Y, \lambda)\)</span> est
alors approximée par : <span class="math display">\[V(g(Y, \lambda))
\approx g&#39;(\mu_Y, \lambda)^2 V(Y)\]</span></p>
<p>Pour que la variance soit constante, nous devons avoir : <span
class="math display">\[g&#39;(\mu_Y, \lambda)^2 V(Y) = c\]</span></p>
<p>En résolvant cette équation pour <span
class="math inline">\(\lambda\)</span>, nous trouvons la valeur optimale
de <span class="math inline">\(\lambda\)</span> qui stabilise la
variance des résidus.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Les transformations stabilisatrices de variance possèdent plusieurs
propriétés importantes. En voici quelques-unes :</p>
<ol>
<li><p>La transformation de Box-Cox est une généralisation de la
transformation logarithmique. En effet, lorsque <span
class="math inline">\(\lambda = 0\)</span>, la transformation de Box-Cox
se réduit à une transformation logarithmique.</p></li>
<li><p>La transformation de Box-Cox est inversible. Cela signifie que
nous pouvons retrouver la variable originale à partir de sa
transformation.</p></li>
<li><p>La transformation de Box-Cox est applicable uniquement aux
variables positives. Pour les variables non positives, d’autres
transformations doivent être utilisées.</p></li>
</ol>
<p>Pour prouver la propriété (i), nous observons simplement que lorsque
<span class="math inline">\(\lambda = 0\)</span>, la transformation de
Box-Cox devient : <span class="math display">\[g(Y, 0) =
\log(Y)\]</span></p>
<p>Pour prouver la propriété (ii), nous devons montrer que pour chaque
<span class="math inline">\(g(Y, \lambda)\)</span>, il existe une
fonction inverse <span class="math inline">\(h\)</span> telle que :
<span class="math display">\[h(g(Y, \lambda)) = Y\]</span></p>
<p>En effet, pour <span class="math inline">\(\lambda \neq 0\)</span>,
nous avons : <span class="math display">\[h(g(Y, \lambda)) = (1 +
\lambda g(Y, \lambda))^{1/\lambda}\]</span></p>
<p>Pour <span class="math inline">\(\lambda = 0\)</span>, nous avons :
<span class="math display">\[h(g(Y, 0)) = e^{g(Y, 0)} = Y\]</span></p>
<p>Pour prouver la propriété (iii), nous observons que la transformation
de Box-Cox est définie uniquement pour <span class="math inline">\(Y
&gt; 0\)</span>. Pour les variables non positives, d’autres
transformations telles que la transformation de Yeo-Johnson peuvent être
utilisées.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Les transformations stabilisatrices de variance sont des outils
puissants pour améliorer la validité et l’efficacité des modèles
statistiques. Le théorème de Box-Cox fournit une méthode systématique
pour trouver la transformation optimale qui stabilise la variance des
résidus. Les propriétés et corollaires de ces transformations en font un
outil indispensable pour l’analyse des données.</p>
</body>
</html>
{% include "footer.html" %}

