{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Loi de Dirichlet a posteriori</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Loi de Dirichlet a posteriori</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La loi de Dirichlet, du nom du mathématicien allemand Johann Peter
Gustav Lejeune Dirichlet, est une généralisation de la loi bêta et joue
un rôle central en théorie des probabilités et en statistiques
bayésiennes. Elle émerge naturellement dans le cadre de l’analyse de
données multinomiales, où elle sert de loi a priori pour les paramètres
de distribution. L’intérêt principal réside dans sa capacité à modéliser
des distributions sur des simplex, c’est-à-dire des ensembles de
probabilités qui s’additionnent à un.</p>
<p>Cette loi est indispensable dans les modèles hiérarchiques et
bayésiens, où elle permet de capturer l’incertitude des paramètres de
manière élégante et flexible. Son utilisation est particulièrement
répandue en apprentissage automatique, en analyse de texte, et dans les
modèles graphiques probabilistes.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la loi de Dirichlet, commençons par comprendre ce que
nous cherchons à modéliser. Supposons que nous ayons un vecteur de
paramètres <span class="math inline">\(\boldsymbol{\theta} = (\theta_1,
\theta_2, \ldots, \theta_k)\)</span> tel que <span
class="math inline">\(\sum_{i=1}^k \theta_i = 1\)</span> et <span
class="math inline">\(\theta_i &gt; 0\)</span> pour tout <span
class="math inline">\(i\)</span>. Nous voulons une distribution qui
capture l’incertitude de ces paramètres.</p>
<p>La loi de Dirichlet est définie comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(\boldsymbol{\alpha} = (\alpha_1,
\alpha_2, \ldots, \alpha_k)\)</span> un vecteur de paramètres positifs.
La densité de probabilité d’une variable aléatoire <span
class="math inline">\(\boldsymbol{\theta}\)</span> suivant une loi de
Dirichlet est donnée par : <span
class="math display">\[p(\boldsymbol{\theta} \mid \boldsymbol{\alpha}) =
\frac{1}{B(\boldsymbol{\alpha})} \prod_{i=1}^k \theta_i^{\alpha_i -
1}\]</span> où <span
class="math inline">\(B(\boldsymbol{\alpha})\)</span> est la fonction
bêta multivariée définie par : <span
class="math display">\[B(\boldsymbol{\alpha}) = \frac{\prod_{i=1}^k
\Gamma(\alpha_i)}{\Gamma\left(\sum_{i=1}^k \alpha_i\right)}\]</span> et
<span class="math inline">\(\Gamma\)</span> est la fonction gamma.</p>
</div>
<p>Une autre formulation équivalente est : <span
class="math display">\[p(\boldsymbol{\theta} \mid \boldsymbol{\alpha}) =
\frac{\Gamma\left(\sum_{i=1}^k \alpha_i\right)}{\prod_{i=1}^k
\Gamma(\alpha_i)} \prod_{i=1}^k \theta_i^{\alpha_i - 1}\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la loi de Dirichlet est le suivant
:</p>
<div class="theorem">
<p>La loi de Dirichlet est une distribution conjointe pour les
paramètres d’une distribution multinomiale. Si <span
class="math inline">\(\boldsymbol{X} = (X_1, X_2, \ldots, X_k)\)</span>
suit une distribution multinomiale avec paramètres <span
class="math inline">\(n\)</span> et <span
class="math inline">\(\boldsymbol{\theta}\)</span>, et que <span
class="math inline">\(\boldsymbol{\theta}\)</span> suit une loi de
Dirichlet avec paramètres <span
class="math inline">\(\boldsymbol{\alpha}\)</span>, alors la
distribution a posteriori de <span
class="math inline">\(\boldsymbol{\theta}\)</span> donnée <span
class="math inline">\(\boldsymbol{X} = \boldsymbol{x}\)</span> est
également une loi de Dirichlet avec paramètres <span
class="math inline">\(\boldsymbol{\alpha} + \boldsymbol{x}\)</span>.</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous utilisons la définition de la
distribution a posteriori et les propriétés des distributions
multinomiale et Dirichlet.</p>
<div class="proof">
<p><em>Proof.</em> La distribution a posteriori de <span
class="math inline">\(\boldsymbol{\theta}\)</span> donnée <span
class="math inline">\(\boldsymbol{X} = \boldsymbol{x}\)</span> est
proportionnelle au produit de la vraisemblance et de la distribution a
priori : <span class="math display">\[p(\boldsymbol{\theta} \mid
\boldsymbol{x}) \propto p(\boldsymbol{x} \mid \boldsymbol{\theta})
p(\boldsymbol{\theta})\]</span> La vraisemblance de <span
class="math inline">\(\boldsymbol{X}\)</span> donnée <span
class="math inline">\(\boldsymbol{\theta}\)</span> est : <span
class="math display">\[p(\boldsymbol{x} \mid \boldsymbol{\theta}) =
\frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k \theta_i^{x_i}\]</span> La
distribution a priori de <span
class="math inline">\(\boldsymbol{\theta}\)</span> est : <span
class="math display">\[p(\boldsymbol{\theta}) =
\frac{1}{B(\boldsymbol{\alpha})} \prod_{i=1}^k \theta_i^{\alpha_i -
1}\]</span> En multipliant ces deux expressions, nous obtenons : <span
class="math display">\[p(\boldsymbol{\theta} \mid \boldsymbol{x})
\propto \prod_{i=1}^k \theta_i^{x_i + \alpha_i - 1}\]</span> Cette
expression est proportionnelle à la densité de probabilité d’une loi de
Dirichlet avec paramètres <span
class="math inline">\(\boldsymbol{\alpha} +
\boldsymbol{x}\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La loi de Dirichlet possède plusieurs propriétés intéressantes :</p>
<ol>
<li><p><strong>Espérance</strong> : L’espérance de <span
class="math inline">\(\boldsymbol{\theta}\)</span> suivant une loi de
Dirichlet est donnée par : <span
class="math display">\[\mathbb{E}[\theta_i] =
\frac{\alpha_i}{\sum_{j=1}^k \alpha_j}\]</span></p></li>
<li><p><strong>Variance</strong> : La variance de <span
class="math inline">\(\theta_i\)</span> est donnée par : <span
class="math display">\[\text{Var}(\theta_i) = \frac{\alpha_i
\left(\sum_{j=1}^k \alpha_j - \alpha_i\right)}{\left(\sum_{j=1}^k
\alpha_j\right)^2 \left(\sum_{j=1}^k \alpha_j +
1\right)}\]</span></p></li>
<li><p><strong>Covariance</strong> : La covariance entre <span
class="math inline">\(\theta_i\)</span> et <span
class="math inline">\(\theta_j\)</span> est donnée par : <span
class="math display">\[\text{Cov}(\theta_i, \theta_j) = -\frac{\alpha_i
\alpha_j}{\left(\sum_{l=1}^k \alpha_l\right)^2 \left(\sum_{l=1}^k
\alpha_l + 1\right)}\]</span></p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La loi de Dirichlet est un outil puissant et flexible pour modéliser
des distributions sur des simplex. Son utilisation en statistiques
bayésiennes et en apprentissage automatique est incontournable, grâce à
ses propriétés de conjugaison et sa capacité à capturer l’incertitude
des paramètres. Les développements futurs pourraient explorer des
extensions de cette loi à des contextes plus généraux et complexes.</p>
</body>
</html>
{% include "footer.html" %}

