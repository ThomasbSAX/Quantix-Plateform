{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Convergence superlinéaire : Une exploration mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Convergence superlinéaire : Une exploration
mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’étude de la convergence des suites et des séries est un pilier
fondamental en analyse mathématique. Parmi les différents types de
convergence, la <strong>convergence superlinéaire</strong> se distingue
par sa rapidité et ses propriétés remarquables. Cette notion émerge
naturellement dans l’étude des méthodes itératives pour la résolution
d’équations non linéaires, où elle permet de garantir une convergence
plus rapide que la convergence linéaire.</p>
<p>La convergence superlinéaire est indispensable dans de nombreux
domaines, notamment en optimisation numérique et en analyse numérique.
Elle permet de réduire le nombre d’itérations nécessaires pour atteindre
une précision donnée, ce qui est crucial dans les applications pratiques
où les ressources computationnelles sont limitées.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la convergence superlinéaire, commençons par rappeler
quelques notions préliminaires. Considérons une suite <span
class="math inline">\((x_n)\)</span> qui converge vers un point fixe
<span class="math inline">\(x^*\)</span>. On dit que la convergence est
<strong>linéaire</strong> si la suite des erreurs <span
class="math inline">\((e_n) = (x_n - x^*)\)</span> satisfait une
relation de la forme :</p>
<p><span class="math display">\[\lim_{n \to \infty} \frac{e_{n+1}}{e_n}
= c &lt; 1\]</span></p>
<p>où <span class="math inline">\(c\)</span> est une constante appelée
<strong>ratio de convergence</strong>.</p>
<p>Maintenant, imaginons que la suite <span
class="math inline">\((x_n)\)</span> converge vers <span
class="math inline">\(x^*\)</span> de manière plus rapide que linéaire.
Pour formaliser cette idée, introduisons la définition suivante :</p>
<div class="definition">
<p>Soit <span class="math inline">\((x_n)\)</span> une suite convergeant
vers un point fixe <span class="math inline">\(x^*\)</span>. On dit que
la convergence est <strong>superlinéaire</strong> si pour tout <span
class="math inline">\(\alpha &gt; 0\)</span>, il existe un entier <span
class="math inline">\(N\)</span> tel que pour tout <span
class="math inline">\(n \geq N\)</span>,</p>
<p><span class="math display">\[\lim_{n \to \infty}
\frac{e_{n+1}}{e_n^\alpha} = 0\]</span></p>
<p>où <span class="math inline">\(e_n = x_n - x^*\)</span>.</p>
</div>
<p>Une autre formulation équivalente est :</p>
<p><span class="math display">\[\lim_{n \to \infty} \frac{|x_{n+1} -
x^*|}{|x_n - x^*|^\alpha} = 0 \quad \forall \alpha &gt; 0\]</span></p>
<p>Cette définition capture l’idée que l’erreur diminue plus rapidement
qu’une puissance arbitraire de l’erreur précédente.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un résultat fondamental concernant la convergence superlinéaire est
le théorème suivant, dû à Kantorovich :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(F: \mathbb{R}^n \to
\mathbb{R}^n\)</span> une fonction différentiable et soit <span
class="math inline">\(x^*\)</span> un point fixe de <span
class="math inline">\(F\)</span>. Supposons que :</p>
<ul>
<li><p>La matrice jacobienne <span
class="math inline">\(J_F(x^*)\)</span> est inversible.</p></li>
<li><p>Il existe des constantes positives <span
class="math inline">\(\eta\)</span>, <span
class="math inline">\(\beta\)</span>, et <span
class="math inline">\(L\)</span> telles que : <span
class="math display">\[\|J_F(x^*)^{-1}(F&#39;(x) - F&#39;(y))\| \leq L
\|x - y\| \quad \forall x, y \in B(x^*, \eta)\]</span> <span
class="math display">\[\|J_F(x^*)^{-1}F&#39;(x^*)\| \leq \beta\]</span>
<span class="math display">\[h = \eta L \beta &lt;
\frac{1}{2}\]</span></p></li>
</ul>
<p>Alors, la méthode de Newton converge superlinéairement vers <span
class="math inline">\(x^*\)</span>.</p>
</div>
<p>Pour démontrer ce théorème, nous avons besoin de quelques lemmes
intermédiaires.</p>
<div class="lemma">
<p>Sous les hypothèses du théorème de Kantorovich, pour tout <span
class="math inline">\(x \in B(x^*, \eta)\)</span>, l’équation de Newton
<span class="math display">\[x_{n+1} = x_n -
F&#39;(x_n)^{-1}F(x_n)\]</span> a une solution unique dans <span
class="math inline">\(B(x^*, \eta)\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve repose sur l’application du théorème des
points fixes de Banach. On définit l’opérateur <span
class="math inline">\(T: B(x^*, \eta) \to \mathbb{R}^n\)</span> par
<span class="math display">\[T(x) = x - F&#39;(x^*)^{-1}F(x)\]</span> On
montre que <span class="math inline">\(T\)</span> est une contraction
sur <span class="math inline">\(B(x^*, \eta)\)</span> en utilisant les
hypothèses du théorème. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Kantorovich, nous procédons comme suit
:</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\((x_n)\)</span> la
suite définie par la méthode de Newton. Nous savons déjà que <span
class="math inline">\(x_n \in B(x^*, \eta)\)</span> pour tout <span
class="math inline">\(n\)</span> suffisamment grand.</p>
<p>Nous voulons montrer que la convergence est superlinéaire,
c’est-à-dire que pour tout <span class="math inline">\(\alpha &gt;
0\)</span>, <span class="math display">\[\lim_{n \to \infty}
\frac{\|x_{n+1} - x^*\|}{\|x_n - x^*\|^\alpha} = 0\]</span></p>
<p>Pour cela, nous utilisons l’expression de l’erreur : <span
class="math display">\[x_{n+1} - x^* = (x_n - x^*) -
F&#39;(x_n)^{-1}F(x_n)\]</span> En utilisant le développement de Taylor
de <span class="math inline">\(F\)</span> autour de <span
class="math inline">\(x^*\)</span>, nous obtenons : <span
class="math display">\[F(x_n) = F&#39;(x^*) (x_n - x^*) + \frac{1}{2}
F&#39;&#39;(x^*) (x_n - x^*, x_n - x^*) + o(\|x_n - x^*\|^2)\]</span> En
substituant cette expression dans l’équation de Newton, nous trouvons :
<span class="math display">\[x_{n+1} - x^* = -\frac{1}{2}
F&#39;(x^*)^{-1} F&#39;&#39;(x^*) (x_n - x^*, x_n - x^*) + o(\|x_n -
x^*\|^2)\]</span> En utilisant les hypothèses du théorème, nous pouvons
majorer cette expression : <span class="math display">\[\|x_{n+1} -
x^*\| \leq L \|x_n - x^*\|^2 + o(\|x_n - x^*\|^2)\]</span> En divisant
par <span class="math inline">\(\|x_n - x^*\|^\alpha\)</span> et en
faisant tendre <span class="math inline">\(n\)</span> vers l’infini,
nous obtenons : <span class="math display">\[\lim_{n \to \infty}
\frac{\|x_{n+1} - x^*\|}{\|x_n - x^*\|^\alpha} = 0\]</span> ce qui
prouve la convergence superlinéaire. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
convergence superlinéaire :</p>
<ul>
<li><p><strong>Stabilité</strong> : La convergence superlinéaire est
stable sous de petites perturbations des données initiales. Plus
précisément, si une suite <span class="math inline">\((x_n)\)</span>
converge superlinéairement vers <span
class="math inline">\(x^*\)</span>, alors toute suite <span
class="math inline">\((\tilde{x}_n)\)</span> obtenue en perturbant
légèrement les termes de <span class="math inline">\((x_n)\)</span>
converge également superlinéairement vers <span
class="math inline">\(x^*\)</span>.</p></li>
<li><p><strong>Ordre de convergence</strong> : La convergence
superlinéaire implique que l’ordre de convergence est supérieur à 1. En
d’autres termes, il existe une constante <span class="math inline">\(C
&gt; 0\)</span> et un entier <span class="math inline">\(N\)</span> tels
que pour tout <span class="math inline">\(n \geq N\)</span>, <span
class="math display">\[\|x_{n+1} - x^*\| \leq C \|x_n -
x^*\|^{p}\]</span> où <span class="math inline">\(p &gt;
1\)</span>.</p></li>
<li><p><strong>Exemples</strong> : La méthode de Newton est un exemple
classique de méthode itérative qui converge superlinéairement sous des
conditions appropriées. D’autres méthodes, telles que les méthodes de
point fixe avec des fonctions contractantes d’ordre supérieur, peuvent
également présenter une convergence superlinéaire.</p></li>
</ul>
<p>Pour démontrer la propriété (ii), nous procédons comme suit :</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\alpha &gt;
1\)</span> et soit <span class="math inline">\(p = \frac{\alpha + 1}{2}
&gt; 1\)</span>. Nous voulons montrer qu’il existe une constante <span
class="math inline">\(C &gt; 0\)</span> et un entier <span
class="math inline">\(N\)</span> tels que pour tout <span
class="math inline">\(n \geq N\)</span>, <span
class="math display">\[\|x_{n+1} - x^*\| \leq C \|x_n -
x^*\|^p\]</span></p>
<p>En utilisant la définition de la convergence superlinéaire, nous
savons que pour tout <span class="math inline">\(\epsilon &gt;
0\)</span>, il existe un entier <span class="math inline">\(N\)</span>
tel que pour tout <span class="math inline">\(n \geq N\)</span>, <span
class="math display">\[\|x_{n+1} - x^*\| \leq (\epsilon + 1) \|x_n -
x^*\|^p\]</span> En choisissant <span
class="math inline">\(\epsilon\)</span> suffisamment petit, nous pouvons
absorber la constante <span class="math inline">\((\epsilon +
1)\)</span> dans <span class="math inline">\(C\)</span>, ce qui prouve
la propriété. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La convergence superlinéaire est un concept fondamental en analyse
numérique et en optimisation. Elle permet de garantir une convergence
rapide des méthodes itératives, ce qui est crucial dans les applications
pratiques. Les théorèmes de Kantorovich et leurs corollaires fournissent
des conditions suffisantes pour la convergence superlinéaire, ainsi que
des propriétés importantes de cette convergence.</p>
<p>Les recherches futures pourraient explorer d’autres méthodes
itératives présentant une convergence superlinéaire, ainsi que des
extensions de ces résultats à des espaces de dimension infinie. La
compréhension approfondie de la convergence superlinéaire ouvre des
perspectives prometteuses pour le développement de nouvelles méthodes
numériques efficaces.</p>
</body>
</html>
{% include "footer.html" %}

