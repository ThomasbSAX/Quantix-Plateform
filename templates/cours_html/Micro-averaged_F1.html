{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Micro-averaged F1: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Micro-averaged F1: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’évaluation des performances des modèles de classification est une
tâche cruciale en apprentissage automatique. Parmi les nombreuses
métriques disponibles, la précision (precision), le rappel (recall) et
la mesure F1 sont des indicateurs clés. Cependant, lorsque l’on traite
avec des données déséquilibrées ou multi-classes, ces métriques doivent
être adaptées pour fournir une évaluation plus robuste. C’est ici que la
micro-averaged F1 entre en jeu.</p>
<p>La micro-averaged F1 est une variante de la mesure F1 qui prend en
compte les détails des classifications individuelles pour calculer une
moyenne globale. Elle est particulièrement utile dans les scénarios où
certaines classes sont sous-représentées, car elle donne à chaque
instance la même importance, indépendamment de sa classe.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la micro-averaged F1, commençons par rappeler les
définitions de base.</p>
<h2 class="unnumbered" id="précision-et-rappel">Précision et Rappel</h2>
<p>La précision d’une classe <span class="math inline">\(c\)</span> est
définie comme le rapport entre les instances correctement classées comme
appartenant à cette classe et toutes les instances classées comme
appartenant à cette classe.</p>
<div class="definition">
<p>Soit <span class="math inline">\(TP_c\)</span> le nombre de vrais
positifs pour la classe <span class="math inline">\(c\)</span>, et <span
class="math inline">\(FP_c\)</span> le nombre de faux positifs pour la
classe <span class="math inline">\(c\)</span>. La précision pour la
classe <span class="math inline">\(c\)</span> est donnée par: <span
class="math display">\[P_c = \frac{TP_c}{TP_c + FP_c}\]</span></p>
</div>
<p>Le rappel d’une classe <span class="math inline">\(c\)</span> est
défini comme le rapport entre les instances correctement classées comme
appartenant à cette classe et toutes les instances réellement
appartenant à cette classe.</p>
<div class="definition">
<p>Soit <span class="math inline">\(FN_c\)</span> le nombre de faux
négatifs pour la classe <span class="math inline">\(c\)</span>. Le
rappel pour la classe <span class="math inline">\(c\)</span> est donné
par: <span class="math display">\[R_c = \frac{TP_c}{TP_c +
FN_c}\]</span></p>
</div>
<h2 class="unnumbered" id="mesure-f1">Mesure F1</h2>
<p>La mesure F1 est la moyenne harmonique de la précision et du rappel.
Elle combine ces deux métriques en une seule valeur.</p>
<div class="definition">
<p>La mesure F1 pour la classe <span class="math inline">\(c\)</span>
est donnée par: <span class="math display">\[F1_c = 2 \cdot \frac{P_c
\cdot R_c}{P_c + R_c}\]</span></p>
</div>
<h2 class="unnumbered" id="micro-averaged-f1">Micro-averaged F1</h2>
<p>La micro-averaged F1 est une moyenne pondérée des mesures F1 de
chaque classe, où les poids sont proportionnels au nombre total
d’instances correctement et incorrectement classées.</p>
<div class="definition">
<p>Soit <span class="math inline">\(N\)</span> le nombre total de
classes, <span class="math inline">\(TP_c\)</span>, <span
class="math inline">\(FP_c\)</span>, et <span
class="math inline">\(FN_c\)</span> les vrais positifs, faux positifs et
faux négatifs pour la classe <span class="math inline">\(c\)</span>,
respectivement. La micro-averaged F1 est donnée par: <span
class="math display">\[\text{Micro-F1} = \frac{2 \cdot \sum_{c=1}^{N}
TP_c}{2 \cdot \sum_{c=1}^{N} TP_c + \sum_{c=1}^{N} FP_c + \sum_{c=1}^{N}
FN_c}\]</span></p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<h2 class="unnumbered" id="théorème-de-la-micro-averaged-f1">Théorème de
la Micro-averaged F1</h2>
<p>La micro-averaged F1 peut être interprétée comme une mesure globale
de la performance du modèle, en tenant compte de toutes les instances
classifiées.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(TP\)</span>, <span
class="math inline">\(FP\)</span>, et <span
class="math inline">\(FN\)</span> les vrais positifs, faux positifs et
faux négatifs globaux pour toutes les classes. La micro-averaged F1 est
donnée par: <span class="math display">\[\text{Micro-F1} = \frac{2 \cdot
TP}{2 \cdot TP + FP + FN}\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<h2 class="unnumbered"
id="preuve-du-théorème-de-la-micro-averaged-f1">Preuve du Théorème de la
Micro-averaged F1</h2>
<p>Pour prouver ce théorème, nous devons montrer que la micro-averaged
F1 peut être exprimée en termes des vrais positifs, faux positifs et
faux négatifs globaux.</p>
<div class="proof">
<p><em>Proof.</em> Considérons les définitions de <span
class="math inline">\(TP\)</span>, <span
class="math inline">\(FP\)</span>, et <span
class="math inline">\(FN\)</span> comme suit: <span
class="math display">\[TP = \sum_{c=1}^{N} TP_c, \quad FP =
\sum_{c=1}^{N} FP_c, \quad FN = \sum_{c=1}^{N} FN_c\]</span></p>
<p>En substituant ces définitions dans la formule de la micro-averaged
F1, nous obtenons: <span class="math display">\[\text{Micro-F1} =
\frac{2 \cdot TP}{2 \cdot TP + FP + FN}\]</span></p>
<p>Cette formule montre que la micro-averaged F1 est effectivement une
mesure globale de la performance du modèle, en tenant compte de toutes
les instances classifiées. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<h2 class="unnumbered"
id="propriété-1-symétrie-de-la-micro-averaged-f1">Propriété 1: Symétrie
de la Micro-averaged F1</h2>
<p>La micro-averaged F1 est symétrique par rapport aux classes, ce qui
signifie qu’elle traite toutes les classes de manière équitable.</p>
<div class="proposition">
<p>La micro-averaged F1 est indépendante de l’ordre des classes.</p>
</div>
<h2 class="unnumbered" id="preuve-de-la-symétrie">Preuve de la
Symétrie</h2>
<p>Pour prouver cette propriété, nous devons montrer que l’ordre des
classes n’affecte pas la valeur de la micro-averaged F1.</p>
<div class="proof">
<p><em>Proof.</em> Considérons deux classes <span
class="math inline">\(c_1\)</span> et <span
class="math inline">\(c_2\)</span>. La micro-averaged F1 pour ces
classes est donnée par: <span class="math display">\[\text{Micro-F1} =
\frac{2 \cdot (TP_{c_1} + TP_{c_2})}{2 \cdot (TP_{c_1} + TP_{c_2}) +
FP_{c_1} + FP_{c_2} + FN_{c_1} + FN_{c_2}}\]</span></p>
<p>En échangeant <span class="math inline">\(c_1\)</span> et <span
class="math inline">\(c_2\)</span>, nous obtenons la même formule, ce
qui montre que l’ordre des classes n’affecte pas la valeur de la
micro-averaged F1. ◻</p>
</div>
<h2 class="unnumbered"
id="corollaire-1-micro-averaged-f1-et-données-déséquilibrées">Corollaire
1: Micro-averaged F1 et Données Déséquilibrées</h2>
<p>La micro-averaged F1 est particulièrement utile dans les scénarios où
certaines classes sont sous-représentées.</p>
<div class="corollary">
<p>Dans les cas de données déséquilibrées, la micro-averaged F1 donne
plus d’importance aux classes minoritaires.</p>
</div>
<h2 class="unnumbered" id="preuve-du-corollaire-1">Preuve du Corollaire
1</h2>
<p>Pour prouver ce corollaire, nous devons montrer que la micro-averaged
F1 prend en compte toutes les instances classifiées, indépendamment de
leur classe.</p>
<div class="proof">
<p><em>Proof.</em> La micro-averaged F1 est calculée en tenant compte de
tous les vrais positifs, faux positifs et faux négatifs globaux. Par
conséquent, elle donne la même importance à chaque instance classifiée,
indépendamment de sa classe.</p>
<p>Cela signifie que les classes minoritaires ont un impact plus
important sur la micro-averaged F1, car elles contribuent de manière
proportionnelle à leur nombre d’instances. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La micro-averaged F1 est une métrique puissante pour évaluer les
performances des modèles de classification, en particulier dans les
scénarios où certaines classes sont sous-représentées. En prenant en
compte toutes les instances classifiées, elle fournit une évaluation
plus robuste et équitable des modèles.</p>
</body>
</html>
{% include "footer.html" %}

