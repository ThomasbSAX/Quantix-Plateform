{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Inégalité de Gibbs : Une Exploration Mathématique et Historique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Inégalité de Gibbs : Une Exploration Mathématique et
Historique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de Gibbs émerge dans le cadre de la théorie des
probabilités et de l’analyse mathématique, offrant une compréhension
profonde des propriétés des fonctions convexes. Cette inégalité doit son
nom à Josiah Willard Gibbs, un physicien et mathématicien américain du
XIXe siècle, dont les travaux ont jeté les bases de la mécanique
statistique. L’inégalité de Gibbs est indispensable dans l’étude des
systèmes thermodynamiques et des processus stochastiques, où elle permet
de quantifier les écarts entre différentes distributions de
probabilité.</p>
<p>L’origine historique de cette inégalité remonte aux travaux de Gibbs
sur l’entropie et les propriétés des systèmes en équilibre.
Conceptuellement, elle résout des problèmes liés à la mesure de
l’incertitude et à la comparaison des distributions de probabilité.
L’inégalité de Gibbs est indispensable dans divers domaines, notamment
la physique statistique, l’information théorie et les sciences des
données.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’inégalité de Gibbs, il est essentiel de définir
quelques concepts préalables. Considérons une fonction convexe <span
class="math inline">\(\phi : \mathbb{R}^n \rightarrow
\mathbb{R}\)</span>. Une fonction convexe satisfait la propriété
suivante pour tout <span class="math inline">\(x, y \in
\mathbb{R}^n\)</span> et tout <span class="math inline">\(\lambda \in
[0, 1]\)</span>:</p>
<p><span class="math display">\[\phi(\lambda x + (1 - \lambda) y) \leq
\lambda \phi(x) + (1 - \lambda) \phi(y)\]</span></p>
<p>Cette propriété est fondamentale pour l’inégalité de Gibbs.
Maintenant, définissons formellement l’inégalité de Gibbs.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\phi : \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction convexe et différentiable. Pour tout
<span class="math inline">\(x, y \in \mathbb{R}^n\)</span>, l’inégalité
de Gibbs s’énonce comme suit:</p>
<p><span class="math display">\[\phi(y) - \phi(x) \geq \nabla \phi(x)
\cdot (y - x)\]</span></p>
<p>où <span class="math inline">\(\nabla \phi(x)\)</span> désigne le
gradient de <span class="math inline">\(\phi\)</span> en <span
class="math inline">\(x\)</span>.</p>
</div>
<p>Une autre formulation de l’inégalité de Gibbs est donnée par:</p>
<p><span class="math display">\[\phi(y) \geq \phi(x) + \nabla \phi(x)
\cdot (y - x)\]</span></p>
<p>Cette inégalité montre que la fonction <span
class="math inline">\(\phi\)</span> est minorée par son plan tangent en
tout point <span class="math inline">\(x\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>L’inégalité de Gibbs est étroitement liée à plusieurs théorèmes
importants en analyse convexe. Un théorème fondamental est le théorème
de Jensen, qui généralise l’inégalité de Gibbs pour les fonctions
convexes.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\phi : \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> une fonction convexe et <span
class="math inline">\(X\)</span> une variable aléatoire à valeurs dans
<span class="math inline">\(\mathbb{R}^n\)</span>. Alors, pour toute
distribution de probabilité <span class="math inline">\(P\)</span> de
<span class="math inline">\(X\)</span>, on a:</p>
<p><span class="math display">\[\phi(\mathbb{E}[X]) \leq
\mathbb{E}[\phi(X)]\]</span></p>
<p>où <span class="math inline">\(\mathbb{E}[X]\)</span> désigne
l’espérance de <span class="math inline">\(X\)</span>.</p>
</div>
<p>La preuve du théorème de Jensen repose sur l’inégalité de Gibbs. En
effet, en appliquant l’inégalité de Gibbs à la fonction <span
class="math inline">\(\phi\)</span> et en prenant l’espérance, on
obtient le résultat désiré.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour démontrer l’inégalité de Gibbs, nous allons utiliser la
définition du gradient et la propriété de convexité.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\phi : \mathbb{R}^n
\rightarrow \mathbb{R}\)</span> une fonction convexe et différentiable.
Pour tout <span class="math inline">\(x, y \in \mathbb{R}^n\)</span>,
nous avons:</p>
<p><span class="math display">\[\phi(y) - \phi(x) = \int_{0}^{1} \nabla
\phi(x + t(y - x)) \cdot (y - x) \, dt\]</span></p>
<p>En utilisant la convexité de <span
class="math inline">\(\phi\)</span>, nous savons que le gradient <span
class="math inline">\(\nabla \phi\)</span> est croissant. Par
conséquent, pour tout <span class="math inline">\(t \in [0, 1]\)</span>,
nous avons:</p>
<p><span class="math display">\[\nabla \phi(x + t(y - x)) \cdot (y - x)
\geq \nabla \phi(x) \cdot (y - x)\]</span></p>
<p>En intégrant cette inégalité sur <span class="math inline">\(t \in
[0, 1]\)</span>, nous obtenons:</p>
<p><span class="math display">\[\phi(y) - \phi(x) \geq \nabla \phi(x)
\cdot (y - x)\]</span></p>
<p>Ce qui achève la démonstration de l’inégalité de Gibbs. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Gibbs possède plusieurs propriétés intéressantes et
corollaires. En voici quelques-uns:</p>
<ol>
<li><p><strong>Propriété de Minoration</strong>: L’inégalité de Gibbs
montre que la fonction <span class="math inline">\(\phi\)</span> est
minorée par son plan tangent en tout point <span
class="math inline">\(x\)</span>. Cette propriété est fondamentale pour
l’étude des fonctions convexes.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\phi : \mathbb{R}^n
\rightarrow \mathbb{R}\)</span> une fonction convexe et différentiable.
Pour tout <span class="math inline">\(x, y \in \mathbb{R}^n\)</span>,
nous avons:</p>
<p><span class="math display">\[\phi(y) \geq \phi(x) + \nabla \phi(x)
\cdot (y - x)\]</span></p>
<p>Cette inégalité montre que le plan tangent à <span
class="math inline">\(\phi\)</span> en <span
class="math inline">\(x\)</span> minorise la fonction <span
class="math inline">\(\phi\)</span>. ◻</p>
</div></li>
<li><p><strong>Corollaire de Jensen</strong>: Le théorème de Jensen est
un corollaire direct de l’inégalité de Gibbs. Il généralise cette
inégalité pour les fonctions convexes et les variables aléatoires.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\phi : \mathbb{R}^n
\rightarrow \mathbb{R}\)</span> une fonction convexe et <span
class="math inline">\(X\)</span> une variable aléatoire à valeurs dans
<span class="math inline">\(\mathbb{R}^n\)</span>. En appliquant
l’inégalité de Gibbs à la fonction <span
class="math inline">\(\phi\)</span> et en prenant l’espérance, nous
obtenons:</p>
<p><span class="math display">\[\phi(\mathbb{E}[X]) \leq
\mathbb{E}[\phi(X)]\]</span></p>
<p>Ce qui achève la démonstration du théorème de Jensen. ◻</p>
</div></li>
<li><p><strong>Propriété de Lissage</strong>: L’inégalité de Gibbs peut
être utilisée pour montrer que les fonctions convexes sont lisses. Plus
précisément, elle implique que le gradient d’une fonction convexe est
Lipschitz continu.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\phi : \mathbb{R}^n
\rightarrow \mathbb{R}\)</span> une fonction convexe et différentiable.
Pour tout <span class="math inline">\(x, y \in \mathbb{R}^n\)</span>,
nous avons:</p>
<p><span class="math display">\[\|\nabla \phi(y) - \nabla \phi(x)\| \leq
L \|y - x\|\]</span></p>
<p>où <span class="math inline">\(L\)</span> est une constante positive.
Cette inégalité montre que le gradient de <span
class="math inline">\(\phi\)</span> est Lipschitz continu. ◻</p>
</div></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’inégalité de Gibbs est un outil fondamental en analyse convexe et
en théorie des probabilités. Elle trouve des applications dans divers
domaines, notamment la physique statistique, l’information théorie et
les sciences des données. Les propriétés et corollaires de cette
inégalité offrent une compréhension profonde des fonctions convexes et
de leurs applications. En conclusion, l’inégalité de Gibbs reste un
sujet d’étude passionnant et essentiel pour les mathématiciens et les
chercheurs en sciences appliquées.</p>
</body>
</html>
{% include "footer.html" %}

