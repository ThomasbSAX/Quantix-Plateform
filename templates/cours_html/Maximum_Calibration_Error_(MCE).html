{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Maximum Calibration Error (MCE)</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Maximum Calibration Error (MCE)</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’erreur de calibration maximale, ou <em>Maximum Calibration
Error</em> (MCE), est une mesure cruciale dans le domaine de
l’apprentissage automatique et des modèles probabilistes. Elle émerge
comme une réponse à la nécessité de quantifier la fiabilité d’un modèle
prédictif, en particulier lorsqu’il s’agit de modèles produisant des
probabilités. La calibration est un concept fondamental qui garantit que
les probabilités prédites par un modèle reflètent fidèlement la réalité.
Par exemple, si un modèle prédit qu’un événement aura une probabilité de
80% d’occurrence, cet événement devrait effectivement se produire
environ 80% du temps.</p>
<p>Le MCE est indispensable dans des domaines où les décisions sont
prises sur la base de probabilités prédites, tels que la médecine, la
finance ou les systèmes autonomes. Une mauvaise calibration peut
entraîner des décisions erronées et coûteuses. Par conséquent, le MCE
offre un cadre rigoureux pour évaluer et améliorer la calibration des
modèles.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre le MCE, commençons par définir ce que nous cherchons
à mesurer. Supposons que nous ayons un modèle qui prédit des
probabilités pour une classe donnée. Nous voulons évaluer si ces
probabilités sont bien calibrées, c’est-à-dire si elles correspondent
aux fréquences observées.</p>
<p>Formellement, soit <span class="math inline">\(\mathcal{D} = \{ (x_i,
y_i) \}_{i=1}^n\)</span> un ensemble de données d’entraînement, où <span
class="math inline">\(x_i\)</span> représente les caractéristiques et
<span class="math inline">\(y_i\)</span> la classe binaire (0 ou 1).
Soit <span class="math inline">\(f(x) = p\)</span> la probabilité
prédite par le modèle pour que <span class="math inline">\(y_i =
1\)</span>.</p>
<p>Nous divisons les prédictions en <span
class="math inline">\(K\)</span> intervalles, ou bins, <span
class="math inline">\(B_1, B_2, \ldots, B_K\)</span>, où chaque bin
<span class="math inline">\(B_k\)</span> correspond à un intervalle de
probabilités prédites. Par exemple, <span
class="math inline">\(B_1\)</span> pourrait correspondre aux prédictions
entre 0 et 0.1, <span class="math inline">\(B_2\)</span> entre 0.1 et
0.2, et ainsi de suite.</p>
<p>Pour chaque bin <span class="math inline">\(B_k\)</span>, nous
calculons la fréquence empirique des événements positifs : <span
class="math display">\[\text{acc}(B_k) = \frac{\sum_{i: f(x_i) \in B_k}
y_i}{\sum_{i: f(x_i) \in B_k} 1}\]</span> Cette fréquence représente la
proportion d’événements positifs observés dans le bin <span
class="math inline">\(B_k\)</span>.</p>
<p>La calibration absolue est atteinte si, pour chaque bin <span
class="math inline">\(B_k\)</span>, la fréquence empirique <span
class="math inline">\(\text{acc}(B_k)\)</span> est égale à la
probabilité moyenne prédite dans ce bin : <span
class="math display">\[\text{acc}(B_k) = \frac{\sum_{i: f(x_i) \in B_k}
f(x_i)}{\sum_{i: f(x_i) \in B_k} 1}\]</span></p>
<p>Le MCE mesure l’écart maximal entre la fréquence empirique et la
probabilité moyenne prédite sur tous les bins : <span
class="math display">\[\text{MCE} = \max_{k=1,\ldots,K} \left|
\text{acc}(B_k) - \frac{\sum_{i: f(x_i) \in B_k} f(x_i)}{\sum_{i: f(x_i)
\in B_k} 1} \right|\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Pour mieux comprendre le MCE, considérons quelques théorèmes et
propriétés associés.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(f\)</span> un modèle prédictif et
<span class="math inline">\(B_k\)</span> un bin de probabilités. Si le
modèle est parfaitement calibré, alors pour tout <span
class="math inline">\(k\)</span>, nous avons : <span
class="math display">\[\text{acc}(B_k) = \frac{\sum_{i: f(x_i) \in B_k}
f(x_i)}{\sum_{i: f(x_i) \in B_k} 1}\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve de ce théorème découle directement de la
définition de la calibration. Si le modèle est parfaitement calibré, les
probabilités prédites correspondent exactement aux fréquences observées
dans chaque bin. Par conséquent, l’égalité est vérifiée pour tout <span
class="math inline">\(k\)</span>. ◻</p>
</div>
<div class="theorem">
<p>Soit <span class="math inline">\(f\)</span> un modèle prédictif et
<span class="math inline">\(K\)</span> le nombre de bins. Le MCE est
borné par : <span class="math display">\[0 \leq \text{MCE} \leq
1\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La borne inférieure est triviale, car l’erreur ne
peut pas être négative. Pour la borne supérieure, notons que les
probabilités prédites sont comprises entre 0 et 1. Par conséquent,
l’écart maximal entre la fréquence empirique et la probabilité moyenne
prédite ne peut pas dépasser 1. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour illustrer les preuves, considérons un exemple simple.</p>
<div class="example">
<p>Supposons que nous ayons un modèle qui prédit des probabilités pour
trois bins : <span class="math inline">\(B_1 = [0, 0.5)\)</span>, <span
class="math inline">\(B_2 = [0.5, 1)\)</span>. Supposons que les
fréquences empiriques et les probabilités moyennes prédites soient les
suivantes : <span class="math display">\[\text{acc}(B_1) = 0.4, \quad
\frac{\sum_{i: f(x_i) \in B_1} f(x_i)}{\sum_{i: f(x_i) \in B_1} 1} =
0.3\]</span> <span class="math display">\[\text{acc}(B_2) = 0.6, \quad
\frac{\sum_{i: f(x_i) \in B_2} f(x_i)}{\sum_{i: f(x_i) \in B_2} 1} =
0.7\]</span> Le MCE est alors : <span class="math display">\[\text{MCE}
= \max \left( |0.4 - 0.3|, |0.6 - 0.7| \right) = \max (0.1, 0.1) =
0.1\]</span></p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le MCE possède plusieurs propriétés intéressantes :</p>
<ol>
<li><p><strong>Invariance par Transformation</strong> : Le MCE est
invariant par transformation monotone des probabilités prédites. Cela
signifie que si nous appliquons une fonction strictement croissante
<span class="math inline">\(g\)</span> aux probabilités prédites, le MCE
reste inchangé.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(g\)</span> une
fonction strictement croissante. Les bins <span
class="math inline">\(B_k\)</span> sont simplement re-mappés par <span
class="math inline">\(g\)</span>, mais les écarts relatifs entre les
fréquences empiriques et les probabilités moyennes prédites restent les
mêmes. ◻</p>
</div></li>
<li><p><strong>Sensibilité aux Petits Échantillons</strong> : Le MCE
peut être sensible à la taille des bins. Si un bin contient peu
d’échantillons, l’estimation de la fréquence empirique peut être
bruyante.</p>
<div class="proof">
<p><em>Proof.</em> Considérons un bin <span
class="math inline">\(B_k\)</span> avec peu d’échantillons. La fréquence
empirique <span class="math inline">\(\text{acc}(B_k)\)</span> peut
varier considérablement en fonction des échantillons spécifiques inclus
dans le bin. Par conséquent, le MCE peut être surestimé ou
sous-estimé. ◻</p>
</div></li>
<li><p><strong>Relation avec d’autres Mesures de Calibration</strong> :
Le MCE est lié à d’autres mesures de calibration, telles que la Brier
Score et l’ECE (Expected Calibration Error). Cependant, le MCE met
davantage l’accent sur les écarts maximaux plutôt que sur les erreurs
moyennes.</p>
<div class="proof">
<p><em>Proof.</em> La Brier Score mesure l’erreur quadratique moyenne
entre les probabilités prédites et les événements observés. L’ECE est
une version pondérée de l’erreur de calibration moyenne sur les bins. Le
MCE, en revanche, se concentre sur l’écart maximal, offrant une
perspective différente sur la calibration. ◻</p>
</div></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Le Maximum Calibration Error (MCE) est une mesure puissante et
intuitive pour évaluer la calibration des modèles prédictifs. En se
concentrant sur l’écart maximal entre les probabilités prédites et les
fréquences observées, le MCE fournit des informations précieuses sur la
fiabilité d’un modèle. Les propriétés et théorèmes associés au MCE
offrent un cadre rigoureux pour comprendre et améliorer la calibration,
rendant cette mesure indispensable dans de nombreux domaines
appliqués.</p>
</body>
</html>
{% include "footer.html" %}

