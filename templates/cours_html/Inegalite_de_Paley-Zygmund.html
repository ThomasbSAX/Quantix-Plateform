{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Inégalité de Paley-Zygmund : Un outil fondamental en théorie des probabilités</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Inégalité de Paley-Zygmund : Un outil fondamental en
théorie des probabilités</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de Paley-Zygmund, nommée d’après les mathématiciens
Raymond Paley et Antoni Zygmund, est un résultat fondamental en théorie
des probabilités. Cette inégalité trouve son origine dans les années
1930, lorsque Paley et Zygmund ont cherché à établir des bornes
inférieures pour les moments d’une variable aléatoire. Leur travail a
été motivé par des questions en analyse harmonique et en théorie des
séries de Fourier, où ils ont cherché à comprendre le comportement des
coefficients de Fourier d’une fonction.</p>
<p>L’inégalité de Paley-Zygmund est indispensable dans le cadre de
l’étude des variables aléatoires non négatives. Elle permet d’établir
des bornes inférieures pour les moments de ces variables, ce qui est
crucial dans de nombreuses applications, notamment en théorie des
martingales et en analyse stochastique. En outre, cette inégalité est
souvent utilisée pour prouver des résultats de type "non-triviaux",
c’est-à-dire pour montrer que certaines quantités ne peuvent pas être
trop petites.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’inégalité de Paley-Zygmund, il est essentiel de
définir quelques notions préalables. Considérons une variable aléatoire
<span class="math inline">\(X\)</span> définie sur un espace probabilisé
<span class="math inline">\((\Omega, \mathcal{F}, P)\)</span>. Nous
cherchons à établir des bornes inférieures pour les moments de <span
class="math inline">\(X\)</span>, c’est-à-dire des expressions du type
<span class="math inline">\(E[X^k]\)</span> pour un certain entier <span
class="math inline">\(k \geq 1\)</span>.</p>
<p>Supposons que <span class="math inline">\(X\)</span> soit une
variable aléatoire non négative, c’est-à-dire que <span
class="math inline">\(X(\omega) \geq 0\)</span> pour tout <span
class="math inline">\(\omega \in \Omega\)</span>. Nous cherchons à
exprimer une borne inférieure pour <span
class="math inline">\(E[X^k]\)</span> en fonction de <span
class="math inline">\(E[X]\)</span> et d’une autre quantité que nous
allons définir.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
non négative définie sur un espace probabilisé <span
class="math inline">\((\Omega, \mathcal{F}, P)\)</span>. Soit <span
class="math inline">\(0 &lt; \theta &lt; 1\)</span>.</p>
<p>L’inégalité de Paley-Zygmund affirme que pour tout <span
class="math inline">\(k &gt; 0\)</span>, on a : <span
class="math display">\[E[X^k] \geq (1 - \theta)^k E[X]^k + k \theta (1 -
\theta)^{k-1} E[X^{k-1}] E[X].\]</span></p>
<p>De manière équivalente, pour tout <span class="math inline">\(k &gt;
0\)</span> et <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>,
on a : <span class="math display">\[E[X^k] \geq (1 - \theta)^k E[X]^k +
k \theta (1 - \theta)^{k-1} E[X^{k-1}] E[X].\]</span></p>
<p>En d’autres termes, pour tout <span class="math inline">\(k &gt;
0\)</span> et <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>,
on a : <span class="math display">\[E[X^k] \geq (1 - \theta)^k E[X]^k +
k \theta (1 - \theta)^{k-1} E[X^{k-1}] E[X].\]</span></p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>L’inégalité de Paley-Zygmund est souvent utilisée pour établir des
bornes inférieures pour les moments d’une variable aléatoire. Voici un
théorème qui illustre cette application.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
non négative définie sur un espace probabilisé <span
class="math inline">\((\Omega, \mathcal{F}, P)\)</span>. Soit <span
class="math inline">\(0 &lt; \theta &lt; 1\)</span>.</p>
<p>Alors, pour tout <span class="math inline">\(k &gt; 0\)</span>, on a
: <span class="math display">\[E[X^k] \geq (1 - \theta)^k E[X]^k + k
\theta (1 - \theta)^{k-1} E[X^{k-1}] E[X].\]</span></p>
<p>De manière équivalente, pour tout <span class="math inline">\(k &gt;
0\)</span> et <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>,
on a : <span class="math display">\[E[X^k] \geq (1 - \theta)^k E[X]^k +
k \theta (1 - \theta)^{k-1} E[X^{k-1}] E[X].\]</span></p>
<p>En d’autres termes, pour tout <span class="math inline">\(k &gt;
0\)</span> et <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>,
on a : <span class="math display">\[E[X^k] \geq (1 - \theta)^k E[X]^k +
k \theta (1 - \theta)^{k-1} E[X^{k-1}] E[X].\]</span></p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver l’inégalité de Paley-Zygmund, nous allons utiliser une
technique classique en théorie des probabilités : la décomposition de la
variable aléatoire en deux parties. Nous allons également utiliser
l’inégalité de Markov et l’inégalité de Jensen.</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(X\)</span> une
variable aléatoire non négative définie sur un espace probabilisé <span
class="math inline">\((\Omega, \mathcal{F}, P)\)</span>. Soit <span
class="math inline">\(0 &lt; \theta &lt; 1\)</span>.</p>
<p>Nous commençons par décomposer <span class="math inline">\(X\)</span>
en deux parties : <span class="math display">\[X = (1 - \theta) X +
\theta X.\]</span></p>
<p>En prenant l’espérance des deux côtés, nous obtenons : <span
class="math display">\[E[X] = (1 - \theta) E[X] + \theta
E[X].\]</span></p>
<p>Cette égalité est triviale, mais elle nous permet de préparer le
terrain pour l’application des inégalités de Markov et de Jensen.</p>
<p>Nous allons maintenant appliquer l’inégalité de Markov à la variable
aléatoire <span class="math inline">\((1 - \theta) X\)</span>.
L’inégalité de Markov affirme que pour toute variable aléatoire non
négative <span class="math inline">\(Y\)</span> et tout <span
class="math inline">\(a &gt; 0\)</span>, on a : <span
class="math display">\[P(Y \geq a) \leq \frac{E[Y]}{a}.\]</span></p>
<p>En prenant <span class="math inline">\(Y = (1 - \theta) X\)</span> et
<span class="math inline">\(a = (1 - \theta) E[X]\)</span>, nous
obtenons : <span class="math display">\[P((1 - \theta) X \geq (1 -
\theta) E[X]) \leq \frac{E[(1 - \theta) X]}{(1 - \theta) E[X]} =
1.\]</span></p>
<p>Cette inégalité est également triviale, mais elle nous permet de
préparer l’application de l’inégalité de Jensen.</p>
<p>Nous allons maintenant appliquer l’inégalité de Jensen à la fonction
convexe <span class="math inline">\(f(x) = x^k\)</span>. L’inégalité de
Jensen affirme que pour toute fonction convexe <span
class="math inline">\(f\)</span> et toute variable aléatoire <span
class="math inline">\(Y\)</span>, on a : <span
class="math display">\[f(E[Y]) \leq E[f(Y)].\]</span></p>
<p>En prenant <span class="math inline">\(Y = (1 - \theta) X\)</span>,
nous obtenons : <span class="math display">\[f(E[(1 - \theta) X]) \leq
E[f((1 - \theta) X)].\]</span></p>
<p>En développant <span class="math inline">\(f\)</span>, nous obtenons
: <span class="math display">\[(1 - \theta)^k E[X]^k \leq (1 - \theta)^k
E[X^k].\]</span></p>
<p>Cette inégalité est la première partie de l’inégalité de
Paley-Zygmund.</p>
<p>Pour obtenir la deuxième partie, nous allons appliquer l’inégalité de
Markov à la variable aléatoire <span class="math inline">\(\theta
X\)</span>. En prenant <span class="math inline">\(Y = \theta X\)</span>
et <span class="math inline">\(a = \theta E[X]\)</span>, nous obtenons :
<span class="math display">\[P(\theta X \geq \theta E[X]) \leq
\frac{E[\theta X]}{\theta E[X]} = 1.\]</span></p>
<p>En appliquant l’inégalité de Jensen à la fonction convexe <span
class="math inline">\(f(x) = x^{k-1}\)</span>, nous obtenons : <span
class="math display">\[f(E[\theta X]) \leq E[f(\theta X)].\]</span></p>
<p>En développant <span class="math inline">\(f\)</span>, nous obtenons
: <span class="math display">\[\theta^{k-1} E[X]^{k-1} \leq \theta^{k-1}
E[X^{k-1}].\]</span></p>
<p>En multipliant par <span class="math inline">\(\theta E[X]\)</span>,
nous obtenons : <span class="math display">\[\theta^k E[X]^k \leq
\theta^k E[X^{k-1}] E[X].\]</span></p>
<p>En combinant cette inégalité avec la première partie, nous obtenons
l’inégalité de Paley-Zygmund : <span class="math display">\[E[X^k] \geq
(1 - \theta)^k E[X]^k + k \theta (1 - \theta)^{k-1} E[X^{k-1}]
E[X].\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Paley-Zygmund possède plusieurs propriétés
intéressantes. Nous allons en énumérer quelques-unes et les
démontrer.</p>
<div class="corollaire">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
non négative définie sur un espace probabilisé <span
class="math inline">\((\Omega, \mathcal{F}, P)\)</span>. Soit <span
class="math inline">\(0 &lt; \theta &lt; 1\)</span>.</p>
<p>Alors, pour tout <span class="math inline">\(k &gt; 0\)</span>, on a
les propriétés suivantes :</p>
<p>(i) Si <span class="math inline">\(E[X] = 0\)</span>, alors <span
class="math inline">\(E[X^k] = 0\)</span>.</p>
<p>(ii) Si <span class="math inline">\(E[X^{k-1}] = 0\)</span>, alors
<span class="math inline">\(E[X^k] \geq (1 - \theta)^k
E[X]^k\)</span>.</p>
<p>(iii) Si <span class="math inline">\(E[X] = 0\)</span> et <span
class="math inline">\(E[X^{k-1}] = 0\)</span>, alors <span
class="math inline">\(E[X^k] = 0\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> (i) Si <span class="math inline">\(E[X] = 0\)</span>,
alors l’inégalité de Paley-Zygmund devient : <span
class="math display">\[E[X^k] \geq (1 - \theta)^k 0 + k \theta (1 -
\theta)^{k-1} E[X^{k-1}] 0 = 0.\]</span></p>
<p>Ainsi, <span class="math inline">\(E[X^k] \geq 0\)</span>. Mais comme
<span class="math inline">\(X\)</span> est non négative, on a également
<span class="math inline">\(E[X^k] \geq 0\)</span>. Par conséquent,
<span class="math inline">\(E[X^k] = 0\)</span>.</p>
<p>(ii) Si <span class="math inline">\(E[X^{k-1}] = 0\)</span>, alors
l’inégalité de Paley-Zygmund devient : <span
class="math display">\[E[X^k] \geq (1 - \theta)^k E[X]^k + k \theta (1 -
\theta)^{k-1} 0 E[X] = (1 - \theta)^k E[X]^k.\]</span></p>
<p>Ainsi, <span class="math inline">\(E[X^k] \geq (1 - \theta)^k
E[X]^k\)</span>.</p>
<p>(iii) Si <span class="math inline">\(E[X] = 0\)</span> et <span
class="math inline">\(E[X^{k-1}] = 0\)</span>, alors les deux parties de
l’inégalité de Paley-Zygmund sont nulles. Par conséquent, <span
class="math inline">\(E[X^k] = 0\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’inégalité de Paley-Zygmund est un outil fondamental en théorie des
probabilités. Elle permet d’établir des bornes inférieures pour les
moments d’une variable aléatoire non négative. Cette inégalité trouve
ses applications dans de nombreux domaines, notamment en analyse
stochastique et en théorie des martingales. Nous avons présenté dans cet
article une preuve détaillée de cette inégalité ainsi que quelques-unes
de ses propriétés.</p>
</body>
</html>
{% include "footer.html" %}

