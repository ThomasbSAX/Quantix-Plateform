{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Distance de Cosinus : Une Mesure Fondamentale en Algèbre Linéaire et Apprentissage Automatique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Distance de Cosinus : Une Mesure Fondamentale en
Algèbre Linéaire et Apprentissage Automatique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’algèbre linéaire, en tant que pilier des mathématiques modernes,
offre une multitude d’outils pour quantifier les relations entre
vecteurs. Parmi ces outils, la distance de cosinus émerge comme une
mesure fondamentale, particulièrement adaptée aux espaces vectoriels de
grande dimension. Son origine remonte aux travaux pionniers sur les
produits scalaires et les angles entre vecteurs, mais son importance a
été amplifiée par l’essor de l’apprentissage automatique et du
traitement du langage naturel.</p>
<p>La distance de cosinus résout un problème crucial : comment comparer
des vecteurs indépendamment de leur magnitude ? Dans des domaines comme
la récupération d’information ou l’analyse de texte, où les vecteurs
représentent souvent des documents ou des mots, la longueur des vecteurs
peut varier considérablement en fonction de facteurs externes. La
distance de cosinus, en se concentrant uniquement sur l’angle entre les
vecteurs, offre une mesure robuste et intuitive de leur similarité.</p>
<p>Cette notion est indispensable dans des cadres où la normalisation
des vecteurs n’est pas possible ou souhaitable. Elle permet de capturer
la structure géométrique sous-jacente des données, révélant ainsi des
patterns et des corrélations qui seraient autrement obscurcis par les
variations de magnitude.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la distance de cosinus, considérons deux vecteurs
<span class="math inline">\(\mathbf{u}\)</span> et <span
class="math inline">\(\mathbf{v}\)</span> dans un espace euclidien. Nous
cherchons une mesure qui reflète l’angle entre ces vecteurs,
indépendamment de leur longueur. Imaginez deux flèches pointant dans des
directions légèrement différentes : nous voulons quantifier cette
différence directionnelle, sans tenir compte de la longueur des
flèches.</p>
<p>La distance de cosinus est définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(\mathbf{u}, \mathbf{v} \in
\mathbb{R}^n\)</span> deux vecteurs non nuls. La distance de cosinus
entre <span class="math inline">\(\mathbf{u}\)</span> et <span
class="math inline">\(\mathbf{v}\)</span> est donnée par : <span
class="math display">\[\cos(\theta) = \frac{\mathbf{u} \cdot
\mathbf{v}}{\|\mathbf{u}\| \|\mathbf{v}\|}\]</span> où <span
class="math inline">\(\theta\)</span> est l’angle entre <span
class="math inline">\(\mathbf{u}\)</span> et <span
class="math inline">\(\mathbf{v}\)</span>, <span
class="math inline">\(\mathbf{u} \cdot \mathbf{v}\)</span> est le
produit scalaire de <span class="math inline">\(\mathbf{u}\)</span> et
<span class="math inline">\(\mathbf{v}\)</span>, et <span
class="math inline">\(\|\mathbf{u}\|\)</span>, <span
class="math inline">\(\|\mathbf{v}\|\)</span> sont les normes
euclidiennes des vecteurs <span
class="math inline">\(\mathbf{u}\)</span> et <span
class="math inline">\(\mathbf{v}\)</span>, respectivement.</p>
</div>
<p>Une autre formulation, souvent utilisée en pratique, est la distance
de cosinus normalisée :</p>
<p><span class="math display">\[d(\mathbf{u}, \mathbf{v}) = 1 -
\cos(\theta) = 1 - \frac{\mathbf{u} \cdot \mathbf{v}}{\|\mathbf{u}\|
\|\mathbf{v}\|}\]</span></p>
<p>Cette formulation transforme la similarité cosinus en une distance
métrique, où <span class="math inline">\(d(\mathbf{u}, \mathbf{v}) \in
[0, 2]\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la distance de cosinus est le théorème
de Cauchy-Schwarz, qui fournit une borne supérieure pour le produit
scalaire.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(\mathbf{u}, \mathbf{v} \in
\mathbb{R}^n\)</span> deux vecteurs. Alors, le produit scalaire
satisfait l’inégalité suivante : <span
class="math display">\[|\mathbf{u} \cdot \mathbf{v}| \leq \|\mathbf{u}\|
\|\mathbf{v}\|\]</span> De plus, l’égalité a lieu si et seulement si
<span class="math inline">\(\mathbf{u}\)</span> et <span
class="math inline">\(\mathbf{v}\)</span> sont linéairement
dépendants.</p>
</div>
<p>Ce théorème est crucial pour comprendre les propriétés de la distance
de cosinus, car il garantit que le dénominateur dans la formule de la
distance de cosinus n’est jamais nul pour des vecteurs non nuls.</p>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Cauchy-Schwarz, nous procédons comme suit
:</p>
<div class="proof">
<p><em>Proof.</em> Considérons le vecteur <span
class="math inline">\(\mathbf{w} = \mathbf{u} - \lambda
\mathbf{v}\)</span> pour un certain scalaire <span
class="math inline">\(\lambda\)</span>. La norme de ce vecteur est
toujours non négative : <span class="math display">\[\|\mathbf{w}\|^2
\geq 0\]</span> En développant cette expression, nous obtenons : <span
class="math display">\[\mathbf{u} \cdot \mathbf{u} - 2\lambda
(\mathbf{u} \cdot \mathbf{v}) + \lambda^2 (\mathbf{v} \cdot \mathbf{v})
\geq 0\]</span> Cette inégalité est un polynôme quadratique en <span
class="math inline">\(\lambda\)</span>. Pour qu’il soit toujours non
négatif, son discriminant doit être non positif : <span
class="math display">\[(2(\mathbf{u} \cdot \mathbf{v}))^2 - 4
(\mathbf{u} \cdot \mathbf{u})(\mathbf{v} \cdot \mathbf{v}) \leq
0\]</span> En simplifiant, nous obtenons : <span
class="math display">\[(\mathbf{u} \cdot \mathbf{v})^2 \leq (\mathbf{u}
\cdot \mathbf{u})(\mathbf{v} \cdot \mathbf{v})\]</span> En prenant la
racine carrée des deux côtés, nous arrivons à l’inégalité de
Cauchy-Schwarz : <span class="math display">\[|\mathbf{u} \cdot
\mathbf{v}| \leq \|\mathbf{u}\| \|\mathbf{v}\|\]</span> L’égalité a lieu
lorsque le vecteur <span class="math inline">\(\mathbf{w}\)</span> est
nul, c’est-à-dire lorsque <span
class="math inline">\(\mathbf{u}\)</span> et <span
class="math inline">\(\mathbf{v}\)</span> sont linéairement
dépendants. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La distance de cosinus possède plusieurs propriétés intéressantes,
que nous énumérons et démontrons ci-dessous :</p>
<ol>
<li><p>La distance de cosinus est invariante par scaling des vecteurs.
Si <span class="math inline">\(\mathbf{u}&#39; = \alpha
\mathbf{u}\)</span> et <span class="math inline">\(\mathbf{v}&#39; =
\beta \mathbf{v}\)</span> pour des scalaires non nuls <span
class="math inline">\(\alpha, \beta\)</span>, alors : <span
class="math display">\[d(\mathbf{u}&#39;, \mathbf{v}&#39;) =
d(\mathbf{u}, \mathbf{v})\]</span></p>
<div class="proof">
<p><em>Proof.</em> En effet, nous avons : <span
class="math display">\[d(\mathbf{u}&#39;, \mathbf{v}&#39;) = 1 -
\frac{\alpha^2 (\mathbf{u} \cdot \mathbf{v})}{\alpha \|\mathbf{u}\|
\beta \|\mathbf{v}\|} = 1 - \frac{\alpha (\mathbf{u} \cdot
\mathbf{v})}{\|\mathbf{u}\| \|\mathbf{v}\|} = d(\mathbf{u},
\mathbf{v})\]</span> ◻</p>
</div></li>
<li><p>La distance de cosinus est symétrique : <span
class="math display">\[d(\mathbf{u}, \mathbf{v}) = d(\mathbf{v},
\mathbf{u})\]</span></p>
<div class="proof">
<p><em>Proof.</em> Cela découle directement de la symétrie du produit
scalaire : <span class="math display">\[d(\mathbf{u}, \mathbf{v}) = 1 -
\frac{\mathbf{u} \cdot \mathbf{v}}{\|\mathbf{u}\| \|\mathbf{v}\|} = 1 -
\frac{\mathbf{v} \cdot \mathbf{u}}{\|\mathbf{v}\| \|\mathbf{u}\|} =
d(\mathbf{v}, \mathbf{u})\]</span> ◻</p>
</div></li>
<li><p>La distance de cosinus satisfait l’inégalité triangulaire : <span
class="math display">\[d(\mathbf{u}, \mathbf{v}) \leq d(\mathbf{u},
\mathbf{w}) + d(\mathbf{w}, \mathbf{v})\]</span> pour tout vecteur <span
class="math inline">\(\mathbf{w} \in \mathbb{R}^n\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Cette propriété est plus subtile et nécessite une
analyse approfondie des angles entre les vecteurs. Elle découle du fait
que la distance de cosinus est une métrique pseudo-ultra, bien qu’elle
ne satisfasse pas toujours l’inégalité triangulaire stricte. ◻</p>
</div></li>
</ol>
<p>En conclusion, la distance de cosinus est un outil puissant et
polyvalent pour comparer des vecteurs dans des espaces de grande
dimension. Ses propriétés mathématiques robustes et son interprétation
géométrique en font un choix privilégié dans de nombreuses applications
pratiques, notamment en apprentissage automatique et en traitement du
langage naturel.</p>
</body>
</html>
{% include "footer.html" %}

