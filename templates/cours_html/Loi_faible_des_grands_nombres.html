{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Loi faible des grands nombres</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Loi faible des grands nombres</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La loi faible des grands nombres (LWGN) est un pilier fondamental de
la théorie des probabilités, illustrant le comportement asymptotique des
moyennes empiriques. Historiquement, elle émerge des travaux de Jacob
Bernoulli au début du XVIIIe siècle, qui cherchait à formaliser le
concept intuitif selon lequel la moyenne d’un grand nombre de
répétitions indépendantes d’une expérience aléatoire converge vers sa
valeur attendue.</p>
<p>La LWGN est indispensable dans de nombreux domaines, notamment en
statistique, où elle justifie la validité des estimations par la méthode
des moments. Elle répond à une question centrale : sous quelles
conditions peut-on garantir que la moyenne empirique d’une suite de
variables aléatoires converge vers leur espérance commune ? La réponse à
cette question est cruciale pour comprendre la stabilité des processus
stochastiques et pour fonder rigoureusement les méthodes
statistiques.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la loi faible des grands nombres, considérons une
suite de variables aléatoires indépendantes et identiquement distribuées
(i.i.d.) <span class="math inline">\(X_1, X_2, \ldots\)</span> avec une
espérance commune <span class="math inline">\(\mu =
\mathbb{E}[X_i]\)</span>. On cherche à comprendre le comportement de la
moyenne empirique <span class="math inline">\(S_n = \frac{1}{n}
\sum_{i=1}^n X_i\)</span> lorsque <span class="math inline">\(n\)</span>
tend vers l’infini.</p>
<p>La loi faible des grands nombres affirme que, sous certaines
conditions, la moyenne empirique converge en probabilité vers
l’espérance commune. Formellement, cela s’exprime comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
une suite de variables aléatoires indépendantes et identiquement
distribuées, avec <span class="math inline">\(\mathbb{E}[X_i] = \mu &lt;
+\infty\)</span> pour tout <span class="math inline">\(i \in
\mathbb{N}\)</span>. Alors, la moyenne empirique <span
class="math inline">\(S_n = \frac{1}{n} \sum_{i=1}^n X_i\)</span>
converge en probabilité vers <span class="math inline">\(\mu\)</span>,
c’est-à-dire que pour tout <span class="math inline">\(\epsilon &gt;
0\)</span>, <span class="math display">\[\lim_{n \to +\infty}
\mathbb{P}\left( \left| S_n - \mu \right| \geq \epsilon \right) =
0.\]</span></p>
</div>
<p>Une autre formulation équivalente de la LWGN utilise la notion de
convergence en loi :</p>
<div class="definition">
<p>La suite <span class="math inline">\((S_n)_{n \in
\mathbb{N}}\)</span> converge en loi vers <span
class="math inline">\(\mu\)</span> si, pour toute fonction continue
bornée <span class="math inline">\(f : \mathbb{R} \to
\mathbb{R}\)</span>, <span class="math display">\[\lim_{n \to +\infty}
\mathbb{E}[f(S_n)] = f(\mu).\]</span></p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Pour établir la loi faible des grands nombres, nous avons besoin de
quelques résultats préliminaires. Le premier théorème que nous
présentons est le théorème de Borel-Cantelli, qui joue un rôle clé dans
la démonstration.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((A_n)_{n \in \mathbb{N}}\)</span>
une suite d’événements. Si <span
class="math inline">\(\sum_{n=1}^{+\infty} \mathbb{P}(A_n) &lt;
+\infty\)</span>, alors <span class="math display">\[\mathbb{P}\left(
\limsup_{n \to +\infty} A_n \right) = 0.\]</span></p>
</div>
<p>Le théorème de Borel-Cantelli est utilisé pour montrer que la
probabilité que la moyenne empirique s’éloigne de l’espérance tend vers
zéro. Voici une formulation du théorème de la loi faible des grands
nombres pour les variables aléatoires i.i.d. :</p>
<div class="theorem">
<p>Soit <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
une suite de variables aléatoires indépendantes et identiquement
distribuées, avec <span class="math inline">\(\mathbb{E}[X_i] = \mu &lt;
+\infty\)</span> pour tout <span class="math inline">\(i \in
\mathbb{N}\)</span>. Alors, la moyenne empirique <span
class="math inline">\(S_n = \frac{1}{n} \sum_{i=1}^n X_i\)</span>
converge en probabilité vers <span class="math inline">\(\mu\)</span>,
c’est-à-dire que pour tout <span class="math inline">\(\epsilon &gt;
0\)</span>, <span class="math display">\[\lim_{n \to +\infty}
\mathbb{P}\left( \left| S_n - \mu \right| \geq \epsilon \right) =
0.\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer la loi faible des grands nombres, nous utilisons le
théorème de Borel-Cantelli. Considérons une suite <span
class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> de variables
aléatoires indépendantes et identiquement distribuées, avec <span
class="math inline">\(\mathbb{E}[X_i] = \mu &lt; +\infty\)</span> pour
tout <span class="math inline">\(i \in \mathbb{N}\)</span>. Nous voulons
montrer que la moyenne empirique <span class="math inline">\(S_n =
\frac{1}{n} \sum_{i=1}^n X_i\)</span> converge en probabilité vers <span
class="math inline">\(\mu\)</span>.</p>
<p>Commençons par appliquer l’inégalité de Markov, qui affirme que pour
toute variable aléatoire <span class="math inline">\(Y\)</span> non
négative et tout <span class="math inline">\(a &gt; 0\)</span>, <span
class="math display">\[\mathbb{P}(Y \geq a) \leq
\frac{\mathbb{E}[Y]}{a}.\]</span></p>
<p>Appliquons cette inégalité à la variable aléatoire <span
class="math inline">\(Y = |S_n - \mu|^2\)</span> et choisissons <span
class="math inline">\(a = \epsilon^2\)</span>. Nous obtenons <span
class="math display">\[\mathbb{P}\left( |S_n - \mu|^2 \geq \epsilon^2
\right) \leq \frac{\mathbb{E}\left[ |S_n - \mu|^2
\right]}{\epsilon^2}.\]</span></p>
<p>Calculons maintenant <span class="math inline">\(\mathbb{E}\left[
|S_n - \mu|^2 \right]\)</span> : <span
class="math display">\[\mathbb{E}\left[ |S_n - \mu|^2 \right] =
\mathbb{E}\left[ \left( \frac{1}{n} \sum_{i=1}^n (X_i - \mu) \right)^2
\right] = \frac{1}{n^2} \sum_{i=1}^n \mathbb{E}\left[ (X_i - \mu)^2
\right] = \frac{\sigma^2}{n},\]</span> où <span
class="math inline">\(\sigma^2 = \mathbb{E}\left[ (X_1 - \mu)^2 \right]
&lt; +\infty\)</span> est la variance des <span
class="math inline">\(X_i\)</span>.</p>
<p>En substituant dans l’inégalité de Markov, nous obtenons <span
class="math display">\[\mathbb{P}\left( |S_n - \mu|^2 \geq \epsilon^2
\right) \leq \frac{\sigma^2}{n \epsilon^2}.\]</span></p>
<p>En faisant tendre <span class="math inline">\(n\)</span> vers
l’infini, nous avons <span class="math display">\[\lim_{n \to +\infty}
\mathbb{P}\left( |S_n - \mu|^2 \geq \epsilon^2 \right) = 0.\]</span></p>
<p>Par conséquent, la moyenne empirique <span
class="math inline">\(S_n\)</span> converge en probabilité vers
l’espérance commune <span class="math inline">\(\mu\)</span>.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La loi faible des grands nombres possède plusieurs propriétés
importantes, que nous énumérons ci-dessous :</p>
<ol>
<li><p>La LWGN s’applique également aux variables aléatoires
indépendantes mais non nécessairement identiquement distribuées, à
condition que leur variance soit uniformément bornée.</p></li>
<li><p>La LWGN justifie l’utilisation des moyennes empiriques comme
estimateurs consistants de l’espérance.</p></li>
<li><p>La LWGN est un résultat asymptotique et ne fournit pas de
garanties sur la vitesse de convergence.</p></li>
</ol>
<p>Pour illustrer la propriété (i), considérons une suite <span
class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> de variables
aléatoires indépendantes, avec <span
class="math inline">\(\mathbb{E}[X_i] = \mu &lt; +\infty\)</span> et
<span class="math inline">\(\text{Var}(X_i) \leq \sigma^2 &lt;
+\infty\)</span> pour tout <span class="math inline">\(i \in
\mathbb{N}\)</span>. Alors, la moyenne empirique <span
class="math inline">\(S_n = \frac{1}{n} \sum_{i=1}^n X_i\)</span>
converge en probabilité vers <span
class="math inline">\(\mu\)</span>.</p>
<p>Pour démontrer cette propriété, nous procédons de manière similaire à
la preuve précédente en utilisant l’inégalité de Markov et le fait que
la variance est uniformément bornée.</p>
<h1 id="conclusion">Conclusion</h1>
<p>La loi faible des grands nombres est un résultat fondamental en
théorie des probabilités, avec des applications dans de nombreux
domaines. Elle illustre la stabilité des processus stochastiques et
justifie l’utilisation des moyennes empiriques comme estimateurs
consistants. Les preuves de la LWGN reposent sur des outils classiques
tels que l’inégalité de Markov et le théorème de Borel-Cantelli. Les
propriétés de la LWGN enrichissent notre compréhension des phénomènes
aléatoires et ouvrent la voie à des développements plus avancés en
statistique et en probabilités.</p>
</body>
</html>
{% include "footer.html" %}

