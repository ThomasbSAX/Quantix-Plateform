{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La distance de Canberra : Une mesure métrique pour les données hétérogènes</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La distance de Canberra : Une mesure métrique pour les
données hétérogènes</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Canberra, nommée d’après la ville australienne où elle
fut développée, est une mesure métrique utilisée pour évaluer la
dissimilarité entre deux vecteurs. Elle trouve son origine dans les
travaux de statisticiens cherchant à quantifier les différences entre
des profils multidimensionnels, notamment dans le contexte de l’analyse
des données biologiques et médicales. Son émergence répond à un besoin
crucial : fournir une métrique robuste capable de capturer les
variations relatives entre des composantes hétérogènes d’un vecteur.</p>
<p>Cette mesure est particulièrement indispensable dans les domaines où
les données présentent des échelles différentes ou des ordres de
grandeur variés. Par exemple, en bioinformatique, les niveaux
d’expression génique peuvent varier sur plusieurs ordres de grandeur,
rendant les métriques classiques comme la distance euclidienne
inadaptées. La distance de Canberra, en prenant en compte les
différences relatives, offre une solution élégante à ce problème.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la distance de Canberra, commençons par considérer
deux vecteurs <span class="math inline">\(\mathbf{x} = (x_1, x_2,
\ldots, x_n)\)</span> et <span class="math inline">\(\mathbf{y} = (y_1,
y_2, \ldots, y_n)\)</span> dans un espace euclidien <span
class="math inline">\(\mathbb{R}^n\)</span>. Nous cherchons une mesure
qui capture la dissimilarité entre ces deux vecteurs, en tenant compte
des différences relatives de leurs composantes.</p>
<p>La distance de Canberra est définie comme suit :</p>
<div class="definition">
<p>Soient <span class="math inline">\(\mathbf{x}, \mathbf{y} \in
\mathbb{R}^n\)</span> deux vecteurs. La distance de Canberra entre <span
class="math inline">\(\mathbf{x}\)</span> et <span
class="math inline">\(\mathbf{y}\)</span> est donnée par : <span
class="math display">\[D_C(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^n
\frac{|x_i - y_i|}{|x_i| + |y_i|}\]</span></p>
</div>
<p>Cette définition peut être reformulée en utilisant des
quantificateurs : <span class="math display">\[\forall \mathbf{x},
\mathbf{y} \in \mathbb{R}^n, \, D_C(\mathbf{x}, \mathbf{y}) =
\sum_{i=1}^n \frac{|x_i - y_i|}{|x_i| + |y_i|}\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental concernant la distance de Canberra est
qu’elle satisfait les propriétés d’une métrique. Cela signifie qu’elle
vérifie les conditions de non-négativité, d’identité des indiscernables,
de symétrie et d’inégalité triangulaire.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(D_C\)</span> la distance de Canberra
définie sur <span class="math inline">\(\mathbb{R}^n\)</span>. Alors,
pour tous vecteurs <span class="math inline">\(\mathbf{x}, \mathbf{y},
\mathbf{z} \in \mathbb{R}^n\)</span>, les propriétés suivantes sont
satisfaites :</p>
<ol>
<li><p>Non-négativité : <span class="math inline">\(D_C(\mathbf{x},
\mathbf{y}) \geq 0\)</span></p></li>
<li><p>Identité des indiscernables : <span
class="math inline">\(D_C(\mathbf{x}, \mathbf{y}) = 0\)</span> si et
seulement si <span class="math inline">\(\mathbf{x} =
\mathbf{y}\)</span></p></li>
<li><p>Symétrie : <span class="math inline">\(D_C(\mathbf{x},
\mathbf{y}) = D_C(\mathbf{y}, \mathbf{x})\)</span></p></li>
<li><p>Inégalité triangulaire : <span
class="math inline">\(D_C(\mathbf{x}, \mathbf{z}) \leq D_C(\mathbf{x},
\mathbf{y}) + D_C(\mathbf{y}, \mathbf{z})\)</span></p></li>
</ol>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour démontrer les propriétés métriques de la distance de Canberra,
nous allons procéder étape par étape.</p>
<div class="proof">
<p><em>Preuve des propriétés métriques.</em> 1. **Non-négativité** : Par
définition, le module <span class="math inline">\(|x_i - y_i|\)</span>
est toujours non-négatif, et <span class="math inline">\(|x_i| +
|y_i|\)</span> est strictement positif pour tout <span
class="math inline">\(i\)</span>. Par conséquent, chaque terme de la
somme est non-négatif, et donc <span
class="math inline">\(D_C(\mathbf{x}, \mathbf{y}) \geq 0\)</span>.</p>
<p>2. **Identité des indiscernables** : Si <span
class="math inline">\(\mathbf{x} = \mathbf{y}\)</span>, alors <span
class="math inline">\(x_i = y_i\)</span> pour tout <span
class="math inline">\(i\)</span>, et donc <span
class="math inline">\(D_C(\mathbf{x}, \mathbf{y}) = 0\)</span>.
Réciproquement, si <span class="math inline">\(D_C(\mathbf{x},
\mathbf{y}) = 0\)</span>, alors chaque terme de la somme doit être nul,
ce qui implique <span class="math inline">\(x_i = y_i\)</span> pour tout
<span class="math inline">\(i\)</span>, et donc <span
class="math inline">\(\mathbf{x} = \mathbf{y}\)</span>.</p>
<p>3. **Symétrie** : La symétrie découle directement de la commutativité
du module et de l’addition : <span
class="math display">\[D_C(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^n
\frac{|x_i - y_i|}{|x_i| + |y_i|} = \sum_{i=1}^n \frac{|y_i -
x_i|}{|y_i| + |x_i|} = D_C(\mathbf{y}, \mathbf{x})\]</span></p>
<p>4. **Inégalité triangulaire** : Pour démontrer l’inégalité
triangulaire, nous utilisons le fait que pour tout <span
class="math inline">\(i\)</span>, <span class="math inline">\(|x_i -
z_i| \leq |x_i - y_i| + |y_i - z_i|\)</span>. En divisant par <span
class="math inline">\(|x_i| + |z_i|\)</span> et en utilisant l’inégalité
de la moyenne, nous obtenons : <span class="math display">\[\frac{|x_i -
z_i|}{|x_i| + |z_i|} \leq \frac{|x_i - y_i| + |y_i - z_i|}{|x_i| +
|z_i|} \leq \frac{|x_i - y_i|}{|x_i| + |y_i|} + \frac{|y_i - z_i|}{|y_i|
+ |z_i|}\]</span> En sommant sur <span class="math inline">\(i\)</span>,
nous obtenons l’inégalité triangulaire souhaitée : <span
class="math display">\[D_C(\mathbf{x}, \mathbf{z}) \leq D_C(\mathbf{x},
\mathbf{y}) + D_C(\mathbf{y}, \mathbf{z})\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La distance de Canberra possède plusieurs propriétés intéressantes
qui en font un outil puissant pour l’analyse des données.</p>
<div class="proposition">
<p>La distance de Canberra est invariante par translation et par
multiplication par un scalaire positif.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(\mathbf{x},
\mathbf{y} \in \mathbb{R}^n\)</span> et <span class="math inline">\(a
&gt; 0\)</span>. Alors, <span class="math display">\[D_C(a\mathbf{x} +
\mathbf{b}, a\mathbf{y} + \mathbf{b}) = \sum_{i=1}^n \frac{|a x_i + b_i
- a y_i - b_i|}{|a x_i + b_i| + |a y_i + b_i|} = \sum_{i=1}^n \frac{a
|x_i - y_i|}{a |x_i| + a |y_i|} = \sum_{i=1}^n \frac{|x_i - y_i|}{|x_i|
+ |y_i|} = D_C(\mathbf{x}, \mathbf{y})\]</span> ◻</p>
</div>
<div class="corollaire">
<p>La distance de Canberra est particulièrement adaptée pour comparer
des vecteurs dont les composantes ont des échelles différentes.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La normalisation implicite par <span
class="math inline">\(|x_i| + |y_i|\)</span> permet de prendre en compte
les différences relatives entre les composantes, ce qui rend la distance
de Canberra insensible aux variations d’échelle. ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La distance de Canberra est une mesure métrique puissante et
flexible, particulièrement adaptée pour l’analyse des données
hétérogènes. Ses propriétés métriques et son invariance par translation
et multiplication par un scalaire positif en font un outil précieux dans
de nombreux domaines, notamment la bioinformatique et l’analyse des
données médicales. En capturant les différences relatives entre les
composantes des vecteurs, elle offre une solution élégante aux défis
posés par les données à échelles variées.</p>
</body>
</html>
{% include "footer.html" %}

