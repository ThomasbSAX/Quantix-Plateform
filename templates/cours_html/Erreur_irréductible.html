{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’erreur irréductible en mesure statistique : Fondements et implications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’erreur irréductible en mesure statistique :
Fondements et implications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’erreur irréductible, concept central en théorie de la mesure
statistique, émerge des limites fondamentales imposées par les principes
d’incertitude quantique et les contraintes informationnelles. Cette
notion, formalisée initialement par Fisher dans le cadre de l’estimation
statistique, révèle les barrières inhérentes à toute tentative
d’évaluation précise des paramètres d’un système. Son importance réside
dans sa capacité à quantifier le bruit intrinsèque, indépendant de toute
imperfection technique ou méthodologique. En explorant cette notion,
nous mettons en lumière les frontières de la connaissance mesurable et
les stratégies pour les contourner.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire l’erreur irréductible, considérons un estimateur
<span class="math inline">\(\hat{\theta}\)</span> d’un paramètre inconnu
<span class="math inline">\(\theta\)</span> dans un modèle statistique.
Nous cherchons à quantifier la précision minimale que cet estimateur
peut atteindre, indépendamment des méthodes d’estimation employées.</p>
<div class="definition">
<p>Soit <span class="math inline">\((\Omega, \mathcal{F},
P_\theta)_{\theta \in \Theta}\)</span> un modèle statistique
paramétrique. L’erreur irréductible associée à l’estimation de <span
class="math inline">\(\theta\)</span> est la borne inférieure des
variances des estimateurs sans biais de <span
class="math inline">\(\theta\)</span>, notée <span
class="math inline">\(V(\hat{\theta})\)</span>.</p>
<p>Formellement, pour tout estimateur sans biais <span
class="math inline">\(\hat{\theta}\)</span> de <span
class="math inline">\(\theta\)</span>, nous avons : <span
class="math display">\[V(\hat{\theta}) \geq I(\theta)^{-1}\]</span> où
<span class="math inline">\(I(\theta)\)</span> est l’information de
Fisher, définie par : <span class="math display">\[I(\theta) =
\mathbb{E}_\theta\left[\left(\frac{\partial}{\partial\theta} \log
p(X|\theta)\right)^2\right]\]</span> avec <span
class="math inline">\(p(X|\theta)\)</span> la densité de probabilité du
modèle.</p>
</div>
<h1 id="théorèmes-fondamentaux">Théorèmes Fondamentaux</h1>
<p>Le théorème de Cramér-Rao, pilier de la théorie statistique, établit
une relation fondamentale entre l’erreur irréductible et l’information
de Fisher.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\hat{\theta}\)</span> un estimateur
sans biais de <span class="math inline">\(\theta\)</span>. Alors, pour
tout <span class="math inline">\(\theta \in \Theta\)</span>, <span
class="math display">\[\text{Var}(\hat{\theta}) \geq
I(\theta)^{-1}\]</span> où <span
class="math inline">\(\text{Var}(\hat{\theta})\)</span> désigne la
variance de l’estimateur <span
class="math inline">\(\hat{\theta}\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer le théorème de Cramér-Rao, nous utilisons l’inégalité
de Cauchy-Schwarz et les propriétés de l’information de Fisher.</p>
<div class="proof">
<p><em>Proof.</em> Considérons un estimateur sans biais <span
class="math inline">\(\hat{\theta}\)</span> de <span
class="math inline">\(\theta\)</span>. Par définition, nous avons :
<span class="math display">\[\mathbb{E}_\theta[\hat{\theta}] =
\theta\]</span></p>
<p>Calculons la covariance entre <span
class="math inline">\(\hat{\theta}\)</span> et le score de Fisher <span
class="math inline">\(S(\theta) = \frac{\partial}{\partial\theta} \log
p(X|\theta)\)</span> : <span
class="math display">\[\text{Cov}(\hat{\theta}, S(\theta)) =
\mathbb{E}_\theta[(\hat{\theta} - \theta)S(\theta)]\]</span></p>
<p>En utilisant l’inégalité de Cauchy-Schwarz, nous obtenons : <span
class="math display">\[\text{Cov}(\hat{\theta}, S(\theta))^2 \leq
\text{Var}(\hat{\theta}) \cdot
\mathbb{E}_\theta[S(\theta)^2]\]</span></p>
<p>Or, <span class="math inline">\(\mathbb{E}_\theta[S(\theta)] =
0\)</span> et <span class="math inline">\(\mathbb{E}_\theta[S(\theta)^2]
= I(\theta)\)</span>. Par conséquent, <span
class="math display">\[\text{Var}(\hat{\theta}) \geq
\frac{I(\theta)^{-1}}{\mathbb{E}_\theta[S(\theta)^2]} =
I(\theta)^{-1}\]</span></p>
<p>Ce qui achève la démonstration. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Plusieurs propriétés découlent du théorème de Cramér-Rao, offrant des
insights sur les limites de l’estimation statistique.</p>
<ol>
<li><p><strong>Attainment of the Lower Bound</strong>: L’erreur
irréductible est atteinte si et seulement si l’estimateur <span
class="math inline">\(\hat{\theta}\)</span> est de la forme : <span
class="math display">\[\hat{\theta} = \theta + c S(\theta)\]</span> pour
une constante <span class="math inline">\(c\)</span>
appropriée.</p></li>
<li><p><strong>Information Additivity</strong>: Pour des modèles
indépendants, l’information de Fisher est additive : <span
class="math display">\[I(\theta) = \sum_{i=1}^n I_i(\theta)\]</span> où
<span class="math inline">\(I_i(\theta)\)</span> est l’information de
Fisher pour le <span class="math inline">\(i\)</span>-ème
échantillon.</p></li>
<li><p><strong>Consistency</strong>: Les estimateurs atteignant l’erreur
irréductible sont consistants, c’est-à-dire que : <span
class="math display">\[\hat{\theta}_n \xrightarrow{P} \theta \quad
\text{quand} \quad n \to \infty\]</span></p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>L’erreur irréductible représente une limite fondamentale en
estimation statistique, révélant les contraintes inhérentes à la mesure
des paramètres. En comprenant et en exploitant cette notion, nous
pouvons développer des méthodes d’estimation optimales, poussant les
frontières de la précision mesurable. Les travaux futurs pourraient
explorer des extensions de cette notion dans des cadres plus généraux,
tels que les modèles non paramétriques ou les systèmes quantiques.</p>
</body>
</html>
{% include "footer.html" %}

