{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Calinski-Harabasz Index: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Calinski-Harabasz Index: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>The Calinski-Harabasz Index, often denoted as the Variance Ratio
Criterion, is a pivotal metric in cluster analysis. Emerging from the
need to objectively evaluate clustering algorithms, this index addresses
the critical challenge of determining the optimal number of clusters in
a dataset. Its inception is rooted in the works of T. Calinski and J.
Harabasz, who sought to quantify the quality of partitioning by
leveraging the ratio of between-cluster dispersion to within-cluster
dispersion.</p>
<p>The necessity for such an index arises from the subjectivity inherent
in manual cluster selection. By providing a numerical value that peaks
at the purported optimal number of clusters, the Calinski-Harabasz Index
offers a data-driven approach to clustering. This is indispensable in
fields ranging from bioinformatics to market segmentation, where the
interpretability and validity of clusters are paramount.</p>
<h1 id="definitions">Definitions</h1>
<p>To understand the Calinski-Harabasz Index, we first need to grasp the
concepts of between-cluster and within-cluster dispersion.</p>
<p>Consider a dataset <span class="math inline">\(X = \{x_1, x_2,
\ldots, x_n\}\)</span> with <span class="math inline">\(n\)</span>
observations and <span class="math inline">\(p\)</span> features. Let
<span class="math inline">\(k\)</span> be the number of clusters, and
let <span class="math inline">\(C = \{C_1, C_2, \ldots, C_k\}\)</span>
be a partition of <span class="math inline">\(X\)</span> into <span
class="math inline">\(k\)</span> clusters.</p>
<p>The within-cluster dispersion matrix <span
class="math inline">\(W_k\)</span> is defined as: <span
class="math display">\[W_k = \sum_{i=1}^{k} \sum_{x_j \in C_i} (x_j -
\mu_i)(x_j - \mu_i)^T\]</span> where <span
class="math inline">\(\mu_i\)</span> is the mean of cluster <span
class="math inline">\(C_i\)</span>.</p>
<p>The between-cluster dispersion matrix <span
class="math inline">\(B_k\)</span> is defined as: <span
class="math display">\[B_k = \sum_{i=1}^{k} n_i (\mu_i - \mu)(\mu_i -
\mu)^T\]</span> where <span class="math inline">\(n_i\)</span> is the
number of observations in cluster <span
class="math inline">\(C_i\)</span>, and <span
class="math inline">\(\mu\)</span> is the overall mean of the
dataset.</p>
<p>The Calinski-Harabasz Index <span class="math inline">\(V(k)\)</span>
for <span class="math inline">\(k\)</span> clusters is then defined as:
<span class="math display">\[V(k) =
\frac{\text{tr}(B_k)}{\text{tr}(W_k)} \cdot \frac{(n - k)}{(k -
1)}\]</span> where <span class="math inline">\(\text{tr}\)</span>
denotes the trace of a matrix.</p>
<h1 id="theorems">Theorems</h1>
<p>One of the key theorems related to the Calinski-Harabasz Index is the
following:</p>
<div class="theorem">
<p>For a given dataset <span class="math inline">\(X\)</span> and
partition <span class="math inline">\(C\)</span>, the Calinski-Harabasz
Index <span class="math inline">\(V(k)\)</span> is maximized when the
ratio of between-cluster dispersion to within-cluster dispersion is
maximized.</p>
</div>
<div class="proof">
<p><em>Proof.</em> The proof of this theorem relies on the properties of
the trace function and the dispersion matrices.</p>
<p>First, note that: <span class="math display">\[\text{tr}(B_k) =
\sum_{i=1}^{k} n_i \|\mu_i - \mu\|^2\]</span> and <span
class="math display">\[\text{tr}(W_k) = \sum_{i=1}^{k} \sum_{x_j \in
C_i} \|x_j - \mu_i\|^2\]</span></p>
<p>The Calinski-Harabasz Index can then be rewritten as: <span
class="math display">\[V(k) = \frac{\sum_{i=1}^{k} n_i \|\mu_i -
\mu\|^2}{\sum_{i=1}^{k} \sum_{x_j \in C_i} \|x_j - \mu_i\|^2} \cdot
\frac{(n - k)}{(k - 1)}\]</span></p>
<p>To maximize <span class="math inline">\(V(k)\)</span>, we need to
maximize the numerator and minimize the denominator. This corresponds to
maximizing the ratio of between-cluster dispersion to within-cluster
dispersion, which is exactly what the theorem states. ◻</p>
</div>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>The Calinski-Harabasz Index has several important properties and
corollaries:</p>
<ol>
<li><p>The index is always non-negative, i.e., <span
class="math inline">\(V(k) \geq 0\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> The trace of a matrix is always non-negative, and the
ratio <span class="math inline">\(\frac{(n - k)}{(k - 1)}\)</span> is
positive for <span class="math inline">\(k &gt; 1\)</span>. Therefore,
<span class="math inline">\(V(k) \geq 0\)</span>. ◻</p>
</div></li>
<li><p>The index is scale-invariant, meaning it remains unchanged under
linear transformations of the data.</p>
<div class="proof">
<p><em>Proof.</em> Let <span class="math inline">\(A\)</span> be a <span
class="math inline">\(p \times p\)</span> invertible matrix, and let
<span class="math inline">\(Y = XA\)</span>. The within-cluster
dispersion matrix for <span class="math inline">\(Y\)</span> is: <span
class="math display">\[W_k^Y = A^T W_k X\]</span> Similarly, the
between-cluster dispersion matrix for <span
class="math inline">\(Y\)</span> is: <span class="math display">\[B_k^Y
= A^T B_k X\]</span> The trace of a matrix product is invariant under
cyclic permutations, so: <span class="math display">\[\text{tr}(B_k^Y) =
\text{tr}(A^T B_k X) = \text{tr}(B_k X A^T) = \text{tr}(B_k)\]</span>
and <span class="math display">\[\text{tr}(W_k^Y) = \text{tr}(A^T W_k X)
= \text{tr}(W_k X A^T) = \text{tr}(W_k)\]</span> Therefore, the
Calinski-Harabasz Index remains unchanged: <span
class="math display">\[V^Y(k) =
\frac{\text{tr}(B_k^Y)}{\text{tr}(W_k^Y)} \cdot \frac{(n - k)}{(k - 1)}
= V(k)\]</span> ◻</p>
</div></li>
<li><p>The index tends to decrease as the number of clusters <span
class="math inline">\(k\)</span> increases.</p>
<div class="proof">
<p><em>Proof.</em> As <span class="math inline">\(k\)</span> increases,
the within-cluster dispersion <span class="math inline">\(W_k\)</span>
tends to decrease because the clusters become more homogeneous. However,
the between-cluster dispersion <span class="math inline">\(B_k\)</span>
also tends to decrease because the clusters become more similar. The
ratio <span
class="math inline">\(\frac{\text{tr}(B_k)}{\text{tr}(W_k)}\)</span> may
increase or decrease depending on the data. However, the factor <span
class="math inline">\(\frac{(n - k)}{(k - 1)}\)</span> decreases as
<span class="math inline">\(k\)</span> increases, which tends to
decrease the overall index. ◻</p>
</div></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>The Calinski-Harabasz Index is a powerful tool for evaluating the
quality of clustering algorithms. Its ability to objectively determine
the optimal number of clusters makes it indispensable in various fields.
By understanding its definitions, theorems, and properties, we can
better appreciate its significance and applicability in cluster
analysis.</p>
</body>
</html>
{% include "footer.html" %}

