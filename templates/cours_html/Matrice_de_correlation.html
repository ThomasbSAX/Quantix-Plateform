{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Matrice de corrélation : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Matrice de corrélation : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La matrice de corrélation émerge comme un outil fondamental en
statistique, permettant de capturer les relations linéaires entre des
variables aléatoires. Son origine remonte aux travaux pionniers de Karl
Pearson au début du XXe siècle, qui introduisit le coefficient de
corrélation pour mesurer la force et la direction d’une relation
linéaire entre deux variables. Cette notion s’est généralisée pour
englober plusieurs variables, donnant naissance à la matrice de
corrélation.</p>
<p>La nécessité d’une telle matrice découle du besoin de comprendre les
dépendances entre variables dans des contextes multidimensionnels. En
économie, par exemple, elle permet d’analyser les interactions entre
différents indicateurs financiers. En biologie, elle aide à identifier
des liens entre gènes ou protéines. Son utilisation est indispensable
dans toute analyse statistique où la compréhension des relations entre
variables est cruciale.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir la matrice de corrélation, commençons par comprendre ce
que nous cherchons à capturer. Imaginons un ensemble de variables
aléatoires. Nous voulons mesurer comment chaque paire de ces variables
varie ensemble. Si deux variables augmentent ou diminuent simultanément,
elles sont positivement corrélées. Si l’une augmente tandis que l’autre
diminue, elles sont négativement corrélées.</p>
<p>Formellement, la matrice de corrélation <span
class="math inline">\(R\)</span> d’un vecteur aléatoire <span
class="math inline">\(X = (X_1, X_2, \ldots, X_n)\)</span> est définie
comme suit :</p>
<p><span class="math display">\[R = (\rho_{ij})_{1 \leq i, j \leq
n}\]</span></p>
<p>où <span class="math inline">\(\rho_{ij}\)</span> est le coefficient
de corrélation entre <span class="math inline">\(X_i\)</span> et <span
class="math inline">\(X_j\)</span>, donné par :</p>
<p><span class="math display">\[\rho_{ij} = \frac{\text{Cov}(X_i,
X_j)}{\sqrt{\text{Var}(X_i) \text{Var}(X_j)}}\]</span></p>
<p>avec <span class="math inline">\(\text{Cov}(X_i, X_j)\)</span> la
covariance entre <span class="math inline">\(X_i\)</span> et <span
class="math inline">\(X_j\)</span>, et <span
class="math inline">\(\text{Var}(X_i)\)</span> la variance de <span
class="math inline">\(X_i\)</span>.</p>
<p>Une autre formulation équivalente est :</p>
<p><span class="math display">\[R = D_X^{-1/2} C_X
D_X^{-1/2}\]</span></p>
<p>où <span class="math inline">\(C_X\)</span> est la matrice de
covariance de <span class="math inline">\(X\)</span>, et <span
class="math inline">\(D_X\)</span> est la matrice diagonale des
variances des composantes de <span class="math inline">\(X\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Considérons maintenant quelques propriétés fondamentales de la
matrice de corrélation. Supposons que <span
class="math inline">\(X\)</span> soit un vecteur aléatoire centré de
variance finie.</p>
<h4 id="théorème-1-symétrie-et-unité">Théorème 1 : Symétrie et
Unité</h4>
<p>La matrice de corrélation <span class="math inline">\(R\)</span> est
symétrique, c’est-à-dire :</p>
<p><span class="math display">\[\forall i, j, \rho_{ij} =
\rho_{ji}\]</span></p>
<p>De plus, les éléments diagonaux de <span
class="math inline">\(R\)</span> sont tous égaux à 1 :</p>
<p><span class="math display">\[\forall i, \rho_{ii} = 1\]</span></p>
<h4 id="démonstration">Démonstration</h4>
<p>La symétrie découle directement de la définition du coefficient de
corrélation, car <span class="math inline">\(\text{Cov}(X_i, X_j) =
\text{Cov}(X_j, X_i)\)</span>. Pour les éléments diagonaux, on a <span
class="math inline">\(\text{Cov}(X_i, X_i) = \text{Var}(X_i)\)</span>,
donc :</p>
<p><span class="math display">\[\rho_{ii} =
\frac{\text{Var}(X_i)}{\sqrt{\text{Var}(X_i)^2}} = 1\]</span></p>
<h4 id="théorème-2-bornes">Théorème 2 : Bornes</h4>
<p>Les coefficients de corrélation sont bornés entre -1 et 1 :</p>
<p><span class="math display">\[\forall i, j, -1 \leq \rho_{ij} \leq
1\]</span></p>
<h4 id="démonstration-1">Démonstration</h4>
<p>Cette propriété découle de l’inégalité de Cauchy-Schwarz appliquée
aux espérances conditionnelles. En effet, pour tout <span
class="math inline">\(\lambda \in \mathbb{R}\)</span>, on a :</p>
<p><span class="math display">\[\text{Var}(X_i + \lambda X_j) \geq
0\]</span></p>
<p>Ce qui se développe en :</p>
<p><span class="math display">\[\text{Var}(X_i) + 2\lambda
\text{Cov}(X_i, X_j) + \lambda^2 \text{Var}(X_j) \geq 0\]</span></p>
<p>Cette inégalité quadratique en <span
class="math inline">\(\lambda\)</span> doit être vérifiée pour tout
<span class="math inline">\(\lambda\)</span>, ce qui implique que le
discriminant est négatif ou nul. On en déduit :</p>
<p><span class="math display">\[(2\text{Cov}(X_i, X_j))^2 -
4\text{Var}(X_i)\text{Var}(X_j) \leq 0\]</span></p>
<p>D’où :</p>
<p><span class="math display">\[\left( \frac{\text{Cov}(X_i,
X_j)}{\sqrt{\text{Var}(X_i)\text{Var}(X_j)}} \right)^2 \leq
1\]</span></p>
<h1 id="preuves">Preuves</h1>
<p>Pour illustrer la puissance de la matrice de corrélation, considérons
un exemple simple. Supposons que nous ayons deux variables aléatoires
<span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> avec les moments suivants :</p>
<p><span class="math display">\[E[X] = 0, \quad E[Y] = 0\]</span> <span
class="math display">\[\text{Var}(X) = 4, \quad \text{Var}(Y) =
9\]</span> <span class="math display">\[\text{Cov}(X, Y) =
6\]</span></p>
<p>Le coefficient de corrélation entre <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> est alors :</p>
<p><span class="math display">\[\rho_{XY} = \frac{6}{\sqrt{4 \times 9}}
= \frac{6}{6} = 1\]</span></p>
<p>Ce résultat indique une corrélation parfaite entre <span
class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>, ce qui signifie que <span
class="math inline">\(Y\)</span> peut être exprimé comme une combinaison
linéaire de <span class="math inline">\(X\)</span>. En effet, on a :</p>
<p><span class="math display">\[Y = \frac{3}{2} X\]</span></p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La matrice de corrélation possède plusieurs propriétés intéressantes,
que nous énumérons ci-dessous :</p>
<h4 id="i-invariance-par-transformation-linéaire">(i) Invariance par
transformation linéaire</h4>
<p>Si <span class="math inline">\(Y = AX + b\)</span>, où <span
class="math inline">\(A\)</span> est une matrice inversible et <span
class="math inline">\(b\)</span> un vecteur, alors la matrice de
corrélation de <span class="math inline">\(Y\)</span> est égale à celle
de <span class="math inline">\(X\)</span>.</p>
<h4 id="démonstration-2">Démonstration</h4>
<p>La matrice de covariance de <span class="math inline">\(Y\)</span>
est donnée par :</p>
<p><span class="math display">\[C_Y = A C_X A^T\]</span></p>
<p>La matrice de corrélation de <span class="math inline">\(Y\)</span>
est donc :</p>
<p><span class="math display">\[R_Y = D_Y^{-1/2} A C_X A^T
D_Y^{-1/2}\]</span></p>
<p>Or, <span class="math inline">\(D_Y = A D_X A^T\)</span>, donc :</p>
<p><span class="math display">\[R_Y = (A D_X A^T)^{-1/2} A C_X A^T (A
D_X A^T)^{-1/2}\]</span></p>
<p>En utilisant la propriété <span class="math inline">\((AB)^{-1/2} =
B^{-1/2} A^{-1}\)</span>, on obtient :</p>
<p><span class="math display">\[R_Y = D_X^{-1/2} A^T (A D_X A^T)^{-1/2}
A C_X A^T (A D_X A^T)^{-1/2} A A^{-1}\]</span></p>
<p>Après simplification, on retrouve <span
class="math inline">\(R_X\)</span>.</p>
<h4 id="ii-déterminant">(ii) Déterminant</h4>
<p>Le déterminant de la matrice de corrélation est toujours compris
entre 0 et 1.</p>
<h4 id="démonstration-3">Démonstration</h4>
<p>La matrice de corrélation est une matrice définie positive, donc son
déterminant est positif. De plus, comme chaque élément diagonal vaut 1
et les éléments hors diagonale sont bornés par -1 et 1, le déterminant
ne peut dépasser 1.</p>
<h4 id="iii-rang">(iii) Rang</h4>
<p>Le rang de la matrice de corrélation est égal au nombre de variables
linéairement indépendantes.</p>
<h4 id="démonstration-4">Démonstration</h4>
<p>Cela découle directement du fait que la matrice de corrélation est
une transformation linéaire de la matrice de covariance, qui a le même
rang que le vecteur aléatoire original.</p>
<h1 id="conclusion">Conclusion</h1>
<p>La matrice de corrélation est un outil puissant et polyvalent en
statistique, permettant de capturer les relations linéaires entre
variables. Ses propriétés fondamentales, telles que la symétrie, les
bornes des coefficients, et l’invariance par transformation linéaire, en
font un instrument indispensable dans de nombreuses applications. Les
démonstrations détaillées présentées ici illustrent la rigueur
mathématique sous-jacente à cet outil, tout en mettant en lumière son
utilité pratique.</p>
</body>
</html>
{% include "footer.html" %}

