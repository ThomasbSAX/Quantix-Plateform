{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance due à l’interaction : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance due à l’interaction : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La variance due à l’interaction est un concept fondamental en
statistique, particulièrement dans le cadre des modèles d’analyse de
variance (ANOVA). Elle émerge du besoin de comprendre comment les effets
combinés de plusieurs facteurs influencent une variable réponse, au-delà
des effets individuels de ces facteurs. Cette notion est indispensable
dans les sciences expérimentales où l’étude des interactions entre
variables permet de révéler des dynamiques complexes et souvent
contre-intuitives.</p>
<p>L’origine historique de la variance due à l’interaction remonte aux
travaux pionniers de Ronald Fisher dans les années 1920. Fisher a
introduit l’ANOVA comme un outil pour analyser les expériences
agricoles, où il était crucial de comprendre non seulement l’effet des
engrais individuels, mais aussi leur interaction. Aujourd’hui, cette
notion est omniprésente en biologie, psychologie, économie et bien
d’autres domaines.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la variance due à l’interaction, commençons par
définir les concepts de base. Supposons que nous avons deux facteurs,
disons <span class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span>, chacun avec plusieurs niveaux. L’effet
principal de chaque facteur est l’effet moyen sur la variable réponse
lorsque l’autre facteur est fixé. L’interaction, en revanche, capture
comment l’effet d’un facteur change en fonction des niveaux de l’autre
facteur.</p>
<p>Formellement, considérons un modèle linéaire généralisé où <span
class="math inline">\(Y\)</span> est la variable réponse, et <span
class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span> sont les facteurs. Le modèle peut être
écrit comme :</p>
<p><span class="math display">\[Y_{ijk} = \mu + \alpha_i + \beta_j +
(\alpha\beta)_{ij} + \epsilon_{ijk}\]</span></p>
<p>où : - <span class="math inline">\(\mu\)</span> est la moyenne
globale, - <span class="math inline">\(\alpha_i\)</span> est l’effet du
facteur <span class="math inline">\(A\)</span> au niveau <span
class="math inline">\(i\)</span>, - <span
class="math inline">\(\beta_j\)</span> est l’effet du facteur <span
class="math inline">\(B\)</span> au niveau <span
class="math inline">\(j\)</span>, - <span
class="math inline">\((\alpha\beta)_{ij}\)</span> est l’effet
d’interaction entre les niveaux <span class="math inline">\(i\)</span>
de <span class="math inline">\(A\)</span> et <span
class="math inline">\(j\)</span> de <span
class="math inline">\(B\)</span>, - <span
class="math inline">\(\epsilon_{ijk}\)</span> est l’erreur
aléatoire.</p>
<p>La variance due à l’interaction est alors définie comme la somme des
carrés des effets d’interaction, divisée par le nombre de degrés de
liberté associés à l’interaction. Mathématiquement, cela s’exprime comme
:</p>
<p><span class="math display">\[\text{Variance due à l&#39;interaction}
= \frac{\sum_{i=1}^{a} \sum_{j=1}^{b}
(\alpha\beta)_{ij}^2}{(a-1)(b-1)}\]</span></p>
<p>où <span class="math inline">\(a\)</span> et <span
class="math inline">\(b\)</span> sont respectivement le nombre de
niveaux des facteurs <span class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème central en ANOVA est le théorème de la décomposition de
la variance, qui stipule que la variance totale peut être décomposée en
plusieurs composantes, y compris la variance due à l’interaction. Ce
théorème est essentiel pour comprendre comment les différentes sources
de variation contribuent à la variance totale observée.</p>
<p>Formellement, le théorème peut être énoncé comme suit :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(Y\)</span> une variable réponse
modélisée par un modèle à deux facteurs avec interaction. Alors, la
variance totale <span class="math inline">\(\text{Var}(Y)\)</span> peut
être décomposée en :</p>
<p><span class="math display">\[\text{Var}(Y) = \text{Var}(A) +
\text{Var}(B) + \text{Var}(A \times B) +
\text{Var}(\epsilon)\]</span></p>
<p>où <span class="math inline">\(\text{Var}(A)\)</span>, <span
class="math inline">\(\text{Var}(B)\)</span>, et <span
class="math inline">\(\text{Var}(A \times B)\)</span> sont
respectivement les variances dues aux effets principaux des facteurs
<span class="math inline">\(A\)</span>, <span
class="math inline">\(B\)</span>, et à leur interaction, et <span
class="math inline">\(\text{Var}(\epsilon)\)</span> est la variance due
à l’erreur aléatoire.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous devons montrer que la somme des carrés
totaux (SST) peut être décomposée en plusieurs composantes. La SST est
définie comme :</p>
<p><span class="math display">\[\text{SST} = \sum_{i=1}^{a}
\sum_{j=1}^{b} \sum_{k=1}^{n} (Y_{ijk} - \bar{Y}_{...})^2\]</span></p>
<p>où <span class="math inline">\(\bar{Y}_{...}\)</span> est la moyenne
globale de <span class="math inline">\(Y\)</span>. La SST peut être
décomposée en :</p>
<p><span class="math display">\[\text{SST} = \text{SSA} + \text{SSB} +
\text{SSAB} + \text{SSE}\]</span></p>
<p>où : - <span class="math inline">\(\text{SSA}\)</span> est la somme
des carrés due au facteur <span class="math inline">\(A\)</span>, -
<span class="math inline">\(\text{SSB}\)</span> est la somme des carrés
due au facteur <span class="math inline">\(B\)</span>, - <span
class="math inline">\(\text{SSAB}\)</span> est la somme des carrés due à
l’interaction entre <span class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span>, - <span
class="math inline">\(\text{SSE}\)</span> est la somme des carrés due à
l’erreur.</p>
<p>La variance due à l’interaction est alors calculée comme :</p>
<p><span class="math display">\[\text{MSAB} =
\frac{\text{SSAB}}{(a-1)(b-1)}\]</span></p>
<p>où <span class="math inline">\(\text{MSAB}\)</span> est la moyenne
des carrés due à l’interaction.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Plusieurs propriétés importantes découlent de la définition de la
variance due à l’interaction :</p>
<ol>
<li><p>La variance due à l’interaction est toujours non négative. Cela
découle du fait que les carrés des effets d’interaction sont
sommés.</p></li>
<li><p>Si les facteurs <span class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span> sont indépendants, la variance due à
l’interaction est nulle. Cela signifie qu’il n’y a pas d’effet combiné
des facteurs au-delà de leurs effets individuels.</p></li>
<li><p>La variance due à l’interaction peut être utilisée pour tester
l’hypothèse nulle selon laquelle il n’y a pas d’interaction entre les
facteurs. Cela se fait généralement par un test F, où le rapport des
moyennes des carrés due à l’interaction et de l’erreur est comparé à une
distribution F.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La variance due à l’interaction est un concept puissant et essentiel
en statistique. Elle permet de capturer les effets complexes qui
émergent des combinaisons de facteurs, offrant ainsi une compréhension
plus profonde des phénomènes étudiés. En maîtrisant cette notion, les
chercheurs peuvent non seulement identifier les interactions
significatives, mais aussi mieux interpréter les résultats de leurs
expériences.</p>
</body>
</html>
{% include "footer.html" %}

