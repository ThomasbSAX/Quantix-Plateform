{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Encodage par extraction de caractéristiques de relation</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Encodage par extraction de caractéristiques de
relation</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’encodage par extraction de caractéristiques de relation est une
technique fondamentale en apprentissage automatique et en traitement du
langage naturel. Cette méthode permet de transformer des données
structurées ou non structurées en représentations vectorielles,
facilitant ainsi leur utilisation dans des modèles d’apprentissage
automatique. L’origine de cette technique remonte aux années 1960 avec
les travaux pionniers sur l’analyse des données et la reconnaissance de
motifs. Aujourd’hui, cette méthode est indispensable dans divers
domaines tels que la reconnaissance d’images, le traitement du langage
naturel et la bioinformatique.</p>
<p>L’émergence de cette technique répond à un besoin crucial :
représenter des données complexes sous une forme exploitable par les
algorithmes d’apprentissage automatique. Les caractéristiques de
relation permettent de capturer des informations structurelles et
contextuelles qui seraient autrement perdues dans une représentation
naïve.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant de définir formellement l’encodage par extraction de
caractéristiques de relation, il est essentiel de comprendre ce que nous
cherchons à accomplir. Nous voulons transformer des données complexes en
une représentation vectorielle qui capture les relations entre les
éléments constitutifs de ces données. Par exemple, dans le cas du
traitement du langage naturel, nous voulons capturer les relations
syntaxiques et sémantiques entre les mots d’une phrase.</p>
<p>Soit <span class="math inline">\(X\)</span> un ensemble de données,
où chaque élément <span class="math inline">\(x \in X\)</span> est une
structure complexe (par exemple, une phrase, une image). Nous cherchons
à définir une fonction d’encodage <span
class="math inline">\(\phi\)</span> telle que :</p>
<p><span class="math display">\[\phi: X \rightarrow
\mathbb{R}^d\]</span></p>
<p>où <span class="math inline">\(d\)</span> est la dimension de
l’espace vectoriel cible.</p>
<p>Formellement, nous définissons l’encodage par extraction de
caractéristiques de relation comme suit :</p>
<p><span class="math display">\[\phi(x) = \left( \phi_1(x), \phi_2(x),
\ldots, \phi_d(x) \right)\]</span></p>
<p>où chaque <span class="math inline">\(\phi_i(x)\)</span> est une
caractéristique de relation extraite de <span
class="math inline">\(x\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental dans le domaine de l’encodage par extraction
de caractéristiques de relation est le théorème de représentation de
Kernel. Ce théorème stipule que toute fonction de similarité entre les
données peut être représentée par un produit scalaire dans un espace de
caractéristiques approprié.</p>
<p>Soit <span class="math inline">\(k: X \times X \rightarrow
\mathbb{R}\)</span> une fonction de similarité. Le théorème de
représentation de Kernel affirme qu’il existe un espace de
caractéristiques <span class="math inline">\(\mathcal{H}\)</span> et une
fonction d’encodage <span class="math inline">\(\phi: X \rightarrow
\mathcal{H}\)</span> tels que :</p>
<p><span class="math display">\[k(x, y) = \langle \phi(x), \phi(y)
\rangle_{\mathcal{H}}\]</span></p>
<p>pour tout <span class="math inline">\(x, y \in X\)</span>.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de représentation de Kernel, nous devons
montrer qu’il existe un espace de caractéristiques <span
class="math inline">\(\mathcal{H}\)</span> et une fonction d’encodage
<span class="math inline">\(\phi\)</span> satisfaisant la condition
ci-dessus. Nous procédons comme suit :</p>
<p>1. **Définition de l’espace de caractéristiques** : Soit <span
class="math inline">\(\mathcal{H}\)</span> un espace de Hilbert. Nous
définissons <span class="math inline">\(\phi(x)\)</span> comme une
fonction qui mappe chaque élément <span class="math inline">\(x \in
X\)</span> à un vecteur dans <span
class="math inline">\(\mathcal{H}\)</span>.</p>
<p>2. **Produit scalaire** : Nous définissons le produit scalaire <span
class="math inline">\(\langle \cdot, \cdot
\rangle_{\mathcal{H}}\)</span> dans <span
class="math inline">\(\mathcal{H}\)</span> de manière à ce qu’il
respecte les propriétés du produit scalaire.</p>
<p>3. **Représentation de la fonction de similarité** : Nous montrons
que pour toute paire <span class="math inline">\((x, y) \in X \times
X\)</span>, la fonction de similarité <span class="math inline">\(k(x,
y)\)</span> peut être exprimée comme le produit scalaire des encodages
<span class="math inline">\(\phi(x)\)</span> et <span
class="math inline">\(\phi(y)\)</span>.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons ci-dessous quelques propriétés et corollaires importants
de l’encodage par extraction de caractéristiques de relation :</p>
<ol>
<li><p>**Propriété de linéarité** : L’encodage par extraction de
caractéristiques de relation est linéaire. Cela signifie que pour tout
<span class="math inline">\(x, y \in X\)</span> et tout <span
class="math inline">\(\alpha, \beta \in \mathbb{R}\)</span>, nous avons
:</p>
<p><span class="math display">\[\phi(\alpha x + \beta y) = \alpha
\phi(x) + \beta \phi(y)\]</span></p></li>
<li><p>**Propriété de conservation de la similarité** : L’encodage
préserve les relations de similarité entre les éléments. Cela signifie
que pour tout <span class="math inline">\(x, y \in X\)</span>, nous
avons :</p>
<p><span class="math display">\[k(x, y) = \langle \phi(x), \phi(y)
\rangle_{\mathcal{H}}\]</span></p></li>
<li><p>**Corollaire de la dimensionnalité** : La dimension <span
class="math inline">\(d\)</span> de l’espace vectoriel cible peut être
choisie arbitrairement, sous réserve que <span
class="math inline">\(d\)</span> soit suffisamment grand pour capturer
les caractéristiques de relation pertinentes.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’encodage par extraction de caractéristiques de relation est une
technique puissante et polyvalente qui trouve des applications dans
divers domaines. En transformant des données complexes en
représentations vectorielles, cette méthode facilite l’utilisation de
ces données dans des modèles d’apprentissage automatique. Les théorèmes
et propriétés associés à cette technique fournissent une base solide
pour son utilisation dans des applications pratiques.</p>
</body>
</html>
{% include "footer.html" %}

