{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Domain Adaptation: Bridging the Gap Between Domains</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Domain Adaptation: Bridging the Gap Between
Domains</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>In the realm of machine learning, the performance of models is often
hindered by the discrepancy between the training and test distributions.
This phenomenon, known as domain shift, has been a persistent challenge
in various applications such as computer vision, natural language
processing, and healthcare. Domain adaptation emerges as a powerful
paradigm to address this issue by leveraging knowledge from a labeled
source domain to improve performance on an unlabeled target domain.</p>
<p>The concept of domain adaptation finds its roots in transfer
learning, where the goal is to transfer knowledge from one domain to
another. Historically, the need for domain adaptation arose in scenarios
where labeled data is scarce or expensive to obtain in the target
domain, while abundant labeled data exists in a related source domain.
By adapting models to the target domain, we can mitigate the performance
degradation caused by domain discrepancy.</p>
<h1 id="definitions">Definitions</h1>
<p>To formalize the problem of domain adaptation, let us first consider
what we aim to achieve. Suppose we have a source domain <span
class="math inline">\(\mathcal{D}_S\)</span> with labeled data <span
class="math inline">\((x_i^s, y_i^s)_{i=1}^{n_s}\)</span> and a target
domain <span class="math inline">\(\mathcal{D}_T\)</span> with unlabeled
data <span class="math inline">\((x_j^t)_{j=1}^{n_t}\)</span>. Our
objective is to learn a model that performs well on the target domain,
even though it has no labels. This leads us to the formal definition of
domain adaptation.</p>
<div class="definition">
<p>Given a source domain <span
class="math inline">\(\mathcal{D}_S\)</span> with distribution <span
class="math inline">\(P_S(x, y)\)</span> and a target domain <span
class="math inline">\(\mathcal{D}_T\)</span> with distribution <span
class="math inline">\(P_T(x)\)</span>, the goal of domain adaptation is
to learn a predictor <span class="math inline">\(f: \mathcal{X}
\rightarrow \mathcal{Y}\)</span> that minimizes the expected risk on
<span class="math inline">\(\mathcal{D}_T\)</span>: <span
class="math display">\[\min_f \mathbb{E}_{(x, y) \sim P_T(x, y)}
[\ell(f(x), y)],\]</span> where <span
class="math inline">\(\ell\)</span> is a loss function. The challenge
lies in the fact that <span class="math inline">\(P_T(x, y)\)</span> is
unknown, and we only have access to samples from <span
class="math inline">\(P_S(x, y)\)</span> and <span
class="math inline">\(P_T(x)\)</span>.</p>
</div>
<h1 id="theorems">Theorems</h1>
<p>One of the foundational results in domain adaptation is the covariate
shift assumption, which posits that the conditional distribution <span
class="math inline">\(P(y|x)\)</span> remains the same across domains,
while the marginal distribution <span
class="math inline">\(P(x)\)</span> may differ.</p>
<div class="theorem">
<p>Assume that the conditional distribution <span
class="math inline">\(P_S(y|x) = P_T(y|x)\)</span> for all <span
class="math inline">\(x \in \mathcal{X}\)</span>. Then, the expected
risk on the target domain can be expressed in terms of the source domain
as: <span class="math display">\[\mathbb{E}_{(x, y) \sim P_T(x, y)}
[\ell(f(x), y)] = \mathbb{E}_{x \sim P_T(x)} \left[
\frac{P_S(y|x)}{P_T(y|x)} \mathbb{E}_{y \sim P_S(y|x)} [\ell(f(x), y)]
\right].\]</span> This theorem suggests that if we can estimate the
ratio <span class="math inline">\(\frac{P_S(y|x)}{P_T(y|x)}\)</span>, we
can adapt the source model to the target domain.</p>
</div>
<h1 id="proofs">Proofs</h1>
<p>To prove the covariate shift assumption theorem, we start by
expressing the expected risk on the target domain: <span
class="math display">\[\mathbb{E}_{(x, y) \sim P_T(x, y)} [\ell(f(x),
y)] = \int_{\mathcal{X} \times \mathcal{Y}} \ell(f(x), y) dP_T(x,
y).\]</span> Using the assumption <span class="math inline">\(P_S(y|x) =
P_T(y|x)\)</span>, we can rewrite the joint distribution as: <span
class="math display">\[dP_T(x, y) = P_T(y|x) dP_T(x) = P_S(y|x)
dP_T(x).\]</span> Substituting this into the expected risk expression,
we get: <span class="math display">\[\mathbb{E}_{(x, y) \sim P_T(x, y)}
[\ell(f(x), y)] = \int_{\mathcal{X}} \left( \int_{\mathcal{Y}}
\ell(f(x), y) P_S(y|x) dP_T(x) \right) dP_T(x).\]</span> Noting that
<span class="math inline">\(\int_{\mathcal{Y}} \ell(f(x), y) P_S(y|x)
dP_T(x)\)</span> is the expected loss under the source distribution, we
can rewrite it as: <span class="math display">\[\mathbb{E}_{(x, y) \sim
P_T(x, y)} [\ell(f(x), y)] = \mathbb{E}_{x \sim P_T(x)} \left[
\frac{P_S(y|x)}{P_T(y|x)} \mathbb{E}_{y \sim P_S(y|x)} [\ell(f(x), y)]
\right].\]</span></p>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>The covariate shift assumption leads to several important properties
and corollaries:</p>
<ol>
<li><p>If the covariate shift assumption holds, then the optimal
predictor <span class="math inline">\(f^*\)</span> that minimizes the
expected risk on the source domain also minimizes the expected risk on
the target domain, up to a reweighting factor.</p></li>
<li><p>The ratio <span
class="math inline">\(\frac{P_S(y|x)}{P_T(y|x)}\)</span> can be
estimated using techniques such as importance weighting or density ratio
estimation.</p></li>
<li><p>Domain adaptation methods based on the covariate shift assumption
can be extended to handle more complex scenarios, such as partial domain
adaptation or multi-source domain adaptation.</p></li>
</ol>
<p>To elaborate on property (ii), we can use importance weighting to
estimate the ratio <span
class="math inline">\(\frac{P_S(y|x)}{P_T(y|x)}\)</span>. Let <span
class="math inline">\(w(x) = \frac{P_S(x)}{P_T(x)}\)</span> be the
importance weight. Then, the expected risk on the target domain can be
approximated as: <span class="math display">\[\mathbb{E}_{(x, y) \sim
P_T(x, y)} [\ell(f(x), y)] \approx \mathbb{E}_{x \sim P_S(x)} [w(x)
\ell(f(x), y)].\]</span> This approximation allows us to use the source
data to estimate the target risk, provided that we can estimate the
importance weights <span class="math inline">\(w(x)\)</span>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Domain adaptation is a crucial paradigm in machine learning that
enables the transfer of knowledge from a labeled source domain to an
unlabeled target domain. By addressing the challenge of domain
discrepancy, domain adaptation methods have the potential to
significantly improve the performance and generalization capabilities of
machine learning models. Future research in this area may explore more
sophisticated assumptions, novel adaptation techniques, and applications
to real-world problems.</p>
</body>
</html>
{% include "footer.html" %}

