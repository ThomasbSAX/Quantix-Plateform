{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La distance de Gower pour les variables nominales</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La distance de Gower pour les variables nominales</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La distance de Gower, introduite par le statisticien britannique
Michael Alan Gower en 1971, est une mesure de dissimilarité qui permet
de comparer des objets décrits par un ensemble de variables, qu’elles
soient quantitatives ou qualitatives. Son émergence répond à un besoin
crucial en analyse de données : disposer d’une métrique capable de
prendre en compte des types de variables hétérogènes dans un même cadre
théorique.</p>
<p>Dans un contexte où les données sont souvent multimodales, la
distance de Gower se distingue par sa capacité à intégrer des variables
nominales, ordinales et quantitatives sans nécessiter de transformation
préalable. Cette propriété en fait un outil indispensable pour les
méthodes d’analyse multivariée, telles que l’analyse des correspondances
multiples ou les méthodes de classification non supervisée.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir la distance de Gower pour les variables nominales,
commençons par comprendre ce que nous cherchons à mesurer. Nous voulons
quantifier la dissimilarité entre deux modalités d’une variable
nominale, c’est-à-dire à quel point deux catégories sont différentes.
Intuitivement, si deux modalités sont identiques, la dissimilarité doit
être nulle.</p>
<p>Formellement, soit <span class="math inline">\(X\)</span> une
variable nominale prenant ses valeurs dans un ensemble fini <span
class="math inline">\(\{x_1, x_2, \dots, x_k\}\)</span>. Pour deux
modalités <span class="math inline">\(x_i\)</span> et <span
class="math inline">\(x_j\)</span>, nous cherchons une fonction <span
class="math inline">\(d(x_i, x_j)\)</span> qui vérifie les propriétés
suivantes :</p>
<ul>
<li><p><span class="math inline">\(d(x_i, x_j) = 0\)</span> si et
seulement si <span class="math inline">\(x_i = x_j\)</span>,</p></li>
<li><p><span class="math inline">\(d(x_i, x_j) = d(x_j,
x_i)\)</span>,</p></li>
<li><p><span class="math inline">\(d(x_i, x_j) \leq d(x_i, x_l) + d(x_l,
x_j)\)</span> pour tout <span class="math inline">\(l\)</span>.</p></li>
</ul>
<p>La distance de Gower pour les variables nominales est définie comme
suit : <span class="math display">\[d(x_i, x_j) = \begin{cases}
0 &amp; \text{si } x_i = x_j, \\
1 &amp; \text{sinon.}
\end{cases}\]</span></p>
<p>Cette définition peut être généralisée pour plusieurs variables
nominales. Soit <span class="math inline">\(\mathbf{X} = (X_1, X_2,
\dots, X_p)\)</span> un vecteur de variables nominales. La distance de
Gower entre deux individus <span
class="math inline">\(\mathbf{x}_a\)</span> et <span
class="math inline">\(\mathbf{x}_b\)</span> est donnée par : <span
class="math display">\[d_G(\mathbf{x}_a, \mathbf{x}_b) =
\frac{\sum_{j=1}^p d(x_{aj}, x_{bj}) \cdot u_j}{\sum_{j=1}^p
u_j},\]</span> où <span class="math inline">\(d(x_{aj}, x_{bj})\)</span>
est la distance de Gower pour la variable <span
class="math inline">\(X_j\)</span>, et <span
class="math inline">\(u_j\)</span> est un poids associé à la variable
<span class="math inline">\(X_j\)</span>. Si toutes les variables sont
pondérées de manière égale, on a <span class="math inline">\(u_j =
1\)</span> pour tout <span class="math inline">\(j\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Pour établir des propriétés importantes de la distance de Gower, nous
commençons par comprendre ce que nous cherchons à démontrer. Nous
voulons montrer que la distance de Gower est une métrique, c’est-à-dire
qu’elle satisfait les propriétés de non-négativité, d’identité des
indiscernables, de symétrie et d’inégalité triangulaire.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\mathbf{X} = (X_1, X_2, \dots,
X_p)\)</span> un vecteur de variables nominales. La distance de Gower
<span class="math inline">\(d_G\)</span> définie par : <span
class="math display">\[d_G(\mathbf{x}_a, \mathbf{x}_b) =
\frac{\sum_{j=1}^p d(x_{aj}, x_{bj}) \cdot u_j}{\sum_{j=1}^p
u_j},\]</span> où <span class="math inline">\(d(x_{aj}, x_{bj})\)</span>
est la distance de Gower pour la variable <span
class="math inline">\(X_j\)</span>, et <span
class="math inline">\(u_j\)</span> est un poids associé à la variable
<span class="math inline">\(X_j\)</span>, satisfait les propriétés
suivantes :</p>
<ol>
<li><p>Non-négativité : <span class="math inline">\(d_G(\mathbf{x}_a,
\mathbf{x}_b) \geq 0\)</span>,</p></li>
<li><p>Identité des indiscernables : <span
class="math inline">\(d_G(\mathbf{x}_a, \mathbf{x}_b) = 0\)</span> si et
seulement si <span class="math inline">\(\mathbf{x}_a =
\mathbf{x}_b\)</span>,</p></li>
<li><p>Symétrie : <span class="math inline">\(d_G(\mathbf{x}_a,
\mathbf{x}_b) = d_G(\mathbf{x}_b, \mathbf{x}_a)\)</span>,</p></li>
<li><p>Inégalité triangulaire : <span
class="math inline">\(d_G(\mathbf{x}_a, \mathbf{x}_c) \leq
d_G(\mathbf{x}_a, \mathbf{x}_b) + d_G(\mathbf{x}_b,
\mathbf{x}_c)\)</span>.</p></li>
</ol>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver les propriétés métriques de la distance de Gower, nous
procédons étape par étape.</p>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p><strong>Non-négativité</strong> : Par définition, <span
class="math inline">\(d(x_{aj}, x_{bj}) \in \{0, 1\}\)</span>. Donc,
<span class="math inline">\(d_G(\mathbf{x}_a, \mathbf{x}_b)\)</span> est
une moyenne pondérée de valeurs dans <span class="math inline">\(\{0,
1\}\)</span>, ce qui implique que <span
class="math inline">\(d_G(\mathbf{x}_a, \mathbf{x}_b) \geq
0\)</span>.</p></li>
<li><p><strong>Identité des indiscernables</strong> : Si <span
class="math inline">\(\mathbf{x}_a = \mathbf{x}_b\)</span>, alors <span
class="math inline">\(x_{aj} = x_{bj}\)</span> pour tout <span
class="math inline">\(j\)</span>, ce qui implique que <span
class="math inline">\(d(x_{aj}, x_{bj}) = 0\)</span> pour tout <span
class="math inline">\(j\)</span>. Donc, <span
class="math inline">\(d_G(\mathbf{x}_a, \mathbf{x}_b) = 0\)</span>.
Réciproquement, si <span class="math inline">\(d_G(\mathbf{x}_a,
\mathbf{x}_b) = 0\)</span>, alors <span class="math inline">\(d(x_{aj},
x_{bj}) = 0\)</span> pour tout <span class="math inline">\(j\)</span>,
ce qui implique que <span class="math inline">\(x_{aj} = x_{bj}\)</span>
pour tout <span class="math inline">\(j\)</span>. Donc, <span
class="math inline">\(\mathbf{x}_a = \mathbf{x}_b\)</span>.</p></li>
<li><p><strong>Symétrie</strong> : Par définition, <span
class="math inline">\(d(x_{aj}, x_{bj}) = d(x_{bj}, x_{aj})\)</span>.
Donc, <span class="math inline">\(d_G(\mathbf{x}_a, \mathbf{x}_b) =
d_G(\mathbf{x}_b, \mathbf{x}_a)\)</span>.</p></li>
<li><p><strong>Inégalité triangulaire</strong> : Nous devons montrer que
pour tout <span class="math inline">\(\mathbf{x}_a, \mathbf{x}_b,
\mathbf{x}_c\)</span>, on a <span
class="math inline">\(d_G(\mathbf{x}_a, \mathbf{x}_c) \leq
d_G(\mathbf{x}_a, \mathbf{x}_b) + d_G(\mathbf{x}_b,
\mathbf{x}_c)\)</span>. Pour chaque variable <span
class="math inline">\(X_j\)</span>, on a <span
class="math inline">\(d(x_{aj}, x_{cj}) \leq d(x_{aj}, x_{bj}) +
d(x_{bj}, x_{cj})\)</span>. En sommant sur <span
class="math inline">\(j\)</span> et en pondérant, on obtient l’inégalité
souhaitée.</p></li>
</ol>
<p> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la
distance de Gower.</p>
<ol>
<li><p><strong>Invariance par transformation des modalités</strong> : La
distance de Gower est invariante par toute permutation des modalités
d’une variable nominale. Cela signifie que si nous renommons les
modalités, la distance reste inchangée.</p></li>
<li><p><strong>Normalisation</strong> : La distance de Gower est
normalisée entre 0 et 1. Cela permet de comparer facilement les
distances obtenues pour différentes variables.</p></li>
<li><p><strong>Extension aux variables ordinales</strong> : La distance
de Gower peut être étendue aux variables ordinales en utilisant une
fonction de dissimilarité appropriée. Par exemple, pour une variable
ordinale <span class="math inline">\(X\)</span> avec <span
class="math inline">\(k\)</span> modalités ordonnées, on peut définir
<span class="math inline">\(d(x_i, x_j) = \frac{|i - j|}{k -
1}\)</span>.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La distance de Gower pour les variables nominales est un outil
puissant et flexible pour mesurer la dissimilarité entre des objets
décrits par des variables de types différents. Son utilisation dans
l’analyse de données multivariées permet de prendre en compte la
complexité des données réelles, où les variables quantitatives et
qualitatives coexistent souvent. Les propriétés métriques de la distance
de Gower en font un choix naturel pour les méthodes d’analyse des
données qui nécessitent une mesure de dissimilarité robuste et
interprétable.</p>
</body>
</html>
{% include "footer.html" %}

