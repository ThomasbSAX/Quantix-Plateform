{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Déviance de Poisson : Une Exploration Mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Déviance de Poisson : Une Exploration
Mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La distribution de Poisson est un pilier fondamental en théorie des
probabilités, notamment pour modéliser le nombre d’événements rares et
indépendants survenant dans un intervalle de temps ou d’espace fixe.
Cependant, l’évaluation de la qualité d’un modèle basé sur cette
distribution nécessite des outils statistiques robustes. La <em>déviance
de Poisson</em> émerge comme une mesure clé pour quantifier l’écart
entre les données observées et celles prédites par un modèle de Poisson.
Cette notion est indispensable dans l’analyse des modèles de comptage,
permettant d’évaluer la pertinence des hypothèses sous-jacentes et
d’identifier les limites du modèle.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la déviance de Poisson, considérons d’abord un modèle
de Poisson où le nombre d’événements <span
class="math inline">\(Y_i\)</span> dans la <span
class="math inline">\(i\)</span>-ème catégorie suit une distribution de
Poisson avec un paramètre <span
class="math inline">\(\lambda_i\)</span>. Nous cherchons à mesurer
l’écart entre les observations <span class="math inline">\(y_i\)</span>
et les prédictions <span class="math inline">\(\hat{y}_i =
\hat{\lambda}_i\)</span>.</p>
<div class="definition">
<p>La déviance de Poisson pour un modèle de Poisson est définie comme :
<span class="math display">\[D(\mathbf{y}, \hat{\mathbf{\lambda}}) = 2
\sum_{i=1}^n \left[ y_i \log\left(\frac{y_i}{\hat{\lambda}_i}\right) -
(y_i - \hat{\lambda}_i) \right]\]</span> où <span
class="math inline">\(y_i\)</span> sont les observations et <span
class="math inline">\(\hat{\lambda}_i\)</span> sont les prédictions du
modèle.</p>
</div>
<p>Cette définition peut être reformulée en utilisant la fonction de
log-vraisemblance : <span class="math display">\[D(\mathbf{y},
\hat{\mathbf{\lambda}}) = 2 \left[ \ell(\mathbf{y}, \mathbf{y}) -
\ell(\mathbf{y}, \hat{\mathbf{\lambda}}) \right]\]</span> où <span
class="math inline">\(\ell(\mathbf{y}, \mathbf{\lambda}) = \sum_{i=1}^n
\left[ y_i \log(\lambda_i) - \lambda_i - \log(y_i!) \right]\)</span> est
la log-vraisemblance du modèle de Poisson.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la déviance de Poisson est le suivant
:</p>
<div class="theorem">
<p>Pour un modèle de Poisson bien spécifié, la déviance suit une
distribution du chi-deux à <span class="math inline">\(n - p\)</span>
degrés de liberté, où <span class="math inline">\(n\)</span> est le
nombre d’observations et <span class="math inline">\(p\)</span> est le
nombre de paramètres estimés.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Considérons un modèle de Poisson où <span
class="math inline">\(Y_i \sim \text{Poisson}(\lambda_i)\)</span>. La
statistique de déviance peut être écrite comme : <span
class="math display">\[D(\mathbf{y}, \hat{\mathbf{\lambda}}) = 2
\sum_{i=1}^n \left[ y_i \log\left(\frac{y_i}{\hat{\lambda}_i}\right) -
(y_i - \hat{\lambda}_i) \right]\]</span> Sous l’hypothèse nulle que le
modèle est correctement spécifié, la déviance peut être approximée par
une somme de termes indépendants suivant une distribution du chi-deux.
Par le théorème central limite, la somme de ces termes suit une
distribution du chi-deux à <span class="math inline">\(n - p\)</span>
degrés de liberté. ◻</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour illustrer la preuve du théorème précédent, développons les
étapes détaillées :</p>
<div class="proof">
<p><em>Proof.</em> 1. **Définition de la Déviance** : <span
class="math display">\[D(\mathbf{y}, \hat{\mathbf{\lambda}}) = 2
\sum_{i=1}^n \left[ y_i \log\left(\frac{y_i}{\hat{\lambda}_i}\right) -
(y_i - \hat{\lambda}_i) \right]\]</span></p>
<p>2. **Approximation de Taylor** : Pour chaque terme <span
class="math inline">\(y_i \log\left(\frac{y_i}{\hat{\lambda}_i}\right) -
(y_i - \hat{\lambda}_i)\)</span>, nous pouvons utiliser une
approximation de Taylor autour de <span
class="math inline">\(\hat{\lambda}_i\)</span> : <span
class="math display">\[y_i \log\left(\frac{y_i}{\hat{\lambda}_i}\right)
- (y_i - \hat{\lambda}_i) \approx \frac{(y_i - \hat{\lambda}_i)^2}{2
\hat{\lambda}_i} - (y_i - \hat{\lambda}_i)\]</span></p>
<p>3. **Somme des Terme** : En sommant sur tous les <span
class="math inline">\(i\)</span>, nous obtenons : <span
class="math display">\[D(\mathbf{y}, \hat{\mathbf{\lambda}}) \approx
\sum_{i=1}^n \left[ \frac{(y_i - \hat{\lambda}_i)^2}{\hat{\lambda}_i} -
2(y_i - \hat{\lambda}_i) \right]\]</span></p>
<p>4. **Distribution du Chi-deux** : Sous l’hypothèse nulle, les termes
<span class="math inline">\(\frac{(y_i -
\hat{\lambda}_i)^2}{\hat{\lambda}_i}\)</span> sont indépendants et
suivent une distribution du chi-deux à 1 degré de liberté. La somme de
<span class="math inline">\(n - p\)</span> tels termes suit donc une
distribution du chi-deux à <span class="math inline">\(n - p\)</span>
degrés de liberté. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Plusieurs propriétés importantes découlent de la déviance de Poisson
:</p>
<ol>
<li><p>**Propriété de Minimisation** : La déviance est minimisée lorsque
<span class="math inline">\(\hat{\lambda}_i = y_i\)</span>, c’est-à-dire
lorsque les prédictions du modèle coïncident avec les observations.</p>
<div class="proof">
<p><em>Proof.</em> Considérons la déviance <span
class="math inline">\(D(\mathbf{y}, \hat{\mathbf{\lambda}})\)</span>.
Pour minimiser cette quantité, il suffit de minimiser chaque terme <span
class="math inline">\(y_i \log\left(\frac{y_i}{\hat{\lambda}_i}\right) -
(y_i - \hat{\lambda}_i)\)</span>. La dérivée par rapport à <span
class="math inline">\(\hat{\lambda}_i\)</span> est : <span
class="math display">\[\frac{\partial}{\partial \hat{\lambda}_i} \left[
y_i \log\left(\frac{y_i}{\hat{\lambda}_i}\right) - (y_i -
\hat{\lambda}_i) \right] = -\frac{y_i}{\hat{\lambda}_i} + 1\]</span> En
annulant la dérivée, nous obtenons <span
class="math inline">\(\hat{\lambda}_i = y_i\)</span>. ◻</p>
</div></li>
<li><p>**Propriété de Consistance** : Pour un modèle de Poisson bien
spécifié, la déviance tend vers zéro lorsque le nombre d’observations
tend vers l’infini.</p>
<div class="proof">
<p><em>Proof.</em> Sous l’hypothèse que le modèle est correct, les
prédictions <span class="math inline">\(\hat{\lambda}_i\)</span>
convergent vers les vraies valeurs <span
class="math inline">\(\lambda_i\)</span>. Par conséquent, la déviance
<span class="math inline">\(D(\mathbf{y},
\hat{\mathbf{\lambda}})\)</span> tend vers zéro. ◻</p>
</div></li>
<li><p>**Propriété de Sensibilité** : La déviance est sensible aux
écarts entre les observations et les prédictions, permettant de détecter
les modèles mal spécifiés.</p>
<div class="proof">
<p><em>Proof.</em> Si le modèle est mal spécifié, les prédictions <span
class="math inline">\(\hat{\lambda}_i\)</span> ne coïncideront pas avec
les observations <span class="math inline">\(y_i\)</span>, entraînant
une déviance élevée. Cela permet de rejeter l’hypothèse que le modèle
est correct. ◻</p>
</div></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>La déviance de Poisson est un outil puissant pour évaluer la qualité
des modèles basés sur la distribution de Poisson. Ses propriétés
mathématiques et statistiques en font un instrument indispensable dans
l’analyse des données de comptage. En comprenant ses définitions,
théorèmes et preuves, nous pouvons mieux apprécier son rôle dans la
modélisation statistique et l’évaluation des hypothèses.</p>
</body>
</html>
{% include "footer.html" %}

