{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’inégalité de Markov : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’inégalité de Markov : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de Markov émerge comme un pilier fondamental dans
l’analyse probabiliste, offrant des bornes essentielles pour les moments
d’une variable aléatoire. Son origine remonte aux travaux pionniers
d’Andreï Markov, un mathématicien russe du début du XXe siècle. Cette
inégalité trouve son utilité dans divers domaines, notamment en théorie
des probabilités et en statistique, où elle permet de contrôler la
probabilité qu’une variable aléatoire positive dépasse un certain seuil.
Son importance réside dans sa simplicité et son universalité,
fournissant des outils puissants pour l’analyse de phénomènes
aléatoires.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire l’inégalité de Markov, considérons une variable
aléatoire <span class="math inline">\(X\)</span> prenant des valeurs
réelles non négatives. Nous cherchons à estimer la probabilité que <span
class="math inline">\(X\)</span> soit supérieure à un certain seuil
<span class="math inline">\(a &gt; 0\)</span>. Intuitivement, si
l’espérance de <span class="math inline">\(X\)</span> est connue, nous
pouvons utiliser cette information pour obtenir une borne supérieure sur
cette probabilité.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
non négative et soit <span class="math inline">\(a &gt; 0\)</span>.
L’inégalité de Markov s’énonce comme suit : <span
class="math display">\[\mathbb{P}(X \geq a) \leq
\frac{\mathbb{E}[X]}{a}.\]</span> En d’autres termes, pour tout <span
class="math inline">\(a &gt; 0\)</span>, la probabilité que <span
class="math inline">\(X\)</span> dépasse <span
class="math inline">\(a\)</span> est majorée par le rapport de
l’espérance de <span class="math inline">\(X\)</span> à <span
class="math inline">\(a\)</span>.</p>
</div>
<p>Cette inégalité peut également être formulée en utilisant des
quantificateurs : <span class="math display">\[\forall a &gt; 0, \quad
\mathbb{P}(X \geq a) \leq \frac{\mathbb{E}[X]}{a}.\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>L’inégalité de Markov est souvent utilisée comme point de départ pour
des résultats plus raffinés, tels que l’inégalité de Tchebyshev. Voici
une formulation du théorème de Markov :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
non négative et soit <span class="math inline">\(a &gt; 0\)</span>.
Alors, <span class="math display">\[\mathbb{P}(X \geq a) \leq
\frac{\mathbb{E}[X]}{a}.\]</span></p>
</div>
<p>Pour démontrer ce théorème, nous procédons comme suit :</p>
<div class="proof">
<p><em>Proof.</em> Considérons la fonction indicatrice <span
class="math inline">\(\mathbb{I}_{X \geq a}\)</span>, qui vaut 1 si
<span class="math inline">\(X \geq a\)</span> et 0 sinon. Nous avons :
<span class="math display">\[X \geq a \mathbb{I}_{X \geq a}.\]</span> En
prenant l’espérance des deux côtés, nous obtenons : <span
class="math display">\[\mathbb{E}[X] \geq a \mathbb{E}[\mathbb{I}_{X
\geq a}] = a \mathbb{P}(X \geq a).\]</span> En réarrangeant cette
inégalité, nous obtenons le résultat souhaité : <span
class="math display">\[\mathbb{P}(X \geq a) \leq
\frac{\mathbb{E}[X]}{a}.\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>La preuve de l’inégalité de Markov repose sur des principes
fondamentaux de l’espérance mathématique. Voici une justification
détaillée :</p>
<div class="proof">
<p><em>Proof.</em> Soit <span class="math inline">\(X\)</span> une
variable aléatoire non négative. Pour tout <span class="math inline">\(a
&gt; 0\)</span>, nous avons : <span class="math display">\[X \geq a
\mathbb{I}_{X \geq a},\]</span> où <span
class="math inline">\(\mathbb{I}_{X \geq a}\)</span> est la fonction
indicatrice de l’événement <span class="math inline">\(X \geq
a\)</span>. En prenant l’espérance des deux côtés, nous obtenons : <span
class="math display">\[\mathbb{E}[X] \geq a \mathbb{E}[\mathbb{I}_{X
\geq a}].\]</span> Puisque <span
class="math inline">\(\mathbb{E}[\mathbb{I}_{X \geq a}] = \mathbb{P}(X
\geq a)\)</span>, nous avons : <span
class="math display">\[\mathbb{E}[X] \geq a \mathbb{P}(X \geq
a).\]</span> En réarrangeant cette inégalité, nous obtenons : <span
class="math display">\[\mathbb{P}(X \geq a) \leq
\frac{\mathbb{E}[X]}{a}.\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Markov possède plusieurs propriétés et corollaires
intéressants. En voici quelques-uns :</p>
<ol>
<li><p><strong>Inégalité de Markov pour les moments supérieurs</strong>
: Si <span class="math inline">\(X\)</span> est une variable aléatoire
non négative et si <span class="math inline">\(k &gt; 0\)</span>, alors
pour tout <span class="math inline">\(a &gt; 0\)</span>, <span
class="math display">\[\mathbb{P}(X \geq a) \leq
\frac{\mathbb{E}[X^k]}{a^k}.\]</span> Cette généralisation est souvent
appelée l’inégalité de Markov généralisée.</p>
<div class="proof">
<p><em>Proof.</em> Considérons la variable aléatoire <span
class="math inline">\(Y = X^k\)</span>. Puisque <span
class="math inline">\(k &gt; 0\)</span>, <span
class="math inline">\(Y\)</span> est également non négative. En
appliquant l’inégalité de Markov à <span
class="math inline">\(Y\)</span>, nous obtenons : <span
class="math display">\[\mathbb{P}(Y \geq a^k) \leq
\frac{\mathbb{E}[Y]}{a^k}.\]</span> En remplaçant <span
class="math inline">\(Y\)</span> par <span
class="math inline">\(X^k\)</span>, nous avons : <span
class="math display">\[\mathbb{P}(X^k \geq a^k) \leq
\frac{\mathbb{E}[X^k]}{a^k}.\]</span> Puisque <span
class="math inline">\(X \geq 0\)</span>, l’événement <span
class="math inline">\(X \geq a\)</span> est équivalent à <span
class="math inline">\(X^k \geq a^k\)</span>. Par conséquent, <span
class="math display">\[\mathbb{P}(X \geq a) \leq
\frac{\mathbb{E}[X^k]}{a^k}.\]</span> ◻</p>
</div></li>
<li><p><strong>Inégalité de Tchebyshev</strong> : Si <span
class="math inline">\(X\)</span> est une variable aléatoire de variance
finie et d’espérance <span class="math inline">\(\mu\)</span>, alors
pour tout <span class="math inline">\(\epsilon &gt; 0\)</span>, <span
class="math display">\[\mathbb{P}(|X - \mu| \geq \epsilon) \leq
\frac{\text{Var}(X)}{\epsilon^2}.\]</span> Cette inégalité est une
application directe de l’inégalité de Markov généralisée à la variable
aléatoire <span class="math inline">\((X - \mu)^2\)</span>.</p>
<div class="proof">
<p><em>Proof.</em> Considérons la variable aléatoire <span
class="math inline">\(Y = (X - \mu)^2\)</span>. En appliquant
l’inégalité de Markov généralisée à <span
class="math inline">\(Y\)</span> avec <span class="math inline">\(k =
2\)</span>, nous obtenons : <span class="math display">\[\mathbb{P}(Y
\geq \epsilon^2) \leq \frac{\mathbb{E}[Y]}{\epsilon^2}.\]</span> Puisque
<span class="math inline">\(Y = (X - \mu)^2\)</span> et que <span
class="math inline">\(\mathbb{E}[Y] = \text{Var}(X)\)</span>, nous avons
: <span class="math display">\[\mathbb{P}((X - \mu)^2 \geq \epsilon^2)
\leq \frac{\text{Var}(X)}{\epsilon^2}.\]</span> En prenant la racine
carrée des deux côtés, nous obtenons : <span
class="math display">\[\mathbb{P}(|X - \mu| \geq \epsilon) \leq
\frac{\text{Var}(X)}{\epsilon^2}.\]</span> ◻</p>
</div></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’inégalité de Markov est un outil fondamental en théorie des
probabilités, offrant des bornes essentielles pour les moments d’une
variable aléatoire. Son application permet de contrôler la probabilité
que cette variable dépasse un certain seuil, ce qui est crucial dans de
nombreuses analyses statistiques. Les propriétés et corollaires dérivés
de cette inégalité, tels que l’inégalité de Tchebyshev, élargissent son
champ d’application et renforcent son utilité dans divers domaines de la
recherche mathématique.</p>
</body>
</html>
{% include "footer.html" %}

