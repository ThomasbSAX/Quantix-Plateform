{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Convergence des chaînes de Markov</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Convergence des chaînes de Markov</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les chaînes de Markov sont des objets fondamentaux en théorie des
probabilités, avec des applications variées allant de la modélisation de
processus aléatoires en finance à l’apprentissage automatique. Leur
étude remonte aux travaux de Markov au début du XXe siècle, qui
cherchait à généraliser le théorème des grands nombres aux processus
dépendants. La convergence des chaînes de Markov est un sujet central,
car elle permet de comprendre le comportement asymptotique de ces
processus et d’en déduire des propriétés stables et invariantes.</p>
<p>Dans cet article, nous explorons les différents aspects de la
convergence des chaînes de Markov, en mettant l’accent sur les
conditions nécessaires et suffisantes pour que ces chaînes convergent
vers une distribution stationnaire. Nous aborderons également les
implications de cette convergence dans divers domaines applicatifs.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant d’aborder la convergence, il est essentiel de définir
précisément ce qu’est une chaîne de Markov. Intuitivement, une chaîne de
Markov est un processus stochastique où l’état futur dépend uniquement
de l’état présent et non des états passés. Cela est souvent résumé par
la propriété de Markov.</p>
<div class="definition">
<p>Soit <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> un
espace probabilisé. Une chaîne de Markov est une suite de variables
aléatoires <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
à valeurs dans un espace d’états <span class="math inline">\(E\)</span>
telle que pour tout <span class="math inline">\(n \in
\mathbb{N}\)</span> et pour tous <span class="math inline">\(x_0, x_1,
\ldots, x_n, x_{n+1} \in E\)</span>,</p>
<p><span class="math display">\[P(X_{n+1} = x_{n+1} \mid X_n = x_n,
X_{n-1} = x_{n-1}, \ldots, X_0 = x_0) = P(X_{n+1} = x_{n+1} \mid X_n =
x_n).\]</span></p>
<p>En d’autres termes, la probabilité de transition ne dépend que de
l’état présent <span class="math inline">\(X_n\)</span>.</p>
</div>
<p>Une chaîne de Markov est dite homogène si les probabilités de
transition ne dépendent pas du temps <span
class="math inline">\(n\)</span>. Dans ce cas, on peut définir une
matrice de transition <span class="math inline">\(P\)</span> où <span
class="math inline">\(P_{ij}\)</span> représente la probabilité de
passer de l’état <span class="math inline">\(i\)</span> à l’état <span
class="math inline">\(j\)</span>.</p>
<div class="definition">
<p>Soit <span class="math inline">\(P\)</span> une matrice carrée
d’ordre <span class="math inline">\(|E|\)</span> où chaque entrée <span
class="math inline">\(P_{ij}\)</span> est définie par</p>
<p><span class="math display">\[P_{ij} = P(X_{n+1} = j \mid X_n = i)
\quad \forall n \in \mathbb{N}, \forall i, j \in E.\]</span></p>
<p>La matrice <span class="math inline">\(P\)</span> est appelée matrice
de transition de la chaîne de Markov.</p>
</div>
<h1 id="théorèmes-de-convergence">Théorèmes de Convergence</h1>
<p>Le théorème fondamental concernant la convergence des chaînes de
Markov est le théorème de convergence ergodique. Ce théorème stipule que
sous certaines conditions, la distribution des états d’une chaîne de
Markov converge vers une distribution stationnaire.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
une chaîne de Markov irréductible et apériodique avec une matrice de
transition <span class="math inline">\(P\)</span>. Alors, il existe une
distribution stationnaire <span class="math inline">\(\pi\)</span> telle
que</p>
<p><span class="math display">\[\lim_{n \to \infty} P(X_n = j \mid X_0 =
i) = \pi_j \quad \forall i, j \in E.\]</span></p>
<p>De plus, la distribution <span class="math inline">\(\pi\)</span> est
unique et vérifie <span class="math inline">\(\pi P = \pi\)</span>.</p>
</div>
<p>Pour démontrer ce théorème, nous avons besoin de plusieurs lemmes et
propriétés.</p>
<div class="lemma">
<p>Soit <span class="math inline">\(P\)</span> une matrice stochastique
irréductible et apériodique. Alors, 1 est la plus grande valeur propre
de <span class="math inline">\(P\)</span> et la matrice <span
class="math inline">\(P^n\)</span> converge vers une matrice dont toutes
les lignes sont égales à la distribution stationnaire <span
class="math inline">\(\pi\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>La preuve du théorème de convergence ergodique repose sur le lemme de
Perron-Frobenius et les propriétés des matrices stochastiques.</p>
<div class="proof">
<p><em>Proof.</em> Considérons une chaîne de Markov <span
class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> avec une matrice
de transition <span class="math inline">\(P\)</span> irréductible et
apériodique. Par le lemme de Perron-Frobenius, 1 est la plus grande
valeur propre de <span class="math inline">\(P\)</span> et la matrice
<span class="math inline">\(P^n\)</span> converge vers une matrice <span
class="math inline">\(\Pi\)</span> où toutes les lignes sont égales à la
distribution stationnaire <span class="math inline">\(\pi\)</span>.</p>
<p>Plus précisément, pour tout <span class="math inline">\(i, j \in
E\)</span>,</p>
<p><span class="math display">\[\lim_{n \to \infty} (P^n)_{ij} =
\pi_j.\]</span></p>
<p>Cela implique que</p>
<p><span class="math display">\[\lim_{n \to \infty} P(X_n = j \mid X_0 =
i) = \pi_j.\]</span></p>
<p>De plus, la distribution <span class="math inline">\(\pi\)</span> est
unique car elle vérifie <span class="math inline">\(\pi P =
\pi\)</span>, ce qui signifie que <span
class="math inline">\(\pi\)</span> est une distribution invariante pour
la chaîne de Markov. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes découlant du
théorème de convergence ergodique.</p>
<ul>
<li><p><strong>Unicité de la Distribution Stationnaire</strong> : La
distribution stationnaire <span class="math inline">\(\pi\)</span> est
unique si et seulement si la chaîne de Markov est irréductible et
apériodique.</p></li>
<li><p><strong>Convergence des Moyennes Empiriques</strong> : Pour une
chaîne de Markov ergodique, la moyenne empirique des états converge vers
l’espérance sous la distribution stationnaire <span
class="math inline">\(\pi\)</span>. Autrement dit,</p>
<p><span class="math display">\[\lim_{n \to \infty} \frac{1}{n}
\sum_{k=0}^{n-1} f(X_k) = \mathbb{E}_{\pi}[f(X)] \quad
\text{p.p.}\]</span></p>
<p>pour toute fonction <span class="math inline">\(f\)</span>
bornée.</p></li>
<li><p><strong>Convergence des Chaînes Réversibles</strong> : Si une
chaîne de Markov est réversible, c’est-à-dire qu’elle vérifie la
condition de dédetail équilibre <span class="math inline">\(\pi_i P_{ij}
= \pi_j P_{ji}\)</span> pour tous <span class="math inline">\(i, j \in
E\)</span>, alors la distribution stationnaire <span
class="math inline">\(\pi\)</span> est donnée par</p>
<p><span class="math display">\[\pi_j = \frac{1}{Z}
\exp\left(-\frac{H(j)}{T}\right),\]</span></p>
<p>où <span class="math inline">\(H(j)\)</span> est l’énergie de l’état
<span class="math inline">\(j\)</span>, <span
class="math inline">\(T\)</span> est la température et <span
class="math inline">\(Z\)</span> est la fonction de partition.</p></li>
</ul>
<h1 id="conclusion">Conclusion</h1>
<p>La convergence des chaînes de Markov est un sujet riche et complexe,
avec des implications profondes en théorie des probabilités et dans de
nombreuses applications pratiques. Le théorème de convergence ergodique,
soutenu par le lemme de Perron-Frobenius, fournit un cadre rigoureux
pour comprendre le comportement asymptotique des chaînes de Markov. Les
propriétés et corollaires dérivés de ce théorème ouvrent la voie à des
avancées dans divers domaines, de l’apprentissage automatique à la
modélisation financière.</p>
</body>
</html>
{% include "footer.html" %}

