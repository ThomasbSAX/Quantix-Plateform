{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Suffisance Bayésienne : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Suffisance Bayésienne : Fondements et
Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La théorie de la décision bayésienne est un pilier fondamental de
l’inférence statistique, offrant une approche cohérente pour intégrer
les informations a priori et les données observées. Au cœur de cette
théorie, la notion de <em>suffisance bayésienne</em> émerge comme un
concept clé pour comprendre comment les données observées encapsulent
toute l’information pertinente concernant le paramètre d’intérêt.</p>
<p>L’origine historique de la suffisance bayésienne remonte aux travaux
pionniers de Thomas Bayes et Ronald Fisher. Bayes a introduit l’idée
d’incorporer des croyances préalables dans l’analyse statistique, tandis
que Fisher a formalisé le concept de statistique suffisante. La fusion
de ces idées a donné naissance à la notion de suffisance bayésienne, qui
joue un rôle crucial dans l’optimisation des procédures d’estimation et
de test d’hypothèses.</p>
<p>Pourquoi la suffisance bayésienne est-elle indispensable ? Elle
permet de réduire l’espace des données à un sous-ensemble minimal
contenant toute l’information nécessaire pour faire des inférences sur
le paramètre. Cela simplifie considérablement les calculs et améliore
l’efficacité des méthodes bayésiennes.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la suffisance bayésienne, commençons par rappeler
quelques concepts fondamentaux. Supposons que nous avons un modèle
statistique défini par une densité de probabilité <span
class="math inline">\(p(x|\theta)\)</span>, où <span
class="math inline">\(x\)</span> représente les données observées et
<span class="math inline">\(\theta\)</span> le paramètre d’intérêt. Une
statistique <span class="math inline">\(T(x)\)</span> est dite
suffisante si elle contient toute l’information des données concernant
<span class="math inline">\(\theta\)</span>.</p>
<p>La suffisance bayésienne étend cette notion en intégrant la
distribution a priori <span class="math inline">\(\pi(\theta)\)</span>.
Nous cherchons à déterminer si une statistique <span
class="math inline">\(T(x)\)</span> est suffisante pour faire des
inférences bayésiennes. Pour ce faire, nous devons montrer que la
distribution a posteriori <span
class="math inline">\(p(\theta|x)\)</span> peut être exprimée uniquement
en fonction de <span class="math inline">\(T(x)\)</span>.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
avec densité de probabilité <span
class="math inline">\(p(x|\theta)\)</span>, où <span
class="math inline">\(\theta \in \Theta\)</span>. Une statistique <span
class="math inline">\(T(X)\)</span> est dite suffisante pour <span
class="math inline">\(\theta\)</span> si, pour tout <span
class="math inline">\(x\)</span> tel que <span
class="math inline">\(p(x|\theta) &gt; 0\)</span>, il existe une
fonction <span class="math inline">\(g\)</span> telle que : <span
class="math display">\[p(x|\theta) = g(T(x), \theta) h(x).\]</span></p>
</div>
<div class="definition">
<p>Une statistique <span class="math inline">\(T(X)\)</span> est dite
bayésiennement suffisante si la distribution a posteriori <span
class="math inline">\(p(\theta|x)\)</span> ne dépend de <span
class="math inline">\(x\)</span> que par l’intermédiaire de <span
class="math inline">\(T(x)\)</span>. Formellement, cela signifie que :
<span class="math display">\[p(\theta|x) = f(T(x), \theta).\]</span></p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Pour établir la suffisance bayésienne, nous devons utiliser des
résultats classiques de la théorie statistique. Le théorème suivant est
fondamental :</p>
<div class="theoreme">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
avec densité de probabilité <span
class="math inline">\(p(x|\theta)\)</span>. Une statistique <span
class="math inline">\(T(X)\)</span> est suffisante pour <span
class="math inline">\(\theta\)</span> si et seulement s’il existe des
fonctions <span class="math inline">\(g\)</span> et <span
class="math inline">\(h\)</span> telles que : <span
class="math display">\[p(x|\theta) = g(T(x), \theta) h(x).\]</span></p>
</div>
<p>Pour démontrer la suffisance bayésienne, nous devons montrer que la
distribution a posteriori ne dépend de <span
class="math inline">\(x\)</span> que par l’intermédiaire de <span
class="math inline">\(T(x)\)</span>. Cela peut être fait en utilisant le
théorème suivant :</p>
<div class="theoreme">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
avec densité de probabilité <span
class="math inline">\(p(x|\theta)\)</span>, et soit <span
class="math inline">\(T(X)\)</span> une statistique suffisante pour
<span class="math inline">\(\theta\)</span>. Supposons que la
distribution a priori <span class="math inline">\(\pi(\theta)\)</span>
est telle que l’intégrale suivante converge : <span
class="math display">\[p(T(x)) = \int_{\Theta} g(T(x), \theta) h(x)
\pi(\theta) d\theta.\]</span> Alors, la distribution a posteriori <span
class="math inline">\(p(\theta|x)\)</span> peut être exprimée comme :
<span class="math display">\[p(\theta|x) = \frac{g(T(x), \theta) h(x)
\pi(\theta)}{p(T(x))}.\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème de la suffisance bayésienne, commençons par
rappeler que <span class="math inline">\(T(X)\)</span> est une
statistique suffisante. Cela signifie que nous pouvons écrire la densité
de probabilité <span class="math inline">\(p(x|\theta)\)</span> sous la
forme : <span class="math display">\[p(x|\theta) = g(T(x), \theta)
h(x).\]</span></p>
<p>En utilisant la définition de la distribution a posteriori, nous
avons : <span class="math display">\[p(\theta|x) = \frac{p(x|\theta)
\pi(\theta)}{p(x)}.\]</span></p>
<p>En substituant l’expression de <span
class="math inline">\(p(x|\theta)\)</span>, nous obtenons : <span
class="math display">\[p(\theta|x) = \frac{g(T(x), \theta) h(x)
\pi(\theta)}{p(x)}.\]</span></p>
<p>Pour montrer que <span class="math inline">\(p(\theta|x)\)</span> ne
dépend de <span class="math inline">\(x\)</span> que par l’intermédiaire
de <span class="math inline">\(T(x)\)</span>, nous devons exprimer <span
class="math inline">\(p(x)\)</span> en fonction de <span
class="math inline">\(T(x)\)</span>. Nous avons : <span
class="math display">\[p(x) = \int_{\Theta} p(x|\theta) \pi(\theta)
d\theta.\]</span></p>
<p>En substituant l’expression de <span
class="math inline">\(p(x|\theta)\)</span>, nous obtenons : <span
class="math display">\[p(x) = \int_{\Theta} g(T(x), \theta) h(x)
\pi(\theta) d\theta.\]</span></p>
<p>En supposant que cette intégrale converge, nous pouvons écrire :
<span class="math display">\[p(x) = h(x) \int_{\Theta} g(T(x), \theta)
\pi(\theta) d\theta.\]</span></p>
<p>En définissant <span class="math inline">\(p(T(x)) = \int_{\Theta}
g(T(x), \theta) \pi(\theta) d\theta\)</span>, nous obtenons finalement :
<span class="math display">\[p(\theta|x) = \frac{g(T(x), \theta) h(x)
\pi(\theta)}{h(x) p(T(x))} = \frac{g(T(x), \theta)
\pi(\theta)}{p(T(x))}.\]</span></p>
<p>Cela montre que <span class="math inline">\(p(\theta|x)\)</span> ne
dépend de <span class="math inline">\(x\)</span> que par l’intermédiaire
de <span class="math inline">\(T(x)\)</span>, ce qui prouve la
suffisance bayésienne.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La notion de suffisance bayésienne possède plusieurs propriétés
importantes :</p>
<ol>
<li><p><strong>Minimalité</strong> : Si <span
class="math inline">\(T(X)\)</span> est une statistique bayésiennement
suffisante, alors elle est aussi minimale, c’est-à-dire qu’elle ne
contient aucune information redondante concernant <span
class="math inline">\(\theta\)</span>.</p></li>
<li><p><strong>Invariance</strong> : La suffisance bayésienne est
invariante sous les transformations de <span
class="math inline">\(\theta\)</span>. Si <span
class="math inline">\(T(X)\)</span> est bayésiennement suffisante pour
<span class="math inline">\(\theta\)</span>, alors elle l’est aussi pour
toute fonction de <span class="math inline">\(\theta\)</span>.</p></li>
<li><p><strong>Consistance</strong> : La suffisance bayésienne est
cohérente avec la théorie de la décision. Si <span
class="math inline">\(T(X)\)</span> est bayésiennement suffisante, alors
toute procédure d’estimation ou de test basée sur <span
class="math inline">\(T(X)\)</span> est admissible.</p></li>
</ol>
<p>Pour démontrer la propriété de minimalité, supposons que <span
class="math inline">\(T(X)\)</span> est une statistique bayésiennement
suffisante. Cela signifie que la distribution a posteriori <span
class="math inline">\(p(\theta|x)\)</span> ne dépend de <span
class="math inline">\(x\)</span> que par l’intermédiaire de <span
class="math inline">\(T(x)\)</span>. Par conséquent, toute autre
statistique <span class="math inline">\(S(X)\)</span> contenant la même
information que <span class="math inline">\(T(X)\)</span> doit être une
fonction de <span class="math inline">\(T(X)\)</span>. Cela montre que
<span class="math inline">\(T(X)\)</span> est minimale.</p>
<p>Pour démontrer la propriété d’invariance, supposons que <span
class="math inline">\(T(X)\)</span> est bayésiennement suffisante pour
<span class="math inline">\(\theta\)</span>. Nous devons montrer qu’elle
l’est aussi pour toute fonction de <span
class="math inline">\(\theta\)</span>, disons <span
class="math inline">\(\psi(\theta)\)</span>. La distribution a
posteriori pour <span class="math inline">\(\psi(\theta)\)</span> est
donnée par : <span class="math display">\[p(\psi(\theta)|x) =
\int_{\Theta} p(\theta|x) \delta(\psi(\theta) - \psi)
d\theta.\]</span></p>
<p>En utilisant l’expression de <span
class="math inline">\(p(\theta|x)\)</span>, nous obtenons : <span
class="math display">\[p(\psi(\theta)|x) = \int_{\Theta} \frac{g(T(x),
\theta) \pi(\theta)}{p(T(x))} \delta(\psi(\theta) - \psi)
d\theta.\]</span></p>
<p>Cette expression ne dépend de <span class="math inline">\(x\)</span>
que par l’intermédiaire de <span class="math inline">\(T(x)\)</span>, ce
qui prouve l’invariance.</p>
<p>Pour démontrer la propriété de consistance, supposons que <span
class="math inline">\(T(X)\)</span> est bayésiennement suffisante. Toute
procédure d’estimation ou de test basée sur <span
class="math inline">\(T(X)\)</span> utilise toute l’information
disponible concernant <span class="math inline">\(\theta\)</span>. Par
conséquent, elle est admissible.</p>
<h1 id="conclusion">Conclusion</h1>
<p>La suffisance bayésienne est un concept fondamental en théorie de la
décision bayésienne. Elle permet de réduire l’espace des données à un
sous-ensemble minimal contenant toute l’information pertinente
concernant le paramètre d’intérêt. Les propriétés de minimalité,
d’invariance et de consistance en font un outil puissant pour
l’optimisation des procédures d’estimation et de test d’hypothèses.</p>
<p>En conclusion, la suffisance bayésienne joue un rôle clé dans
l’inférence statistique. Elle offre une approche cohérente pour intégrer
les informations a priori et les données observées, simplifiant
considérablement les calculs et améliorant l’efficacité des méthodes
bayésiennes.</p>
</body>
</html>
{% include "footer.html" %}

