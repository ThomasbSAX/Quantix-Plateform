{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Encodage par extraction de caractéristiques de binning par normalisation robuste</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Encodage par extraction de caractéristiques de binning
par normalisation robuste</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’encodage des variables catégorielles est une étape cruciale dans de
nombreux domaines de l’apprentissage automatique et du traitement des
données. Les méthodes traditionnelles, telles que le one-hot encoding ou
l’encodage par moyenne ciblée, présentent des limitations importantes.
L’encodage par extraction de caractéristiques de binning par
normalisation robuste (RBNE) émerge comme une solution innovante pour
surmonter ces défis.</p>
<p>L’idée centrale derrière le RBNE est de transformer les variables
catégorielles en caractéristiques numériques robustes, tout en
préservant l’information statistique sous-jacente. Cette approche est
particulièrement utile dans les contextes où les données sont bruitées
ou incomplètes, car elle permet de normaliser les caractéristiques
extraites de manière robuste.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant de définir formellement le RBNE, il est essentiel de comprendre
les concepts sous-jacents. Supposons que nous ayons une variable
catégorielle <span class="math inline">\(X\)</span> avec <span
class="math inline">\(k\)</span> catégories distinctes. Notre objectif
est de transformer cette variable en un ensemble de caractéristiques
numériques <span class="math inline">\(\mathbf{Z} = (Z_1, Z_2, \ldots,
Z_m)\)</span>, où <span class="math inline">\(m\)</span> est le nombre
de caractéristiques extraites.</p>
<p>Pour ce faire, nous devons d’abord diviser les données en intervalles
ou "bins". Soit <span class="math inline">\(B_1, B_2, \ldots,
B_n\)</span> les bins obtenus. Ensuite, pour chaque bin <span
class="math inline">\(B_i\)</span>, nous calculons une statistique
robuste, telle que la médiane ou un quantile.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X\)</span> une variable catégorielle
avec <span class="math inline">\(k\)</span> catégories. Soit <span
class="math inline">\(B_1, B_2, \ldots, B_n\)</span> les bins obtenus
par une méthode de binning appropriée. Pour chaque bin <span
class="math inline">\(B_i\)</span>, nous définissons la caractéristique
normalisée robuste <span class="math inline">\(Z_i\)</span> comme suit :
<span class="math display">\[Z_i = \frac{\text{Med}(Y | X \in B_i) -
\mu}{\sigma}\]</span> où <span class="math inline">\(\text{Med}(Y | X
\in B_i)\)</span> est la médiane de <span
class="math inline">\(Y\)</span> conditionnellement à <span
class="math inline">\(X \in B_i\)</span>, <span
class="math inline">\(\mu\)</span> est la moyenne globale de <span
class="math inline">\(Y\)</span>, et <span
class="math inline">\(\sigma\)</span> est l’écart-type global de <span
class="math inline">\(Y\)</span>.</p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Pour comprendre l’efficacité du RBNE, il est utile d’examiner
certains théorèmes clés. Supposons que nous ayons un modèle de
régression linéaire <span class="math inline">\(Y = \beta_0 +
\mathbf{Z}^T \boldsymbol{\beta} + \epsilon\)</span>, où <span
class="math inline">\(\mathbf{Z}\)</span> est le vecteur de
caractéristiques extraites par RBNE.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>
l’estimateur des moindres carrés de <span
class="math inline">\(\boldsymbol{\beta}\)</span>. Si les bins sont
construits de manière à minimiser la variance intra-bin et à maximiser
la variance inter-bins, alors <span
class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> est
consistent.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve de ce théorème repose sur le fait que la
normalisation robuste réduit la variance des caractéristiques extraites,
ce qui améliore la stabilité de l’estimateur des moindres carrés. En
outre, le binning approprié garantit que les caractéristiques extraites
capturent l’information statistique pertinente.</p>
<p>Formellement, nous avons : <span
class="math display">\[\hat{\boldsymbol{\beta}} = (\mathbf{Z}^T
\mathbf{Z})^{-1} \mathbf{Z}^T Y\]</span> où <span
class="math inline">\(\mathbf{Z}\)</span> est la matrice de design avec
les caractéristiques extraites par RBNE. La consistance de <span
class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> découle du
théorème central limite et des propriétés de la normalisation
robuste. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour illustrer les propriétés du RBNE, considérons un exemple simple.
Supposons que nous ayons une variable catégorielle <span
class="math inline">\(X\)</span> avec trois catégories : "Faible",
"Moyen" et "Élevé". Nous divisons les données en trois bins
correspondants.</p>
<div class="proof">
<p><em>Proof.</em> Pour chaque bin <span
class="math inline">\(B_i\)</span>, nous calculons la médiane de <span
class="math inline">\(Y\)</span> conditionnellement à <span
class="math inline">\(X \in B_i\)</span>. Ensuite, nous normalisons ces
médianes en utilisant la moyenne globale <span
class="math inline">\(\mu\)</span> et l’écart-type global <span
class="math inline">\(\sigma\)</span>.</p>
<p>Les caractéristiques extraites sont : <span
class="math display">\[Z_1 = \frac{\text{Med}(Y | X \in B_1) -
\mu}{\sigma}, \quad Z_2 = \frac{\text{Med}(Y | X \in B_2) -
\mu}{\sigma}, \quad Z_3 = \frac{\text{Med}(Y | X \in B_3) -
\mu}{\sigma}\]</span></p>
<p>En utilisant ces caractéristiques dans un modèle de régression
linéaire, nous pouvons montrer que l’estimateur des moindres carrés est
consistent. Cela découle du fait que la normalisation robuste réduit la
variance des caractéristiques extraites, ce qui améliore la stabilité de
l’estimateur. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le RBNE présente plusieurs propriétés intéressantes qui en font une
méthode puissante pour l’encodage des variables catégorielles.</p>
<ul>
<li><p><strong>Robustesse aux valeurs aberrantes</strong> : La
normalisation robuste rend les caractéristiques extraites moins
sensibles aux valeurs aberrantes dans les données.</p></li>
<li><p><strong>Consistance</strong> : Comme démontré précédemment,
l’utilisation du RBNE dans un modèle de régression linéaire conduit à
des estimateurs consistants.</p></li>
<li><p><strong>Interprétabilité</strong> : Les caractéristiques
extraites par RBNE peuvent être interprétées comme des mesures de la
relation entre la variable catégorielle et la variable cible, ce qui
facilite l’interprétation du modèle.</p></li>
</ul>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’encodage par extraction de caractéristiques de binning par
normalisation robuste est une méthode puissante pour transformer les
variables catégorielles en caractéristiques numériques robustes. Cette
approche offre plusieurs avantages, notamment la robustesse aux valeurs
aberrantes, la consistance des estimateurs et l’interprétabilité des
caractéristiques extraites. En intégrant le RBNE dans les modèles
d’apprentissage automatique, nous pouvons améliorer la performance et la
fiabilité des prédictions.</p>
</body>
</html>
{% include "footer.html" %}

