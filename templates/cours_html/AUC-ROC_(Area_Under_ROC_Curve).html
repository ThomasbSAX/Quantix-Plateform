{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’AUC-ROC : Une mesure fondamentale en apprentissage automatique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’AUC-ROC : Une mesure fondamentale en apprentissage
automatique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’apprentissage automatique est un domaine en pleine expansion, où la
capacité à évaluer la performance des modèles est cruciale. Parmi les
nombreuses métriques disponibles, l’AUC-ROC (Area Under the Receiver
Operating Characteristic Curve) se distingue comme une mesure
essentielle pour les tâches de classification binaire. Cette métrique
émerge d’un besoin fondamental : quantifier la capacité d’un modèle à
distinguer les classes positives des classes négatives, indépendamment
du seuil de classification choisi.</p>
<p>L’AUC-ROC trouve ses racines dans la théorie des tests statistiques,
où la courbe ROC (Receiver Operating Characteristic) a été initialement
utilisée pour évaluer les performances des systèmes de détection. En
apprentissage automatique, cette courbe est devenue un outil
incontournable pour visualiser le compromis entre le taux de vrais
positifs (sensibilité) et le taux de faux positifs (1-spécificité).
L’aire sous cette courbe, l’AUC-ROC, offre une mesure unique et globale
de la performance du modèle.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre l’AUC-ROC, il est essentiel de définir d’abord les
concepts fondamentaux qui la composent.</p>
<h2 id="taux-de-vrais-positifs-et-taux-de-faux-positifs">Taux de vrais
positifs et taux de faux positifs</h2>
<p>Considérons un problème de classification binaire où nous avons deux
classes : positive et négative. Pour un seuil de classification donné,
notons :</p>
<ul>
<li><p><span class="math inline">\(TP\)</span> (True Positives) : le
nombre de vrais positifs,</p></li>
<li><p><span class="math inline">\(FP\)</span> (False Positives) : le
nombre de faux positifs,</p></li>
<li><p><span class="math inline">\(TN\)</span> (True Negatives) : le
nombre de vrais négatifs,</p></li>
<li><p><span class="math inline">\(FN\)</span> (False Negatives) : le
nombre de faux négatifs.</p></li>
</ul>
<p>Le taux de vrais positifs (ou sensibilité) est défini comme : <span
class="math display">\[TPR = \frac{TP}{TP + FN}\]</span> Le taux de faux
positifs est défini comme : <span class="math display">\[FPR =
\frac{FP}{FP + TN}\]</span></p>
<h2 id="courbe-roc">Courbe ROC</h2>
<p>La courbe ROC est un graphique qui représente le taux de vrais
positifs (<span class="math inline">\(TPR\)</span>) en fonction du taux
de faux positifs (<span class="math inline">\(FPR\)</span>) pour
différents seuils de classification. Formellement, la courbe ROC est une
fonction <span class="math inline">\(ROC : [0, 1] \rightarrow [0,
1]\)</span> définie par : <span class="math display">\[ROC(t) = (FPR(t),
TPR(t)) \quad \text{pour} \quad t \in [0, 1]\]</span> où <span
class="math inline">\(t\)</span> représente le seuil de
classification.</p>
<h2 id="auc-roc">AUC-ROC</h2>
<p>L’AUC-ROC est l’aire sous la courbe ROC. Elle peut être définie comme
: <span class="math display">\[AUC = \int_{0}^{1} TPR(FPR^{-1}(f)) \,
df\]</span> où <span class="math inline">\(FPR^{-1}\)</span> est la
fonction inverse du taux de faux positifs. Une autre formulation
équivalente est : <span class="math display">\[AUC =
\int_{-\infty}^{+\infty} TPR(t) \cdot f_{FPR}(t) \, dt\]</span> où <span
class="math inline">\(f_{FPR}\)</span> est la densité de probabilité du
taux de faux positifs.</p>
<h1 id="théorèmes">Théorèmes</h1>
<h2 id="propriétés-de-lauc-roc">Propriétés de l’AUC-ROC</h2>
<p>L’AUC-ROC possède plusieurs propriétés importantes qui en font une
mesure robuste et informative.</p>
<div class="theorem">
<p>L’AUC-ROC vérifie les propriétés suivantes :</p>
<ol>
<li><p><span class="math inline">\(0 \leq AUC \leq 1\)</span>,</p></li>
<li><p>Si le modèle est parfait, alors <span class="math inline">\(AUC =
1\)</span>,</p></li>
<li><p>Si le modèle est équivalent à un tirage aléatoire, alors <span
class="math inline">\(AUC = 0.5\)</span>.</p></li>
</ol>
</div>
<h2 id="lien-avec-la-probabilité-de-classement-correct">Lien avec la
probabilité de classement correct</h2>
<p>L’AUC-ROC est également liée à la probabilité que le modèle classe
correctement une paire d’échantillons, l’un positif et l’autre
négatif.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(P\)</span> la probabilité que le
modèle classe correctement une paire d’échantillons, l’un positif et
l’autre négatif. Alors : <span class="math display">\[AUC =
P\]</span></p>
</div>
<h1 id="preuves">Preuves</h1>
<h2 id="preuve-de-la-propriété-de-lauc-roc">Preuve de la propriété de
l’AUC-ROC</h2>
<p>Pour prouver les propriétés de l’AUC-ROC, nous procédons comme suit
:</p>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p>Pour montrer que <span class="math inline">\(0 \leq AUC \leq
1\)</span>, notons que la courbe ROC est toujours située entre les
points <span class="math inline">\((0, 0)\)</span> et <span
class="math inline">\((1, 1)\)</span>. L’aire sous cette courbe est donc
comprise entre 0 (si la courbe passe par <span class="math inline">\((0,
0)\)</span> et <span class="math inline">\((1, 1)\)</span>) et 1 (si la
courbe passe par <span class="math inline">\((0, 1)\)</span> et <span
class="math inline">\((1, 1)\)</span>).</p></li>
<li><p>Si le modèle est parfait, alors pour tout seuil <span
class="math inline">\(t\)</span>, <span class="math inline">\(TPR(t) =
1\)</span> et <span class="math inline">\(FPR(t) = 0\)</span>. La courbe
ROC passe donc par <span class="math inline">\((0, 1)\)</span> et <span
class="math inline">\((1, 1)\)</span>, et l’aire sous la courbe est
égale à 1.</p></li>
<li><p>Si le modèle est équivalent à un tirage aléatoire, alors pour
tout seuil <span class="math inline">\(t\)</span>, <span
class="math inline">\(TPR(t) = FPR(t)\)</span>. La courbe ROC est la
première bissectrice, et l’aire sous la courbe est égale à 0.5.</p></li>
</ol>
<p> ◻</p>
</div>
<h2 id="preuve-du-lien-avec-la-probabilité-de-classement-correct">Preuve
du lien avec la probabilité de classement correct</h2>
<p>Pour prouver le lien entre l’AUC-ROC et la probabilité de classement
correct, nous procédons comme suit :</p>
<div class="proof">
<p><em>Proof.</em> Considérons une paire d’échantillons, l’un positif et
l’autre négatif. La probabilité que le modèle classe correctement cette
paire est égale à la probabilité que le score du modèle pour
l’échantillon positif soit supérieur au score pour l’échantillon
négatif. Cette probabilité est exactement l’AUC-ROC. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<h2 id="propriétés-de-lauc-roc-1">Propriétés de l’AUC-ROC</h2>
<p>L’AUC-ROC possède plusieurs propriétés supplémentaires qui en font
une mesure robuste et informative.</p>
<ol>
<li><p><strong>Invariance par transformation monotone</strong> :
L’AUC-ROC est invariant par toute transformation monotone des scores du
modèle. Cela signifie que l’AUC-ROC reste inchangé si nous appliquons
une fonction strictement croissante aux scores du modèle.</p></li>
<li><p><strong>Stabilité</strong> : L’AUC-ROC est une mesure stable,
c’est-à-dire qu’elle ne varie pas beaucoup lorsque de petits changements
sont apportés aux données ou au modèle.</p></li>
<li><p><strong>Interprétabilité</strong> : L’AUC-ROC est facile à
interpréter. Une valeur proche de 1 indique un modèle performant, tandis
qu’une valeur proche de 0.5 indique un modèle équivalent à un tirage
aléatoire.</p></li>
</ol>
<h2 id="corollaires">Corollaires</h2>
<div class="corollary">
<p>Si deux modèles ont des courbes ROC qui ne se croisent pas, alors le
modèle avec la plus grande AUC-ROC est strictement meilleur que l’autre
pour tous les seuils de classification.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Si deux courbes ROC ne se croisent pas, alors l’une
est toujours au-dessus de l’autre. Par conséquent, pour tout seuil de
classification, le modèle avec la courbe ROC supérieure aura un taux de
vrais positifs plus élevé pour un taux de faux positifs donné. Cela
implique que le modèle avec la plus grande AUC-ROC est strictement
meilleur. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>L’AUC-ROC est une mesure fondamentale en apprentissage automatique,
offrant une évaluation globale et robuste de la performance des modèles
de classification binaire. Ses propriétés mathématiques solides, son
interprétation intuitive et sa stabilité en font un outil indispensable
pour les chercheurs et les praticiens. En comprenant profondément
l’AUC-ROC, nous pouvons mieux évaluer et améliorer nos modèles,
contribuant ainsi à l’avancement de l’apprentissage automatique.</p>
</body>
</html>
{% include "footer.html" %}

