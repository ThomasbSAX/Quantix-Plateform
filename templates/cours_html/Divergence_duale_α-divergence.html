{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Divergence duale et \alpha-divergence : Une exploration mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Divergence duale et <span
class="math inline">\(\alpha\)</span>-divergence : Une exploration
mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’étude des divergences en théorie de l’information a toujours été un
champ fertile pour les mathématiciens et les statisticiens. Parmi
celles-ci, la divergence duale et l’<span
class="math inline">\(\alpha\)</span>-divergence occupent une place
particulière en raison de leurs propriétés remarquables et de leur
utilité dans divers domaines, allant de la théorie des codes à
l’apprentissage automatique.</p>
<p>La divergence duale émerge naturellement comme une généralisation de
la divergence de Kullback-Leibler, permettant d’incorporer des
contraintes supplémentaires et offrant une flexibilité accrue dans les
modèles probabilistes. L’<span
class="math inline">\(\alpha\)</span>-divergence, quant à elle, est une
famille de divergences paramétrées par un réel <span
class="math inline">\(\alpha\)</span>, qui englobe plusieurs mesures
classiques comme la divergence de Kullback-Leibler et la divergence de
Hellinger.</p>
<p>Dans cet article, nous explorerons ces notions en détail, en
commençant par leurs définitions formelles, puis en examinant leurs
propriétés et les théorèmes associés. Nous mettrons un accent
particulier sur les preuves rigoureuses de ces résultats, en utilisant
des quantificateurs et des notations mathématiques précises.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant de définir formellement la divergence duale et l’<span
class="math inline">\(\alpha\)</span>-divergence, il est essentiel de
comprendre ce que nous cherchons à capturer. Nous voulons mesurer la
distance entre deux distributions de probabilité <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span>, mais de manière à ce que cette mesure
soit invariante sous certaines transformations et qu’elle satisfasse des
propriétés spécifiques, telles que la convexité.</p>
<h2 class="unnumbered" id="divergence-duale">Divergence Duale</h2>
<p>Nous cherchons une mesure de divergence <span
class="math inline">\(D(P \parallel Q)\)</span> qui soit duale à la
divergence de Kullback-Leibler, c’est-à-dire qu’elle satisfait certaines
conditions de symétrie et d’invariance. Plus précisément, nous voulons
que cette divergence soit définie pour des distributions <span
class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> telles que <span
class="math inline">\(P\)</span> est absolument continue par rapport à
<span class="math inline">\(Q\)</span>.</p>
<div class="definition">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilité sur
un espace mesurable <span class="math inline">\(\Omega\)</span>, avec
<span class="math inline">\(P\)</span> absolument continue par rapport à
<span class="math inline">\(Q\)</span>. La divergence duale de <span
class="math inline">\(P\)</span> par rapport à <span
class="math inline">\(Q\)</span> est définie comme : <span
class="math display">\[D(P \parallel Q) = \sup_{f \in \mathcal{F}}
\left( \mathbb{E}_P[f] - \log \mathbb{E}_Q[e^f] \right),\]</span> où
<span class="math inline">\(\mathcal{F}\)</span> est l’ensemble des
fonctions mesurables bornées.</p>
</div>
<p>De manière équivalente, on peut écrire : <span
class="math display">\[D(P \parallel Q) = \sup_{f} \left( \int_{\Omega}
f \, dP - \log \int_{\Omega} e^f \, dQ \right).\]</span></p>
<h2 class="unnumbered" id="alpha-divergence"><span
class="math inline">\(\alpha\)</span>-Divergence</h2>
<p>Nous cherchons une famille de divergences paramétrées par un réel
<span class="math inline">\(\alpha\)</span> qui généralise la divergence
de Kullback-Leibler. Cette famille doit inclure des mesures classiques
pour certaines valeurs spécifiques de <span
class="math inline">\(\alpha\)</span>.</p>
<div class="definition">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilité sur
un espace mesurable <span class="math inline">\(\Omega\)</span>, avec
<span class="math inline">\(P\)</span> absolument continue par rapport à
<span class="math inline">\(Q\)</span>. L’<span
class="math inline">\(\alpha\)</span>-divergence de <span
class="math inline">\(P\)</span> par rapport à <span
class="math inline">\(Q\)</span> est définie comme : <span
class="math display">\[D_{\alpha}(P \parallel Q) = \frac{4}{1 -
\alpha^2} \left( 1 - \int_{\Omega} \left( \frac{dP}{dQ} \right)^{\frac{1
- \alpha}{2}} \, dQ \right),\]</span> pour <span
class="math inline">\(\alpha \in (-1, 1) \setminus \{0\}\)</span>.</p>
</div>
<p>Pour <span class="math inline">\(\alpha = 0\)</span>, on retrouve la
divergence de Kullback-Leibler : <span class="math display">\[D_{KL}(P
\parallel Q) = \int_{\Omega} \log \left( \frac{dP}{dQ} \right) \,
dP.\]</span></p>
<p>Pour <span class="math inline">\(\alpha = 1\)</span>, on obtient la
divergence de Hellinger : <span class="math display">\[D_{H}(P \parallel
Q) = 2 \left( 1 - \int_{\Omega} \sqrt{\frac{dP}{dQ}} \, dQ
\right).\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<h2 class="unnumbered" id="théorème-de-la-divergence-duale">Théorème de
la Divergence Duale</h2>
<p>Nous cherchons à établir une relation entre la divergence duale et la
divergence de Kullback-Leibler. Plus précisément, nous voulons montrer
que la divergence duale est égale à la divergence de Kullback-Leibler
sous certaines conditions.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilité sur
un espace mesurable <span class="math inline">\(\Omega\)</span>, avec
<span class="math inline">\(P\)</span> absolument continue par rapport à
<span class="math inline">\(Q\)</span>. Alors, <span
class="math display">\[D(P \parallel Q) = D_{KL}(P \parallel
Q).\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Nous commençons par remarquer que pour toute fonction
<span class="math inline">\(f\)</span> mesurable bornée, nous avons :
<span class="math display">\[\mathbb{E}_P[f] - \log \mathbb{E}_Q[e^f] =
\int_{\Omega} f \, dP - \log \int_{\Omega} e^f \, dQ.\]</span></p>
<p>En utilisant l’inégalité de Jensen, nous obtenons : <span
class="math display">\[\int_{\Omega} f \, dP - \log \int_{\Omega} e^f \,
dQ \leq \int_{\Omega} f \, dP - \int_{\Omega} \log e^f \, dQ =
\int_{\Omega} f \, dP - \int_{\Omega} f \, dQ.\]</span></p>
<p>En prenant la supériorité sur toutes les fonctions <span
class="math inline">\(f\)</span> mesurables bornées, nous avons : <span
class="math display">\[D(P \parallel Q) \leq D_{KL}(P \parallel
Q).\]</span></p>
<p>Pour montrer l’égalité, nous choisissons <span
class="math inline">\(f = \log \left( \frac{dP}{dQ} \right)\)</span>. En
effet, cette fonction est bien définie et bornée car <span
class="math inline">\(P\)</span> est absolument continue par rapport à
<span class="math inline">\(Q\)</span>. En substituant cette fonction
dans la définition de la divergence duale, nous obtenons : <span
class="math display">\[D(P \parallel Q) = D_{KL}(P \parallel
Q).\]</span></p>
<p>Ceci conclut la preuve. ◻</p>
</div>
<h2 class="unnumbered" id="théorème-de-lalpha-divergence">Théorème de
l’<span class="math inline">\(\alpha\)</span>-Divergence</h2>
<p>Nous cherchons à établir une relation entre l’<span
class="math inline">\(\alpha\)</span>-divergence et la divergence de
Kullback-Leibler. Plus précisément, nous voulons montrer que l’<span
class="math inline">\(\alpha\)</span>-divergence est une généralisation
de la divergence de Kullback-Leibler.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(P\)</span> et <span
class="math inline">\(Q\)</span> deux distributions de probabilité sur
un espace mesurable <span class="math inline">\(\Omega\)</span>, avec
<span class="math inline">\(P\)</span> absolument continue par rapport à
<span class="math inline">\(Q\)</span>. Alors, pour tout <span
class="math inline">\(\alpha \in (-1, 1) \setminus \{0\}\)</span>, <span
class="math display">\[\lim_{\alpha \to 0} D_{\alpha}(P \parallel Q) =
D_{KL}(P \parallel Q).\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Nous commençons par réécrire l’<span
class="math inline">\(\alpha\)</span>-divergence : <span
class="math display">\[D_{\alpha}(P \parallel Q) = \frac{4}{1 -
\alpha^2} \left( 1 - \int_{\Omega} \left( \frac{dP}{dQ} \right)^{\frac{1
- \alpha}{2}} \, dQ \right).\]</span></p>
<p>Nous utilisons le développement de Taylor de la fonction
exponentielle autour de <span class="math inline">\(\alpha = 0\)</span>
: <span class="math display">\[\left( \frac{dP}{dQ} \right)^{\frac{1 -
\alpha}{2}} = e^{\frac{1 - \alpha}{2} \log \left( \frac{dP}{dQ} \right)}
= 1 + \frac{1 - \alpha}{2} \log \left( \frac{dP}{dQ} \right) +
o(\alpha).\]</span></p>
<p>En substituant ce développement dans l’expression de l’<span
class="math inline">\(\alpha\)</span>-divergence, nous obtenons : <span
class="math display">\[D_{\alpha}(P \parallel Q) = \frac{4}{1 -
\alpha^2} \left( 1 - \int_{\Omega} \left( 1 + \frac{1 - \alpha}{2} \log
\left( \frac{dP}{dQ} \right) + o(\alpha) \right) \, dQ
\right).\]</span></p>
<p>En simplifiant, nous avons : <span
class="math display">\[D_{\alpha}(P \parallel Q) = \frac{4}{1 -
\alpha^2} \left( -\frac{1 - \alpha}{2} \int_{\Omega} \log \left(
\frac{dP}{dQ} \right) \, dP + o(\alpha) \right).\]</span></p>
<p>En prenant la limite lorsque <span
class="math inline">\(\alpha\)</span> tend vers <span
class="math inline">\(0\)</span>, nous obtenons : <span
class="math display">\[\lim_{\alpha \to 0} D_{\alpha}(P \parallel Q) =
D_{KL}(P \parallel Q).\]</span></p>
<p>Ceci conclut la preuve. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<h2 class="unnumbered" id="propriétés-de-la-divergence-duale">Propriétés
de la Divergence Duale</h2>
<ol>
<li><p>La divergence duale est toujours non négative : <span
class="math display">\[D(P \parallel Q) \geq 0.\]</span></p></li>
<li><p>La divergence duale est invariante sous les transformations
mesurables : Si <span class="math inline">\(T : \Omega \to
\Omega&#39;\)</span> est une transformation mesurable et bijective,
alors <span class="math display">\[D(P \parallel Q) = D(T_{\#}P
\parallel T_{\#}Q),\]</span> où <span
class="math inline">\(T_{\#}P\)</span> et <span
class="math inline">\(T_{\#}Q\)</span> sont les mesures poussées par
<span class="math inline">\(T\)</span>.</p></li>
<li><p>La divergence duale satisfait l’inégalité de triangle : <span
class="math display">\[D(P \parallel R) \leq D(P \parallel Q) + D(Q
\parallel R).\]</span></p></li>
</ol>
<h2 class="unnumbered" id="propriétés-de-lalpha-divergence">Propriétés
de l’<span class="math inline">\(\alpha\)</span>-Divergence</h2>
<ol>
<li><p>L’<span class="math inline">\(\alpha\)</span>-divergence est
toujours non négative : <span class="math display">\[D_{\alpha}(P
\parallel Q) \geq 0.\]</span></p></li>
<li><p>L’<span class="math inline">\(\alpha\)</span>-divergence est
symétrique pour <span class="math inline">\(\alpha = -1\)</span> : <span
class="math display">\[D_{-1}(P \parallel Q) = D_{-1}(Q \parallel
P).\]</span></p></li>
<li><p>L’<span class="math inline">\(\alpha\)</span>-divergence
satisfait l’inégalité de triangle pour certains <span
class="math inline">\(\alpha\)</span> : <span
class="math display">\[D_{\alpha}(P \parallel R) \leq D_{\alpha}(P
\parallel Q) + D_{\alpha}(Q \parallel R).\]</span></p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Dans cet article, nous avons exploré en détail la divergence duale et
l’<span class="math inline">\(\alpha\)</span>-divergence, deux notions
fondamentales en théorie de l’information. Nous avons vu comment ces
divergences généralisent la divergence de Kullback-Leibler et comment
elles peuvent être utilisées pour mesurer la distance entre deux
distributions de probabilité. Les théorèmes et les propriétés présentés
offrent une base solide pour des applications futures dans divers
domaines, tels que l’apprentissage automatique et la théorie des
codes.</p>
</body>
</html>
{% include "footer.html" %}

