{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Évidence bayésienne : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Évidence bayésienne : Fondements et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’évidence bayésienne, ou facteur de Bayes, émerge comme un outil
fondamental dans le cadre de l’inférence statistique bayésienne. Son
origine remonte aux travaux pionniers de Thomas Bayes au XVIIIe siècle,
mais c’est avec la formalisation moderne de l’analyse bayésienne que
cette notion a pris toute son ampleur. L’évidence bayésienne permet de
quantifier le degré de soutien qu’une donnée apporte à une hypothèse par
rapport à une autre. Elle est indispensable dans les domaines où la
prise de décision repose sur des probabilités a posteriori, comme en
médecine, en finance ou en intelligence artificielle.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire l’évidence bayésienne, considérons deux hypothèses
<span class="math inline">\(H_0\)</span> et <span
class="math inline">\(H_1\)</span>, et une donnée <span
class="math inline">\(D\)</span>. Nous cherchons à mesurer comment la
donnée <span class="math inline">\(D\)</span> influence notre croyance
en ces hypothèses. Intuitivement, l’évidence bayésienne compare les
probabilités des données sous chaque hypothèse.</p>
<div class="definition">
<p>Soient <span class="math inline">\(H_0\)</span> et <span
class="math inline">\(H_1\)</span> deux hypothèses, et <span
class="math inline">\(D\)</span> une donnée. L’évidence bayésienne en
faveur de <span class="math inline">\(H_1\)</span> par rapport à <span
class="math inline">\(H_0\)</span> est définie comme le rapport des
probabilités des données sous chaque hypothèse : <span
class="math display">\[B_{10} = \frac{P(D|H_1)}{P(D|H_0)}\]</span> où
<span class="math inline">\(P(D|H_i)\)</span> est la probabilité des
données <span class="math inline">\(D\)</span> sous l’hypothèse <span
class="math inline">\(H_i\)</span>, pour <span
class="math inline">\(i=0,1\)</span>.</p>
</div>
<p>Une autre formulation de l’évidence bayésienne utilise les densités
de probabilité. Si <span class="math inline">\(f(D|H_i)\)</span>
représente la densité de probabilité des données <span
class="math inline">\(D\)</span> sous l’hypothèse <span
class="math inline">\(H_i\)</span>, alors : <span
class="math display">\[B_{10} = \frac{\int f(D|\theta, H_1)
\pi(\theta|H_1) d\theta}{\int f(D|\theta, H_0) \pi(\theta|H_0)
d\theta}\]</span> où <span
class="math inline">\(\pi(\theta|H_i)\)</span> est la distribution a
priori de <span class="math inline">\(\theta\)</span> sous l’hypothèse
<span class="math inline">\(H_i\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème central en inférence bayésienne est le théorème de Bayes,
qui relie les probabilités a priori et a posteriori.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(H\)</span> une hypothèse et <span
class="math inline">\(D\)</span> une donnée. La probabilité a posteriori
de l’hypothèse <span class="math inline">\(H\)</span> donné les données
<span class="math inline">\(D\)</span> est : <span
class="math display">\[P(H|D) = \frac{P(D|H) P(H)}{P(D)}\]</span> où
<span class="math inline">\(P(D) = \sum_{i} P(D|H_i) P(H_i)\)</span> est
l’évidence marginale des données.</p>
</div>
<p>Une autre formulation du théorème de Bayes utilise les densités de
probabilité : <span class="math display">\[f(\theta|D) =
\frac{f(D|\theta) \pi(\theta)}{\int f(D|\theta) \pi(\theta)
d\theta}\]</span> où <span class="math inline">\(f(\theta|D)\)</span>
est la densité a posteriori de <span
class="math inline">\(\theta\)</span> donné les données <span
class="math inline">\(D\)</span>, et <span
class="math inline">\(\pi(\theta)\)</span> est la densité a priori de
<span class="math inline">\(\theta\)</span>.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de Bayes, nous partons de la définition de
la probabilité conditionnelle : <span class="math display">\[P(H|D) =
\frac{P(D \cap H)}{P(D)}\]</span> En utilisant la loi des probabilités
totales, nous avons : <span class="math display">\[P(D) = \sum_{i}
P(D|H_i) P(H_i)\]</span> En substituant cette expression dans la
définition de <span class="math inline">\(P(H|D)\)</span>, nous obtenons
: <span class="math display">\[P(H|D) = \frac{P(D|H) P(H)}{\sum_{i}
P(D|H_i) P(H_i)}\]</span> Ceci achève la preuve du théorème de
Bayes.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’évidence bayésienne possède plusieurs propriétés importantes :</p>
<ol>
<li><p><strong>Propriété de symétrie</strong> : L’évidence bayésienne en
faveur de <span class="math inline">\(H_0\)</span> par rapport à <span
class="math inline">\(H_1\)</span> est l’inverse de l’évidence
bayésienne en faveur de <span class="math inline">\(H_1\)</span> par
rapport à <span class="math inline">\(H_0\)</span> : <span
class="math display">\[B_{01} = \frac{1}{B_{10}}\]</span></p></li>
<li><p><strong>Propriété de transitivité</strong> : Si <span
class="math inline">\(H_0\)</span>, <span
class="math inline">\(H_1\)</span> et <span
class="math inline">\(H_2\)</span> sont trois hypothèses, alors : <span
class="math display">\[B_{10} \cdot B_{21} = B_{20}\]</span></p></li>
<li><p><strong>Propriété de combinaison</strong> : Si <span
class="math inline">\(D_1\)</span> et <span
class="math inline">\(D_2\)</span> sont deux ensembles de données
indépendants, alors : <span class="math display">\[B_{10}(D_1 \cup D_2)
= B_{10}(D_1) \cdot B_{10}(D_2)\]</span></p></li>
</ol>
<p>La preuve de ces propriétés découle directement des définitions et
des propriétés des probabilités conditionnelles.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’évidence bayésienne est un outil puissant pour comparer des
hypothèses en présence de données. Elle trouve des applications dans de
nombreux domaines, de la médecine à l’intelligence artificielle, en
passant par la finance. Sa formalisation rigoureuse permet de prendre
des décisions éclairées basées sur des probabilités a posteriori.</p>
</body>
</html>
{% include "footer.html" %}

