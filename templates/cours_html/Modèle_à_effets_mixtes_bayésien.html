{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Modèle à effets mixtes bayésien</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Modèle à effets mixtes bayésien</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les modèles à effets mixtes bayésiens constituent une avancée majeure
dans l’analyse statistique des données hiérarchiques ou longitudinales.
Ces modèles permettent de capturer la variabilité à différents niveaux
tout en intégrant des informations a priori, offrant ainsi une
flexibilité et une puissance prédictive accrues.</p>
<p>L’émergence de ces modèles est motivée par la nécessité de modéliser
des structures complexes où les observations sont regroupées en clusters
ou mesurées à plusieurs reprises sur les mêmes unités. Les approches
classiques, telles que les modèles linéaires généralisés (GLM), peinent
à capturer cette hiérarchie, conduisant souvent à des estimations
biaisées ou inefficaces.</p>
<p>Les modèles à effets mixtes bayésiens résolvent ce problème en
introduisant des effets aléatoires, modélisés par des distributions a
priori, qui capturent la variabilité intra-clusters. Cette approche
permet non seulement de mieux estimer les paramètres fixes, mais aussi
d’inférer sur la distribution des effets aléatoires.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre les modèles à effets mixtes bayésiens, il est
essentiel de définir les concepts clés.</p>
<div class="definition">
<p><strong>Définition 1</strong> (Modèle à effets mixtes).
<em>Considérons un ensemble de données hiérarchiques où chaque
observation <span class="math inline">\(y_{ij}\)</span> est associée à
une unité <span class="math inline">\(i\)</span> et à un cluster <span
class="math inline">\(j\)</span>. Nous cherchons à modéliser la relation
entre une variable réponse <span class="math inline">\(y_{ij}\)</span>
et un ensemble de covariables <span
class="math inline">\(x_{ij}\)</span>.</em></p>
<p><em>Nous supposons que la variable réponse peut être exprimée comme :
<span class="math display">\[y_{ij} = x_{ij}^T \beta + u_i +
\epsilon_{ij}\]</span> où :</em></p>
<ul>
<li><p><em><span class="math inline">\(\beta\)</span> est un vecteur de
paramètres fixes.</em></p></li>
<li><p><em><span class="math inline">\(u_i\)</span> est un effet
aléatoire associé à l’unité <span class="math inline">\(i\)</span>,
modélisé par une distribution a priori.</em></p></li>
<li><p><em><span class="math inline">\(\epsilon_{ij}\)</span> est un
terme d’erreur, généralement supposé gaussien.</em></p></li>
</ul>
<p><em>Formellement, nous pouvons écrire : <span
class="math display">\[y_{ij} \mid \beta, u_i, \sigma^2 \sim
\mathcal{N}(x_{ij}^T \beta + u_i, \sigma^2)\]</span> <span
class="math display">\[u_i \mid \tau^2 \sim \mathcal{N}(0,
\tau^2)\]</span> où <span class="math inline">\(\sigma^2\)</span> et
<span class="math inline">\(\tau^2\)</span> sont les variances des
termes d’erreur et des effets aléatoires, respectivement.</em></p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Les modèles à effets mixtes bayésiens reposent sur plusieurs
théorèmes fondamentaux, notamment ceux concernant l’inférence bayésienne
et la théorie des modèles linéaires généralisés.</p>
<div class="theorem">
<p><strong>Théorème 1</strong> (Théorème de Bayes). <em>Le théorème de
Bayes est à la base de l’inférence bayésienne. Il permet de mettre à
jour les croyances a priori en fonction des données observées.</em></p>
<p><em>Formellement, pour deux variables aléatoires <span
class="math inline">\(\theta\)</span> et <span
class="math inline">\(y\)</span>, le théorème de Bayes s’énonce comme
suit : <span class="math display">\[p(\theta \mid y) = \frac{p(y \mid
\theta) p(\theta)}{p(y)}\]</span> où :</em></p>
<ul>
<li><p><em><span class="math inline">\(p(\theta \mid y)\)</span> est la
distribution a posteriori de <span
class="math inline">\(\theta\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(p(y \mid \theta)\)</span> est la
vraisemblance des données.</em></p></li>
<li><p><em><span class="math inline">\(p(\theta)\)</span> est la
distribution a priori de <span
class="math inline">\(\theta\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(p(y)\)</span> est la probabilité
marginale des données.</em></p></li>
</ul>
</div>
<h1 id="preuves">Preuves</h1>
<p>La preuve du théorème de Bayes est relativement simple et repose sur
la définition des probabilités conditionnelles.</p>
<div class="proof">
<p><em>Proof.</em> Par définition de la probabilité conditionnelle, nous
avons : <span class="math display">\[p(\theta \mid y) = \frac{p(y,
\theta)}{p(y)}\]</span></p>
<p>En utilisant la définition de la probabilité jointe, nous pouvons
écrire : <span class="math display">\[p(y, \theta) = p(y \mid \theta)
p(\theta)\]</span></p>
<p>En substituant cette expression dans la formule précédente, nous
obtenons : <span class="math display">\[p(\theta \mid y) = \frac{p(y
\mid \theta) p(\theta)}{p(y)}\]</span></p>
<p>Ceci conclut la preuve du théorème de Bayes. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Les modèles à effets mixtes bayésiens possèdent plusieurs propriétés
intéressantes, que nous allons explorer dans cette section.</p>
<div class="corollary">
<p><strong>Corollaire 1</strong> (Propriété de convergence). <em>Les
estimateurs bayésiens convergent vers les vrais paramètres lorsque le
nombre de données tend vers l’infini.</em></p>
<p><em>Formellement, soit <span class="math inline">\(\theta_n\)</span>
l’estimateur bayésien basé sur un échantillon de taille <span
class="math inline">\(n\)</span>. Nous avons : <span
class="math display">\[\theta_n \xrightarrow{n \to \infty}
\theta\]</span> où <span class="math inline">\(\theta\)</span> est le
vrai paramètre.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Cette propriété découle du théorème de la limite
centrale et des propriétés de convergence des estimateurs bayésiens. En
effet, lorsque <span class="math inline">\(n\)</span> tend vers
l’infini, la distribution a posteriori devient de plus en plus
concentrée autour du vrai paramètre <span
class="math inline">\(\theta\)</span>, ce qui implique la convergence de
l’estimateur bayésien. ◻</p>
</div>
<div class="corollary">
<p><strong>Corollaire 2</strong> (Propriété de robustesse). <em>Les
modèles à effets mixtes bayésiens sont robustes aux violations des
hypothèses de normalité.</em></p>
<p><em>Formellement, même si les termes d’erreur <span
class="math inline">\(\epsilon_{ij}\)</span> ne sont pas exactement
gaussiens, les estimateurs bayésiens restent consistants.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Cette propriété découle de la robustesse des méthodes
bayésiennes aux spécifications du modèle. En effet, les distributions a
priori permettent de capturer une grande variété de structures de
données, rendant les estimateurs bayésiens relativement insensibles aux
violations des hypothèses de normalité. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Les modèles à effets mixtes bayésiens offrent une approche puissante
et flexible pour l’analyse des données hiérarchiques ou longitudinales.
En intégrant des informations a priori et en modélisant les effets
aléatoires, ces modèles permettent de capturer la variabilité à
différents niveaux et d’améliorer la précision des estimations.</p>
<p>Les théorèmes et propriétés présentés dans cet article illustrent la
rigueur mathématique sous-jacente à ces modèles et soulignent leur
importance dans le domaine de la statistique bayésienne.</p>
</body>
</html>
{% include "footer.html" %}

