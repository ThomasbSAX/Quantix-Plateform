{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Loi a posteriori : Fondements et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Loi a posteriori : Fondements et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’inférence bayésienne, pilier de la statistique moderne, repose sur
un principe fondamental : la mise à jour des croyances en présence de
nouvelles données. Au cœur de cette approche se trouve la loi a
posteriori, un concept qui transcende les simples calculs pour embrasser
une philosophie de l’apprentissage. Cette loi, fruit d’un dialogue entre
nos connaissances préalables et les observations empiriques, incarne
l’essence même de la pensée probabiliste.</p>
<p>L’émergence de la loi a posteriori remonte aux travaux pionniers de
Thomas Bayes, dont le théorème éponyme pose les bases d’une révolution
statistique. Ce concept est indispensable dans des domaines aussi variés
que la médecine, l’ingénierie ou les sciences sociales, où il permet de
quantifier l’incertitude et d’affiner nos prédictions. Son importance
réside dans sa capacité à synthétiser l’information disponible et à
guider les décisions sous incertitude.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la loi a posteriori, commençons par poser le cadre.
Supposons que nous avons une variable aléatoire <span
class="math inline">\(X\)</span> dont la distribution est inconnue, mais
pour laquelle nous disposons d’une information partielle. Nous cherchons
à décrire comment cette distribution évolue lorsqu’on nous fournit de
nouvelles données <span class="math inline">\(D\)</span>.</p>
<p>La loi a posteriori est la distribution de probabilité conditionnelle
de <span class="math inline">\(X\)</span> étant donné les données <span
class="math inline">\(D\)</span>. Elle reflète notre état de
connaissance après avoir pris en compte ces nouvelles informations.
Formellement, nous cherchons à exprimer <span class="math inline">\(P(X
\mid D)\)</span>.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\theta\)</span> un paramètre inconnu
d’un modèle statistique, et <span class="math inline">\(D\)</span> un
ensemble de données observées. La loi a posteriori de <span
class="math inline">\(\theta\)</span> étant donné <span
class="math inline">\(D\)</span>, notée <span
class="math inline">\(\pi(\theta \mid D)\)</span>, est définie par :
<span class="math display">\[\pi(\theta \mid D) = \frac{\pi(\theta) f(D
\mid \theta)}{\int_{\Theta} \pi(\phi) f(D \mid \phi) \, d\phi}\]</span>
où :</p>
<ul>
<li><p><span class="math inline">\(\pi(\theta)\)</span> est la loi a
priori de <span class="math inline">\(\theta\)</span>,</p></li>
<li><p><span class="math inline">\(f(D \mid \theta)\)</span> est la
vraisemblance des données <span class="math inline">\(D\)</span> étant
donné <span class="math inline">\(\theta\)</span>,</p></li>
<li><p><span class="math inline">\(\Theta\)</span> est l’espace des
paramètres possibles.</p></li>
</ul>
</div>
<p>Cette définition peut être réécrite en utilisant le théorème de Bayes
: <span class="math display">\[\pi(\theta \mid D) = \frac{f(D \mid
\theta) \pi(\theta)}{\int_{\Theta} f(D \mid \phi) \pi(\phi) \,
d\phi}\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Le théorème de Bayes est le pilier sur lequel repose la notion de loi
a posteriori. Ce théorème permet de mettre à jour nos croyances en
fonction des nouvelles données observées.</p>
<div class="theorem">
<p>Soient <span class="math inline">\(A\)</span> et <span
class="math inline">\(B\)</span> deux événements tels que <span
class="math inline">\(P(B) &gt; 0\)</span>. Alors : <span
class="math display">\[P(A \mid B) = \frac{P(B \mid A)
P(A)}{P(B)}\]</span></p>
</div>
<p>En appliquant ce théorème au contexte de la loi a posteriori, nous
obtenons : <span class="math display">\[\pi(\theta \mid D) = \frac{f(D
\mid \theta) \pi(\theta)}{\int_{\Theta} f(D \mid \phi) \pi(\phi) \,
d\phi}\]</span></p>
<h1 id="preuves">Preuves</h1>
<p>Pour démontrer le théorème de Bayes, nous partons de la définition de
la probabilité conditionnelle. La probabilité conditionnelle <span
class="math inline">\(P(A \mid B)\)</span> est définie par : <span
class="math display">\[P(A \mid B) = \frac{P(A \cap
B)}{P(B)}\]</span></p>
<p>En utilisant la formule de l’événement composé, nous avons : <span
class="math display">\[P(A \cap B) = P(B \mid A) P(A)\]</span></p>
<p>En substituant cette expression dans la définition de <span
class="math inline">\(P(A \mid B)\)</span>, nous obtenons : <span
class="math display">\[P(A \mid B) = \frac{P(B \mid A)
P(A)}{P(B)}\]</span></p>
<p>Cette démonstration est fondamentale car elle justifie la mise à jour
des probabilités conditionnelles en fonction de nouvelles
informations.</p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La loi a posteriori possède plusieurs propriétés intéressantes qui en
font un outil puissant pour l’inférence statistique.</p>
<div class="proposition">
<p>Soit <span class="math inline">\(\pi(\theta \mid D)\)</span> la loi a
posteriori de <span class="math inline">\(\theta\)</span> étant donné
<span class="math inline">\(D\)</span>. Alors :</p>
<ol>
<li><p>La loi a posteriori est une distribution de probabilité valide,
c’est-à-dire qu’elle intègre à 1 sur l’espace des paramètres : <span
class="math display">\[\int_{\Theta} \pi(\theta \mid D) \, d\theta =
1\]</span></p></li>
<li><p>La loi a posteriori est proportionnelle au produit de la
vraisemblance et de la loi a priori : <span
class="math display">\[\pi(\theta \mid D) \propto f(D \mid \theta)
\pi(\theta)\]</span></p></li>
<li><p>Si la loi a priori <span
class="math inline">\(\pi(\theta)\)</span> est une distribution uniforme
sur <span class="math inline">\(\Theta\)</span>, alors la loi a
posteriori est proportionnelle à la vraisemblance : <span
class="math display">\[\pi(\theta \mid D) \propto f(D \mid
\theta)\]</span></p></li>
</ol>
</div>
<div class="proof">
<p><em>Preuve des propriétés.</em> Pour la propriété (i), nous utilisons
le fait que l’intégrale de la loi a posteriori sur <span
class="math inline">\(\Theta\)</span> est égale à 1 par définition de la
distribution conditionnelle.</p>
<p>Pour la propriété (ii), nous observons que le dénominateur dans
l’expression de <span class="math inline">\(\pi(\theta \mid D)\)</span>
est une constante de normalisation qui assure que la loi a posteriori
intègre à 1.</p>
<p>Pour la propriété (iii), si <span
class="math inline">\(\pi(\theta)\)</span> est une distribution
uniforme, alors <span class="math inline">\(\pi(\theta) = c\)</span>
pour une constante <span class="math inline">\(c &gt; 0\)</span>. Ainsi,
le produit de la vraisemblance et de la loi a priori est proportionnel à
la vraisemblance seule. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La loi a posteriori est un concept central en statistique bayésienne,
permettant de fusionner les connaissances préalables avec les données
observées pour obtenir une description mise à jour des paramètres d’un
modèle. Son importance réside dans sa capacité à quantifier
l’incertitude et à guider les décisions sous incertitude. Les propriétés
et théorèmes associés à cette loi en font un outil indispensable pour
l’inférence statistique moderne.</p>
</body>
</html>
{% include "footer.html" %}

