{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Variance généralisée : une approche matricielle</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Variance généralisée : une approche matricielle</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La notion de variance généralisée émerge naturellement dans le cadre
de l’analyse multicritère et des systèmes dynamiques. Historiquement,
cette idée prend racine dans les travaux de Fisher sur l’analyse des
variances et se développe avec l’avènement de la théorie des matrices.
La variance généralisée, souvent associée au déterminant d’une matrice
de covariance, permet de quantifier la dispersion conjointe de plusieurs
variables aléatoires.</p>
<p>Dans un contexte où les données sont multidimensionnelles, la
variance généralisée offre une mesure synthétique de la variabilité
globale. Elle est indispensable dans des domaines tels que
l’économétrie, le traitement du signal et la finance quantitative, où la
compréhension des interactions entre variables est cruciale.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la variance généralisée, commençons par rappeler le
concept de matrice de covariance. Considérons un vecteur aléatoire <span
class="math inline">\(\mathbf{X} = (X_1, X_2, \ldots, X_n)^T\)</span> de
dimension <span class="math inline">\(n\)</span>. La matrice de
covariance <span class="math inline">\(\Sigma\)</span> est définie comme
:</p>
<p><span class="math display">\[\Sigma = \mathbb{E}\left[(\mathbf{X} -
\mathbb{E}[\mathbf{X}])(\mathbf{X} -
\mathbb{E}[\mathbf{X}])^T\right]\]</span></p>
<p>La variance généralisée est alors définie comme le déterminant de
cette matrice de covariance. Formellement, nous avons :</p>
<p><span class="math display">\[\text{Var}_{\text{gén}} (\mathbf{X}) =
\det(\Sigma)\]</span></p>
<p>Cette définition peut être interprétée comme le produit des <span
class="math inline">\(n\)</span> valeurs propres de la matrice de
covariance, ce qui reflète la dispersion conjointe des variables.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la variance généralisée est le suivant
:</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\mathbf{X}\)</span> un vecteur
aléatoire de dimension <span class="math inline">\(n\)</span> avec
matrice de covariance <span class="math inline">\(\Sigma\)</span>.
Alors, pour tout vecteur <span class="math inline">\(\mathbf{a} \in
\mathbb{R}^n\)</span>, on a :</p>
<p><span class="math display">\[\mathbf{a}^T \Sigma \mathbf{a} \leq
\det(\Sigma)^{\frac{1}{n}} \|\mathbf{a}\|^2\]</span></p>
<p>où <span class="math inline">\(\|\mathbf{a}\|\)</span> désigne la
norme euclidienne de <span
class="math inline">\(\mathbf{a}\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve repose sur le théorème spectral et
l’inégalité de Cauchy-Schwarz. Considérons la décomposition spectrale de
<span class="math inline">\(\Sigma\)</span> :</p>
<p><span class="math display">\[\Sigma = U \Lambda U^T\]</span></p>
<p>où <span class="math inline">\(U\)</span> est une matrice orthogonale
et <span class="math inline">\(\Lambda\)</span> est une matrice
diagonale contenant les valeurs propres de <span
class="math inline">\(\Sigma\)</span>. Alors,</p>
<p><span class="math display">\[\mathbf{a}^T \Sigma \mathbf{a} =
\mathbf{a}^T U \Lambda U^T \mathbf{a} = \sum_{i=1}^n \lambda_i (U^T
\mathbf{a})_i^2\]</span></p>
<p>où <span class="math inline">\(\lambda_i\)</span> sont les valeurs
propres de <span class="math inline">\(\Sigma\)</span>. En utilisant
l’inégalité de Cauchy-Schwarz, nous avons :</p>
<p><span class="math display">\[\mathbf{a}^T \Sigma \mathbf{a} \leq
\left( \sum_{i=1}^n \lambda_i \right) \left( \sum_{i=1}^n (U^T
\mathbf{a})_i^2 \right) = \det(\Sigma)^{\frac{1}{n}}
\|\mathbf{a}\|^2\]</span></p>
<p>car <span class="math inline">\(\sum_{i=1}^n \lambda_i \leq n
(\det(\Sigma))^{\frac{1}{n}}\)</span> par l’inégalité
arithmético-géométrique. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La variance généralisée possède plusieurs propriétés intéressantes
:</p>
<ul>
<li><p><strong>Invariance par transformation linéaire</strong> : Soit
<span class="math inline">\(A\)</span> une matrice inversible.
Alors,</p>
<p><span class="math display">\[\text{Var}_{\text{gén}} (A\mathbf{X}) =
|\det(A)|^2 \text{Var}_{\text{gén}} (\mathbf{X})\]</span></p></li>
<li><p><strong>Additivité</strong> : Si <span
class="math inline">\(\mathbf{X}\)</span> et <span
class="math inline">\(\mathbf{Y}\)</span> sont deux vecteurs aléatoires
indépendants, alors</p>
<p><span class="math display">\[\text{Var}_{\text{gén}} (\mathbf{X} +
\mathbf{Y}) = \text{Var}_{\text{gén}} (\mathbf{X}) \cdot
\text{Var}_{\text{gén}} (\mathbf{Y})\]</span></p></li>
<li><p><strong>Inégalité de Hadamard</strong> : Pour une matrice de
covariance <span class="math inline">\(\Sigma\)</span>, on a</p>
<p><span class="math display">\[\det(\Sigma) \leq \prod_{i=1}^n
\Sigma_{ii}\]</span></p>
<p>où <span class="math inline">\(\Sigma_{ii}\)</span> sont les éléments
diagonaux de <span class="math inline">\(\Sigma\)</span>.</p></li>
</ul>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La variance généralisée, à travers le déterminant de la matrice de
covariance, offre une mesure puissante et synthétique de la dispersion
conjointe des variables dans un espace multidimensionnel. Ses propriétés
et ses applications en font un outil indispensable dans de nombreux
domaines scientifiques et techniques.</p>
</body>
</html>
{% include "footer.html" %}

