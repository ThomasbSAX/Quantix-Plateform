{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Chaînes de Markov par Monte Carlo (MCMC)</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Chaînes de Markov par Monte Carlo (MCMC)</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>Les méthodes de Monte Carlo ont révolutionné le calcul numérique en
permettant d’approximer des quantités intraitables analytiquement. Parmi
celles-ci, les Chaînes de Markov par Monte Carlo (MCMC) occupent une
place centrale. Elles permettent d’échantillonner des distributions de
probabilité complexes, souvent rencontrées en statistique bayésienne, en
physique statistique, et dans de nombreux autres domaines.</p>
<p>L’idée fondamentale derrière les MCMC est d’utiliser des propriétés
ergodiques de chaînes de Markov pour générer des échantillons à partir
d’une distribution cible. Cette approche est particulièrement puissante
lorsque la distribution cible est connue à une constante multiplicative
près, ce qui est souvent le cas en statistique bayésienne.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre les MCMC, commençons par définir une chaîne de
Markov. Une chaîne de Markov est un processus stochastique où la
probabilité de transition vers un nouvel état dépend uniquement de
l’état actuel et non des états précédents. Formellement, une chaîne de
Markov est définie par :</p>
<div class="definition">
<p>Une chaîne de Markov sur un espace d’états <span
class="math inline">\(E\)</span> est une suite de variables aléatoires
<span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> telle que
pour tout <span class="math inline">\(n \geq 0\)</span>, la loi
conditionnelle de <span class="math inline">\(X_{n+1}\)</span> sachant
<span class="math inline">\(X_0, X_1, \ldots, X_n\)</span> est identique
à la loi conditionnelle de <span class="math inline">\(X_{n+1}\)</span>
sachant <span class="math inline">\(X_n\)</span>. En d’autres termes,
pour tout <span class="math inline">\(x_0, x_1, \ldots, x_n, y \in
E\)</span>, on a : <span class="math display">\[P(X_{n+1} = y | X_0 =
x_0, \ldots, X_n = x_n) = P(X_{n+1} = y | X_n = x_n).\]</span></p>
</div>
<p>Une chaîne de Markov est dite irréductible si pour tout couple
d’états <span class="math inline">\((x, y)\)</span>, il existe un entier
<span class="math inline">\(n\)</span> tel que <span
class="math inline">\(P(X_n = y | X_0 = x) &gt; 0\)</span>. Une chaîne
de Markov est dite apériodique si elle n’est pas périodique,
c’est-à-dire qu’il n’existe pas d’entier <span class="math inline">\(d
\geq 2\)</span> tel que pour tout <span class="math inline">\(x, y \in
E\)</span>, <span class="math inline">\(P(X_n = y | X_0 = x) =
0\)</span> si <span class="math inline">\(n\)</span> et <span
class="math inline">\(d\)</span> ne sont pas premiers entre eux.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux concernant les chaînes de Markov est le
théorème ergodique. Ce théorème garantit que sous certaines conditions,
la moyenne empirique des états visités par une chaîne de Markov converge
vers l’espérance sous la distribution stationnaire.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
une chaîne de Markov irréductible, apériodique et à espace d’états fini.
Supposons que <span class="math inline">\(\pi\)</span> est la
distribution stationnaire de cette chaîne. Alors, pour toute fonction
mesurable <span class="math inline">\(f : E \rightarrow
\mathbb{R}\)</span>, on a : <span class="math display">\[\lim_{n \to
\infty} \frac{1}{n} \sum_{k=0}^{n-1} f(X_k) = \mathbb{E}_\pi[f] \quad
\text{p.s.}\]</span> où <span
class="math inline">\(\mathbb{E}_\pi[f]\)</span> désigne l’espérance de
<span class="math inline">\(f\)</span> sous la distribution <span
class="math inline">\(\pi\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver le théorème ergodique, nous avons besoin de plusieurs
étapes. Tout d’abord, nous devons montrer que la chaîne de Markov
converge vers sa distribution stationnaire. Ensuite, nous utilisons
cette convergence pour prouver le théorème ergodique.</p>
<div class="proof">
<p><em>Proof.</em> Supposons que <span class="math inline">\((X_n)_{n
\in \mathbb{N}}\)</span> est une chaîne de Markov irréductible,
apériodique et à espace d’états fini. Soit <span
class="math inline">\(\pi\)</span> la distribution stationnaire de cette
chaîne.</p>
<p>1. **Convergence vers la distribution stationnaire** :</p>
<p>Par le théorème de convergence des chaînes de Markov, nous savons que
pour tout état initial <span class="math inline">\(x \in E\)</span>, on
a : <span class="math display">\[\lim_{n \to \infty} P(X_n = y | X_0 =
x) = \pi(y).\]</span></p>
<p>2. **Théorème ergodique** :</p>
<p>Soit <span class="math inline">\(f : E \rightarrow
\mathbb{R}\)</span> une fonction mesurable. Nous voulons montrer que :
<span class="math display">\[\lim_{n \to \infty} \frac{1}{n}
\sum_{k=0}^{n-1} f(X_k) = \mathbb{E}_\pi[f] \quad
\text{p.s.}\]</span></p>
<p>Par la loi forte des grands nombres pour les chaînes de Markov, nous
savons que : <span class="math display">\[\lim_{n \to \infty}
\frac{1}{n} \sum_{k=0}^{n-1} f(X_k) = \mathbb{E}_\pi[f] \quad
\text{p.s.}\]</span> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Les MCMC possèdent de nombreuses propriétés intéressantes. En voici
quelques-unes :</p>
<ol>
<li><p>**Propriété de réversibilité** : Une chaîne de Markov est dite
réversible si pour tout couple d’états <span class="math inline">\((x,
y)\)</span>, on a : <span class="math display">\[\pi(x) P(x, y) = \pi(y)
P(y, x).\]</span> Cette propriété est souvent utilisée pour construire
des chaînes de Markov dont la distribution stationnaire est
connue.</p></li>
<li><p>**Propriété de mélange rapide** : Une chaîne de Markov est dite à
mélange rapide si elle converge rapidement vers sa distribution
stationnaire. Cette propriété est cruciale pour les applications
pratiques des MCMC.</p></li>
<li><p>**Propriété de détail équilibré** : Une chaîne de Markov vérifie
la propriété de détail équilibré si pour tout couple d’états <span
class="math inline">\((x, y)\)</span>, on a : <span
class="math display">\[\pi(x) P(x, y) = \pi(y) P(y, x).\]</span> Cette
propriété est plus forte que la réversibilité et implique que la chaîne
de Markov est réversible.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>Les Chaînes de Markov par Monte Carlo sont des outils puissants pour
l’échantillonnage de distributions complexes. Elles trouvent des
applications dans de nombreux domaines, allant de la statistique
bayésienne à la physique statistique. Les propriétés ergodiques des
chaînes de Markov permettent de garantir la convergence des estimateurs
obtenus par échantillonnage.</p>
</body>
</html>
{% include "footer.html" %}

