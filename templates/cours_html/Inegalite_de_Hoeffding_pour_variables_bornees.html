{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Inégalité de Hoeffding pour variables bornées</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Inégalité de Hoeffding pour variables bornées</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de Hoeffding est un résultat fondamental en théorie des
probabilités, particulièrement utile dans l’analyse des variables
aléatoires bornées. Elle trouve ses racines dans les travaux de Wassily
Hoeffding au milieu du XXème siècle, et depuis, elle a trouvé des
applications dans divers domaines tels que la statistique,
l’apprentissage automatique et la théorie de l’information.</p>
<p>L’inégalité émerge comme une réponse à un besoin crucial : fournir
des bornes probabilistes sur la somme de variables aléatoires
indépendantes, mais non nécessairement identiquement distribuées. Elle
est indispensable dans les cadres où l’on souhaite contrôler la
déviation d’une somme aléatoire par rapport à sa moyenne, notamment dans
les algorithmes de concentration de mesure et les preuves d’erreur de
généralisation.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Avant d’énoncer l’inégalité de Hoeffding, il est essentiel de bien
comprendre les concepts sous-jacents. Nous cherchons à contrôler la
probabilité qu’une somme de variables aléatoires indépendantes s’écarte
significativement de sa moyenne. Pour cela, nous devons d’abord définir
ce que signifie une variable aléatoire bornée.</p>
<p>Considérons une variable aléatoire <span
class="math inline">\(X\)</span> définie sur un espace probabilisé <span
class="math inline">\((\Omega, \mathcal{F}, P)\)</span>. Nous disons que
<span class="math inline">\(X\)</span> est bornée si elle vérifie
certaines conditions. Intuitivement, cela signifie que <span
class="math inline">\(X\)</span> ne peut prendre des valeurs trop
extrêmes.</p>
<div class="definition">
<p><strong>Définition 1</strong>. <em>Une variable aléatoire <span
class="math inline">\(X\)</span> est dite bornée si et seulement s’il
existe des constantes réelles <span class="math inline">\(a\)</span> et
<span class="math inline">\(b\)</span> telles que <span
class="math display">\[P(a \leq X \leq b) = 1.\]</span></em></p>
</div>
<p>En d’autres termes, <span class="math inline">\(X\)</span> est bornée
si elle satisfait presque sûrement l’inégalité <span
class="math inline">\(a \leq X \leq b\)</span>. Cette notion est
cruciale pour l’énoncé de l’inégalité de Hoeffding.</p>
<h1 class="unnumbered" id="inégalité-de-hoeffding">Inégalité de
Hoeffding</h1>
<p>Nous sommes maintenant prêts à énoncer l’inégalité de Hoeffding.
L’idée est de fournir une borne sur la probabilité que la somme de
variables aléatoires indépendantes et bornées s’écarte de sa
moyenne.</p>
<p>Supposons que nous ayons <span class="math inline">\(n\)</span>
variables aléatoires indépendantes <span class="math inline">\(X_1, X_2,
\ldots, X_n\)</span>, chacune bornée entre <span
class="math inline">\(a_i\)</span> et <span
class="math inline">\(b_i\)</span>. Nous voulons contrôler la
probabilité que leur somme <span class="math inline">\(S_n = X_1 + X_2 +
\ldots + X_n\)</span> s’écarte de sa moyenne <span
class="math inline">\(\mathbb{E}[S_n]\)</span>.</p>
<div class="theorem">
<p><strong>Théorème 1</strong> (Inégalité de Hoeffding). <em>Soient
<span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des variables
aléatoires indépendantes telles que pour chaque <span
class="math inline">\(i\)</span>, <span class="math inline">\(a_i \leq
X_i \leq b_i\)</span> presque sûrement. Alors, pour tout <span
class="math inline">\(t &gt; 0\)</span>, <span
class="math display">\[P\left( S_n - \mathbb{E}[S_n] \geq t \right) \leq
\exp\left( -\frac{2t^2}{\sum_{i=1}^n (b_i - a_i)^2} \right),\]</span> et
de même, <span class="math display">\[P\left( S_n - \mathbb{E}[S_n] \leq
-t \right) \leq \exp\left( -\frac{2t^2}{\sum_{i=1}^n (b_i - a_i)^2}
\right).\]</span></em></p>
</div>
<p>Cette inégalité nous donne une borne exponentielle sur la probabilité
que <span class="math inline">\(S_n\)</span> s’écarte de sa moyenne.
Plus précisément, plus <span class="math inline">\(t\)</span> est grand,
plus la probabilité que <span class="math inline">\(S_n\)</span>
s’écarte de sa moyenne devient faible.</p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver l’inégalité de Hoeffding, nous allons utiliser des
techniques de fonctions génératrices de moments et des inégalités
classiques. Nous commençons par rappeler quelques lemmes
intermédiaires.</p>
<div class="lemma">
<p><strong>Lemme 1</strong> (Lemme de Chernoff). <em>Pour toute variable
aléatoire <span class="math inline">\(X\)</span> bornée entre <span
class="math inline">\(a\)</span> et <span
class="math inline">\(b\)</span>, et pour tout <span
class="math inline">\(s &gt; 0\)</span>, <span
class="math display">\[\mathbb{E}[e^{s(X - \mathbb{E}[X])}] \leq
e^{\frac{s^2(b-a)^2}{8}}.\]</span></em></p>
</div>
<p>Ce lemme est crucial pour la preuve de l’inégalité de Hoeffding. Il
permet de borner la fonction génératrice de moments exponentielle.</p>
<div class="proof">
<p><em>Proof.</em> La preuve du lemme de Chernoff repose sur le
développement en série de Taylor et l’utilisation de l’inégalité de
Jensen. Considérons la fonction <span class="math inline">\(\phi(s) =
\mathbb{E}[e^{s(X - \mathbb{E}[X])}]\)</span>. Nous avons <span
class="math display">\[\phi(s) = \sum_{k=0}^{\infty} \frac{s^k}{k!}
\mathbb{E}[(X - \mathbb{E}[X])^k].\]</span></p>
<p>En utilisant l’inégalité de Jensen, nous pouvons montrer que les
moments centrés <span class="math inline">\(\mathbb{E}[(X -
\mathbb{E}[X])^k]\)</span> sont bornés par <span
class="math inline">\((b-a)^k\)</span>. Par conséquent, <span
class="math display">\[\phi(s) \leq \sum_{k=0}^{\infty} \frac{s^k}{k!}
(b-a)^k = e^{s(b-a)}.\]</span></p>
<p>En appliquant l’inégalité de Taylor-Lagrange, nous obtenons <span
class="math display">\[e^{s(b-a)} \leq 1 + s(b-a) + \frac{s^2(b-a)^2}{2}
e^{s(b-a)}.\]</span></p>
<p>En résolvant cette inégalité, nous trouvons <span
class="math display">\[\phi(s) \leq
e^{\frac{s^2(b-a)^2}{8}}.\]</span> ◻</p>
</div>
<p>Nous pouvons maintenant prouver l’inégalité de Hoeffding.</p>
<div class="proof">
<p><em>Proof.</em> Considérons la somme <span class="math inline">\(S_n
= X_1 + X_2 + \ldots + X_n\)</span>. Nous voulons borner <span
class="math inline">\(P(S_n - \mathbb{E}[S_n] \geq t)\)</span>. En
utilisant le lemme de Chernoff, nous avons <span
class="math display">\[P(S_n - \mathbb{E}[S_n] \geq t) = P(e^{s(S_n -
\mathbb{E}[S_n])} \geq e^{st}) \leq e^{-st} \mathbb{E}[e^{s(S_n -
\mathbb{E}[S_n])}].\]</span></p>
<p>En développant le produit, nous obtenons <span
class="math display">\[\mathbb{E}[e^{s(S_n - \mathbb{E}[S_n])}] =
\prod_{i=1}^n \mathbb{E}[e^{s(X_i - \mathbb{E}[X_i])}] \leq
\prod_{i=1}^n e^{\frac{s^2(b_i - a_i)^2}{8}} = e^{\frac{s^2 \sum_{i=1}^n
(b_i - a_i)^2}{8}}.\]</span></p>
<p>En choisissant <span class="math inline">\(s = \frac{4t}{\sum_{i=1}^n
(b_i - a_i)^2}\)</span>, nous obtenons <span
class="math display">\[P(S_n - \mathbb{E}[S_n] \geq t) \leq
e^{-\frac{2t^2}{\sum_{i=1}^n (b_i - a_i)^2}}.\]</span></p>
<p>De même, pour la déviation négative, <span
class="math display">\[P(S_n - \mathbb{E}[S_n] \leq -t) = P(-(S_n -
\mathbb{E}[S_n]) \geq t) \leq e^{-\frac{2t^2}{\sum_{i=1}^n (b_i -
a_i)^2}}.\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Hoeffding possède plusieurs propriétés intéressantes
et corollaires. Nous en énumérons quelques-uns ci-dessous.</p>
<div class="corollary">
<p><strong>Corollaire 1</strong>. <em>Soient <span
class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des variables
aléatoires indépendantes et identiquement distribuées (i.i.d.) bornées
entre <span class="math inline">\(a\)</span> et <span
class="math inline">\(b\)</span>. Alors, pour tout <span
class="math inline">\(t &gt; 0\)</span>, <span
class="math display">\[P\left( \left| \frac{1}{n} S_n - \mathbb{E}[X_1]
\right| \geq t \right) \leq 2 \exp\left( -\frac{2n^2 t^2}{(b-a)^2}
\right).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> En appliquant l’inégalité de Hoeffding à <span
class="math inline">\(S_n\)</span>, nous obtenons <span
class="math display">\[P\left( \left| \frac{1}{n} S_n - \mathbb{E}[X_1]
\right| \geq t \right) = P\left( \left| S_n - n \mathbb{E}[X_1] \right|
\geq nt \right) \leq 2 \exp\left( -\frac{2n^2 t^2}{\sum_{i=1}^n (b_i -
a_i)^2} \right).\]</span></p>
<p>Puisque <span class="math inline">\(X_i\)</span> sont i.i.d., nous
avons <span class="math inline">\(b_i = b\)</span> et <span
class="math inline">\(a_i = a\)</span> pour tout <span
class="math inline">\(i\)</span>. Par conséquent, <span
class="math display">\[P\left( \left| \frac{1}{n} S_n - \mathbb{E}[X_1]
\right| \geq t \right) \leq 2 \exp\left( -\frac{2n^2 t^2}{(b-a)^2}
\right).\]</span> ◻</p>
</div>
<div class="corollary">
<p><strong>Corollaire 2</strong>. <em>Soient <span
class="math inline">\(X_1, X_2, \ldots, X_n\)</span> des variables
aléatoires indépendantes et bornées entre <span
class="math inline">\(0\)</span> et <span
class="math inline">\(1\)</span>. Alors, pour tout <span
class="math inline">\(t &gt; 0\)</span>, <span
class="math display">\[P\left( \left| \frac{1}{n} S_n - p \right| \geq t
\right) \leq 2 \exp(-2n t^2),\]</span> où <span class="math inline">\(p
= \mathbb{E}[X_1]\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> En appliquant l’inégalité de Hoeffding avec <span
class="math inline">\(a_i = 0\)</span> et <span
class="math inline">\(b_i = 1\)</span>, nous obtenons <span
class="math display">\[P\left( \left| \frac{1}{n} S_n - p \right| \geq t
\right) \leq 2 \exp\left( -\frac{2n^2 t^2}{\sum_{i=1}^n (b_i - a_i)^2}
\right) = 2 \exp(-2n t^2).\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’inégalité de Hoeffding est un outil puissant pour contrôler les
déviations des sommes de variables aléatoires bornées. Elle trouve des
applications dans divers domaines, notamment en statistique et en
apprentissage automatique. Les preuves et les corollaires présentés dans
cet article illustrent la puissance et l’utilité de cette inégalité.</p>
</body>
</html>
{% include "footer.html" %}

