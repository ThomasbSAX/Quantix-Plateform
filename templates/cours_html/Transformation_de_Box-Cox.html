{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Transformation de Box-Cox : Un Outil Puissant pour la Modélisation Statistique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Transformation de Box-Cox : Un Outil Puissant pour
la Modélisation Statistique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La transformation de Box-Cox est une technique statistique introduite
par George Box et David Cox en 1964. Elle vise à stabiliser la variance
et rendre les données plus proches d’une distribution normale, ce qui
est crucial pour de nombreuses méthodes statistiques. Cette
transformation est particulièrement utile lorsque les données présentent
une hétéroscédasticité ou une asymétrie marquée.</p>
<p>L’idée sous-jacente est de transformer les données originales <span
class="math inline">\(y\)</span> en une nouvelle variable <span
class="math inline">\(z\)</span> telle que la distribution de <span
class="math inline">\(z\)</span> soit plus proche d’une loi normale.
Cela permet d’améliorer les résultats des analyses de régression, des
tests d’hypothèses et d’autres méthodes statistiques.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour comprendre la transformation de Box-Cox, commençons par définir
ce que nous cherchons à atteindre. Supposons que nous ayons un ensemble
de données <span class="math inline">\(y_1, y_2, \dots, y_n\)</span> qui
ne sont pas normalement distribuées. Nous voulons trouver une
transformation <span class="math inline">\(z_i = f(y_i)\)</span> telle
que les <span class="math inline">\(z_i\)</span> soient normalement
distribués.</p>
<p>La transformation de Box-Cox est définie comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(y &gt; 0\)</span> une variable
aléatoire positive. La transformation de Box-Cox est définie par : <span
class="math display">\[z = \begin{cases}
\frac{y^\lambda - 1}{\lambda} &amp; \text{si } \lambda \neq 0, \\
\ln(y) &amp; \text{si } \lambda = 0.
\end{cases}\]</span> où <span class="math inline">\(\lambda\)</span> est
un paramètre à estimer.</p>
</div>
<p>Cette transformation peut être réécrite de manière plus générale pour
un ensemble de données <span class="math inline">\(y_1, y_2, \dots,
y_n\)</span> : <span class="math display">\[z_i = \begin{cases}
\frac{y_i^\lambda - 1}{\lambda} &amp; \text{si } \lambda \neq 0, \\
\ln(y_i) &amp; \text{si } \lambda = 0.
\end{cases}\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème important lié à la transformation de Box-Cox est celui de
l’estimation du paramètre <span class="math inline">\(\lambda\)</span>.
Ce théorème permet de déterminer la valeur optimale de <span
class="math inline">\(\lambda\)</span> qui maximise la vraisemblance des
données transformées.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(y_1, y_2, \dots, y_n\)</span> un
échantillon de données positives. Le paramètre <span
class="math inline">\(\lambda\)</span> qui maximise la vraisemblance des
données transformées est donné par : <span
class="math display">\[\hat{\lambda} = \argmax_{\lambda} \left(
-\frac{n}{2} \ln(\text{SSE}(\lambda)) + (\lambda - 1) \sum_{i=1}^n
\ln(y_i) \right),\]</span> où <span
class="math inline">\(\text{SSE}(\lambda)\)</span> est la somme des
carrés des écarts pour la transformation avec paramètre <span
class="math inline">\(\lambda\)</span>.</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour prouver ce théorème, nous devons d’abord définir la fonction de
vraisemblance pour les données transformées. Supposons que les données
transformées <span class="math inline">\(z_i\)</span> suivent une
distribution normale <span class="math inline">\(N(\mu,
\sigma^2)\)</span>. La fonction de vraisemblance est alors : <span
class="math display">\[L(\mu, \sigma^2, \lambda) = \prod_{i=1}^n
\frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(z_i -
\mu)^2}{2\sigma^2} \right).\]</span></p>
<p>En prenant le logarithme de cette fonction, nous obtenons la
log-vraisemblance : <span class="math display">\[\ln L(\mu, \sigma^2,
\lambda) = -\frac{n}{2} \ln(2\pi) - \frac{n}{2} \ln(\sigma^2) -
\frac{1}{2\sigma^2} \sum_{i=1}^n (z_i - \mu)^2.\]</span></p>
<p>Pour maximiser cette fonction par rapport à <span
class="math inline">\(\lambda\)</span>, nous devons prendre la dérivée
partielle de la log-vraisemblance par rapport à <span
class="math inline">\(\lambda\)</span> et la mettre à zéro. Cela conduit
à l’équation : <span class="math display">\[\frac{\partial \ln
L}{\partial \lambda} = -\frac{n}{2} \frac{\partial
\ln(\text{SSE}(\lambda))}{\partial \lambda} + (\lambda - 1) \sum_{i=1}^n
\frac{\partial \ln(y_i)}{\partial \lambda} = 0.\]</span></p>
<p>En résolvant cette équation, nous obtenons l’estimateur du maximum de
vraisemblance pour <span class="math inline">\(\lambda\)</span> : <span
class="math display">\[\hat{\lambda} = \argmax_{\lambda} \left(
-\frac{n}{2} \ln(\text{SSE}(\lambda)) + (\lambda - 1) \sum_{i=1}^n
\ln(y_i) \right).\]</span></p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>La transformation de Box-Cox possède plusieurs propriétés importantes
qui en font un outil puissant pour la modélisation statistique.</p>
<div class="proposition">
<p>La transformation de Box-Cox est une fonction strictement croissante
pour <span class="math inline">\(\lambda &gt; 0\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour montrer que la transformation est strictement
croissante, nous devons démontrer que sa dérivée par rapport à <span
class="math inline">\(y\)</span> est positive. La dérivée de la
transformation de Box-Cox est : <span
class="math display">\[\frac{dz}{dy} = \begin{cases}
y^{\lambda - 1} &amp; \text{si } \lambda \neq 0, \\
\frac{1}{y} &amp; \text{si } \lambda = 0.
\end{cases}\]</span> Puisque <span class="math inline">\(y &gt;
0\)</span>, cette dérivée est toujours positive, ce qui signifie que la
transformation est strictement croissante. ◻</p>
</div>
<div class="proposition">
<p>La transformation de Box-Cox est invariante sous les transformations
linéaires des données.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Supposons que nous appliquions une transformation
linéaire aux données <span class="math inline">\(y_i\)</span> de la
forme <span class="math inline">\(y_i&#39; = a y_i + b\)</span>, où
<span class="math inline">\(a &gt; 0\)</span>. La transformation de
Box-Cox des nouvelles données est : <span
class="math display">\[z_i&#39; = \begin{cases}
\frac{(a y_i + b)^\lambda - 1}{\lambda} &amp; \text{si } \lambda \neq 0,
\\
\ln(a y_i + b) &amp; \text{si } \lambda = 0.
\end{cases}\]</span> Pour <span class="math inline">\(\lambda \neq
0\)</span>, nous pouvons réécrire cette expression comme : <span
class="math display">\[z_i&#39; = a^\lambda \frac{y_i^\lambda -
1}{\lambda} + \frac{b^\lambda - 1}{\lambda} = a^\lambda z_i +
c,\]</span> où <span class="math inline">\(c\)</span> est une constante.
Pour <span class="math inline">\(\lambda = 0\)</span>, nous avons :
<span class="math display">\[z_i&#39; = \ln(a) + \ln(y_i) = \ln(a) +
z_i.\]</span> Dans les deux cas, la transformation de Box-Cox est
invariante sous les transformations linéaires des données. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La transformation de Box-Cox est un outil puissant pour la
modélisation statistique, permettant de stabiliser la variance et de
rendre les données plus proches d’une distribution normale. En
comprenant les définitions, les théorèmes et les propriétés de cette
transformation, nous pouvons l’utiliser efficacement pour améliorer les
résultats des analyses statistiques.</p>
</body>
</html>
{% include "footer.html" %}

