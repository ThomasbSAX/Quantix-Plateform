{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Chaînes de Markov : Théorie et Applications</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Chaînes de Markov : Théorie et Applications</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>Les chaînes de Markov trouvent leur origine dans les travaux d’Andreï
Markov (1856-1922), un mathématicien russe qui cherchait à généraliser
les travaux de son contemporain, le grand Andreï Kolmogorov. Elles
émergent comme un outil puissant pour modéliser des phénomènes où l’état
futur dépend uniquement de l’état présent, et non de l’histoire passée.
Cette propriété, dite "sans mémoire", est au cœur de leur puissance et
de leur simplicité.</p>
<p>Les chaînes de Markov sont indispensables dans des domaines aussi
variés que la finance, la biologie, l’ingénierie et les sciences
sociales. Elles permettent de modéliser des processus stochastiques,
c’est-à-dire des phénomènes aléatoires évoluant dans le temps. Par
exemple, elles sont utilisées pour prédire l’évolution des marchés
financiers, modéliser les mutations génétiques ou encore optimiser les
stratégies de recherche sur Internet.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre ce qu’est une chaîne de Markov, imaginons un
processus où nous observons un système à des instants discrets. À chaque
instant, le système peut se trouver dans un certain nombre d’états. La
propriété clé est que la probabilité de passer à un état futur dépend
uniquement de l’état présent, et non des états précédents.</p>
<p>Formellement, une chaîne de Markov est définie comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
une suite de variables aléatoires à valeurs dans un ensemble fini ou
dénombrable <span class="math inline">\(E\)</span>. On dit que cette
suite est une chaîne de Markov si pour tout <span
class="math inline">\(n \in \mathbb{N}\)</span> et pour tous <span
class="math inline">\(i_0, i_1, \ldots, i_n, j \in E\)</span>, on a :
<span class="math display">\[P(X_{n+1} = j \mid X_n = i_n, X_{n-1} =
i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j \mid X_n = i_n)\]</span></p>
</div>
<p>Cette définition peut être réécrite en utilisant des quantificateurs
: <span class="math display">\[\forall n \in \mathbb{N}, \forall i_0,
i_1, \ldots, i_n, j \in E, P(X_{n+1} = j \mid X_n = i_n, X_{n-1} =
i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j \mid X_n = i_n)\]</span></p>
<p>Une autre manière de formuler cette propriété est la suivante : <span
class="math display">\[P(X_{n+1} = j \mid X_n = i_n, X_{n-1} = i_{n-1},
\ldots, X_0 = i_0) = P(X_{n+1} = j \mid X_n = i_n) \quad \forall n \in
\mathbb{N}, \forall i_0, i_1, \ldots, i_n, j \in E\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux concernant les chaînes de Markov est le
théorème de convergence vers la distribution stationnaire. Ce théorème
nous dit que sous certaines conditions, une chaîne de Markov converge
vers une distribution de probabilité invariante.</p>
<div class="theorem">
<p>Soit <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
une chaîne de Markov irréductible et apériodique. Si cette chaîne est
récurrente positive, alors elle admet une distribution stationnaire
<span class="math inline">\(\pi\)</span> telle que : <span
class="math display">\[\lim_{n \to \infty} P(X_n = j) = \pi_j \quad
\forall j \in E\]</span></p>
</div>
<p>Ce théorème peut être formulé de manière plus précise en utilisant
des quantificateurs : <span class="math display">\[\exists \pi =
(\pi_j)_{j \in E} \text{ telle que } \sum_{j \in E} \pi_j = 1 \text{ et
} \lim_{n \to \infty} P(X_n = j) = \pi_j \quad \forall j \in
E\]</span></p>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver le théorème de convergence, nous devons d’abord établir
l’existence d’une distribution stationnaire. Une distribution <span
class="math inline">\(\pi\)</span> est dite stationnaire si elle
satisfait l’équation de Chapman-Kolmogorov : <span
class="math display">\[\pi_j = \sum_{i \in E} \pi_i p_{ij}\]</span> où
<span class="math inline">\(p_{ij}\)</span> est la probabilité de
transition de l’état <span class="math inline">\(i\)</span> à l’état
<span class="math inline">\(j\)</span>.</p>
<p>La preuve repose sur plusieurs étapes clés : 1. Montrer que la chaîne
est récurrente positive. 2. Utiliser le théorème ergodique pour les
chaînes de Markov. 3. Montrer que la distribution stationnaire est
unique.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Les chaînes de Markov possèdent plusieurs propriétés importantes, que
nous énumérons ci-dessous :</p>
<ol>
<li><p><strong>Propriété de Markov</strong> : La probabilité de
transition ne dépend que de l’état présent.</p></li>
<li><p><strong>Distribution stationnaire</strong> : Une chaîne
irréductible et apériodique admet une distribution stationnaire
unique.</p></li>
<li><p><strong>Convergence</strong> : Sous certaines conditions, la
chaîne converge vers sa distribution stationnaire.</p></li>
</ol>
<p>Chacune de ces propriétés peut être démontrée en utilisant les outils
de la théorie des probabilités et des processus stochastiques. Par
exemple, pour prouver l’existence d’une distribution stationnaire, on
peut utiliser le théorème de Perron-Frobenius sur les matrices
positives.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>Les chaînes de Markov sont un outil puissant et polyvalent pour
modéliser des phénomènes stochastiques. Leur simplicité et leur
puissance en font un sujet de recherche actif et un outil indispensable
dans de nombreux domaines. Les théorèmes et propriétés présentés ici ne
sont qu’un aperçu des riches possibilités offertes par cette
théorie.</p>
</body>
</html>
{% include "footer.html" %}

