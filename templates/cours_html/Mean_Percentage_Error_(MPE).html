{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Moyenne de l’Erreur en Pourcentage : Une Analyse Mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Moyenne de l’Erreur en Pourcentage : Une Analyse
Mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’évaluation des modèles prédictifs est une tâche cruciale en science
des données et en apprentissage automatique. Parmi les nombreuses
métriques disponibles, la <strong>Moyenne de l’Erreur en
Pourcentage</strong> (MPE) se distingue par sa simplicité et son
interprétation intuitive. Historiquement, le MPE a été utilisé pour
quantifier l’erreur relative entre les valeurs prédites et les valeurs
réelles, offrant ainsi une mesure normalisée de la performance des
modèles.</p>
<p>Le MPE émerge comme une solution naturelle pour comparer les
performances des modèles sur des échelles différentes. Il est
particulièrement utile lorsque les données présentent une grande
variabilité ou lorsque les unités de mesure diffèrent. Le MPE est
indispensable dans des domaines tels que la prévision économique, la
finance, et l’ingénierie, où une compréhension précise des erreurs est
cruciale pour la prise de décision.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre le MPE, commençons par définir les concepts de base.
Supposons que nous avons un ensemble de <span
class="math inline">\(n\)</span> observations, où chaque observation
<span class="math inline">\(i\)</span> est composée d’une valeur réelle
<span class="math inline">\(y_i\)</span> et d’une valeur prédite <span
class="math inline">\(\hat{y}_i\)</span>.</p>
<p>Nous cherchons une mesure qui quantifie l’erreur relative entre <span
class="math inline">\(y_i\)</span> et <span
class="math inline">\(\hat{y}_i\)</span>. Cette erreur doit être
exprimée en pourcentage pour faciliter l’interprétation. De plus, nous
voulons une moyenne de ces erreurs sur toutes les observations.</p>
<p>Formellement, le MPE est défini comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(y_i\)</span> la valeur réelle et
<span class="math inline">\(\hat{y}_i\)</span> la valeur prédite pour
l’observation <span class="math inline">\(i\)</span>, où <span
class="math inline">\(i = 1, 2, \dots, n\)</span>. Le MPE est donné par
: <span class="math display">\[\text{MPE} = \frac{100}{n} \sum_{i=1}^{n}
\left( \frac{y_i - \hat{y}_i}{y_i} \right)\]</span></p>
</div>
<p>Cette définition peut également être exprimée en utilisant des
quantificateurs : <span class="math display">\[\text{MPE} =
\frac{100}{n} \sum_{i=1}^{n} \left( \frac{y_i - \hat{y}_i}{y_i} \right)
= \frac{100}{n} \sum_{i=1}^{n} \left( 1 - \frac{\hat{y}_i}{y_i}
\right)\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Le MPE possède plusieurs propriétés intéressantes qui en font une
métrique robuste pour l’évaluation des modèles. Considérons le théorème
suivant :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(y_i\)</span> et <span
class="math inline">\(\hat{y}_i\)</span> définis comme précédemment. Si
<span class="math inline">\(y_i &gt; 0\)</span> pour tout <span
class="math inline">\(i\)</span>, alors le MPE est une mesure de
l’erreur relative moyenne.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer ce théorème, nous devons montrer que
le MPE mesure effectivement l’erreur relative moyenne. Commençons par
exprimer le MPE en termes d’erreurs relatives : <span
class="math display">\[\text{MPE} = \frac{100}{n} \sum_{i=1}^{n} \left(
\frac{y_i - \hat{y}_i}{y_i} \right)\]</span> Cette expression montre que
le MPE est la moyenne des erreurs relatives <span
class="math inline">\(\frac{y_i - \hat{y}_i}{y_i}\)</span>, multipliée
par 100 pour obtenir un pourcentage. Ainsi, le MPE est bien une mesure
de l’erreur relative moyenne. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour approfondir notre compréhension du MPE, examinons une preuve
détaillée de ses propriétés. Considérons le lemme suivant :</p>
<div class="lemma">
<p>Soit <span class="math inline">\(y_i\)</span> et <span
class="math inline">\(\hat{y}_i\)</span> définis comme précédemment. Si
<span class="math inline">\(y_i &gt; 0\)</span> pour tout <span
class="math inline">\(i\)</span>, alors le MPE est invariant sous
l’échelle des valeurs réelles.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer ce lemme, supposons que nous
multiplions toutes les valeurs réelles par un facteur positif <span
class="math inline">\(c\)</span>. Soit <span
class="math inline">\(y_i&#39; = c y_i\)</span> et <span
class="math inline">\(\hat{y}_i&#39; = c \hat{y}_i\)</span>. Calculons
le MPE pour les nouvelles valeurs : <span
class="math display">\[\text{MPE}&#39; = \frac{100}{n} \sum_{i=1}^{n}
\left( \frac{y_i&#39; - \hat{y}_i&#39;}{y_i&#39;} \right) =
\frac{100}{n} \sum_{i=1}^{n} \left( \frac{c y_i - c \hat{y}_i}{c y_i}
\right) = \frac{100}{n} \sum_{i=1}^{n} \left( \frac{y_i -
\hat{y}_i}{y_i} \right) = \text{MPE}\]</span> Ainsi, le MPE est
invariant sous l’échelle des valeurs réelles. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Le MPE possède plusieurs propriétés intéressantes qui en font une
métrique robuste pour l’évaluation des modèles. Examinons quelques-unes
de ces propriétés :</p>
<ul>
<li><p><strong>Invariance sous l’échelle</strong> : Comme démontré dans
le lemme précédent, le MPE est invariant sous l’échelle des valeurs
réelles. Cela signifie que multiplier toutes les valeurs réelles par un
facteur positif ne change pas le MPE.</p></li>
<li><p><strong>Sensibilité aux erreurs</strong> : Le MPE est sensible
aux erreurs de prédiction, en particulier lorsque les valeurs réelles
sont proches de zéro. Cela peut être un avantage ou un inconvénient,
selon le contexte d’application.</p></li>
<li><p><strong>Interprétation intuitive</strong> : Le MPE offre une
interprétation intuitive de l’erreur relative moyenne, exprimée en
pourcentage. Cela facilite la communication des résultats aux parties
prenantes non techniques.</p></li>
</ul>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>En conclusion, la Moyenne de l’Erreur en Pourcentage (MPE) est une
métrique puissante et intuitive pour évaluer les performances des
modèles prédictifs. Son invariance sous l’échelle des valeurs réelles et
sa sensibilité aux erreurs en font un outil précieux dans de nombreux
domaines d’application. En comprenant les propriétés et les théorèmes
associés au MPE, nous pouvons mieux interpréter et utiliser cette
métrique pour améliorer la qualité de nos modèles.</p>
</body>
</html>
{% include "footer.html" %}

