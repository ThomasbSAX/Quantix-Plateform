{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>F-beta score : Mesure de la performance des modèles de classification</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">F-beta score : Mesure de la performance des modèles de
classification</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’évaluation des modèles de classification est une étape cruciale
dans le développement de systèmes intelligents. Parmi les nombreuses
métriques disponibles, le F-beta score se distingue par sa capacité à
pondérer l’importance relative de la précision et du rappel. Ce score
est particulièrement utile dans les contextes où l’équilibre entre ces
deux mesures est crucial, comme dans la détection de fraudes ou le
diagnostic médical.</p>
<p>Le F-beta score émerge d’une nécessité de combiner deux métriques
fondamentales : la précision et le rappel. La précision mesure la
proportion des prédictions positives qui sont réellement positives,
tandis que le rappel mesure la proportion des exemples positifs qui sont
correctement identifiés. Le F-beta score permet de trouver un compromis
entre ces deux mesures, en accordant une importance relative variable à
chacune d’elles.</p>
<h1 id="définitions">Définitions</h1>
<p>Avant de définir formellement le F-beta score, il est essentiel de
comprendre les concepts sous-jacents. Considérons un problème de
classification binaire où nous avons deux classes : positive et
négative. Pour évaluer la performance d’un modèle, nous avons besoin de
quatre quantités fondamentales :</p>
<ul>
<li><p>Vrais Positifs (VP) : le nombre d’exemples positifs correctement
prédits.</p></li>
<li><p>Faux Positifs (FP) : le nombre d’exemples négatifs incorrectement
prédits comme positifs.</p></li>
<li><p>Vrais Négatifs (VN) : le nombre d’exemples négatifs correctement
prédits.</p></li>
<li><p>Faux Négatifs (FN) : le nombre d’exemples positifs incorrectement
prédits comme négatifs.</p></li>
</ul>
<p>À partir de ces quantités, nous pouvons définir la précision et le
rappel :</p>
<div class="definition">
<p>La précision est définie comme la proportion des prédictions
positives qui sont réellement positives. Formellement, pour un ensemble
de données donné, la précision <span class="math inline">\(P\)</span>
est donnée par : <span class="math display">\[P = \frac{VP}{VP +
FP}\]</span></p>
</div>
<div class="definition">
<p>Le rappel est défini comme la proportion des exemples positifs qui
sont correctement identifiés. Formellement, pour un ensemble de données
donné, le rappel <span class="math inline">\(R\)</span> est donné par :
<span class="math display">\[R = \frac{VP}{VP + FN}\]</span></p>
</div>
<p>Maintenant, nous sommes prêts à définir le F-beta score. Le F-beta
score est une mesure de la performance qui combine la précision et le
rappel en une seule métrique. Le paramètre beta permet de pondérer
l’importance relative du rappel par rapport à la précision.</p>
<div class="definition">
<p>Le F-beta score est défini comme la moyenne harmonique pondérée de la
précision et du rappel. Formellement, pour un paramètre beta <span
class="math inline">\(\beta \geq 0\)</span>, le F-beta score <span
class="math inline">\(F_\beta\)</span> est donné par : <span
class="math display">\[F_\beta = (1 + \beta^2) \cdot \frac{P \cdot
R}{(\beta^2 \cdot P) + R}\]</span> où <span
class="math inline">\(P\)</span> est la précision et <span
class="math inline">\(R\)</span> est le rappel.</p>
</div>
<h1 id="théorèmes">Théorèmes</h1>
<p>Le F-beta score possède plusieurs propriétés intéressantes qui le
rendent utile dans divers contextes. Nous allons explorer quelques-unes
de ces propriétés sous forme de théorèmes.</p>
<div class="theorem">
<p>Le F-beta score est une moyenne harmonique pondérée de la précision
et du rappel. Cela signifie que le F-beta score est toujours compris
entre la précision et le rappel, en fonction de la valeur de beta.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, nous devons montrer
que le F-beta score est toujours compris entre la précision et le
rappel. Considérons la définition du F-beta score : <span
class="math display">\[F_\beta = (1 + \beta^2) \cdot \frac{P \cdot
R}{(\beta^2 \cdot P) + R}\]</span> Nous voulons montrer que <span
class="math inline">\(F_\beta\)</span> est compris entre <span
class="math inline">\(P\)</span> et <span
class="math inline">\(R\)</span>. Pour ce faire, nous pouvons utiliser
l’inégalité de la moyenne harmonique. L’inégalité de la moyenne
harmonique stipule que pour deux nombres positifs <span
class="math inline">\(a\)</span> et <span
class="math inline">\(b\)</span>, la moyenne harmonique est toujours
inférieure ou égale à la moyenne arithmétique : <span
class="math display">\[\frac{2ab}{a + b} \leq \frac{a + b}{2}\]</span>
En appliquant cette inégalité à la précision et au rappel, nous obtenons
: <span class="math display">\[\frac{2PR}{P + R} \leq \frac{P +
R}{2}\]</span> En multipliant les deux côtés par <span
class="math inline">\((1 + \beta^2)\)</span>, nous obtenons : <span
class="math display">\[(1 + \beta^2) \cdot \frac{2PR}{P + R} \leq (1 +
\beta^2) \cdot \frac{P + R}{2}\]</span> En comparant cette inégalité
avec la définition du F-beta score, nous voyons que <span
class="math inline">\(F_\beta\)</span> est toujours compris entre la
précision et le rappel. ◻</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Pour illustrer l’utilité du F-beta score, nous allons prouver
quelques-unes de ses propriétés fondamentales.</p>
<div class="theorem">
<p>Lorsque beta tend vers zéro, le F-beta score tend vers la précision.
Lorsque beta tend vers l’infini, le F-beta score tend vers le
rappel.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, nous devons examiner
le comportement du F-beta score lorsque beta tend vers zéro et vers
l’infini. Considérons la définition du F-beta score : <span
class="math display">\[F_\beta = (1 + \beta^2) \cdot \frac{P \cdot
R}{(\beta^2 \cdot P) + R}\]</span> Lorsque beta tend vers zéro, le terme
<span class="math inline">\(\beta^2\)</span> devient négligeable. Par
conséquent, l’expression se simplifie en : <span
class="math display">\[F_\beta \approx (1 + 0) \cdot \frac{P \cdot R}{0
\cdot P + R} = P\]</span> Ainsi, lorsque beta tend vers zéro, le F-beta
score tend vers la précision.</p>
<p>Lorsque beta tend vers l’infini, le terme <span
class="math inline">\(\beta^2\)</span> domine. Par conséquent,
l’expression se simplifie en : <span class="math display">\[F_\beta
\approx (1 + \infty) \cdot \frac{P \cdot R}{\infty \cdot P + R} =
\frac{P \cdot R}{P} = R\]</span> Ainsi, lorsque beta tend vers l’infini,
le F-beta score tend vers le rappel. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Le F-beta score possède plusieurs propriétés intéressantes qui le
rendent utile dans divers contextes. Nous allons explorer quelques-unes
de ces propriétés sous forme de corollaires.</p>
<div class="corollary">
<p>Le F-beta score est symétrique en précision et rappel lorsque beta
est égal à un. Cela signifie que le F-beta score donne la même
importance à la précision et au rappel lorsque beta est égal à un.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, nous devons montrer
que le F-beta score est symétrique en précision et rappel lorsque beta
est égal à un. Considérons la définition du F-beta score : <span
class="math display">\[F_\beta = (1 + \beta^2) \cdot \frac{P \cdot
R}{(\beta^2 \cdot P) + R}\]</span> Lorsque beta est égal à un,
l’expression se simplifie en : <span class="math display">\[F_1 = (1 +
1) \cdot \frac{P \cdot R}{(1 \cdot P) + R} = 2 \cdot \frac{P \cdot R}{P
+ R}\]</span> Cette expression est symétrique en précision et rappel, ce
qui signifie que le F-beta score donne la même importance à la précision
et au rappel lorsque beta est égal à un. ◻</p>
</div>
<div class="corollary">
<p>Le F-beta score est une fonction croissante de la précision et du
rappel. Cela signifie que si la précision ou le rappel augmente, le
F-beta score augmente également.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, nous devons montrer
que le F-beta score est une fonction croissante de la précision et du
rappel. Considérons la définition du F-beta score : <span
class="math display">\[F_\beta = (1 + \beta^2) \cdot \frac{P \cdot
R}{(\beta^2 \cdot P) + R}\]</span> Pour montrer que le F-beta score est
une fonction croissante de la précision, nous devons montrer que si
<span class="math inline">\(P\)</span> augmente, <span
class="math inline">\(F_\beta\)</span> augmente également. Pour ce
faire, nous pouvons examiner la dérivée partielle de <span
class="math inline">\(F_\beta\)</span> par rapport à <span
class="math inline">\(P\)</span> : <span
class="math display">\[\frac{\partial F_\beta}{\partial P} = (1 +
\beta^2) \cdot \frac{R \cdot [(\beta^2 \cdot P) + R] - P \cdot R \cdot
\beta^2}{[(\beta^2 \cdot P) + R]^2} = (1 + \beta^2) \cdot
\frac{R^2}{[(\beta^2 \cdot P) + R]^2} &gt; 0\]</span> Puisque la dérivée
partielle est toujours positive, le F-beta score est une fonction
croissante de la précision.</p>
<p>De manière similaire, pour montrer que le F-beta score est une
fonction croissante du rappel, nous devons montrer que si <span
class="math inline">\(R\)</span> augmente, <span
class="math inline">\(F_\beta\)</span> augmente également. Pour ce
faire, nous pouvons examiner la dérivée partielle de <span
class="math inline">\(F_\beta\)</span> par rapport à <span
class="math inline">\(R\)</span> : <span
class="math display">\[\frac{\partial F_\beta}{\partial R} = (1 +
\beta^2) \cdot \frac{P \cdot [(\beta^2 \cdot P) + R] - P \cdot
R}{[(\beta^2 \cdot P) + R]^2} = (1 + \beta^2) \cdot \frac{P^2 \cdot
\beta^2}{[(\beta^2 \cdot P) + R]^2} &gt; 0\]</span> Puisque la dérivée
partielle est toujours positive, le F-beta score est une fonction
croissante du rappel. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>Le F-beta score est une métrique puissante pour évaluer la
performance des modèles de classification. En combinant la précision et
le rappel en une seule métrique, il permet de trouver un compromis entre
ces deux mesures. Le paramètre beta offre une flexibilité
supplémentaire, permettant d’accorder une importance relative variable à
la précision et au rappel. Les propriétés du F-beta score, telles que sa
symétrie et sa monotonie, en font un outil précieux pour l’évaluation
des modèles de classification.</p>
</body>
</html>
{% include "footer.html" %}

