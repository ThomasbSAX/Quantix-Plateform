{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Gower pour variables discrètes symétriques normalisées</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Gower pour variables discrètes symétriques
normalisées</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’analyse des données discrètes symétriques est un domaine
fondamental en statistique et en apprentissage automatique. Les
variables discrètes, souvent qualitatives ou catégorielles, nécessitent
des outils spécifiques pour mesurer leur similarité. La distance de
Gower émerge comme une solution élégante et puissante pour comparer des
objets décrits par des variables discrètes symétriques normalisées.</p>
<p>Historiquement, la distance de Gower a été introduite par G. C. Gower
en 1971 pour généraliser la notion de distance aux données mixtes,
combinant à la fois des variables quantitatives et qualitatives. Dans ce
chapitre, nous nous concentrons sur son application aux variables
discrètes symétriques normalisées.</p>
<p>Pourquoi cette notion est-elle indispensable ? Elle permet de
capturer la similarité entre objets de manière robuste, en tenant compte
des spécificités des variables discrètes. Elle est particulièrement
utile dans les domaines où les données sont de nature mixte, comme la
bioinformatique, la sociologie ou l’économie.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir la distance de Gower, commençons par comprendre ce que
nous cherchons à mesurer. Nous voulons quantifier la dissimilarité entre
deux objets décrits par des variables discrètes symétriques normalisées.
Ces variables prennent des valeurs dans un ensemble fini et sont
symétriques, ce qui signifie que la distance entre deux valeurs est
indépendante de leur ordre.</p>
<p>Supposons que nous ayons un ensemble de variables discrètes
symétriques normalisées <span class="math inline">\(X_1, X_2, \dots,
X_p\)</span>. Chaque variable <span class="math inline">\(X_j\)</span>
prend des valeurs dans un ensemble fini <span class="math inline">\(S_j
= \{s_{j1}, s_{j2}, \dots, s_{jk_j}\}\)</span>. Nous voulons définir une
distance <span class="math inline">\(d\)</span> entre deux objets
décrits par ces variables.</p>
<p>Formellement, la distance de Gower pour des variables discrètes
symétriques normalisées est définie comme suit :</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathbf{x} = (x_1, x_2, \dots,
x_p)\)</span> et <span class="math inline">\(\mathbf{y} = (y_1, y_2,
\dots, y_p)\)</span> deux objets décrits par <span
class="math inline">\(p\)</span> variables discrètes symétriques
normalisées. La distance de Gower entre <span
class="math inline">\(\mathbf{x}\)</span> et <span
class="math inline">\(\mathbf{y}\)</span> est donnée par :</p>
<p><span class="math display">\[d(\mathbf{x}, \mathbf{y}) = \frac{1}{p}
\sum_{j=1}^p \delta_j(x_j, y_j)\]</span></p>
<p>où <span class="math inline">\(\delta_j(x_j, y_j)\)</span> est la
distance entre les valeurs <span class="math inline">\(x_j\)</span> et
<span class="math inline">\(y_j\)</span> pour la variable <span
class="math inline">\(X_j\)</span>.</p>
</div>
<p>La distance <span class="math inline">\(\delta_j(x_j, y_j)\)</span>
peut être définie de différentes manières. Pour des variables discrètes
symétriques normalisées, une définition courante est :</p>
<p><span class="math display">\[\delta_j(x_j, y_j) = \begin{cases}
0 &amp; \text{si } x_j = y_j, \\
1 &amp; \text{sinon.}
\end{cases}\]</span></p>
<p>Cette définition est simple et intuitive, mais d’autres définitions
plus sophistiquées peuvent être utilisées en fonction du contexte.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Pour établir les propriétés de la distance de Gower, nous commençons
par comprendre ce que nous cherchons à prouver. Nous voulons montrer que
la distance de Gower satisfait les propriétés d’une distance métrique :
non-négativité, identité des indiscernables, symétrie et inégalité
triangulaire.</p>
<div class="theorem">
<p>La distance de Gower <span class="math inline">\(d\)</span> définie
précédemment satisfait les propriétés suivantes :</p>
<ol>
<li><p>Non-négativité : <span class="math inline">\(d(\mathbf{x},
\mathbf{y}) \geq 0\)</span> pour tous <span
class="math inline">\(\mathbf{x}, \mathbf{y}\)</span>.</p></li>
<li><p>Identité des indiscernables : <span
class="math inline">\(d(\mathbf{x}, \mathbf{y}) = 0\)</span> si et
seulement si <span class="math inline">\(\mathbf{x} =
\mathbf{y}\)</span>.</p></li>
<li><p>Symétrie : <span class="math inline">\(d(\mathbf{x}, \mathbf{y})
= d(\mathbf{y}, \mathbf{x})\)</span> pour tous <span
class="math inline">\(\mathbf{x}, \mathbf{y}\)</span>.</p></li>
<li><p>Inégalité triangulaire : <span
class="math inline">\(d(\mathbf{x}, \mathbf{z}) \leq d(\mathbf{x},
\mathbf{y}) + d(\mathbf{y}, \mathbf{z})\)</span> pour tous <span
class="math inline">\(\mathbf{x}, \mathbf{y},
\mathbf{z}\)</span>.</p></li>
</ol>
</div>
<h1 id="preuves">Preuves</h1>
<p>Nous allons maintenant prouver chaque propriété de la distance de
Gower.</p>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p>Non-négativité : Puisque <span
class="math inline">\(\delta_j(x_j, y_j) \geq 0\)</span> pour tous <span
class="math inline">\(j\)</span>, il suit que <span
class="math inline">\(d(\mathbf{x}, \mathbf{y}) = \frac{1}{p}
\sum_{j=1}^p \delta_j(x_j, y_j) \geq 0\)</span>.</p></li>
<li><p>Identité des indiscernables : Si <span
class="math inline">\(\mathbf{x} = \mathbf{y}\)</span>, alors <span
class="math inline">\(x_j = y_j\)</span> pour tous <span
class="math inline">\(j\)</span>, et donc <span
class="math inline">\(\delta_j(x_j, y_j) = 0\)</span>. Par conséquent,
<span class="math inline">\(d(\mathbf{x}, \mathbf{y}) = 0\)</span>.
Réciproquement, si <span class="math inline">\(d(\mathbf{x}, \mathbf{y})
= 0\)</span>, alors <span class="math inline">\(\sum_{j=1}^p
\delta_j(x_j, y_j) = 0\)</span>, ce qui implique que <span
class="math inline">\(\delta_j(x_j, y_j) = 0\)</span> pour tous <span
class="math inline">\(j\)</span>. Donc <span class="math inline">\(x_j =
y_j\)</span> pour tous <span class="math inline">\(j\)</span>, et <span
class="math inline">\(\mathbf{x} = \mathbf{y}\)</span>.</p></li>
<li><p>Symétrie : Puisque <span class="math inline">\(\delta_j(x_j, y_j)
= \delta_j(y_j, x_j)\)</span>, il suit que <span
class="math inline">\(d(\mathbf{x}, \mathbf{y}) = \frac{1}{p}
\sum_{j=1}^p \delta_j(x_j, y_j) = \frac{1}{p} \sum_{j=1}^p \delta_j(y_j,
x_j) = d(\mathbf{y}, \mathbf{x})\)</span>.</p></li>
<li><p>Inégalité triangulaire : Pour prouver l’inégalité triangulaire,
nous utilisons le fait que <span class="math inline">\(\delta_j\)</span>
est une distance. Donc, pour chaque <span
class="math inline">\(j\)</span>, nous avons <span
class="math inline">\(\delta_j(x_j, z_j) \leq \delta_j(x_j, y_j) +
\delta_j(y_j, z_j)\)</span>. En sommant sur <span
class="math inline">\(j\)</span>, nous obtenons :</p>
<p><span class="math display">\[\sum_{j=1}^p \delta_j(x_j, z_j) \leq
\sum_{j=1}^p \delta_j(x_j, y_j) + \sum_{j=1}^p \delta_j(y_j,
z_j)\]</span></p>
<p>En divisant par <span class="math inline">\(p\)</span>, nous obtenons
:</p>
<p><span class="math display">\[d(\mathbf{x}, \mathbf{z}) \leq
d(\mathbf{x}, \mathbf{y}) + d(\mathbf{y}, \mathbf{z})\]</span></p>
<p>Ce qui prouve l’inégalité triangulaire.</p></li>
</ol>
<p> ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous allons maintenant énoncer quelques propriétés et corollaires de
la distance de Gower.</p>
<div class="proposition">
<p>La distance de Gower est invariante par translation et par échelle
des variables.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La distance de Gower est définie en termes des
différences entre les valeurs des variables. Les translations et les
changements d’échelle n’affectent pas ces différences, donc la distance
reste inchangée. ◻</p>
</div>
<div class="corollaire">
<p>La distance de Gower peut être utilisée pour comparer des objets
décrits par des variables discrètes symétriques normalisées, même si les
échelles des variables sont différentes.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Cela découle directement de la proposition
précédente. Puisque la distance est invariante par échelle, les
différences d’échelle entre les variables n’affectent pas la mesure de
similarité. ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La distance de Gower pour variables discrètes symétriques normalisées
est un outil puissant et flexible pour mesurer la similarité entre
objets décrits par des variables discrètes. Ses propriétés métriques en
font un choix naturel pour de nombreuses applications en statistique et
en apprentissage automatique. En comprenant ses définitions, théorèmes
et preuves, nous pouvons l’appliquer de manière efficace à divers
problèmes pratiques.</p>
</body>
</html>
{% include "footer.html" %}

