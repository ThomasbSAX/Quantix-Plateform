{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Variance Inter-Individuelle : Mesure de la Dispersion des Caractéristiques dans une Population</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Variance Inter-Individuelle : Mesure de la
Dispersion des Caractéristiques dans une Population</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La variance inter-individuelle est une notion fondamentale en
statistique descriptive, permettant de quantifier la dispersion des
caractéristiques au sein d’une population. Elle trouve ses racines dans
les travaux de Karl Pearson et Ronald Fisher, qui ont posé les bases de
l’analyse statistique moderne. L’étude de cette variance est cruciale
dans de nombreux domaines, tels que la biologie, l’économie, et les
sciences sociales, où elle permet de comprendre les différences
individuelles au sein d’un groupe.</p>
<p>L’émergence de cette notion répond à un besoin essentiel : mesurer
objectivement les écarts entre individus. En effet, une moyenne seule ne
suffit pas à décrire complètement une population ; il est nécessaire de
connaître également la dispersion autour de cette moyenne. La variance
inter-individuelle offre une réponse précise à cette question, en
fournissant un indicateur de la variabilité des données.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la variance inter-individuelle, commençons par
comprendre ce que nous cherchons à mesurer. Imaginons une population
d’individus, chacun caractérisé par une variable quantitative (taille,
revenu, etc.). Nous voulons quantifier à quel point ces individus
diffèrent les uns des autres par rapport à cette variable.</p>
<p>Formellement, la variance inter-individuelle <span
class="math inline">\(\sigma^2\)</span> d’une population de <span
class="math inline">\(N\)</span> individus est définie comme suit :</p>
<p><span class="math display">\[\sigma^2 = \frac{1}{N} \sum_{i=1}^{N}
(X_i - \mu)^2\]</span></p>
<p>où :</p>
<ul>
<li><p><span class="math inline">\(X_i\)</span> représente la valeur de
la variable pour l’individu <span
class="math inline">\(i\)</span>,</p></li>
<li><p><span class="math inline">\(\mu\)</span> est la moyenne de la
population, définie par <span class="math inline">\(\mu = \frac{1}{N}
\sum_{i=1}^{N} X_i\)</span>,</p></li>
<li><p><span class="math inline">\(N\)</span> est le nombre total
d’individus dans la population.</p></li>
</ul>
<p>Cette définition peut également être réécrite en utilisant la formule
de la variance non centrée :</p>
<p><span class="math display">\[\sigma^2 = \frac{1}{N} \sum_{i=1}^{N}
X_i^2 - \mu^2\]</span></p>
<p>Cette formulation est souvent plus pratique pour les calculs, car
elle évite de devoir calculer explicitement chaque écart à la
moyenne.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la variance inter-individuelle est le
théorème de la loi des grands nombres, qui établit que la moyenne
empirique d’un échantillon converge vers la moyenne de la population
lorsque la taille de l’échantillon tend vers l’infini. Ce théorème
justifie l’utilisation de la variance inter-individuelle comme mesure de
la dispersion dans une population.</p>
<p><strong>Théorème (Loi des grands nombres)</strong> : Soit <span
class="math inline">\(X_1, X_2, \ldots, X_n\)</span> une suite de
variables aléatoires indépendantes et identiquement distribuées (i.i.d.)
avec une espérance finie <span class="math inline">\(\mu\)</span>.
Alors, la moyenne empirique <span class="math inline">\(\bar{X}_n =
\frac{1}{n} \sum_{i=1}^{n} X_i\)</span> converge presque sûrement vers
<span class="math inline">\(\mu\)</span> lorsque <span
class="math inline">\(n\)</span> tend vers l’infini.</p>
<p><strong>Preuve</strong> : La preuve de ce théorème repose sur des
résultats avancés en théorie des probabilités, tels que l’inégalité de
Bienaymé-Tchebyshev et le lemme de Borel-Cantelli. Elle montre que la
variance inter-individuelle est une mesure stable et fiable de la
dispersion dans une population.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>La variance inter-individuelle possède plusieurs propriétés
importantes, que nous allons énumérer et démontrer.</p>
<ol>
<li><p><strong>Non-négativité</strong> : La variance est toujours non
négative. En effet, pour tout <span class="math inline">\(i\)</span>,
<span class="math inline">\((X_i - \mu)^2 \geq 0\)</span>, donc <span
class="math inline">\(\sigma^2 \geq 0\)</span>.</p></li>
<li><p><strong>Invariance par translation</strong> : La variance est
invariante par translation. Si nous ajoutons une constante <span
class="math inline">\(c\)</span> à chaque valeur de la variable, la
variance reste inchangée. Formellement, si <span
class="math inline">\(Y_i = X_i + c\)</span>, alors <span
class="math inline">\(\text{Var}(Y) = \text{Var}(X)\)</span>.</p></li>
<li><p><strong>Homogénéité</strong> : La variance est homogène de degré
2. Si nous multiplions chaque valeur de la variable par une constante
<span class="math inline">\(a\)</span>, la variance est multipliée par
<span class="math inline">\(a^2\)</span>. Formellement, si <span
class="math inline">\(Y_i = aX_i\)</span>, alors <span
class="math inline">\(\text{Var}(Y) = a^2
\text{Var}(X)\)</span>.</p></li>
</ol>
<p><strong>Démonstration de l’invariance par translation</strong> : Soit
<span class="math inline">\(Y_i = X_i + c\)</span>. Alors, la moyenne de
<span class="math inline">\(Y\)</span> est <span
class="math inline">\(\mu_Y = \mu_X + c\)</span>. La variance de <span
class="math inline">\(Y\)</span> est :</p>
<p><span class="math display">\[\sigma_Y^2 = \frac{1}{N} \sum_{i=1}^{N}
(Y_i - \mu_Y)^2 = \frac{1}{N} \sum_{i=1}^{N} (X_i + c - (\mu_X + c))^2 =
\frac{1}{N} \sum_{i=1}^{N} (X_i - \mu_X)^2 = \sigma_X^2\]</span></p>
<p>Ainsi, <span class="math inline">\(\text{Var}(Y) =
\text{Var}(X)\)</span>, ce qui prouve l’invariance par translation.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La variance inter-individuelle est une mesure essentielle pour
quantifier la dispersion des caractéristiques au sein d’une population.
Elle trouve des applications dans de nombreux domaines et est soutenue
par des théorèmes fondamentaux en statistique. Comprendre cette notion
permet de mieux analyser et interpréter les données, offrant ainsi des
insights précieux pour la recherche et l’analyse descriptive.</p>
</body>
</html>
{% include "footer.html" %}

