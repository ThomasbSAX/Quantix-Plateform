{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>AUC-PR (Area Under Precision-Recall Curve) : Une mesure clé en apprentissage automatique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">AUC-PR (Area Under Precision-Recall Curve) : Une
mesure clé en apprentissage automatique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’apprentissage automatique est un domaine en pleine expansion, où
l’évaluation des modèles de classification est cruciale. Parmi les
nombreuses métriques disponibles, la courbe Precision-Recall (PR) et son
intégrale, l’AUC-PR (Area Under the Precision-Recall Curve), jouent un
rôle fondamental. L’AUC-PR est une mesure de la performance globale d’un
modèle, en particulier dans les cas où les classes sont déséquilibrées.
Elle offre une vision synthétique de la capacité du modèle à distinguer
les classes positives des négatives, en tenant compte à la fois de la
précision et du rappel.</p>
<p>L’origine de cette métrique remonte aux travaux en statistique et en
théorie des tests. La précision (Precision) mesure la proportion de
vrais positifs parmi les éléments prédits comme positifs, tandis que le
rappel (Recall) mesure la proportion de vrais positifs parmi tous les
éléments réellement positifs. La courbe PR trace ces deux métriques en
fonction du seuil de décision, et l’AUC-PR est l’aire sous cette courbe.
Cette mesure est particulièrement utile dans les contextes où les faux
positifs sont coûteux, comme en médecine ou en détection de fraude.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre l’AUC-PR, il est essentiel de définir d’abord les
concepts de précision et de rappel.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathcal{D} = \{ (x_i, y_i)
\}_{i=1}^n\)</span> un ensemble de données étiquetées, où <span
class="math inline">\(x_i \in \mathcal{X}\)</span> et <span
class="math inline">\(y_i \in \{0, 1\}\)</span>. Soit <span
class="math inline">\(f: \mathcal{X} \rightarrow [0, 1]\)</span> une
fonction de score prédit par un modèle. Pour un seuil <span
class="math inline">\(t \in [0, 1]\)</span>, définissons les prédictions
binaires <span class="math inline">\(\hat{y}_i = \mathbb{I}(f(x_i) \geq
t)\)</span>, où <span class="math inline">\(\mathbb{I}\)</span> est
l’indicatrice.</p>
<p>La précision au seuil <span class="math inline">\(t\)</span> est
définie comme : <span class="math display">\[P(t) = \frac{\sum_{i=1}^n
y_i \hat{y}_i}{\sum_{i=1}^n \hat{y}_i}\]</span> Si <span
class="math inline">\(\sum_{i=1}^n \hat{y}_i = 0\)</span>, on pose <span
class="math inline">\(P(t) = 1\)</span>.</p>
<p>En termes quantifiés, la précision est : <span
class="math display">\[P(t) = \frac{\sum_{i=1}^n y_i \mathbb{I}(f(x_i)
\geq t)}{\sum_{i=1}^n \mathbb{I}(f(x_i) \geq t)}\]</span></p>
</div>
<div class="definition">
<p>Le rappel au seuil <span class="math inline">\(t\)</span> est défini
comme : <span class="math display">\[R(t) = \frac{\sum_{i=1}^n y_i
\hat{y}_i}{\sum_{i=1}^n y_i}\]</span> En termes quantifiés, le rappel
est : <span class="math display">\[R(t) = \frac{\sum_{i=1}^n y_i
\mathbb{I}(f(x_i) \geq t)}{\sum_{i=1}^n y_i}\]</span></p>
</div>
<div class="definition">
<p>La courbe PR est le graphe de la fonction <span
class="math inline">\(t \mapsto (R(t), P(t))\)</span> pour <span
class="math inline">\(t \in [0, 1]\)</span>.</p>
<p>Formellement, la courbe PR est définie par : <span
class="math display">\[\text{PR} = \{ (R(t), P(t)) \mid t \in [0, 1]
\}\]</span></p>
</div>
<div class="definition">
<p>L’AUC-PR est l’aire sous la courbe PR. Elle peut être calculée comme
l’intégrale de <span class="math inline">\(P(t)\)</span> par rapport à
<span class="math inline">\(R(t)\)</span>.</p>
<p>Formellement, l’AUC-PR est définie comme : <span
class="math display">\[\text{AUC-PR} = \int_{0}^{1} P(t) \,
dR(t)\]</span></p>
</div>
<h1 class="unnumbered" id="théorèmes-et-propriétés">Théorèmes et
Propriétés</h1>
<p>L’AUC-PR possède plusieurs propriétés intéressantes, notamment en
termes de lien avec d’autres métriques et en termes de comportement
asymptotique.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(\text{AUC-PR}\)</span> et <span
class="math inline">\(\text{AUC-ROC}\)</span> les aires sous les courbes
PR et ROC respectivement. Alors, pour un modèle aléatoire, <span
class="math inline">\(\text{AUC-PR} = P_{\text{positif}}\)</span>, où
<span class="math inline">\(P_{\text{positif}}\)</span> est la
proportion de positifs dans l’ensemble de données.</p>
<p>Formellement, si <span class="math inline">\(f\)</span> est une
fonction aléatoire indépendante des étiquettes <span
class="math inline">\(y_i\)</span>, alors : <span
class="math display">\[\mathbb{E}[\text{AUC-PR}] =
P_{\text{positif}}\]</span> où <span
class="math inline">\(\mathbb{E}\)</span> désigne l’espérance.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour un modèle aléatoire, la précision <span
class="math inline">\(P(t)\)</span> est égale à la proportion de
positifs parmi les éléments prédits comme positifs. Comme le modèle est
aléatoire, cette proportion est égale à <span
class="math inline">\(P_{\text{positif}}\)</span> pour tout seuil <span
class="math inline">\(t\)</span>. Par conséquent, l’intégrale de <span
class="math inline">\(P(t)\)</span> par rapport à <span
class="math inline">\(R(t)\)</span> est simplement <span
class="math inline">\(P_{\text{positif}}\)</span>.</p>
<p>En termes quantifiés : <span class="math display">\[\mathbb{E}[P(t)]
= P_{\text{positif}} \quad \forall t \in [0, 1]\]</span> <span
class="math display">\[\mathbb{E}[\text{AUC-PR}] = \int_{0}^{1}
\mathbb{E}[P(t)] \, dR(t) = P_{\text{positif}}\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’AUC-PR possède plusieurs propriétés qui en font une métrique
robuste et informative.</p>
<div class="corollaire">
<p>L’AUC-PR est une mesure monotone en ce sens que si un modèle <span
class="math inline">\(f_1\)</span> domine strictement un autre modèle
<span class="math inline">\(f_2\)</span> (i.e., pour tout seuil <span
class="math inline">\(t\)</span>, <span class="math inline">\(P_{f_1}(t)
\geq P_{f_2}(t)\)</span> et <span class="math inline">\(R_{f_1}(t) \geq
R_{f_2}(t)\)</span>), alors <span
class="math inline">\(\text{AUC-PR}_{f_1} \geq
\text{AUC-PR}_{f_2}\)</span>.</p>
<p>Formellement, si <span class="math inline">\(f_1\)</span> domine
strictement <span class="math inline">\(f_2\)</span>, alors : <span
class="math display">\[\text{AUC-PR}_{f_1} \geq
\text{AUC-PR}_{f_2}\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La monotonie de l’AUC-PR découle directement de la
définition de l’intégrale. Si <span class="math inline">\(P_{f_1}(t)
\geq P_{f_2}(t)\)</span> pour tout <span
class="math inline">\(t\)</span>, alors l’intégrale de <span
class="math inline">\(P_{f_1}(t)\)</span> par rapport à <span
class="math inline">\(R(t)\)</span> sera supérieure ou égale à
l’intégrale de <span class="math inline">\(P_{f_2}(t)\)</span>.</p>
<p>En termes quantifiés : <span
class="math display">\[\text{AUC-PR}_{f_1} = \int_{0}^{1} P_{f_1}(t) \,
dR(t) \geq \int_{0}^{1} P_{f_2}(t) \, dR(t) =
\text{AUC-PR}_{f_2}\]</span> ◻</p>
</div>
<div class="corollaire">
<p>L’AUC-PR est invariante par normalisation des scores prédits. Si
<span class="math inline">\(f\)</span> et <span
class="math inline">\(g\)</span> sont deux fonctions de score telles que
<span class="math inline">\(g(x) = a f(x) + b\)</span>, où <span
class="math inline">\(a &gt; 0\)</span>, alors <span
class="math inline">\(\text{AUC-PR}_f = \text{AUC-PR}_g\)</span>.</p>
<p>Formellement, si <span class="math inline">\(g(x) = a f(x) +
b\)</span>, alors : <span class="math display">\[\text{AUC-PR}_f =
\text{AUC-PR}_g\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> La normalisation des scores <span
class="math inline">\(g(x) = a f(x) + b\)</span> ne change pas l’ordre
des prédictions, et donc les valeurs de <span
class="math inline">\(P(t)\)</span> et <span
class="math inline">\(R(t)\)</span> restent inchangées. Par conséquent,
l’intégrale sous la courbe PR reste la même.</p>
<p>En termes quantifiés : <span class="math display">\[P_g(t) = P_f(t)
\quad \text{et} \quad R_g(t) = R_f(t)\]</span> <span
class="math display">\[\text{AUC-PR}_g = \int_{0}^{1} P_g(t) \, dR_g(t)
= \int_{0}^{1} P_f(t) \, dR_f(t) = \text{AUC-PR}_f\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’AUC-PR est une métrique puissante et informative pour évaluer la
performance des modèles de classification, en particulier dans les cas
où les classes sont déséquilibrées. Elle offre une vision synthétique de
la capacité du modèle à distinguer les classes positives des négatives,
en tenant compte à la fois de la précision et du rappel. Les propriétés
et théorèmes associés à l’AUC-PR en font une mesure robuste et fiable,
largement utilisée dans les applications pratiques de l’apprentissage
automatique.</p>
</body>
</html>
{% include "footer.html" %}

