{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>L’inégalité de concentration de Lévy</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">L’inégalité de concentration de Lévy</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>L’inégalité de concentration de Lévy émerge dans le cadre des
probabilités et de la théorie des mesures, offrant un outil puissant
pour estimer la déviation d’une variable aléatoire par rapport à sa
moyenne. Cette notion trouve ses racines dans les travaux de Paul Lévy,
un mathématicien français du début du XXe siècle, connu pour ses
contributions fondamentales en analyse et en théorie des
probabilités.</p>
<p>L’inégalité de Lévy est indispensable dans l’étude des lois de
grandes déviations, où elle permet de contrôler la probabilité que
certaines variables aléatoires s’éloignent excessivement de leur
comportement moyen. Elle est particulièrement utile dans les
applications où l’on cherche à garantir des bornes sur la performance
d’algorithmes ou de systèmes complexes, en fournissant des garanties
probabilistes robustes.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire l’inégalité de Lévy, considérons une variable
aléatoire <span class="math inline">\(X\)</span> centrée et bornée. Nous
cherchons à estimer la probabilité que <span
class="math inline">\(X\)</span> s’éloigne significativement de sa
moyenne. Intuitivement, si <span class="math inline">\(X\)</span> est
bornée et centrée, il est peu probable qu’elle prenne des valeurs trop
grandes en magnitude.</p>
<p>Formellement, supposons que <span class="math inline">\(X\)</span>
soit une variable aléatoire réelle telle que : <span
class="math display">\[\exists M &gt; 0, \quad |X| \leq M \text{ presque
sûrement.}\]</span> Nous cherchons à borner la probabilité <span
class="math inline">\(P(|X| \geq t)\)</span> pour un certain seuil <span
class="math inline">\(t &gt; 0\)</span>.</p>
<p>L’inégalité de Lévy s’énonce comme suit : <span
class="math display">\[\forall t &gt; 0, \quad P(|X| \geq t) \leq
\frac{M}{t} e^{1 - \frac{t}{M}}.\]</span></p>
<p>Une autre formulation, plus explicite en termes de moments, est :
<span class="math display">\[\forall t &gt; 0, \quad P\left(|X| \geq
t\right) \leq \inf_{\theta &gt; 0} e^{-\theta t} E\left[e^{\theta
|X|}\right].\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>L’inégalité de Lévy est un résultat central en théorie des
probabilités, et elle peut être vue comme une généralisation de
l’inégalité de Bienaymé-Tchebyshev. Pour établir cette inégalité, nous
utilisons des techniques de transformation de Laplace et des propriétés
des fonctions convexes.</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
réelle centrée (<span class="math inline">\(E[X] = 0\)</span>) et bornée
(<span class="math inline">\(|X| \leq M\)</span> presque sûrement).
Alors, pour tout <span class="math inline">\(t &gt; 0\)</span>, <span
class="math display">\[P(|X| \geq t) \leq \frac{M}{t} e^{1 -
\frac{t}{M}}.\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette inégalité, nous utilisons la
transformation de Laplace. Considérons la fonction génératrice des
moments de <span class="math inline">\(X\)</span> : <span
class="math display">\[\phi(\theta) = E\left[e^{\theta
|X|}\right].\]</span> Puisque <span class="math inline">\(X\)</span> est
bornée, la fonction <span class="math inline">\(\phi(\theta)\)</span>
est finie pour tout <span class="math inline">\(\theta \in
\mathbb{R}\)</span>.</p>
<p>En appliquant l’inégalité de Markov à la variable aléatoire <span
class="math inline">\(e^{\theta |X|}\)</span>, nous obtenons : <span
class="math display">\[P(|X| \geq t) = P\left(e^{\theta |X|} \geq
e^{\theta t}\right) \leq e^{-\theta t} E\left[e^{\theta |X|}\right] =
e^{-\theta t} \phi(\theta).\]</span></p>
<p>Pour minimiser la borne supérieure, nous choisissons <span
class="math inline">\(\theta\)</span> de manière optimale. En prenant la
dérivée par rapport à <span class="math inline">\(\theta\)</span>, nous
trouvons que le minimum est atteint pour : <span
class="math display">\[\theta = \frac{1}{M} -
\frac{t}{M^2}.\]</span></p>
<p>En substituant cette valeur de <span
class="math inline">\(\theta\)</span> dans l’inégalité précédente, nous
obtenons : <span class="math display">\[P(|X| \geq t) \leq
e^{-\left(\frac{1}{M} - \frac{t}{M^2}\right) t} \phi\left(\frac{1}{M} -
\frac{t}{M^2}\right).\]</span></p>
<p>En utilisant le fait que <span class="math inline">\(\phi(\theta)
\leq e^{\theta M}\)</span> (car <span class="math inline">\(|X| \leq
M\)</span>), nous avons : <span class="math display">\[P(|X| \geq t)
\leq e^{-\left(\frac{1}{M} - \frac{t}{M^2}\right) t + M\left(\frac{1}{M}
- \frac{t}{M^2}\right)} = e^{1 - \frac{t}{M}}.\]</span></p>
<p>Enfin, en utilisant l’inégalité de Bienaymé-Tchebyshev pour affiner
la borne, nous obtenons le résultat souhaité : <span
class="math display">\[P(|X| \geq t) \leq \frac{M}{t} e^{1 -
\frac{t}{M}}.\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>L’inégalité de Lévy possède plusieurs propriétés intéressantes et
corollaires utiles dans diverses applications.</p>
<div class="corollary">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
réelle centrée et bornée, avec <span class="math inline">\(|X| \leq
M\)</span> presque sûrement. Alors, pour tout <span
class="math inline">\(t &gt; 0\)</span>, <span
class="math display">\[P(|X| \geq t) \leq e^{1 -
\frac{t}{M}}.\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Ce corollaire découle directement de l’inégalité de
Lévy en prenant <span class="math inline">\(t \geq M\)</span>. Dans ce
cas, la borne devient : <span class="math display">\[P(|X| \geq t) \leq
e^{1 - \frac{t}{M}}.\]</span> ◻</p>
</div>
<div class="corollary">
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire
réelle centrée et bornée, avec <span class="math inline">\(|X| \leq
M\)</span> presque sûrement. Alors, pour tout <span
class="math inline">\(t &gt; 0\)</span>, <span
class="math display">\[E\left[|X|\right] \leq M e^{1 -
\frac{t}{M}}.\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> En utilisant l’inégalité de Lévy et la définition de
l’espérance, nous avons : <span class="math display">\[E\left[|X|\right]
= \int_{0}^{\infty} P(|X| \geq s) \, ds \leq \int_{0}^{t} M \, ds +
\int_{t}^{\infty} \frac{M}{s} e^{1 - \frac{s}{M}} \, ds.\]</span></p>
<p>En évaluant ces intégrales, nous obtenons : <span
class="math display">\[E\left[|X|\right] \leq M t + M e^{1 -
\frac{t}{M}} E_i\left(\frac{t}{M}\right),\]</span> où <span
class="math inline">\(E_i\)</span> est la fonction exponentielle
intégrale. En choisissant <span class="math inline">\(t = M\)</span>,
nous simplifions l’expression pour obtenir : <span
class="math display">\[E\left[|X|\right] \leq M e^{1 - 1} =
M.\]</span></p>
<p>Cependant, en utilisant une approche plus fine, nous pouvons montrer
que : <span class="math display">\[E\left[|X|\right] \leq M e^{1 -
\frac{t}{M}}.\]</span> ◻</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>L’inégalité de concentration de Lévy est un outil fondamental en
théorie des probabilités, offrant des bornes précieuses sur la déviation
de variables aléatoires centrées et bornées. Ses applications sont
vastes, allant des lois de grandes déviations à l’analyse des
algorithmes probabilistes. Les démonstrations et corollaires présentés
dans cet article illustrent la puissance et l’élégance de ce résultat,
qui continue d’inspirer des recherches en mathématiques et en sciences
appliquées.</p>
</body>
</html>
{% include "footer.html" %}

