{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Loi de Wishart a posteriori : Une exploration mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Loi de Wishart a posteriori : Une exploration
mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La loi de Wishart a posteriori émerge dans le cadre des modèles
bayésiens pour les matrices de covariance. Son importance réside dans sa
capacité à capturer l’incertitude sur la structure de covariance d’un
vecteur aléatoire multivarié. Historiquement, cette loi trouve ses
racines dans les travaux de John Wishart sur la généralisation de la
distribution du chi-deux à plusieurs dimensions. Dans un contexte
bayésien, elle permet d’incorporer des informations a priori sur la
matrice de covariance et de les mettre à jour en fonction des données
observées, offrant ainsi une estimation robuste et flexible.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour introduire la loi de Wishart a posteriori, commençons par
comprendre ce que nous cherchons à modéliser. Supposons que nous avons
un vecteur aléatoire multivarié <span class="math inline">\(\mathbf{X}
\sim \mathcal{N}_p(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span>, où
<span class="math inline">\(\boldsymbol{\Sigma}\)</span> est la matrice
de covariance inconnue. Nous souhaitons estimer <span
class="math inline">\(\boldsymbol{\Sigma}\)</span> en utilisant une
approche bayésienne, c’est-à-dire en incorporant des informations a
priori et en les mettant à jour avec les données observées.</p>
<div class="definition">
<p>Soit <span class="math inline">\(\mathbf{X}_1, \mathbf{X}_2, \dots,
\mathbf{X}_n\)</span> des observations indépendantes et identiquement
distribuées selon une loi normale multivariée <span
class="math inline">\(\mathcal{N}_p(\boldsymbol{\mu},
\boldsymbol{\Sigma})\)</span>. Supposons que la matrice de covariance
<span class="math inline">\(\boldsymbol{\Sigma}\)</span> suit une loi a
priori de Wishart inverse avec paramètres <span
class="math inline">\(\mathbf{S}_0\)</span> et <span
class="math inline">\(\nu_0\)</span>, notée <span
class="math inline">\(\boldsymbol{\Sigma} \sim
\mathcal{W}^{-1}_p(\mathbf{S}_0, \nu_0)\)</span>.</p>
<p>La loi a posteriori de <span
class="math inline">\(\boldsymbol{\Sigma}\)</span>, donnée les
observations <span class="math inline">\(\mathbf{X}_1, \mathbf{X}_2,
\dots, \mathbf{X}_n\)</span>, est une loi de Wishart inverse avec
paramètres mis à jour <span class="math inline">\(\mathbf{S}_n\)</span>
et <span class="math inline">\(\nu_n\)</span>, notée <span
class="math inline">\(\boldsymbol{\Sigma} \mid \mathbf{X}_1,
\mathbf{X}_2, \dots, \mathbf{X}_n \sim \mathcal{W}^{-1}_p(\mathbf{S}_n,
\nu_n)\)</span>, où : <span class="math display">\[\mathbf{S}_n =
\mathbf{S}_0 + \sum_{i=1}^n (\mathbf{X}_i -
\boldsymbol{\mu})(\mathbf{X}_i - \boldsymbol{\mu})^\top\]</span> <span
class="math display">\[\nu_n = \nu_0 + n\]</span></p>
</div>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Pour établir les propriétés de la loi de Wishart a posteriori, nous
avons besoin de quelques théorèmes fondamentaux.</p>
<div class="theorem">
<p>Supposons que <span class="math inline">\(\mathbf{X} \sim
\mathcal{N}_p(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span> et que
<span class="math inline">\(\boldsymbol{\Sigma} \sim
\mathcal{W}^{-1}_p(\mathbf{S}_0, \nu_0)\)</span>. Alors, la loi a
posteriori de <span class="math inline">\(\boldsymbol{\Sigma}\)</span>,
donnée les observations <span class="math inline">\(\mathbf{X}_1,
\mathbf{X}_2, \dots, \mathbf{X}_n\)</span>, est également une loi de
Wishart inverse avec paramètres mis à jour <span
class="math inline">\(\mathbf{S}_n\)</span> et <span
class="math inline">\(\nu_n\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> La preuve de ce théorème repose sur la propriété de
conjugaison de la loi de Wishart inverse. En effet, si l’on choisit une
loi a priori de Wishart inverse pour <span
class="math inline">\(\boldsymbol{\Sigma}\)</span>, alors la loi a
posteriori sera également une loi de Wishart inverse avec des paramètres
mis à jour en fonction des observations.</p>
<p>Plus précisément, nous avons : <span
class="math display">\[p(\boldsymbol{\Sigma} \mid \mathbf{X}_1,
\mathbf{X}_2, \dots, \mathbf{X}_n) \propto p(\boldsymbol{\Sigma})
\prod_{i=1}^n p(\mathbf{X}_i \mid \boldsymbol{\Sigma})\]</span> En
substituant les expressions des densités a priori et de vraisemblance,
nous obtenons : <span class="math display">\[p(\boldsymbol{\Sigma} \mid
\mathbf{X}_1, \mathbf{X}_2, \dots, \mathbf{X}_n) \propto
|\boldsymbol{\Sigma}|^{-\frac{\nu_0 + p + 1}{2}} \exp\left(-\frac{1}{2}
\text{tr}(\mathbf{S}_0 \boldsymbol{\Sigma}^{-1})\right) \prod_{i=1}^n
|\boldsymbol{\Sigma}|^{-\frac{1}{2}} \exp\left(-\frac{1}{2}
(\mathbf{X}_i - \boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1}
(\mathbf{X}_i - \boldsymbol{\mu})\right)\]</span> En simplifiant, nous
trouvons que la loi a posteriori est une loi de Wishart inverse avec
paramètres <span class="math inline">\(\mathbf{S}_n = \mathbf{S}_0 +
\sum_{i=1}^n (\mathbf{X}_i - \boldsymbol{\mu})(\mathbf{X}_i -
\boldsymbol{\mu})^\top\)</span> et <span class="math inline">\(\nu_n =
\nu_0 + n\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour illustrer la preuve du théorème de conjugaison, développons les
étapes détaillées.</p>
<div class="proof">
<p><em>Proof.</em> Nous commençons par exprimer la densité a posteriori
de <span class="math inline">\(\boldsymbol{\Sigma}\)</span> : <span
class="math display">\[p(\boldsymbol{\Sigma} \mid \mathbf{X}_1,
\mathbf{X}_2, \dots, \mathbf{X}_n) = \frac{p(\boldsymbol{\Sigma})
\prod_{i=1}^n p(\mathbf{X}_i \mid \boldsymbol{\Sigma})}{p(\mathbf{X}_1,
\mathbf{X}_2, \dots, \mathbf{X}_n)}\]</span> En utilisant les
expressions des densités a priori et de vraisemblance, nous avons :
<span class="math display">\[p(\boldsymbol{\Sigma}) =
\frac{|\mathbf{S}_0|^{\frac{\nu_0}{2}}}{2^{\frac{\nu_0 p}{2}}
\Gamma_p\left(\frac{\nu_0}{2}\right)}
|\boldsymbol{\Sigma}|^{-\frac{\nu_0 + p + 1}{2}} \exp\left(-\frac{1}{2}
\text{tr}(\mathbf{S}_0 \boldsymbol{\Sigma}^{-1})\right)\]</span> <span
class="math display">\[p(\mathbf{X}_i \mid \boldsymbol{\Sigma}) =
(2\pi)^{-\frac{p}{2}} |\boldsymbol{\Sigma}|^{-\frac{1}{2}}
\exp\left(-\frac{1}{2} (\mathbf{X}_i - \boldsymbol{\mu})^\top
\boldsymbol{\Sigma}^{-1} (\mathbf{X}_i -
\boldsymbol{\mu})\right)\]</span> En substituant ces expressions dans la
densité a posteriori, nous obtenons : <span
class="math display">\[p(\boldsymbol{\Sigma} \mid \mathbf{X}_1,
\mathbf{X}_2, \dots, \mathbf{X}_n) \propto
|\boldsymbol{\Sigma}|^{-\frac{\nu_0 + p + 1}{2}} \exp\left(-\frac{1}{2}
\text{tr}(\mathbf{S}_0 \boldsymbol{\Sigma}^{-1})\right) \prod_{i=1}^n
|\boldsymbol{\Sigma}|^{-\frac{1}{2}} \exp\left(-\frac{1}{2}
(\mathbf{X}_i - \boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1}
(\mathbf{X}_i - \boldsymbol{\mu})\right)\]</span> En simplifiant les
termes exponentiels et en combinant les puissances de <span
class="math inline">\(|\boldsymbol{\Sigma}|\)</span>, nous trouvons :
<span class="math display">\[p(\boldsymbol{\Sigma} \mid \mathbf{X}_1,
\mathbf{X}_2, \dots, \mathbf{X}_n) \propto
|\boldsymbol{\Sigma}|^{-\frac{\nu_0 + n + p + 1}{2}}
\exp\left(-\frac{1}{2} \text{tr}\left(\left(\mathbf{S}_0 + \sum_{i=1}^n
(\mathbf{X}_i - \boldsymbol{\mu})(\mathbf{X}_i -
\boldsymbol{\mu})^\top\right)
\boldsymbol{\Sigma}^{-1}\right)\right)\]</span> Cette expression
correspond à la densité d’une loi de Wishart inverse avec paramètres
<span class="math inline">\(\mathbf{S}_n = \mathbf{S}_0 + \sum_{i=1}^n
(\mathbf{X}_i - \boldsymbol{\mu})(\mathbf{X}_i -
\boldsymbol{\mu})^\top\)</span> et <span class="math inline">\(\nu_n =
\nu_0 + n\)</span>. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons maintenant quelques propriétés importantes de la loi de
Wishart a posteriori.</p>
<ol>
<li><p>La loi de Wishart a posteriori est une loi de conjugaison pour la
matrice de covariance <span
class="math inline">\(\boldsymbol{\Sigma}\)</span> dans un modèle normal
multivarié.</p></li>
<li><p>Les paramètres a posteriori <span
class="math inline">\(\mathbf{S}_n\)</span> et <span
class="math inline">\(\nu_n\)</span> sont des fonctions linéaires et
additives des observations, respectivement.</p></li>
<li><p>La loi de Wishart a posteriori permet d’incorporer des
informations a priori sur la matrice de covariance et de les mettre à
jour en fonction des données observées.</p></li>
</ol>
<p>Pour illustrer ces propriétés, considérons un exemple simple.</p>
<div class="example">
<p>Supposons que nous avons <span class="math inline">\(n = 2\)</span>
observations <span class="math inline">\(\mathbf{X}_1\)</span> et <span
class="math inline">\(\mathbf{X}_2\)</span> d’un vecteur aléatoire
bivariate <span class="math inline">\(\mathbf{X} \sim
\mathcal{N}_2(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span>. Supposons
également que <span class="math inline">\(\boldsymbol{\Sigma}\)</span>
suit une loi a priori de Wishart inverse avec paramètres <span
class="math inline">\(\mathbf{S}_0 = \mathbf{I}_2\)</span> et <span
class="math inline">\(\nu_0 = 3\)</span>.</p>
<p>Les paramètres a posteriori sont alors : <span
class="math display">\[\mathbf{S}_2 = \mathbf{I}_2 + (\mathbf{X}_1 -
\boldsymbol{\mu})(\mathbf{X}_1 - \boldsymbol{\mu})^\top + (\mathbf{X}_2
- \boldsymbol{\mu})(\mathbf{X}_2 - \boldsymbol{\mu})^\top\]</span> <span
class="math display">\[\nu_2 = 3 + 2 = 5\]</span> La loi a posteriori de
<span class="math inline">\(\boldsymbol{\Sigma}\)</span> est donc une
loi de Wishart inverse avec paramètres <span
class="math inline">\(\mathbf{S}_2\)</span> et <span
class="math inline">\(\nu_2\)</span>.</p>
</div>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La loi de Wishart a posteriori joue un rôle crucial dans l’estimation
bayésienne des matrices de covariance. Son utilisation permet
d’incorporer des informations a priori et de les mettre à jour en
fonction des données observées, offrant ainsi une estimation robuste et
flexible. Les propriétés de conjugaison et les théorèmes associés
montrent la puissance et l’efficacité de cette approche dans le cadre
des modèles normaux multivariés.</p>
</body>
</html>
{% include "footer.html" %}

