{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La distance de Gower pour variables continues</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La distance de Gower pour variables continues</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La distance de Gower émerge dans le cadre de l’analyse des données
multivariées, où l’on cherche à mesurer la dissimilarité entre individus
décrits par plusieurs variables. Cette notion, introduite par G.A. Gower
en 1971, est particulièrement utile lorsqu’on manipule des variables de
types différents (quantitatives, qualitatives, ordinales).</p>
<p>L’intérêt principal de la distance de Gower réside dans sa capacité à
unifier le traitement de variables hétérogènes. En effet, les méthodes
classiques de distance (comme la distance euclidienne) ne sont adaptées
qu’aux variables quantitatives. La distance de Gower, en revanche,
permet de prendre en compte des variables qualitatives et ordinales, ce
qui en fait un outil indispensable pour l’analyse de données
complexes.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour définir la distance de Gower, commençons par comprendre ce que
nous cherchons à mesurer. Supposons que nous avons un ensemble
d’individus décrits par plusieurs variables, certaines quantitatives et
d’autres qualitatives. Nous voulons mesurer la dissimilarité entre deux
individus en tenant compte de toutes ces variables.</p>
<p>Formellement, soit <span class="math inline">\(n\)</span> le nombre
d’individus et <span class="math inline">\(p\)</span> le nombre de
variables. Pour chaque individu <span class="math inline">\(i\)</span>
(où <span class="math inline">\(1 \leq i \leq n\)</span>) et chaque
variable <span class="math inline">\(j\)</span> (où <span
class="math inline">\(1 \leq j \leq p\)</span>), nous avons une valeur
<span class="math inline">\(x_{ij}\)</span>.</p>
<p>La distance de Gower entre deux individus <span
class="math inline">\(i\)</span> et <span
class="math inline">\(k\)</span> est définie comme la moyenne des
dissimilarités sur toutes les variables. Pour une variable quantitative,
la dissimilarité est simplement la différence absolue normalisée. Pour
une variable qualitative, la dissimilarité est 0 si les deux individus
ont la même valeur et 1 sinon.</p>
<div class="definition">
<p>Soient <span class="math inline">\(i\)</span> et <span
class="math inline">\(k\)</span> deux individus décrits par <span
class="math inline">\(p\)</span> variables. La distance de Gower entre
<span class="math inline">\(i\)</span> et <span
class="math inline">\(k\)</span> est définie par : <span
class="math display">\[d_{ik} = \frac{\sum_{j=1}^{p}
d_{ik}^{(j)}}{\sum_{j=1}^{p} \delta_{jk}},\]</span> où <span
class="math inline">\(d_{ik}^{(j)}\)</span> est la dissimilarité entre
les individus <span class="math inline">\(i\)</span> et <span
class="math inline">\(k\)</span> pour la variable <span
class="math inline">\(j\)</span>, et <span
class="math inline">\(\delta_{jk}\)</span> est un indicateur qui vaut 1
si la variable <span class="math inline">\(j\)</span> est prise en
compte et 0 sinon.</p>
</div>
<p>Pour une variable quantitative <span
class="math inline">\(j\)</span>, la dissimilarité est définie par :
<span class="math display">\[d_{ik}^{(j)} = \frac{|x_{ij} -
x_{kj}|}{R_j},\]</span> où <span class="math inline">\(R_j\)</span> est
l’étendue de la variable <span class="math inline">\(j\)</span>,
c’est-à-dire la différence entre la valeur maximale et minimale de cette
variable.</p>
<p>Pour une variable qualitative <span class="math inline">\(j\)</span>,
la dissimilarité est définie par : <span
class="math display">\[d_{ik}^{(j)} = \begin{cases}
0 &amp; \text{si } x_{ij} = x_{kj}, \\
1 &amp; \text{sinon.}
\end{cases}\]</span></p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un théorème important lié à la distance de Gower est le théorème
suivant, qui montre que la distance de Gower satisfait les propriétés
d’une distance métrique.</p>
<div class="theorem">
<p>La distance de Gower <span class="math inline">\(d_{ik}\)</span>
satisfait les propriétés suivantes :</p>
<ol>
<li><p>(Positivité) <span class="math inline">\(d_{ik} \geq 0\)</span>
pour tout <span class="math inline">\(i, k\)</span>.</p></li>
<li><p>(Identité des indiscernables) <span class="math inline">\(d_{ik}
= 0\)</span> si et seulement si <span class="math inline">\(i =
k\)</span>.</p></li>
<li><p>(Symétrie) <span class="math inline">\(d_{ik} = d_{ki}\)</span>
pour tout <span class="math inline">\(i, k\)</span>.</p></li>
<li><p>(Inégalité triangulaire) <span class="math inline">\(d_{ik} \leq
d_{ij} + d_{jk}\)</span> pour tout <span class="math inline">\(i, j,
k\)</span>.</p></li>
</ol>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver que la distance de Gower satisfait les propriétés d’une
distance métrique, nous allons examiner chaque propriété une par
une.</p>
<div class="proof">
<p><em>Positivité.</em> Par définition, la dissimilarité <span
class="math inline">\(d_{ik}^{(j)}\)</span> est toujours non négative
pour toute variable <span class="math inline">\(j\)</span>. Par
conséquent, la somme des dissimilarités <span
class="math inline">\(\sum_{j=1}^{p} d_{ik}^{(j)}\)</span> est également
non négative. La division par <span class="math inline">\(\sum_{j=1}^{p}
\delta_{jk}\)</span> (qui est positif) préserve la non-négativité. Donc,
<span class="math inline">\(d_{ik} \geq 0\)</span>. ◻</p>
</div>
<div class="proof">
<p><em>Identité des indiscernables.</em> Si <span
class="math inline">\(i = k\)</span>, alors pour toute variable <span
class="math inline">\(j\)</span>, <span
class="math inline">\(d_{ik}^{(j)} = 0\)</span>. Par conséquent, <span
class="math inline">\(d_{ik} = 0\)</span>.</p>
<p>Réciproquement, si <span class="math inline">\(d_{ik} = 0\)</span>,
alors pour toute variable <span class="math inline">\(j\)</span> prise
en compte (<span class="math inline">\(\delta_{jk} = 1\)</span>), <span
class="math inline">\(d_{ik}^{(j)} = 0\)</span>. Pour une variable
quantitative, cela implique que <span class="math inline">\(x_{ij} =
x_{kj}\)</span>. Pour une variable qualitative, cela implique également
que <span class="math inline">\(x_{ij} = x_{kj}\)</span>. Par
conséquent, <span class="math inline">\(i\)</span> et <span
class="math inline">\(k\)</span> sont identiques. ◻</p>
</div>
<div class="proof">
<p><em>Symétrie.</em> La dissimilarité <span
class="math inline">\(d_{ik}^{(j)}\)</span> est symétrique par
définition, car elle ne dépend que de la différence absolue pour les
variables quantitatives et est définie de manière symétrique pour les
variables qualitatives. Par conséquent, <span
class="math inline">\(d_{ik} = d_{ki}\)</span>. ◻</p>
</div>
<div class="proof">
<p><em>Inégalité triangulaire.</em> Pour prouver l’inégalité
triangulaire, nous devons montrer que <span class="math inline">\(d_{ik}
\leq d_{ij} + d_{jk}\)</span>. Cela découle du fait que chaque
dissimilarité <span class="math inline">\(d_{ik}^{(j)}\)</span>
satisfait l’inégalité triangulaire. Pour les variables quantitatives,
cela est une conséquence de la définition de la distance absolue. Pour
les variables qualitatives, l’inégalité triangulaire est triviale. ◻</p>
</div>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons ici quelques propriétés importantes de la distance de
Gower.</p>
<ol>
<li><p>(Normalisation) La distance de Gower est normalisée par l’étendue
des variables quantitatives, ce qui permet de comparer des variables sur
des échelles différentes.</p></li>
<li><p>(Traitement des valeurs manquantes) La distance de Gower peut
être adaptée pour traiter les valeurs manquantes en ajustant
l’indicateur <span class="math inline">\(\delta_{jk}\)</span>.</p></li>
<li><p>(Extension aux variables ordinales) La distance de Gower peut
être étendue aux variables ordinales en utilisant une dissimilarité
appropriée, par exemple basée sur les rangs.</p></li>
</ol>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La distance de Gower est un outil puissant pour l’analyse des données
multivariées, permettant de mesurer la dissimilarité entre individus
décrits par des variables hétérogènes. Ses propriétés métriques en font
un choix naturel pour les méthodes d’analyse de données, telles que
l’analyse des correspondances multiples ou la classification
hiérarchique.</p>
</body>
</html>
{% include "footer.html" %}

