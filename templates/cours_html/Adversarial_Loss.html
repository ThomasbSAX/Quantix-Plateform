{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Adversarial Loss: A Comprehensive Study</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Adversarial Loss: A Comprehensive Study</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-and-motivations">Introduction and Motivations</h1>
<p>The concept of adversarial loss emerges from the intersection of game
theory, optimization, and machine learning. Historically rooted in the
adversarial settings of zero-sum games, this notion has found a renewed
relevance in modern machine learning paradigms, particularly in
generative models. The adversarial loss function is indispensable in
training generative adversarial networks (GANs), where it facilitates
the duality between a generator and a discriminator. This duality is
crucial for generating data that closely mimics the distribution of
real-world data.</p>
<p>The adversarial loss function addresses the challenge of training
generative models to produce high-quality samples. Traditional methods
often struggle with mode collapse and lack of diversity in generated
samples. The adversarial loss, by its nature, encourages the generator
to produce a wide variety of samples that fool the discriminator,
thereby enhancing the diversity and quality of generated data.</p>
<h1 id="definitions">Definitions</h1>
<p>To understand adversarial loss, we first need to grasp the components
involved. Consider a scenario where we have two players: a generator
<span class="math inline">\(G\)</span> and a discriminator <span
class="math inline">\(D\)</span>. The generator aims to produce data
that is indistinguishable from real data, while the discriminator aims
to distinguish between real and generated data.</p>
<p>We seek a loss function <span
class="math inline">\(\mathcal{L}\)</span> that quantifies the
performance of both players. The generator’s goal is to minimize <span
class="math inline">\(\mathcal{L}\)</span>, while the discriminator’s
goal is to maximize it. This can be formalized as follows:</p>
<div class="definition">
<p>Let <span class="math inline">\(\mathcal{X}\)</span> be the data
space, <span class="math inline">\(p_{\text{data}}(x)\)</span> be the
distribution of real data, and <span
class="math inline">\(p_z(z)\)</span> be the distribution of noise. The
adversarial loss for a generator <span class="math inline">\(G\)</span>
and discriminator <span class="math inline">\(D\)</span> is defined
as:</p>
<p><span class="math display">\[\mathcal{L}(G, D) = \mathbb{E}_{x \sim
p_{\text{data}}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log (1 -
D(G(z)))]\]</span></p>
<p>Alternatively, it can be expressed as:</p>
<p><span class="math display">\[\mathcal{L}(G, D) = \mathbb{E}_{x \sim
p_{\text{data}}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log (1 -
D(G(z)))] = \sup_{D \in \mathcal{D}} \mathbb{E}_{x \sim
p_{\text{data}}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log (1 -
D(G(z)))]\]</span></p>
<p>where <span class="math inline">\(\mathcal{D}\)</span> is the set of
all possible discriminators.</p>
</div>
<h1 id="theorems">Theorems</h1>
<p>One of the fundamental theorems related to adversarial loss is the
minimax theorem, which guarantees the existence of a saddle point for
the adversarial loss function.</p>
<div class="theorem">
<p>For a given generator <span class="math inline">\(G\)</span> and
discriminator <span class="math inline">\(D\)</span>, there exists a
saddle point <span class="math inline">\((G^*, D^*)\)</span> such
that:</p>
<p><span class="math display">\[\mathcal{L}(G^*, D) \leq
\mathcal{L}(G^*, D^*) \leq \mathcal{L}(G, D^*)\]</span></p>
<p>for all <span class="math inline">\(G\)</span> and <span
class="math inline">\(D\)</span>.</p>
</div>
<p>The proof of this theorem relies on the properties of convex-concave
functions and the existence of saddle points in such settings. The
minimax theorem ensures that the adversarial training process converges
to an optimal solution where the generator and discriminator are in
equilibrium.</p>
<h1 id="proofs">Proofs</h1>
<p>To prove the minimax theorem, we need to establish several lemmas and
properties.</p>
<div class="lemma">
<p>For a convex-concave function <span
class="math inline">\(\mathcal{L}(G, D)\)</span>, there exists a saddle
point <span class="math inline">\((G^*, D^*)\)</span> such that:</p>
<p><span class="math display">\[\mathcal{L}(G^*, D) \leq
\mathcal{L}(G^*, D^*) \leq \mathcal{L}(G, D^*)\]</span></p>
<p>for all <span class="math inline">\(G\)</span> and <span
class="math inline">\(D\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> The existence of a saddle point follows from the
properties of convex-concave functions. Specifically, for any convex
function <span class="math inline">\(f\)</span> and concave function
<span class="math inline">\(g\)</span>, the function <span
class="math inline">\(h(x, y) = f(x) - g(y)\)</span> has a saddle point.
This is a consequence of the minimax theorem in game theory, which
guarantees the existence of a saddle point for zero-sum games. ◻</p>
</div>
<p>Using this lemma, we can now prove the minimax theorem.</p>
<div class="proof">
<p><em>Proof of Minimax Theorem.</em> By the lemma, we know that there
exists a saddle point <span class="math inline">\((G^*, D^*)\)</span>
for the adversarial loss function <span
class="math inline">\(\mathcal{L}(G, D)\)</span>. This means that:</p>
<p><span class="math display">\[\mathcal{L}(G^*, D) \leq
\mathcal{L}(G^*, D^*) \leq \mathcal{L}(G, D^*)\]</span></p>
<p>for all <span class="math inline">\(G\)</span> and <span
class="math inline">\(D\)</span>. This completes the proof. ◻</p>
</div>
<h1 id="properties-and-corollaries">Properties and Corollaries</h1>
<p>The adversarial loss function has several important properties and
corollaries that are crucial for understanding its behavior.</p>
<ol>
<li><p><strong>Convergence to Optimal Solution:</strong> The adversarial
loss function ensures that the generator and discriminator converge to
an optimal solution where the generator produces data that is
indistinguishable from real data.</p>
<div class="proof">
<p><em>Proof.</em> This property follows directly from the minimax
theorem, which guarantees the existence of a saddle point. At this
saddle point, the generator and discriminator are in equilibrium,
meaning that the generator produces data that fools the discriminator,
and the discriminator is unable to distinguish between real and
generated data. ◻</p>
</div></li>
<li><p><strong>Stability of Training:</strong> The adversarial loss
function provides a stable training process for generative models, as it
encourages the generator to produce diverse and high-quality
samples.</p>
<div class="proof">
<p><em>Proof.</em> The stability of training is a consequence of the
duality between the generator and discriminator. As the generator
improves, the discriminator becomes more challenging, which in turn
forces the generator to produce better samples. This iterative process
leads to a stable training dynamic. ◻</p>
</div></li>
<li><p><strong>Robustness to Noise:</strong> The adversarial loss
function is robust to noise in the data, as it focuses on the overall
distribution rather than individual samples.</p>
<div class="proof">
<p><em>Proof.</em> The robustness to noise is due to the expectation
over the data distribution in the adversarial loss function. By
considering the expected loss, the model is less sensitive to outliers
and noise in the data. ◻</p>
</div></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>The adversarial loss function is a powerful tool in the training of
generative models, particularly in the context of generative adversarial
networks. Its historical roots in game theory and optimization provide a
solid foundation for understanding its behavior and properties. The
minimax theorem guarantees the existence of an optimal solution, while
the various properties and corollaries ensure stable and robust
training. As research in generative models continues to advance, the
adversarial loss function will remain a crucial component in the
development of high-quality generative models.</p>
</body>
</html>
{% include "footer.html" %}

