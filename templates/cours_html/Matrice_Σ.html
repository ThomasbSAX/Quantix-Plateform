{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>La Matrice \Sigma : Une Exploration Mathématique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">La Matrice <span class="math inline">\(\Sigma\)</span>
: Une Exploration Mathématique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 class="unnumbered" id="introduction-et-motivations">Introduction et
Motivations</h1>
<p>La matrice <span class="math inline">\(\Sigma\)</span> est un objet
mathématique d’une richesse insoupçonnée, émergée des profondeurs de
l’algèbre linéaire et des statistiques. Son importance est telle qu’elle
transcende les frontières disciplinaires, trouvant des applications
aussi bien en théorie des probabilités qu’en traitement du signal ou en
apprentissage automatique. À l’origine, cette matrice est apparue comme
une généralisation de la notion de variance, permettant de capturer les
covariances entre plusieurs variables aléatoires. Son émergence a été
rendue nécessaire par le besoin de modéliser des phénomènes complexes où
les variables ne sont pas indépendantes.</p>
<p>Dans ce chapitre, nous explorerons les multiples facettes de la
matrice <span class="math inline">\(\Sigma\)</span>, en commençant par
ses définitions fondamentales, puis en passant par les théorèmes qui la
caractérisent et enfin en examinant ses propriétés et corollaires.</p>
<h1 class="unnumbered" id="définitions">Définitions</h1>
<p>Pour comprendre la matrice <span
class="math inline">\(\Sigma\)</span>, commençons par nous interroger
sur ce que nous cherchons à capturer. Imaginons un ensemble de variables
aléatoires <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span>.
Nous voulons non seulement connaître la variance de chaque variable
individuellement, mais aussi comment elles varient ensemble. C’est ici
que la matrice <span class="math inline">\(\Sigma\)</span> entre en
jeu.</p>
<div class="definition">
<p>Soit <span class="math inline">\(X = (X_1, X_2, \ldots,
X_n)^T\)</span> un vecteur aléatoire de dimension <span
class="math inline">\(n\)</span>. La matrice de covariance <span
class="math inline">\(\Sigma\)</span> de <span
class="math inline">\(X\)</span> est définie comme : <span
class="math display">\[\Sigma = \mathbb{E}\left[(X - \mathbb{E}[X])(X -
\mathbb{E}[X])^T\right]\]</span> où <span
class="math inline">\(\mathbb{E}[\cdot]\)</span> désigne l’espérance
mathématique.</p>
</div>
<p>Cette définition peut être reformulée de plusieurs manières. En
effet, pour tout <span class="math inline">\(i, j \in \{1, 2, \ldots,
n\}\)</span>, l’élément <span class="math inline">\(\Sigma_{ij}\)</span>
de la matrice <span class="math inline">\(\Sigma\)</span> est donné par
: <span class="math display">\[\Sigma_{ij} = \text{Cov}(X_i, X_j) =
\mathbb{E}\left[(X_i - \mathbb{E}[X_i])(X_j -
\mathbb{E}[X_j])\right]\]</span> où <span
class="math inline">\(\text{Cov}(X_i, X_j)\)</span> désigne la
covariance entre les variables <span class="math inline">\(X_i\)</span>
et <span class="math inline">\(X_j\)</span>.</p>
<h1 class="unnumbered" id="théorèmes">Théorèmes</h1>
<p>Un des théorèmes fondamentaux concernant la matrice <span
class="math inline">\(\Sigma\)</span> est le suivant :</p>
<div class="theorem">
<p>Soit <span class="math inline">\(X\)</span> un vecteur aléatoire de
dimension <span class="math inline">\(n\)</span>. La matrice <span
class="math inline">\(\Sigma\)</span> de covariance de <span
class="math inline">\(X\)</span> vérifie les propriétés suivantes :</p>
<ol>
<li><p><span class="math inline">\(\Sigma\)</span> est symétrique,
c’est-à-dire que pour tout <span class="math inline">\(i, j \in \{1, 2,
\ldots, n\}\)</span>, <span class="math inline">\(\Sigma_{ij} =
\Sigma_{ji}\)</span>.</p></li>
<li><p><span class="math inline">\(\Sigma\)</span> est semi-définie
positive, c’est-à-dire que pour tout vecteur <span
class="math inline">\(a \in \mathbb{R}^n\)</span>, on a <span
class="math inline">\(a^T \Sigma a \geq 0\)</span>.</p></li>
<li><p>La diagonale de <span class="math inline">\(\Sigma\)</span> est
constituée des variances des variables <span
class="math inline">\(X_i\)</span>, c’est-à-dire que pour tout <span
class="math inline">\(i \in \{1, 2, \ldots, n\}\)</span>, <span
class="math inline">\(\Sigma_{ii} = \text{Var}(X_i)\)</span>.</p></li>
</ol>
</div>
<h1 class="unnumbered" id="preuves">Preuves</h1>
<p>Pour prouver la symétrie de <span
class="math inline">\(\Sigma\)</span>, nous avons : <span
class="math display">\[\Sigma_{ij} = \mathbb{E}\left[(X_i -
\mathbb{E}[X_i])(X_j - \mathbb{E}[X_j])\right] = \mathbb{E}\left[(X_j -
\mathbb{E}[X_j])(X_i - \mathbb{E}[X_i])\right] = \Sigma_{ji}\]</span>
Cette égalité montre que <span class="math inline">\(\Sigma\)</span> est
bien symétrique.</p>
<p>Pour prouver la semi-définie positivité de <span
class="math inline">\(\Sigma\)</span>, nous avons pour tout <span
class="math inline">\(a \in \mathbb{R}^n\)</span> : <span
class="math display">\[a^T \Sigma a = \sum_{i,j} a_i a_j \Sigma_{ij} =
\mathbb{E}\left[\left(\sum_{i} a_i (X_i -
\mathbb{E}[X_i])\right)^2\right] \geq 0\]</span> Cette égalité montre
que <span class="math inline">\(\Sigma\)</span> est bien semi-définie
positive.</p>
<h1 class="unnumbered" id="propriétés-et-corollaires">Propriétés et
Corollaires</h1>
<p>Nous listons ci-dessous quelques propriétés importantes de la matrice
<span class="math inline">\(\Sigma\)</span> :</p>
<ol>
<li><p>Si <span class="math inline">\(X\)</span> est un vecteur
aléatoire centré, c’est-à-dire que <span
class="math inline">\(\mathbb{E}[X] = 0\)</span>, alors la matrice de
covariance <span class="math inline">\(\Sigma\)</span> se simplifie en :
<span class="math display">\[\Sigma = \mathbb{E}[XX^T]\]</span></p></li>
<li><p>Si <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span> sont deux vecteurs aléatoires de
dimensions respectives <span class="math inline">\(n\)</span> et <span
class="math inline">\(m\)</span>, et si <span
class="math inline">\(A\)</span> est une matrice <span
class="math inline">\(p \times n\)</span> et <span
class="math inline">\(B\)</span> une matrice <span
class="math inline">\(p \times m\)</span>, alors la matrice de
covariance du vecteur <span class="math inline">\((AX, BY)\)</span> est
donnée par : <span class="math display">\[\Sigma_{AX,BY} = A \Sigma_X
B^T\]</span> où <span class="math inline">\(\Sigma_X\)</span> et <span
class="math inline">\(\Sigma_Y\)</span> sont les matrices de covariance
respectives de <span class="math inline">\(X\)</span> et <span
class="math inline">\(Y\)</span>.</p></li>
<li><p>La matrice <span class="math inline">\(\Sigma\)</span> est
invariante par translation, c’est-à-dire que pour tout vecteur <span
class="math inline">\(c \in \mathbb{R}^n\)</span>, la matrice de
covariance de <span class="math inline">\(X + c\)</span> est égale à
celle de <span class="math inline">\(X\)</span>.</p></li>
</ol>
<p>Pour prouver la propriété (i), nous avons : <span
class="math display">\[\Sigma = \mathbb{E}\left[(X - \mathbb{E}[X])(X -
\mathbb{E}[X])^T\right] = \mathbb{E}[XX^T]\]</span> puisque <span
class="math inline">\(\mathbb{E}[X] = 0\)</span>.</p>
<p>Pour prouver la propriété (ii), nous avons : <span
class="math display">\[\Sigma_{AX,BY} = \mathbb{E}\left[(AX -
\mathbb{E}[AX])(BY - \mathbb{E}[BY])^T\right] = A \mathbb{E}\left[(X -
\mathbb{E}[X])(Y - \mathbb{E}[Y])^T\right] B^T = A \Sigma_X B^T\]</span>
où nous avons utilisé le fait que <span
class="math inline">\(\mathbb{E}[AX] = A \mathbb{E}[X]\)</span> et <span
class="math inline">\(\mathbb{E}[BY] = B \mathbb{E}[Y]\)</span>.</p>
<p>Pour prouver la propriété (iii), nous avons : <span
class="math display">\[\Sigma_{X + c} = \mathbb{E}\left[(X + c -
\mathbb{E}[X + c])(X + c - \mathbb{E}[X + c])^T\right] =
\mathbb{E}\left[(X - \mathbb{E}[X])(X - \mathbb{E}[X])^T\right] =
\Sigma_X\]</span> puisque <span class="math inline">\(c\)</span> est une
constante.</p>
<h1 class="unnumbered" id="conclusion">Conclusion</h1>
<p>La matrice <span class="math inline">\(\Sigma\)</span> est un outil
puissant et polyvalent en mathématiques, avec des applications dans de
nombreux domaines. Nous avons exploré ses définitions, ses théorèmes
fondamentaux et ses propriétés. Cette exploration nous a permis de mieux
comprendre la richesse et la complexité de cet objet mathématique.</p>
</body>
</html>
{% include "footer.html" %}

