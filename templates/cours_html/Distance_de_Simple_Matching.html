{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Distance de Simple Matching : Une Exploration Mathématique et Historique</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distance de Simple Matching : Une Exploration
Mathématique et Historique</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>La distance de Simple Matching émerge comme une notion fondamentale
en analyse des données, particulièrement dans le cadre de la
classification et de la comparaison d’objets. Son origine historique
remonte aux années 1950, avec les travaux pionniers de Robert Sokal et
Peter Sneath sur la taxonomie numérique. Ces chercheurs cherchaient à
quantifier les similitudes entre des espèces biologiques en se basant
sur des caractéristiques binaires.</p>
<p>Cette distance est indispensable dans les domaines où les données
sont représentées par des variables binaires. Par exemple, en génétique,
elle permet de comparer des séquences d’ADN en termes de présence ou
d’absence de certains gènes. En informatique, elle est utilisée pour
évaluer la similarité entre des documents textuels représentés par des
vecteurs de mots binaires.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour définir la distance de Simple Matching, commençons par
comprendre ce que nous cherchons à mesurer. Imaginons deux objets
décrits par un ensemble de caractéristiques binaires. Nous voulons
quantifier à quel point ces deux objets sont similaires en comparant
chacune de leurs caractéristiques.</p>
<p>La distance de Simple Matching est une mesure de dissimilarité entre
deux vecteurs binaires. Elle compte le nombre de positions où les deux
vecteurs diffèrent, que ce soit par des valeurs différentes ou par une
combinaison de 0 et 1.</p>
<p>Formellement, soient <span class="math inline">\(\mathbf{x} = (x_1,
x_2, \ldots, x_n)\)</span> et <span class="math inline">\(\mathbf{y} =
(y_1, y_2, \ldots, y_n)\)</span> deux vecteurs binaires de longueur
<span class="math inline">\(n\)</span>. La distance de Simple Matching
entre <span class="math inline">\(\mathbf{x}\)</span> et <span
class="math inline">\(\mathbf{y}\)</span> est définie comme :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y}) =
\frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i \neq y_i)\]</span></p>
<p>où <span class="math inline">\(\mathbb{I}\)</span> est la fonction
indicatrice qui vaut 1 si la condition est vraie et 0 sinon.</p>
<p>Une autre formulation équivalente est :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y}) =
1 - \frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i = y_i)\]</span></p>
<p>Cette distance peut également être exprimée en termes de produit
scalaire :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y}) =
1 - \frac{\mathbf{x} \cdot \mathbf{y} + (n - \|\mathbf{x}\|_1)(n -
\|\mathbf{y}\|_1)}{n^2}\]</span></p>
<p>où <span class="math inline">\(\mathbf{x} \cdot \mathbf{y}\)</span>
désigne le produit scalaire des vecteurs <span
class="math inline">\(\mathbf{x}\)</span> et <span
class="math inline">\(\mathbf{y}\)</span>, et <span
class="math inline">\(\|\mathbf{x}\|_1\)</span> représente la somme des
éléments de <span class="math inline">\(\mathbf{x}\)</span>.</p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Un théorème fondamental lié à la distance de Simple Matching est le
théorème de l’inégalité triangulaire. Ce théorème stipule que pour toute
distance valide, la somme des distances entre trois points doit
satisfaire une certaine inégalité.</p>
<p>Commençons par comprendre pourquoi l’inégalité triangulaire est
importante. Nous voulons nous assurer que la distance de Simple Matching
respecte les propriétés métriques de base, ce qui est crucial pour son
utilisation dans des algorithmes de classification et de
regroupement.</p>
<p>Formellement, soit <span class="math inline">\(d_{\text{SM}}\)</span>
la distance de Simple Matching. Pour tous vecteurs binaires <span
class="math inline">\(\mathbf{x}, \mathbf{y}, \mathbf{z}\)</span>,
l’inégalité triangulaire s’écrit :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{z})
\leq d_{\text{SM}}(\mathbf{x}, \mathbf{y}) + d_{\text{SM}}(\mathbf{y},
\mathbf{z})\]</span></p>
<p>Preuve : Nous allons démontrer cette inégalité en utilisant les
propriétés de la distance de Simple Matching. Considérons trois vecteurs
binaires <span class="math inline">\(\mathbf{x}, \mathbf{y},
\mathbf{z}\)</span>. Nous avons :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{z}) =
1 - \frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i = z_i)\]</span></p>
<p>De même,</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y}) =
1 - \frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i = y_i)\]</span></p>
<p>et</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{y}, \mathbf{z}) =
1 - \frac{1}{n} \sum_{i=1}^n \mathbb{I}(y_i = z_i)\]</span></p>
<p>Nous devons montrer que :</p>
<p><span class="math display">\[1 - \frac{1}{n} \sum_{i=1}^n
\mathbb{I}(x_i = z_i) \leq 2 - \frac{1}{n} \sum_{i=1}^n (\mathbb{I}(x_i
= y_i) + \mathbb{I}(y_i = z_i))\]</span></p>
<p>En réarrangeant les termes, nous obtenons :</p>
<p><span class="math display">\[\sum_{i=1}^n (\mathbb{I}(x_i = y_i) +
\mathbb{I}(y_i = z_i)) \leq 1 + \sum_{i=1}^n \mathbb{I}(x_i =
z_i)\]</span></p>
<p>Cette inégalité est une conséquence directe de la propriété de
transitivité de l’égalité. En effet, pour chaque indice <span
class="math inline">\(i\)</span>, nous avons :</p>
<p><span class="math display">\[\mathbb{I}(x_i = y_i) + \mathbb{I}(y_i =
z_i) \leq 1 + \mathbb{I}(x_i = z_i)\]</span></p>
<p>En sommant sur tous les indices <span
class="math inline">\(i\)</span>, nous obtenons l’inégalité
souhaitée.</p>
<h1 id="preuves">Preuves</h1>
<p>Pour illustrer la validité de la distance de Simple Matching, nous
allons démontrer qu’elle satisfait les propriétés métriques de base :
non-négativité, identité des indiscernables et symétrie.</p>
<div class="theorem">
<p>Pour tous vecteurs binaires <span class="math inline">\(\mathbf{x},
\mathbf{y}\)</span>, nous avons :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y})
\geq 0\]</span></p>
</div>
<p>Preuve : La fonction indicatrice <span
class="math inline">\(\mathbb{I}(x_i \neq y_i)\)</span> prend des
valeurs dans <span class="math inline">\(\{0, 1\}\)</span>. Par
conséquent, la somme <span class="math inline">\(\sum_{i=1}^n
\mathbb{I}(x_i \neq y_i)\)</span> est un entier non négatif. En divisant
par <span class="math inline">\(n\)</span>, nous obtenons une valeur non
négative.</p>
<div class="theorem">
<p>Pour tout vecteur binaire <span
class="math inline">\(\mathbf{x}\)</span>, nous avons :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{x}) =
0\]</span></p>
</div>
<p>Preuve : Pour chaque indice <span class="math inline">\(i\)</span>,
nous avons <span class="math inline">\(x_i = x_i\)</span>. Par
conséquent, <span class="math inline">\(\mathbb{I}(x_i \neq x_i) =
0\)</span> pour tout <span class="math inline">\(i\)</span>. Ainsi,</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{x}) =
\frac{1}{n} \sum_{i=1}^n 0 = 0\]</span></p>
<div class="theorem">
<p>Pour tous vecteurs binaires <span class="math inline">\(\mathbf{x},
\mathbf{y}\)</span>, nous avons :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y}) =
d_{\text{SM}}(\mathbf{y}, \mathbf{x})\]</span></p>
</div>
<p>Preuve : La fonction indicatrice <span
class="math inline">\(\mathbb{I}(x_i \neq y_i)\)</span> est symétrique
en <span class="math inline">\(x_i\)</span> et <span
class="math inline">\(y_i\)</span>. Par conséquent,</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y}) =
\frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i \neq y_i) = \frac{1}{n}
\sum_{i=1}^n \mathbb{I}(y_i \neq x_i) = d_{\text{SM}}(\mathbf{y},
\mathbf{x})\]</span></p>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous allons maintenant énoncer et démontrer quelques propriétés
importantes de la distance de Simple Matching.</p>
<div class="proposition">
<p>La distance de Simple Matching est bornée par :</p>
<p><span class="math display">\[0 \leq d_{\text{SM}}(\mathbf{x},
\mathbf{y}) \leq 1\]</span></p>
</div>
<p>Preuve : La non-négativité a déjà été démontrée. Pour la borne
supérieure, notons que <span class="math inline">\(\mathbb{I}(x_i \neq
y_i) \leq 1\)</span> pour tout <span class="math inline">\(i\)</span>.
Par conséquent,</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x}, \mathbf{y}) =
\frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i \neq y_i) \leq \frac{1}{n}
\sum_{i=1}^n 1 = 1\]</span></p>
<div class="proposition">
<p>La distance de Simple Matching est invariante par translation
binaire. C’est-à-dire, pour tout vecteur binaire <span
class="math inline">\(\mathbf{a} = (a_1, a_2, \ldots, a_n)\)</span>,
nous avons :</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x} + \mathbf{a},
\mathbf{y} + \mathbf{a}) = d_{\text{SM}}(\mathbf{x},
\mathbf{y})\]</span></p>
<p>où l’addition est effectuée modulo 2.</p>
</div>
<p>Preuve : Pour chaque indice <span class="math inline">\(i\)</span>,
nous avons :</p>
<p><span class="math display">\[\mathbb{I}((x_i + a_i) \neq (y_i + a_i))
= \mathbb{I}(x_i \neq y_i)\]</span></p>
<p>Par conséquent,</p>
<p><span class="math display">\[d_{\text{SM}}(\mathbf{x} + \mathbf{a},
\mathbf{y} + \mathbf{a}) = \frac{1}{n} \sum_{i=1}^n \mathbb{I}((x_i +
a_i) \neq (y_i + a_i)) = \frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i \neq
y_i) = d_{\text{SM}}(\mathbf{x}, \mathbf{y})\]</span></p>
<div class="proposition">
<p>La distance de Simple Matching est invariante par permutation des
coordonnées. C’est-à-dire, pour toute permutation <span
class="math inline">\(\sigma\)</span> de <span
class="math inline">\(\{1, 2, \ldots, n\}\)</span>, nous avons :</p>
<p><span class="math display">\[d_{\text{SM}}(\sigma(\mathbf{x}),
\sigma(\mathbf{y})) = d_{\text{SM}}(\mathbf{x}, \mathbf{y})\]</span></p>
<p>où <span class="math inline">\(\sigma(\mathbf{x}) = (x_{\sigma(1)},
x_{\sigma(2)}, \ldots, x_{\sigma(n)})\)</span>.</p>
</div>
<p>Preuve : Pour chaque indice <span class="math inline">\(i\)</span>,
nous avons :</p>
<p><span class="math display">\[\mathbb{I}(x_{\sigma(i)} \neq
y_{\sigma(i)}) = \mathbb{I}(x_i \neq y_i)\]</span></p>
<p>Par conséquent,</p>
<p><span class="math display">\[d_{\text{SM}}(\sigma(\mathbf{x}),
\sigma(\mathbf{y})) = \frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_{\sigma(i)}
\neq y_{\sigma(i)}) = \frac{1}{n} \sum_{i=1}^n \mathbb{I}(x_i \neq y_i)
= d_{\text{SM}}(\mathbf{x}, \mathbf{y})\]</span></p>
<h1 id="conclusion">Conclusion</h1>
<p>La distance de Simple Matching est une mesure puissante et élégante
pour comparer des objets décrits par des caractéristiques binaires. Son
utilisation dans divers domaines, allant de la génétique à
l’informatique, témoigne de sa polyvalence et de son utilité. Les
propriétés mathématiques que nous avons explorées montrent qu’elle
respecte les principes fondamentaux des distances métriques, ce qui en
fait un outil fiable pour l’analyse des données.</p>
</body>
</html>
{% include "footer.html" %}

