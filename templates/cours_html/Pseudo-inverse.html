{% include "header.html" %}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- CSS du site -->
  <link rel="stylesheet" href="{{ url_for('static', filename='css/base.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/layout.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/footer.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/components.css') }}">

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Quantix" />
  <meta name="dcterms.date" content="2026-01-11" />
  <title>Pseudo-inverse : Une généralisation de l’inverse matricielle</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/cours.css') }}">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Pseudo-inverse : Une généralisation de l’inverse
matricielle</h1>
<p class="author">Quantix</p>
<p class="date">2026-01-11</p>
</header>
<h1 id="introduction-et-motivations">Introduction et Motivations</h1>
<p>L’étude des matrices et de leurs inverses est un pilier fondamental
en algèbre linéaire. Cependant, certaines matrices ne possèdent pas
d’inverse classique, notamment les matrices non carrées ou celles dont
le déterminant est nul. Pour pallier cette limitation, la notion de
pseudo-inverse a été introduite. Cette généralisation permet d’étendre
les concepts d’inverse à des matrices non carrées ou singulières,
ouvrant ainsi de nouvelles perspectives en analyse numérique et en
traitement du signal.</p>
<p>L’origine historique de la pseudo-inverse remonte aux travaux de
Moore en 1920 et Penrose en 1955, qui ont formalisé cette notion. La
pseudo-inverse est indispensable dans de nombreux domaines, tels que la
résolution de systèmes linéaires surdéterminés ou sous-déterminés,
l’optimisation, et la théorie des graphes.</p>
<h1 id="définitions">Définitions</h1>
<p>Pour introduire la notion de pseudo-inverse, commençons par rappeler
ce que nous cherchons à obtenir. Supposons que nous ayons une matrice
<span class="math inline">\(A\)</span> de taille <span
class="math inline">\(m \times n\)</span>. Nous souhaitons trouver une
matrice <span class="math inline">\(X\)</span> telle que <span
class="math inline">\(AXA = A\)</span>, ce qui généraliserait l’idée
d’une inverse. De plus, nous voulons que <span class="math inline">\(XAX
= X\)</span> et que les produits <span class="math inline">\(AX\)</span>
et <span class="math inline">\(XA\)</span> soient symétriques.</p>
<p>La pseudo-inverse de Moore-Penrose, notée <span
class="math inline">\(A^+\)</span>, est définie comme la matrice qui
satisfait les quatre conditions suivantes, appelées équations de
Moore-Penrose :</p>
<div class="definition">
<p>Soit <span class="math inline">\(A\)</span> une matrice réelle ou
complexe de taille <span class="math inline">\(m \times n\)</span>. La
pseudo-inverse <span class="math inline">\(A^+\)</span> de <span
class="math inline">\(A\)</span> est la matrice unique qui satisfait les
quatre conditions suivantes :</p>
<ol>
<li><p><span class="math inline">\(A A^+ A = A\)</span></p></li>
<li><p><span class="math inline">\(A^+ A A^+ = A^+\)</span></p></li>
<li><p><span class="math inline">\((A A^+)^\top = A
A^+\)</span></p></li>
<li><p><span class="math inline">\((A^+ A)^\top = A^+
A\)</span></p></li>
</ol>
</div>
<p>Ces conditions peuvent être réinterprétées de manière équivalente en
utilisant des quantificateurs. Par exemple, la première condition peut
s’écrire : <span class="math display">\[\forall X \in \mathbb{R}^{n
\times m}, (A A^+ A = A) \Rightarrow (X = A^+)\]</span></p>
<h1 id="théorèmes">Théorèmes</h1>
<p>Pour mieux comprendre les propriétés de la pseudo-inverse, nous
allons maintenant énoncer quelques théorèmes importants.</p>
<div class="theorem">
<p>Pour toute matrice <span class="math inline">\(A\)</span> de taille
<span class="math inline">\(m \times n\)</span>, il existe une unique
matrice <span class="math inline">\(A^+\)</span> qui satisfait les
quatre conditions de Moore-Penrose.</p>
</div>
<div class="proof">
<p><em>Proof.</em> L’existence et l’unicité de la pseudo-inverse peuvent
être démontrées en utilisant la décomposition en valeurs singulières
(SVD) de <span class="math inline">\(A\)</span>. Soit <span
class="math inline">\(A = U \Sigma V^\top\)</span>, où <span
class="math inline">\(U\)</span> et <span
class="math inline">\(V\)</span> sont des matrices orthogonales, et
<span class="math inline">\(\Sigma\)</span> est une matrice diagonale
avec les valeurs singulières de <span class="math inline">\(A\)</span>.
La pseudo-inverse peut alors être définie comme : <span
class="math display">\[A^+ = V \Sigma^+ U^\top\]</span> où <span
class="math inline">\(\Sigma^+\)</span> est obtenue en inversant les
valeurs singulières non nulles de <span
class="math inline">\(\Sigma\)</span>.</p>
<p>Pour montrer que cette définition satisfait les quatre conditions de
Moore-Penrose, nous devons vérifier chaque condition séparément. Par
exemple, pour la première condition <span class="math inline">\(A A^+ A
= A\)</span>, nous avons : <span class="math display">\[A A^+ A = U
\Sigma V^\top V \Sigma^+ U^\top U \Sigma V^\top = U \Sigma \Sigma^+
\Sigma V^\top\]</span> En utilisant la propriété de l’inverse des
valeurs singulières, nous obtenons : <span class="math display">\[\Sigma
\Sigma^+ \Sigma = \Sigma\]</span> Ainsi, <span class="math display">\[A
A^+ A = U \Sigma V^\top = A\]</span> Ce qui prouve la première
condition. Les autres conditions peuvent être vérifiées de manière
similaire. ◻</p>
</div>
<h1 id="preuves">Preuves</h1>
<p>Nous allons maintenant détailler les preuves des propriétés de la
pseudo-inverse.</p>
<div class="theorem">
<p>La pseudo-inverse <span class="math inline">\(A^+\)</span> minimise
la norme de Frobenius de <span class="math inline">\(X\)</span> sous la
contrainte <span class="math inline">\(AXA = A\)</span>. C’est-à-dire :
<span class="math display">\[A^+ = \argmin_{X : AXA = A} \| X
\|_F\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Pour démontrer cette propriété, nous utilisons la
décomposition en valeurs singulières de <span
class="math inline">\(A\)</span>. Soit <span class="math inline">\(A = U
\Sigma V^\top\)</span>, où <span class="math inline">\(U\)</span> et
<span class="math inline">\(V\)</span> sont des matrices orthogonales,
et <span class="math inline">\(\Sigma\)</span> est une matrice diagonale
avec les valeurs singulières de <span class="math inline">\(A\)</span>.
La pseudo-inverse peut alors être définie comme : <span
class="math display">\[A^+ = V \Sigma^+ U^\top\]</span> où <span
class="math inline">\(\Sigma^+\)</span> est obtenue en inversant les
valeurs singulières non nulles de <span
class="math inline">\(\Sigma\)</span>.</p>
<p>Nous devons montrer que pour toute matrice <span
class="math inline">\(X\)</span> telle que <span
class="math inline">\(AXA = A\)</span>, nous avons : <span
class="math display">\[\| A^+ \|_F \leq \| X \|_F\]</span></p>
<p>En utilisant la décomposition en valeurs singulières, nous pouvons
écrire <span class="math inline">\(X\)</span> sous la forme : <span
class="math display">\[X = V Y U^\top\]</span> où <span
class="math inline">\(Y\)</span> est une matrice appropriée. La
contrainte <span class="math inline">\(AXA = A\)</span> se traduit alors
par : <span class="math display">\[U \Sigma V^\top V Y U^\top U \Sigma
V^\top = U \Sigma V^\top\]</span> Ce qui simplifie à : <span
class="math display">\[\Sigma Y \Sigma = \Sigma\]</span></p>
<p>Pour minimiser <span class="math inline">\(\| X \|_F\)</span>, nous
devons minimiser <span class="math inline">\(\| Y \|_F\)</span> sous la
contrainte <span class="math inline">\(\Sigma Y \Sigma =
\Sigma\)</span>. En utilisant le fait que les valeurs singulières de
<span class="math inline">\(X\)</span> sont les mêmes que celles de
<span class="math inline">\(Y\)</span>, nous pouvons montrer que la
solution optimale est obtenue lorsque <span class="math inline">\(Y =
\Sigma^+\)</span>.</p>
<p>Ainsi, nous avons : <span class="math display">\[\| A^+ \|_F = \| V
\Sigma^+ U^\top \|_F = \| \Sigma^+ \|_F\]</span> et pour toute matrice
<span class="math inline">\(X\)</span> satisfaisant la contrainte, nous
avons : <span class="math display">\[\| X \|_F = \| V Y U^\top \|_F = \|
Y \|_F \geq \| \Sigma^+ \|_F\]</span> Ce qui prouve que <span
class="math inline">\(A^+\)</span> minimise la norme de Frobenius de
<span class="math inline">\(X\)</span> sous la contrainte <span
class="math inline">\(AXA = A\)</span>. ◻</p>
</div>
<h1 id="propriétés-et-corollaires">Propriétés et Corollaires</h1>
<p>Nous allons maintenant énoncer quelques propriétés importantes de la
pseudo-inverse.</p>
<div class="corollaire">
<p>La matrice <span class="math inline">\(A A^+\)</span> est symétrique,
c’est-à-dire : <span class="math display">\[(A A^+)^\top = A
A^+\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> En utilisant la décomposition en valeurs singulières
de <span class="math inline">\(A\)</span>, nous avons : <span
class="math display">\[A = U \Sigma V^\top\]</span> et <span
class="math display">\[A^+ = V \Sigma^+ U^\top\]</span></p>
<p>Ainsi, <span class="math display">\[A A^+ = U \Sigma V^\top V
\Sigma^+ U^\top = U \Sigma \Sigma^+ U^\top\]</span> En utilisant la
propriété de l’inverse des valeurs singulières, nous obtenons : <span
class="math display">\[\Sigma \Sigma^+ = I\]</span> où <span
class="math inline">\(I\)</span> est la matrice identité. Donc, <span
class="math display">\[A A^+ = U I U^\top = U U^\top\]</span> Puisque
<span class="math inline">\(U\)</span> est une matrice orthogonale, nous
avons : <span class="math display">\[(A A^+)^\top = (U U^\top)^\top = U
U^\top = A A^+\]</span> Ce qui prouve la symétrie de <span
class="math inline">\(A A^+\)</span>. ◻</p>
</div>
<div class="corollaire">
<p>Si <span class="math inline">\(A\)</span> est une matrice carrée et
inversible, alors la pseudo-inverse de <span
class="math inline">\(A\)</span> coïncide avec son inverse classique :
<span class="math display">\[A^+ = A^{-1}\]</span></p>
</div>
<div class="proof">
<p><em>Proof.</em> Si <span class="math inline">\(A\)</span> est
inversible, alors les quatre conditions de Moore-Penrose sont
satisfaites par <span class="math inline">\(A^{-1}\)</span>. En effet,
nous avons :</p>
<ol>
<li><p><span class="math inline">\(A A^{-1} A = A\)</span></p></li>
<li><p><span class="math inline">\(A^{-1} A A^{-1} =
A^{-1}\)</span></p></li>
<li><p><span class="math inline">\((A A^{-1})^\top = I = A
A^{-1}\)</span></p></li>
<li><p><span class="math inline">\((A^{-1} A)^\top = I = A^{-1}
A\)</span></p></li>
</ol>
<p>Ainsi, par unicité de la pseudo-inverse, nous avons : <span
class="math display">\[A^+ = A^{-1}\]</span> ◻</p>
</div>
<h1 id="conclusion">Conclusion</h1>
<p>La pseudo-inverse de Moore-Penrose est un outil puissant et
généralisé qui permet d’étendre les concepts d’inverse matricielle à des
matrices non carrées ou singulières. Ses propriétés et ses applications
sont vastes, allant de la résolution de systèmes linéaires à
l’optimisation. La compréhension approfondie de cette notion est
essentielle pour tout chercheur en algèbre linéaire et en analyse
numérique.</p>
</body>
</html>
{% include "footer.html" %}

